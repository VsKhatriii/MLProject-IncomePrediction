2024-01-01 23:21:04,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:21:04,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:21:04,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:21:04,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:21:11,149:INFO:PyCaret ClassificationExperiment
2024-01-01 23:21:11,149:INFO:Logging name: clf-default-name
2024-01-01 23:21:11,150:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:21:11,150:INFO:version 3.1.0
2024-01-01 23:21:11,151:INFO:Initializing setup()
2024-01-01 23:21:11,151:INFO:self.USI: 7c86
2024-01-01 23:21:11,151:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:21:11,151:INFO:Checking environment
2024-01-01 23:21:11,151:INFO:python_version: 3.10.9
2024-01-01 23:21:11,151:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:21:11,151:INFO:machine: AMD64
2024-01-01 23:21:11,151:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:21:11,151:INFO:Memory: svmem(total=16954372096, available=4450816000, percent=73.7, used=12503556096, free=4450816000)
2024-01-01 23:21:11,151:INFO:Physical Core: 8
2024-01-01 23:21:11,151:INFO:Logical Core: 16
2024-01-01 23:21:11,151:INFO:Checking libraries
2024-01-01 23:21:11,151:INFO:System:
2024-01-01 23:21:11,152:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:21:11,152:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:21:11,152:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:21:11,152:INFO:PyCaret required dependencies:
2024-01-01 23:21:11,871:INFO:                 pip: 22.3.1
2024-01-01 23:21:11,871:INFO:          setuptools: 65.6.3
2024-01-01 23:21:11,871:INFO:             pycaret: 3.1.0
2024-01-01 23:21:11,871:INFO:             IPython: 8.10.0
2024-01-01 23:21:11,871:INFO:          ipywidgets: 7.6.5
2024-01-01 23:21:11,871:INFO:                tqdm: 4.64.1
2024-01-01 23:21:11,871:INFO:               numpy: 1.23.5
2024-01-01 23:21:11,871:INFO:              pandas: 1.5.3
2024-01-01 23:21:11,871:INFO:              jinja2: 3.1.2
2024-01-01 23:21:11,871:INFO:               scipy: 1.10.1
2024-01-01 23:21:11,871:INFO:              joblib: 1.3.2
2024-01-01 23:21:11,871:INFO:             sklearn: 1.2.1
2024-01-01 23:21:11,871:INFO:                pyod: 1.1.0
2024-01-01 23:21:11,871:INFO:            imblearn: 0.10.1
2024-01-01 23:21:11,871:INFO:   category_encoders: 2.6.2
2024-01-01 23:21:11,871:INFO:            lightgbm: 4.1.0
2024-01-01 23:21:11,872:INFO:               numba: 0.56.4
2024-01-01 23:21:11,872:INFO:            requests: 2.28.1
2024-01-01 23:21:11,872:INFO:          matplotlib: 3.7.0
2024-01-01 23:21:11,872:INFO:          scikitplot: 0.3.7
2024-01-01 23:21:11,872:INFO:         yellowbrick: 1.5
2024-01-01 23:21:11,872:INFO:              plotly: 5.9.0
2024-01-01 23:21:11,872:INFO:    plotly-resampler: Not installed
2024-01-01 23:21:11,872:INFO:             kaleido: 0.2.1
2024-01-01 23:21:11,872:INFO:           schemdraw: 0.15
2024-01-01 23:21:11,872:INFO:         statsmodels: 0.13.5
2024-01-01 23:21:11,872:INFO:              sktime: 0.21.1
2024-01-01 23:21:11,872:INFO:               tbats: 1.1.3
2024-01-01 23:21:11,872:INFO:            pmdarima: 2.0.3
2024-01-01 23:21:11,872:INFO:              psutil: 5.9.0
2024-01-01 23:21:11,872:INFO:          markupsafe: 2.1.1
2024-01-01 23:21:11,872:INFO:             pickle5: Not installed
2024-01-01 23:21:11,872:INFO:         cloudpickle: 2.0.0
2024-01-01 23:21:11,872:INFO:         deprecation: 2.1.0
2024-01-01 23:21:11,872:INFO:              xxhash: 3.4.1
2024-01-01 23:21:11,872:INFO:           wurlitzer: Not installed
2024-01-01 23:21:11,872:INFO:PyCaret optional dependencies:
2024-01-01 23:21:11,887:INFO:                shap: Not installed
2024-01-01 23:21:11,887:INFO:           interpret: Not installed
2024-01-01 23:21:11,887:INFO:                umap: Not installed
2024-01-01 23:21:11,887:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:21:11,887:INFO:  explainerdashboard: Not installed
2024-01-01 23:21:11,887:INFO:             autoviz: Not installed
2024-01-01 23:21:11,887:INFO:           fairlearn: Not installed
2024-01-01 23:21:11,887:INFO:          deepchecks: Not installed
2024-01-01 23:21:11,887:INFO:             xgboost: Not installed
2024-01-01 23:21:11,887:INFO:            catboost: Not installed
2024-01-01 23:21:11,888:INFO:              kmodes: Not installed
2024-01-01 23:21:11,888:INFO:             mlxtend: Not installed
2024-01-01 23:21:11,888:INFO:       statsforecast: Not installed
2024-01-01 23:21:11,888:INFO:        tune_sklearn: Not installed
2024-01-01 23:21:11,888:INFO:                 ray: Not installed
2024-01-01 23:21:11,888:INFO:            hyperopt: Not installed
2024-01-01 23:21:11,888:INFO:              optuna: Not installed
2024-01-01 23:21:11,888:INFO:               skopt: Not installed
2024-01-01 23:21:11,888:INFO:              mlflow: Not installed
2024-01-01 23:21:11,888:INFO:              gradio: Not installed
2024-01-01 23:21:11,888:INFO:             fastapi: Not installed
2024-01-01 23:21:11,888:INFO:             uvicorn: Not installed
2024-01-01 23:21:11,888:INFO:              m2cgen: Not installed
2024-01-01 23:21:11,888:INFO:           evidently: Not installed
2024-01-01 23:21:11,888:INFO:               fugue: Not installed
2024-01-01 23:21:11,888:INFO:           streamlit: Not installed
2024-01-01 23:21:11,888:INFO:             prophet: Not installed
2024-01-01 23:21:11,888:INFO:None
2024-01-01 23:21:11,888:INFO:Set up data.
2024-01-01 23:21:31,711:INFO:PyCaret ClassificationExperiment
2024-01-01 23:21:31,711:INFO:Logging name: clf-default-name
2024-01-01 23:21:31,712:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:21:31,712:INFO:version 3.1.0
2024-01-01 23:21:31,712:INFO:Initializing setup()
2024-01-01 23:21:31,712:INFO:self.USI: 6ae9
2024-01-01 23:21:31,712:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:21:31,712:INFO:Checking environment
2024-01-01 23:21:31,712:INFO:python_version: 3.10.9
2024-01-01 23:21:31,712:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:21:31,712:INFO:machine: AMD64
2024-01-01 23:21:31,712:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:21:31,712:INFO:Memory: svmem(total=16954372096, available=4442284032, percent=73.8, used=12512088064, free=4442284032)
2024-01-01 23:21:31,712:INFO:Physical Core: 8
2024-01-01 23:21:31,712:INFO:Logical Core: 16
2024-01-01 23:21:31,712:INFO:Checking libraries
2024-01-01 23:21:31,713:INFO:System:
2024-01-01 23:21:31,713:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:21:31,713:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:21:31,713:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:21:31,713:INFO:PyCaret required dependencies:
2024-01-01 23:21:31,713:INFO:                 pip: 22.3.1
2024-01-01 23:21:31,713:INFO:          setuptools: 65.6.3
2024-01-01 23:21:31,713:INFO:             pycaret: 3.1.0
2024-01-01 23:21:31,713:INFO:             IPython: 8.10.0
2024-01-01 23:21:31,713:INFO:          ipywidgets: 7.6.5
2024-01-01 23:21:31,713:INFO:                tqdm: 4.64.1
2024-01-01 23:21:31,713:INFO:               numpy: 1.23.5
2024-01-01 23:21:31,713:INFO:              pandas: 1.5.3
2024-01-01 23:21:31,713:INFO:              jinja2: 3.1.2
2024-01-01 23:21:31,713:INFO:               scipy: 1.10.1
2024-01-01 23:21:31,713:INFO:              joblib: 1.3.2
2024-01-01 23:21:31,713:INFO:             sklearn: 1.2.1
2024-01-01 23:21:31,713:INFO:                pyod: 1.1.0
2024-01-01 23:21:31,713:INFO:            imblearn: 0.10.1
2024-01-01 23:21:31,713:INFO:   category_encoders: 2.6.2
2024-01-01 23:21:31,713:INFO:            lightgbm: 4.1.0
2024-01-01 23:21:31,713:INFO:               numba: 0.56.4
2024-01-01 23:21:31,713:INFO:            requests: 2.28.1
2024-01-01 23:21:31,713:INFO:          matplotlib: 3.7.0
2024-01-01 23:21:31,713:INFO:          scikitplot: 0.3.7
2024-01-01 23:21:31,713:INFO:         yellowbrick: 1.5
2024-01-01 23:21:31,714:INFO:              plotly: 5.9.0
2024-01-01 23:21:31,714:INFO:    plotly-resampler: Not installed
2024-01-01 23:21:31,714:INFO:             kaleido: 0.2.1
2024-01-01 23:21:31,714:INFO:           schemdraw: 0.15
2024-01-01 23:21:31,714:INFO:         statsmodels: 0.13.5
2024-01-01 23:21:31,714:INFO:              sktime: 0.21.1
2024-01-01 23:21:31,714:INFO:               tbats: 1.1.3
2024-01-01 23:21:31,714:INFO:            pmdarima: 2.0.3
2024-01-01 23:21:31,714:INFO:              psutil: 5.9.0
2024-01-01 23:21:31,714:INFO:          markupsafe: 2.1.1
2024-01-01 23:21:31,714:INFO:             pickle5: Not installed
2024-01-01 23:21:31,714:INFO:         cloudpickle: 2.0.0
2024-01-01 23:21:31,714:INFO:         deprecation: 2.1.0
2024-01-01 23:21:31,714:INFO:              xxhash: 3.4.1
2024-01-01 23:21:31,714:INFO:           wurlitzer: Not installed
2024-01-01 23:21:31,714:INFO:PyCaret optional dependencies:
2024-01-01 23:21:31,714:INFO:                shap: Not installed
2024-01-01 23:21:31,714:INFO:           interpret: Not installed
2024-01-01 23:21:31,714:INFO:                umap: Not installed
2024-01-01 23:21:31,714:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:21:31,715:INFO:  explainerdashboard: Not installed
2024-01-01 23:21:31,715:INFO:             autoviz: Not installed
2024-01-01 23:21:31,715:INFO:           fairlearn: Not installed
2024-01-01 23:21:31,715:INFO:          deepchecks: Not installed
2024-01-01 23:21:31,715:INFO:             xgboost: Not installed
2024-01-01 23:21:31,715:INFO:            catboost: Not installed
2024-01-01 23:21:31,715:INFO:              kmodes: Not installed
2024-01-01 23:21:31,715:INFO:             mlxtend: Not installed
2024-01-01 23:21:31,715:INFO:       statsforecast: Not installed
2024-01-01 23:21:31,715:INFO:        tune_sklearn: Not installed
2024-01-01 23:21:31,715:INFO:                 ray: Not installed
2024-01-01 23:21:31,715:INFO:            hyperopt: Not installed
2024-01-01 23:21:31,716:INFO:              optuna: Not installed
2024-01-01 23:21:31,716:INFO:               skopt: Not installed
2024-01-01 23:21:31,716:INFO:              mlflow: Not installed
2024-01-01 23:21:31,716:INFO:              gradio: Not installed
2024-01-01 23:21:31,716:INFO:             fastapi: Not installed
2024-01-01 23:21:31,716:INFO:             uvicorn: Not installed
2024-01-01 23:21:31,716:INFO:              m2cgen: Not installed
2024-01-01 23:21:31,716:INFO:           evidently: Not installed
2024-01-01 23:21:31,716:INFO:               fugue: Not installed
2024-01-01 23:21:31,716:INFO:           streamlit: Not installed
2024-01-01 23:21:31,716:INFO:             prophet: Not installed
2024-01-01 23:21:31,716:INFO:None
2024-01-01 23:21:31,716:INFO:Set up data.
2024-01-01 23:21:31,733:INFO:Set up folding strategy.
2024-01-01 23:21:31,734:INFO:Set up train/test split.
2024-01-01 23:21:31,746:INFO:Set up index.
2024-01-01 23:21:31,747:INFO:Assigning column types.
2024-01-01 23:21:31,752:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:21:31,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:21:31,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:21:31,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:31,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:31,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:21:31,864:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:21:31,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:31,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:31,889:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:21:31,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:21:31,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:31,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:31,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:21:32,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,012:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:21:32,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,138:INFO:Preparing preprocessing pipeline...
2024-01-01 23:21:32,140:INFO:Set up simple imputation.
2024-01-01 23:21:32,141:INFO:Set up column name cleaning.
2024-01-01 23:21:32,168:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:21:32,175:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Profession Class',
                                             'Education-num', 'marital-status',
                                             'occupation', 'race', 'Gender',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'country'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fil...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:21:32,175:INFO:Creating final display dataframe.
2024-01-01 23:21:32,258:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 12)
4        Transformed data shape       (31978, 12)
5   Transformed train set shape       (25582, 12)
6    Transformed test set shape        (6396, 12)
7              Numeric features                11
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6ae9
2024-01-01 23:21:32,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,393:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:21:32,393:INFO:setup() successfully completed in 0.68s...............
2024-01-01 23:21:49,247:INFO:Initializing compare_models()
2024-01-01 23:21:49,248:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:21:49,248:INFO:Checking exceptions
2024-01-01 23:21:49,254:INFO:Preparing display monitor
2024-01-01 23:21:49,278:INFO:Initializing Logistic Regression
2024-01-01 23:21:49,279:INFO:Total runtime is 1.6597906748453774e-05 minutes
2024-01-01 23:21:49,282:INFO:SubProcess create_model() called ==================================
2024-01-01 23:21:49,282:INFO:Initializing create_model()
2024-01-01 23:21:49,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:21:49,282:INFO:Checking exceptions
2024-01-01 23:21:49,282:INFO:Importing libraries
2024-01-01 23:21:49,282:INFO:Copying training dataset
2024-01-01 23:21:49,291:INFO:Defining folds
2024-01-01 23:21:49,291:INFO:Declaring metric variables
2024-01-01 23:21:49,294:INFO:Importing untrained model
2024-01-01 23:21:49,298:INFO:Logistic Regression Imported successfully
2024-01-01 23:21:49,305:INFO:Starting cross validation
2024-01-01 23:21:49,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:00,206:INFO:Calculating mean and std
2024-01-01 23:22:00,207:INFO:Creating metrics dataframe
2024-01-01 23:22:00,212:INFO:Uploading results into container
2024-01-01 23:22:00,212:INFO:Uploading model into container now
2024-01-01 23:22:00,213:INFO:_master_model_container: 1
2024-01-01 23:22:00,213:INFO:_display_container: 2
2024-01-01 23:22:00,214:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:22:00,214:INFO:create_model() successfully completed......................................
2024-01-01 23:22:00,446:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:00,446:INFO:Creating metrics dataframe
2024-01-01 23:22:00,454:INFO:Initializing K Neighbors Classifier
2024-01-01 23:22:00,454:INFO:Total runtime is 0.18626213471094769 minutes
2024-01-01 23:22:00,457:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:00,457:INFO:Initializing create_model()
2024-01-01 23:22:00,457:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:00,457:INFO:Checking exceptions
2024-01-01 23:22:00,457:INFO:Importing libraries
2024-01-01 23:22:00,458:INFO:Copying training dataset
2024-01-01 23:22:00,466:INFO:Defining folds
2024-01-01 23:22:00,466:INFO:Declaring metric variables
2024-01-01 23:22:00,470:INFO:Importing untrained model
2024-01-01 23:22:00,474:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:22:00,480:INFO:Starting cross validation
2024-01-01 23:22:00,481:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:06,412:INFO:Calculating mean and std
2024-01-01 23:22:06,413:INFO:Creating metrics dataframe
2024-01-01 23:22:06,418:INFO:Uploading results into container
2024-01-01 23:22:06,419:INFO:Uploading model into container now
2024-01-01 23:22:06,419:INFO:_master_model_container: 2
2024-01-01 23:22:06,419:INFO:_display_container: 2
2024-01-01 23:22:06,420:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:22:06,420:INFO:create_model() successfully completed......................................
2024-01-01 23:22:06,651:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:06,651:INFO:Creating metrics dataframe
2024-01-01 23:22:06,662:INFO:Initializing Naive Bayes
2024-01-01 23:22:06,662:INFO:Total runtime is 0.2897254308064779 minutes
2024-01-01 23:22:06,666:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:06,666:INFO:Initializing create_model()
2024-01-01 23:22:06,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:06,666:INFO:Checking exceptions
2024-01-01 23:22:06,666:INFO:Importing libraries
2024-01-01 23:22:06,666:INFO:Copying training dataset
2024-01-01 23:22:06,676:INFO:Defining folds
2024-01-01 23:22:06,677:INFO:Declaring metric variables
2024-01-01 23:22:06,681:INFO:Importing untrained model
2024-01-01 23:22:06,685:INFO:Naive Bayes Imported successfully
2024-01-01 23:22:06,694:INFO:Starting cross validation
2024-01-01 23:22:06,695:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:06,943:INFO:Calculating mean and std
2024-01-01 23:22:06,947:INFO:Creating metrics dataframe
2024-01-01 23:22:06,955:INFO:Uploading results into container
2024-01-01 23:22:06,956:INFO:Uploading model into container now
2024-01-01 23:22:06,957:INFO:_master_model_container: 3
2024-01-01 23:22:06,957:INFO:_display_container: 2
2024-01-01 23:22:06,958:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:22:06,958:INFO:create_model() successfully completed......................................
2024-01-01 23:22:07,153:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:07,153:INFO:Creating metrics dataframe
2024-01-01 23:22:07,163:INFO:Initializing Decision Tree Classifier
2024-01-01 23:22:07,163:INFO:Total runtime is 0.29807128508885705 minutes
2024-01-01 23:22:07,166:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:07,166:INFO:Initializing create_model()
2024-01-01 23:22:07,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:07,166:INFO:Checking exceptions
2024-01-01 23:22:07,166:INFO:Importing libraries
2024-01-01 23:22:07,167:INFO:Copying training dataset
2024-01-01 23:22:07,175:INFO:Defining folds
2024-01-01 23:22:07,175:INFO:Declaring metric variables
2024-01-01 23:22:07,178:INFO:Importing untrained model
2024-01-01 23:22:07,182:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:22:07,188:INFO:Starting cross validation
2024-01-01 23:22:07,189:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:07,413:INFO:Calculating mean and std
2024-01-01 23:22:07,465:INFO:Creating metrics dataframe
2024-01-01 23:22:07,468:INFO:Uploading results into container
2024-01-01 23:22:07,468:INFO:Uploading model into container now
2024-01-01 23:22:07,469:INFO:_master_model_container: 4
2024-01-01 23:22:07,469:INFO:_display_container: 2
2024-01-01 23:22:07,469:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:22:07,470:INFO:create_model() successfully completed......................................
2024-01-01 23:22:07,700:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:07,700:INFO:Creating metrics dataframe
2024-01-01 23:22:07,709:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:22:07,710:INFO:Total runtime is 0.3071861624717713 minutes
2024-01-01 23:22:07,712:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:07,713:INFO:Initializing create_model()
2024-01-01 23:22:07,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:07,713:INFO:Checking exceptions
2024-01-01 23:22:07,713:INFO:Importing libraries
2024-01-01 23:22:07,713:INFO:Copying training dataset
2024-01-01 23:22:07,721:INFO:Defining folds
2024-01-01 23:22:07,721:INFO:Declaring metric variables
2024-01-01 23:22:07,723:INFO:Importing untrained model
2024-01-01 23:22:07,727:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:22:07,733:INFO:Starting cross validation
2024-01-01 23:22:07,734:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:08,536:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,629:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,694:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,783:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,808:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,873:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,903:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,917:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,937:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:22:08,957:INFO:Calculating mean and std
2024-01-01 23:22:08,961:INFO:Creating metrics dataframe
2024-01-01 23:22:08,969:INFO:Uploading results into container
2024-01-01 23:22:08,970:INFO:Uploading model into container now
2024-01-01 23:22:08,971:INFO:_master_model_container: 5
2024-01-01 23:22:08,971:INFO:_display_container: 2
2024-01-01 23:22:08,971:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:22:08,972:INFO:create_model() successfully completed......................................
2024-01-01 23:22:09,183:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:09,184:INFO:Creating metrics dataframe
2024-01-01 23:22:09,197:INFO:Initializing Ridge Classifier
2024-01-01 23:22:09,198:INFO:Total runtime is 0.3319853226343791 minutes
2024-01-01 23:22:09,202:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:09,203:INFO:Initializing create_model()
2024-01-01 23:22:09,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:09,203:INFO:Checking exceptions
2024-01-01 23:22:09,203:INFO:Importing libraries
2024-01-01 23:22:09,203:INFO:Copying training dataset
2024-01-01 23:22:09,214:INFO:Defining folds
2024-01-01 23:22:09,214:INFO:Declaring metric variables
2024-01-01 23:22:09,217:INFO:Importing untrained model
2024-01-01 23:22:09,221:INFO:Ridge Classifier Imported successfully
2024-01-01 23:22:09,228:INFO:Starting cross validation
2024-01-01 23:22:09,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:09,364:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,365:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,370:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,373:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,375:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,381:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,383:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,387:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,390:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,396:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:22:09,411:INFO:Calculating mean and std
2024-01-01 23:22:09,412:INFO:Creating metrics dataframe
2024-01-01 23:22:09,415:INFO:Uploading results into container
2024-01-01 23:22:09,416:INFO:Uploading model into container now
2024-01-01 23:22:09,416:INFO:_master_model_container: 6
2024-01-01 23:22:09,416:INFO:_display_container: 2
2024-01-01 23:22:09,417:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:22:09,417:INFO:create_model() successfully completed......................................
2024-01-01 23:22:09,583:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:09,583:INFO:Creating metrics dataframe
2024-01-01 23:22:09,592:INFO:Initializing Random Forest Classifier
2024-01-01 23:22:09,592:INFO:Total runtime is 0.3385555903116862 minutes
2024-01-01 23:22:09,595:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:09,595:INFO:Initializing create_model()
2024-01-01 23:22:09,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:09,595:INFO:Checking exceptions
2024-01-01 23:22:09,595:INFO:Importing libraries
2024-01-01 23:22:09,595:INFO:Copying training dataset
2024-01-01 23:22:09,603:INFO:Defining folds
2024-01-01 23:22:09,603:INFO:Declaring metric variables
2024-01-01 23:22:09,607:INFO:Importing untrained model
2024-01-01 23:22:09,610:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:22:09,616:INFO:Starting cross validation
2024-01-01 23:22:09,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:12,440:INFO:Calculating mean and std
2024-01-01 23:22:12,443:INFO:Creating metrics dataframe
2024-01-01 23:22:12,448:INFO:Uploading results into container
2024-01-01 23:22:12,449:INFO:Uploading model into container now
2024-01-01 23:22:12,450:INFO:_master_model_container: 7
2024-01-01 23:22:12,450:INFO:_display_container: 2
2024-01-01 23:22:12,451:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:22:12,451:INFO:create_model() successfully completed......................................
2024-01-01 23:22:12,815:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:12,815:INFO:Creating metrics dataframe
2024-01-01 23:22:12,826:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:22:12,826:INFO:Total runtime is 0.39245195786158243 minutes
2024-01-01 23:22:12,830:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:12,831:INFO:Initializing create_model()
2024-01-01 23:22:12,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:12,831:INFO:Checking exceptions
2024-01-01 23:22:12,831:INFO:Importing libraries
2024-01-01 23:22:12,831:INFO:Copying training dataset
2024-01-01 23:22:12,844:INFO:Defining folds
2024-01-01 23:22:12,845:INFO:Declaring metric variables
2024-01-01 23:22:12,850:INFO:Importing untrained model
2024-01-01 23:22:12,856:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:22:12,867:INFO:Starting cross validation
2024-01-01 23:22:12,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:13,223:INFO:Calculating mean and std
2024-01-01 23:22:13,224:INFO:Creating metrics dataframe
2024-01-01 23:22:13,227:INFO:Uploading results into container
2024-01-01 23:22:13,228:INFO:Uploading model into container now
2024-01-01 23:22:13,228:INFO:_master_model_container: 8
2024-01-01 23:22:13,228:INFO:_display_container: 2
2024-01-01 23:22:13,229:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:22:13,229:INFO:create_model() successfully completed......................................
2024-01-01 23:22:13,471:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:13,471:INFO:Creating metrics dataframe
2024-01-01 23:22:13,481:INFO:Initializing Ada Boost Classifier
2024-01-01 23:22:13,481:INFO:Total runtime is 0.40337636868158977 minutes
2024-01-01 23:22:13,484:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:13,484:INFO:Initializing create_model()
2024-01-01 23:22:13,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:13,485:INFO:Checking exceptions
2024-01-01 23:22:13,485:INFO:Importing libraries
2024-01-01 23:22:13,485:INFO:Copying training dataset
2024-01-01 23:22:13,493:INFO:Defining folds
2024-01-01 23:22:13,493:INFO:Declaring metric variables
2024-01-01 23:22:13,497:INFO:Importing untrained model
2024-01-01 23:22:13,501:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:22:13,509:INFO:Starting cross validation
2024-01-01 23:22:13,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:15,030:INFO:Calculating mean and std
2024-01-01 23:22:15,031:INFO:Creating metrics dataframe
2024-01-01 23:22:15,034:INFO:Uploading results into container
2024-01-01 23:22:15,035:INFO:Uploading model into container now
2024-01-01 23:22:15,035:INFO:_master_model_container: 9
2024-01-01 23:22:15,035:INFO:_display_container: 2
2024-01-01 23:22:15,036:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:22:15,036:INFO:create_model() successfully completed......................................
2024-01-01 23:22:15,259:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:15,259:INFO:Creating metrics dataframe
2024-01-01 23:22:15,270:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:22:15,270:INFO:Total runtime is 0.43319759766260785 minutes
2024-01-01 23:22:15,273:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:15,274:INFO:Initializing create_model()
2024-01-01 23:22:15,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:15,274:INFO:Checking exceptions
2024-01-01 23:22:15,274:INFO:Importing libraries
2024-01-01 23:22:15,274:INFO:Copying training dataset
2024-01-01 23:22:15,283:INFO:Defining folds
2024-01-01 23:22:15,284:INFO:Declaring metric variables
2024-01-01 23:22:15,287:INFO:Importing untrained model
2024-01-01 23:22:15,290:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:22:15,298:INFO:Starting cross validation
2024-01-01 23:22:15,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:18,225:INFO:Calculating mean and std
2024-01-01 23:22:18,227:INFO:Creating metrics dataframe
2024-01-01 23:22:18,232:INFO:Uploading results into container
2024-01-01 23:22:18,232:INFO:Uploading model into container now
2024-01-01 23:22:18,233:INFO:_master_model_container: 10
2024-01-01 23:22:18,233:INFO:_display_container: 2
2024-01-01 23:22:18,234:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:22:18,234:INFO:create_model() successfully completed......................................
2024-01-01 23:22:18,495:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:18,495:INFO:Creating metrics dataframe
2024-01-01 23:22:18,509:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:22:18,509:INFO:Total runtime is 0.4871803402900696 minutes
2024-01-01 23:22:18,515:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:18,515:INFO:Initializing create_model()
2024-01-01 23:22:18,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:18,515:INFO:Checking exceptions
2024-01-01 23:22:18,516:INFO:Importing libraries
2024-01-01 23:22:18,516:INFO:Copying training dataset
2024-01-01 23:22:18,525:INFO:Defining folds
2024-01-01 23:22:18,525:INFO:Declaring metric variables
2024-01-01 23:22:18,529:INFO:Importing untrained model
2024-01-01 23:22:18,533:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:22:18,541:INFO:Starting cross validation
2024-01-01 23:22:18,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:18,836:INFO:Calculating mean and std
2024-01-01 23:22:18,837:INFO:Creating metrics dataframe
2024-01-01 23:22:18,842:INFO:Uploading results into container
2024-01-01 23:22:18,842:INFO:Uploading model into container now
2024-01-01 23:22:18,843:INFO:_master_model_container: 11
2024-01-01 23:22:18,843:INFO:_display_container: 2
2024-01-01 23:22:18,843:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:22:18,843:INFO:create_model() successfully completed......................................
2024-01-01 23:22:19,038:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:19,038:INFO:Creating metrics dataframe
2024-01-01 23:22:19,049:INFO:Initializing Extra Trees Classifier
2024-01-01 23:22:19,049:INFO:Total runtime is 0.4961746732393901 minutes
2024-01-01 23:22:19,052:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:19,052:INFO:Initializing create_model()
2024-01-01 23:22:19,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:19,053:INFO:Checking exceptions
2024-01-01 23:22:19,053:INFO:Importing libraries
2024-01-01 23:22:19,053:INFO:Copying training dataset
2024-01-01 23:22:19,062:INFO:Defining folds
2024-01-01 23:22:19,062:INFO:Declaring metric variables
2024-01-01 23:22:19,065:INFO:Importing untrained model
2024-01-01 23:22:19,068:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:22:19,076:INFO:Starting cross validation
2024-01-01 23:22:19,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:22,173:INFO:Calculating mean and std
2024-01-01 23:22:22,175:INFO:Creating metrics dataframe
2024-01-01 23:22:22,179:INFO:Uploading results into container
2024-01-01 23:22:22,180:INFO:Uploading model into container now
2024-01-01 23:22:22,181:INFO:_master_model_container: 12
2024-01-01 23:22:22,181:INFO:_display_container: 2
2024-01-01 23:22:22,182:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:22:22,182:INFO:create_model() successfully completed......................................
2024-01-01 23:22:22,429:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:22,429:INFO:Creating metrics dataframe
2024-01-01 23:22:22,441:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:22:22,441:INFO:Total runtime is 0.5527119477589926 minutes
2024-01-01 23:22:22,451:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:22,453:INFO:Initializing create_model()
2024-01-01 23:22:22,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:22,453:INFO:Checking exceptions
2024-01-01 23:22:22,453:INFO:Importing libraries
2024-01-01 23:22:22,453:INFO:Copying training dataset
2024-01-01 23:22:22,478:INFO:Defining folds
2024-01-01 23:22:22,479:INFO:Declaring metric variables
2024-01-01 23:22:22,482:INFO:Importing untrained model
2024-01-01 23:22:22,486:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:22:22,491:INFO:Starting cross validation
2024-01-01 23:22:22,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:23,881:INFO:Calculating mean and std
2024-01-01 23:22:23,883:INFO:Creating metrics dataframe
2024-01-01 23:22:23,889:INFO:Uploading results into container
2024-01-01 23:22:23,889:INFO:Uploading model into container now
2024-01-01 23:22:23,890:INFO:_master_model_container: 13
2024-01-01 23:22:23,890:INFO:_display_container: 2
2024-01-01 23:22:23,891:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:22:23,891:INFO:create_model() successfully completed......................................
2024-01-01 23:22:24,145:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:24,145:INFO:Creating metrics dataframe
2024-01-01 23:22:24,156:INFO:Initializing Dummy Classifier
2024-01-01 23:22:24,157:INFO:Total runtime is 0.5813069462776185 minutes
2024-01-01 23:22:24,159:INFO:SubProcess create_model() called ==================================
2024-01-01 23:22:24,159:INFO:Initializing create_model()
2024-01-01 23:22:24,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F90B65780>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:24,160:INFO:Checking exceptions
2024-01-01 23:22:24,160:INFO:Importing libraries
2024-01-01 23:22:24,160:INFO:Copying training dataset
2024-01-01 23:22:24,168:INFO:Defining folds
2024-01-01 23:22:24,168:INFO:Declaring metric variables
2024-01-01 23:22:24,171:INFO:Importing untrained model
2024-01-01 23:22:24,174:INFO:Dummy Classifier Imported successfully
2024-01-01 23:22:24,180:INFO:Starting cross validation
2024-01-01 23:22:24,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:22:24,269:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,278:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,288:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,293:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,298:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,305:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,306:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,310:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,311:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:22:24,319:INFO:Calculating mean and std
2024-01-01 23:22:24,320:INFO:Creating metrics dataframe
2024-01-01 23:22:24,323:INFO:Uploading results into container
2024-01-01 23:22:24,324:INFO:Uploading model into container now
2024-01-01 23:22:24,324:INFO:_master_model_container: 14
2024-01-01 23:22:24,324:INFO:_display_container: 2
2024-01-01 23:22:24,325:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:22:24,325:INFO:create_model() successfully completed......................................
2024-01-01 23:22:24,499:INFO:SubProcess create_model() end ==================================
2024-01-01 23:22:24,499:INFO:Creating metrics dataframe
2024-01-01 23:22:24,523:INFO:Initializing create_model()
2024-01-01 23:22:24,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:22:24,524:INFO:Checking exceptions
2024-01-01 23:22:24,526:INFO:Importing libraries
2024-01-01 23:22:24,527:INFO:Copying training dataset
2024-01-01 23:22:24,543:INFO:Defining folds
2024-01-01 23:22:24,544:INFO:Declaring metric variables
2024-01-01 23:22:24,544:INFO:Importing untrained model
2024-01-01 23:22:24,544:INFO:Declaring custom model
2024-01-01 23:22:24,545:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:22:24,546:INFO:Cross validation set to False
2024-01-01 23:22:24,547:INFO:Fitting Model
2024-01-01 23:22:24,587:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-01 23:22:24,588:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:22:24,589:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000564 seconds.
2024-01-01 23:22:24,589:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:22:24,589:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:22:24,589:INFO:[LightGBM] [Info] Total Bins 403
2024-01-01 23:22:24,590:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 11
2024-01-01 23:22:24,590:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:22:24,590:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:22:24,672:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:22:24,672:INFO:create_model() successfully completed......................................
2024-01-01 23:22:24,941:INFO:_master_model_container: 14
2024-01-01 23:22:24,941:INFO:_display_container: 2
2024-01-01 23:22:24,942:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:22:24,942:INFO:compare_models() successfully completed......................................
2024-01-01 23:23:44,668:INFO:Initializing plot_model()
2024-01-01 23:23:44,668:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, system=True)
2024-01-01 23:23:44,668:INFO:Checking exceptions
2024-01-01 23:23:44,675:INFO:Preloading libraries
2024-01-01 23:23:44,680:INFO:Copying training dataset
2024-01-01 23:23:44,680:INFO:Plot type: auc
2024-01-01 23:23:44,839:INFO:Fitting Model
2024-01-01 23:23:44,840:INFO:Scoring test/hold-out set
2024-01-01 23:23:45,102:INFO:Visual Rendered Successfully
2024-01-01 23:23:45,359:INFO:plot_model() successfully completed......................................
2024-01-01 23:23:45,429:INFO:Initializing plot_model()
2024-01-01 23:23:45,430:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, system=True)
2024-01-01 23:23:45,430:INFO:Checking exceptions
2024-01-01 23:23:45,436:INFO:Preloading libraries
2024-01-01 23:23:45,443:INFO:Copying training dataset
2024-01-01 23:23:45,443:INFO:Plot type: confusion_matrix
2024-01-01 23:23:45,578:INFO:Fitting Model
2024-01-01 23:23:45,578:INFO:Scoring test/hold-out set
2024-01-01 23:23:45,747:INFO:Visual Rendered Successfully
2024-01-01 23:23:45,963:INFO:plot_model() successfully completed......................................
2024-01-01 23:23:46,020:INFO:Initializing plot_model()
2024-01-01 23:23:46,021:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, system=True)
2024-01-01 23:23:46,021:INFO:Checking exceptions
2024-01-01 23:23:46,029:INFO:Preloading libraries
2024-01-01 23:23:46,035:INFO:Copying training dataset
2024-01-01 23:23:46,035:INFO:Plot type: class_report
2024-01-01 23:23:46,174:INFO:Fitting Model
2024-01-01 23:23:46,174:INFO:Scoring test/hold-out set
2024-01-01 23:23:46,450:INFO:Visual Rendered Successfully
2024-01-01 23:23:46,698:INFO:plot_model() successfully completed......................................
2024-01-01 23:23:46,742:INFO:Initializing tune_model()
2024-01-01 23:23:46,743:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>)
2024-01-01 23:23:46,743:INFO:Checking exceptions
2024-01-01 23:23:46,764:INFO:Copying training dataset
2024-01-01 23:23:46,771:INFO:Checking base model
2024-01-01 23:23:46,772:INFO:Base model : Light Gradient Boosting Machine
2024-01-01 23:23:46,776:INFO:Declaring metric variables
2024-01-01 23:23:46,779:INFO:Defining Hyperparameters
2024-01-01 23:23:47,042:INFO:Tuning with n_jobs=-1
2024-01-01 23:23:47,042:INFO:Initializing RandomizedSearchCV
2024-01-01 23:24:15,894:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-01-01 23:24:15,895:INFO:Hyperparameter search completed
2024-01-01 23:24:15,895:INFO:SubProcess create_model() called ==================================
2024-01-01 23:24:15,896:INFO:Initializing create_model()
2024-01-01 23:24:15,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F9AF7D300>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-01-01 23:24:15,897:INFO:Checking exceptions
2024-01-01 23:24:15,897:INFO:Importing libraries
2024-01-01 23:24:15,897:INFO:Copying training dataset
2024-01-01 23:24:15,913:INFO:Defining folds
2024-01-01 23:24:15,913:INFO:Declaring metric variables
2024-01-01 23:24:15,919:INFO:Importing untrained model
2024-01-01 23:24:15,919:INFO:Declaring custom model
2024-01-01 23:24:15,926:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:24:15,936:INFO:Starting cross validation
2024-01-01 23:24:15,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:24:18,966:INFO:Calculating mean and std
2024-01-01 23:24:18,968:INFO:Creating metrics dataframe
2024-01-01 23:24:18,978:INFO:Finalizing model
2024-01-01 23:24:19,011:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-01 23:24:19,012:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-01 23:24:19,012:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-01 23:24:19,023:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-01 23:24:19,024:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-01-01 23:24:19,024:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-01-01 23:24:19,024:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-01-01 23:24:19,024:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:24:19,026:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001057 seconds.
2024-01-01 23:24:19,027:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:24:19,027:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:24:19,027:INFO:[LightGBM] [Info] Total Bins 403
2024-01-01 23:24:19,027:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 11
2024-01-01 23:24:19,028:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:24:19,028:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:24:19,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,318:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:24:19,395:INFO:Uploading results into container
2024-01-01 23:24:19,396:INFO:Uploading model into container now
2024-01-01 23:24:19,397:INFO:_master_model_container: 15
2024-01-01 23:24:19,397:INFO:_display_container: 3
2024-01-01 23:24:19,398:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:24:19,399:INFO:create_model() successfully completed......................................
2024-01-01 23:24:19,717:INFO:SubProcess create_model() end ==================================
2024-01-01 23:24:19,717:INFO:choose_better activated
2024-01-01 23:24:19,721:INFO:SubProcess create_model() called ==================================
2024-01-01 23:24:19,722:INFO:Initializing create_model()
2024-01-01 23:24:19,722:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:24:19,723:INFO:Checking exceptions
2024-01-01 23:24:19,725:INFO:Importing libraries
2024-01-01 23:24:19,726:INFO:Copying training dataset
2024-01-01 23:24:19,737:INFO:Defining folds
2024-01-01 23:24:19,737:INFO:Declaring metric variables
2024-01-01 23:24:19,738:INFO:Importing untrained model
2024-01-01 23:24:19,738:INFO:Declaring custom model
2024-01-01 23:24:19,738:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:24:19,739:INFO:Starting cross validation
2024-01-01 23:24:19,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:24:21,842:INFO:Calculating mean and std
2024-01-01 23:24:21,843:INFO:Creating metrics dataframe
2024-01-01 23:24:21,846:INFO:Finalizing model
2024-01-01 23:24:21,886:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-01 23:24:21,887:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:24:21,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001577 seconds.
2024-01-01 23:24:21,890:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:24:21,890:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:24:21,890:INFO:[LightGBM] [Info] Total Bins 403
2024-01-01 23:24:21,891:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 11
2024-01-01 23:24:21,891:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:24:21,891:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:24:22,076:INFO:Uploading results into container
2024-01-01 23:24:22,076:INFO:Uploading model into container now
2024-01-01 23:24:22,077:INFO:_master_model_container: 16
2024-01-01 23:24:22,077:INFO:_display_container: 4
2024-01-01 23:24:22,078:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:24:22,078:INFO:create_model() successfully completed......................................
2024-01-01 23:24:22,350:INFO:SubProcess create_model() end ==================================
2024-01-01 23:24:22,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8717
2024-01-01 23:24:22,351:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8709
2024-01-01 23:24:22,351:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-01 23:24:22,351:INFO:choose_better completed
2024-01-01 23:24:22,352:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-01 23:24:22,362:INFO:_master_model_container: 16
2024-01-01 23:24:22,363:INFO:_display_container: 3
2024-01-01 23:24:22,363:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:24:22,363:INFO:tune_model() successfully completed......................................
2024-01-01 23:24:22,890:INFO:Initializing plot_model()
2024-01-01 23:24:22,891:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, system=True)
2024-01-01 23:24:22,891:INFO:Checking exceptions
2024-01-01 23:24:22,897:INFO:Preloading libraries
2024-01-01 23:24:22,903:INFO:Copying training dataset
2024-01-01 23:24:22,903:INFO:Plot type: auc
2024-01-01 23:24:23,043:INFO:Fitting Model
2024-01-01 23:24:23,044:INFO:Scoring test/hold-out set
2024-01-01 23:24:23,321:INFO:Visual Rendered Successfully
2024-01-01 23:24:23,534:INFO:plot_model() successfully completed......................................
2024-01-01 23:24:23,590:INFO:Initializing plot_model()
2024-01-01 23:24:23,591:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, system=True)
2024-01-01 23:24:23,591:INFO:Checking exceptions
2024-01-01 23:24:23,600:INFO:Preloading libraries
2024-01-01 23:24:23,605:INFO:Copying training dataset
2024-01-01 23:24:23,605:INFO:Plot type: confusion_matrix
2024-01-01 23:24:23,739:INFO:Fitting Model
2024-01-01 23:24:23,740:INFO:Scoring test/hold-out set
2024-01-01 23:24:23,911:INFO:Visual Rendered Successfully
2024-01-01 23:24:24,156:INFO:plot_model() successfully completed......................................
2024-01-01 23:24:24,192:INFO:Initializing plot_model()
2024-01-01 23:24:24,193:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, system=True)
2024-01-01 23:24:24,193:INFO:Checking exceptions
2024-01-01 23:24:24,200:INFO:Preloading libraries
2024-01-01 23:24:24,205:INFO:Copying training dataset
2024-01-01 23:24:24,206:INFO:Plot type: class_report
2024-01-01 23:24:24,368:INFO:Fitting Model
2024-01-01 23:24:24,369:INFO:Scoring test/hold-out set
2024-01-01 23:24:24,665:INFO:Visual Rendered Successfully
2024-01-01 23:24:24,894:INFO:plot_model() successfully completed......................................
2024-01-01 23:24:24,927:INFO:Initializing finalize_model()
2024-01-01 23:24:24,927:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-01 23:24:24,927:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:24:24,934:INFO:Initializing create_model()
2024-01-01 23:24:24,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-01 23:24:24,934:INFO:Checking exceptions
2024-01-01 23:24:24,936:INFO:Importing libraries
2024-01-01 23:24:24,936:INFO:Copying training dataset
2024-01-01 23:24:24,936:INFO:Defining folds
2024-01-01 23:24:24,937:INFO:Declaring metric variables
2024-01-01 23:24:24,937:INFO:Importing untrained model
2024-01-01 23:24:24,937:INFO:Declaring custom model
2024-01-01 23:24:24,938:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:24:24,939:INFO:Cross validation set to False
2024-01-01 23:24:24,939:INFO:Fitting Model
2024-01-01 23:24:24,978:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-01 23:24:24,979:INFO:[LightGBM] [Info] Number of positive: 7695, number of negative: 24283
2024-01-01 23:24:24,981:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000885 seconds.
2024-01-01 23:24:24,982:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:24:24,982:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:24:24,982:INFO:[LightGBM] [Info] Total Bins 414
2024-01-01 23:24:24,982:INFO:[LightGBM] [Info] Number of data points in the train set: 31978, number of used features: 11
2024-01-01 23:24:24,982:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240634 -> initscore=-1.149206
2024-01-01 23:24:24,982:INFO:[LightGBM] [Info] Start training from score -1.149206
2024-01-01 23:24:25,169:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Profession Class',
                                             'Education-num', 'marital-status',
                                             'occupation', 'race', 'Gender',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'country'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              m...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-01 23:24:25,170:INFO:create_model() successfully completed......................................
2024-01-01 23:24:25,432:INFO:_master_model_container: 16
2024-01-01 23:24:25,432:INFO:_display_container: 3
2024-01-01 23:24:25,438:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Profession Class',
                                             'Education-num', 'marital-status',
                                             'occupation', 'race', 'Gender',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'country'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              m...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-01 23:24:25,438:INFO:finalize_model() successfully completed......................................
2024-01-01 23:24:46,190:INFO:Initializing predict_model()
2024-01-01 23:24:46,190:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F9A0B6500>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Profession Class',
                                             'Education-num', 'marital-status',
                                             'occupation', 'race', 'Gender',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'country'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              m...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020FA654F9A0>)
2024-01-01 23:24:46,190:INFO:Checking exceptions
2024-01-01 23:24:46,190:INFO:Preloading libraries
2024-01-01 23:24:46,194:INFO:Set up data.
2024-01-01 23:24:46,222:INFO:Set up index.
2024-01-01 23:40:55,625:INFO:PyCaret ClassificationExperiment
2024-01-01 23:40:55,625:INFO:Logging name: clf-default-name
2024-01-01 23:40:55,625:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:40:55,626:INFO:version 3.1.0
2024-01-01 23:40:55,626:INFO:Initializing setup()
2024-01-01 23:40:55,626:INFO:self.USI: 3d90
2024-01-01 23:40:55,626:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:40:55,626:INFO:Checking environment
2024-01-01 23:40:55,626:INFO:python_version: 3.10.9
2024-01-01 23:40:55,626:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:40:55,626:INFO:machine: AMD64
2024-01-01 23:40:55,626:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:40:55,626:INFO:Memory: svmem(total=16954372096, available=4974280704, percent=70.7, used=11980091392, free=4974280704)
2024-01-01 23:40:55,626:INFO:Physical Core: 8
2024-01-01 23:40:55,626:INFO:Logical Core: 16
2024-01-01 23:40:55,626:INFO:Checking libraries
2024-01-01 23:40:55,626:INFO:System:
2024-01-01 23:40:55,626:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:40:55,626:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:40:55,626:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:40:55,626:INFO:PyCaret required dependencies:
2024-01-01 23:40:55,626:INFO:                 pip: 22.3.1
2024-01-01 23:40:55,626:INFO:          setuptools: 65.6.3
2024-01-01 23:40:55,626:INFO:             pycaret: 3.1.0
2024-01-01 23:40:55,627:INFO:             IPython: 8.10.0
2024-01-01 23:40:55,627:INFO:          ipywidgets: 7.6.5
2024-01-01 23:40:55,627:INFO:                tqdm: 4.64.1
2024-01-01 23:40:55,627:INFO:               numpy: 1.23.5
2024-01-01 23:40:55,627:INFO:              pandas: 1.5.3
2024-01-01 23:40:55,627:INFO:              jinja2: 3.1.2
2024-01-01 23:40:55,627:INFO:               scipy: 1.10.1
2024-01-01 23:40:55,627:INFO:              joblib: 1.3.2
2024-01-01 23:40:55,627:INFO:             sklearn: 1.2.1
2024-01-01 23:40:55,627:INFO:                pyod: 1.1.0
2024-01-01 23:40:55,627:INFO:            imblearn: 0.10.1
2024-01-01 23:40:55,627:INFO:   category_encoders: 2.6.2
2024-01-01 23:40:55,627:INFO:            lightgbm: 4.1.0
2024-01-01 23:40:55,627:INFO:               numba: 0.56.4
2024-01-01 23:40:55,627:INFO:            requests: 2.28.1
2024-01-01 23:40:55,627:INFO:          matplotlib: 3.7.0
2024-01-01 23:40:55,627:INFO:          scikitplot: 0.3.7
2024-01-01 23:40:55,627:INFO:         yellowbrick: 1.5
2024-01-01 23:40:55,627:INFO:              plotly: 5.9.0
2024-01-01 23:40:55,627:INFO:    plotly-resampler: Not installed
2024-01-01 23:40:55,627:INFO:             kaleido: 0.2.1
2024-01-01 23:40:55,627:INFO:           schemdraw: 0.15
2024-01-01 23:40:55,627:INFO:         statsmodels: 0.13.5
2024-01-01 23:40:55,627:INFO:              sktime: 0.21.1
2024-01-01 23:40:55,628:INFO:               tbats: 1.1.3
2024-01-01 23:40:55,628:INFO:            pmdarima: 2.0.3
2024-01-01 23:40:55,628:INFO:              psutil: 5.9.0
2024-01-01 23:40:55,628:INFO:          markupsafe: 2.1.1
2024-01-01 23:40:55,628:INFO:             pickle5: Not installed
2024-01-01 23:40:55,628:INFO:         cloudpickle: 2.0.0
2024-01-01 23:40:55,628:INFO:         deprecation: 2.1.0
2024-01-01 23:40:55,628:INFO:              xxhash: 3.4.1
2024-01-01 23:40:55,628:INFO:           wurlitzer: Not installed
2024-01-01 23:40:55,628:INFO:PyCaret optional dependencies:
2024-01-01 23:40:55,628:INFO:                shap: Not installed
2024-01-01 23:40:55,628:INFO:           interpret: Not installed
2024-01-01 23:40:55,628:INFO:                umap: Not installed
2024-01-01 23:40:55,628:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:40:55,628:INFO:  explainerdashboard: Not installed
2024-01-01 23:40:55,628:INFO:             autoviz: Not installed
2024-01-01 23:40:55,628:INFO:           fairlearn: Not installed
2024-01-01 23:40:55,628:INFO:          deepchecks: Not installed
2024-01-01 23:40:55,628:INFO:             xgboost: Not installed
2024-01-01 23:40:55,628:INFO:            catboost: Not installed
2024-01-01 23:40:55,628:INFO:              kmodes: Not installed
2024-01-01 23:40:55,628:INFO:             mlxtend: Not installed
2024-01-01 23:40:55,628:INFO:       statsforecast: Not installed
2024-01-01 23:40:55,629:INFO:        tune_sklearn: Not installed
2024-01-01 23:40:55,629:INFO:                 ray: Not installed
2024-01-01 23:40:55,629:INFO:            hyperopt: Not installed
2024-01-01 23:40:55,629:INFO:              optuna: Not installed
2024-01-01 23:40:55,629:INFO:               skopt: Not installed
2024-01-01 23:40:55,629:INFO:              mlflow: Not installed
2024-01-01 23:40:55,629:INFO:              gradio: Not installed
2024-01-01 23:40:55,629:INFO:             fastapi: Not installed
2024-01-01 23:40:55,629:INFO:             uvicorn: Not installed
2024-01-01 23:40:55,629:INFO:              m2cgen: Not installed
2024-01-01 23:40:55,629:INFO:           evidently: Not installed
2024-01-01 23:40:55,629:INFO:               fugue: Not installed
2024-01-01 23:40:55,629:INFO:           streamlit: Not installed
2024-01-01 23:40:55,629:INFO:             prophet: Not installed
2024-01-01 23:40:55,629:INFO:None
2024-01-01 23:40:55,629:INFO:Set up data.
2024-01-01 23:40:55,689:INFO:Set up folding strategy.
2024-01-01 23:40:55,689:INFO:Set up train/test split.
2024-01-01 23:40:55,710:INFO:Set up index.
2024-01-01 23:40:55,710:INFO:Assigning column types.
2024-01-01 23:40:55,716:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:40:55,758:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:40:55,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:40:55,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,825:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:40:55,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:40:55,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,853:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:40:55,894:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:40:55,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,921:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,964:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:40:55,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:55,989:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:40:56,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:56,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:56,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:56,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:56,133:INFO:Preparing preprocessing pipeline...
2024-01-01 23:40:56,135:INFO:Set up simple imputation.
2024-01-01 23:40:56,145:INFO:Set up encoding of ordinal features.
2024-01-01 23:40:56,153:INFO:Set up encoding of categorical features.
2024-01-01 23:40:56,154:INFO:Set up column name cleaning.
2024-01-01 23:40:56,583:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:40:56,617:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              s...
                 TransformerWrapper(exclude=None, include=['country'],
                                    transformer=TargetEncoder(cols=['country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:40:56,618:INFO:Creating final display dataframe.
2024-01-01 23:40:57,239:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 14)
4        Transformed data shape       (31978, 38)
5   Transformed train set shape       (25582, 38)
6    Transformed test set shape        (6396, 38)
7              Ordinal features                 3
8              Numeric features                 6
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              3d90
2024-01-01 23:40:57,322:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:57,322:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:57,389:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:57,389:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:40:57,390:INFO:setup() successfully completed in 1.77s...............
2024-01-01 23:40:57,425:INFO:Initializing compare_models()
2024-01-01 23:40:57,426:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:40:57,426:INFO:Checking exceptions
2024-01-01 23:40:57,433:INFO:Preparing display monitor
2024-01-01 23:40:57,461:INFO:Initializing Logistic Regression
2024-01-01 23:40:57,461:INFO:Total runtime is 0.0 minutes
2024-01-01 23:40:57,466:INFO:SubProcess create_model() called ==================================
2024-01-01 23:40:57,468:INFO:Initializing create_model()
2024-01-01 23:40:57,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:40:57,468:INFO:Checking exceptions
2024-01-01 23:40:57,468:INFO:Importing libraries
2024-01-01 23:40:57,468:INFO:Copying training dataset
2024-01-01 23:40:57,480:INFO:Defining folds
2024-01-01 23:40:57,480:INFO:Declaring metric variables
2024-01-01 23:40:57,483:INFO:Importing untrained model
2024-01-01 23:40:57,486:INFO:Logistic Regression Imported successfully
2024-01-01 23:40:57,494:INFO:Starting cross validation
2024-01-01 23:40:57,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:07,879:INFO:Calculating mean and std
2024-01-01 23:41:07,880:INFO:Creating metrics dataframe
2024-01-01 23:41:07,883:INFO:Uploading results into container
2024-01-01 23:41:07,884:INFO:Uploading model into container now
2024-01-01 23:41:07,884:INFO:_master_model_container: 1
2024-01-01 23:41:07,884:INFO:_display_container: 2
2024-01-01 23:41:07,885:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:41:07,885:INFO:create_model() successfully completed......................................
2024-01-01 23:41:08,170:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:08,170:INFO:Creating metrics dataframe
2024-01-01 23:41:08,178:INFO:Initializing K Neighbors Classifier
2024-01-01 23:41:08,179:INFO:Total runtime is 0.17861001094182333 minutes
2024-01-01 23:41:08,181:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:08,182:INFO:Initializing create_model()
2024-01-01 23:41:08,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:08,182:INFO:Checking exceptions
2024-01-01 23:41:08,182:INFO:Importing libraries
2024-01-01 23:41:08,182:INFO:Copying training dataset
2024-01-01 23:41:08,190:INFO:Defining folds
2024-01-01 23:41:08,190:INFO:Declaring metric variables
2024-01-01 23:41:08,194:INFO:Importing untrained model
2024-01-01 23:41:08,197:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:41:08,202:INFO:Starting cross validation
2024-01-01 23:41:08,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:15,088:INFO:Calculating mean and std
2024-01-01 23:41:15,090:INFO:Creating metrics dataframe
2024-01-01 23:41:15,096:INFO:Uploading results into container
2024-01-01 23:41:15,098:INFO:Uploading model into container now
2024-01-01 23:41:15,098:INFO:_master_model_container: 2
2024-01-01 23:41:15,098:INFO:_display_container: 2
2024-01-01 23:41:15,099:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:41:15,099:INFO:create_model() successfully completed......................................
2024-01-01 23:41:15,581:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:15,581:INFO:Creating metrics dataframe
2024-01-01 23:41:15,592:INFO:Initializing Naive Bayes
2024-01-01 23:41:15,592:INFO:Total runtime is 0.30218714475631714 minutes
2024-01-01 23:41:15,596:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:15,596:INFO:Initializing create_model()
2024-01-01 23:41:15,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:15,597:INFO:Checking exceptions
2024-01-01 23:41:15,597:INFO:Importing libraries
2024-01-01 23:41:15,597:INFO:Copying training dataset
2024-01-01 23:41:15,621:INFO:Defining folds
2024-01-01 23:41:15,621:INFO:Declaring metric variables
2024-01-01 23:41:15,627:INFO:Importing untrained model
2024-01-01 23:41:15,633:INFO:Naive Bayes Imported successfully
2024-01-01 23:41:15,647:INFO:Starting cross validation
2024-01-01 23:41:15,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:17,319:INFO:Calculating mean and std
2024-01-01 23:41:17,320:INFO:Creating metrics dataframe
2024-01-01 23:41:17,323:INFO:Uploading results into container
2024-01-01 23:41:17,324:INFO:Uploading model into container now
2024-01-01 23:41:17,324:INFO:_master_model_container: 3
2024-01-01 23:41:17,325:INFO:_display_container: 2
2024-01-01 23:41:17,325:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:41:17,325:INFO:create_model() successfully completed......................................
2024-01-01 23:41:17,649:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:17,650:INFO:Creating metrics dataframe
2024-01-01 23:41:17,659:INFO:Initializing Decision Tree Classifier
2024-01-01 23:41:17,659:INFO:Total runtime is 0.33662768999735515 minutes
2024-01-01 23:41:17,662:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:17,662:INFO:Initializing create_model()
2024-01-01 23:41:17,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:17,662:INFO:Checking exceptions
2024-01-01 23:41:17,662:INFO:Importing libraries
2024-01-01 23:41:17,662:INFO:Copying training dataset
2024-01-01 23:41:17,672:INFO:Defining folds
2024-01-01 23:41:17,673:INFO:Declaring metric variables
2024-01-01 23:41:17,676:INFO:Importing untrained model
2024-01-01 23:41:17,679:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:41:17,686:INFO:Starting cross validation
2024-01-01 23:41:17,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:19,170:INFO:Calculating mean and std
2024-01-01 23:41:19,172:INFO:Creating metrics dataframe
2024-01-01 23:41:19,175:INFO:Uploading results into container
2024-01-01 23:41:19,176:INFO:Uploading model into container now
2024-01-01 23:41:19,176:INFO:_master_model_container: 4
2024-01-01 23:41:19,176:INFO:_display_container: 2
2024-01-01 23:41:19,177:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:41:19,177:INFO:create_model() successfully completed......................................
2024-01-01 23:41:19,516:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:19,516:INFO:Creating metrics dataframe
2024-01-01 23:41:19,526:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:41:19,526:INFO:Total runtime is 0.36775554418563844 minutes
2024-01-01 23:41:19,529:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:19,529:INFO:Initializing create_model()
2024-01-01 23:41:19,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:19,529:INFO:Checking exceptions
2024-01-01 23:41:19,529:INFO:Importing libraries
2024-01-01 23:41:19,530:INFO:Copying training dataset
2024-01-01 23:41:19,539:INFO:Defining folds
2024-01-01 23:41:19,539:INFO:Declaring metric variables
2024-01-01 23:41:19,542:INFO:Importing untrained model
2024-01-01 23:41:19,546:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:41:19,553:INFO:Starting cross validation
2024-01-01 23:41:19,555:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:22,786:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:22,951:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,033:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,069:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,106:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,213:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,246:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,302:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,442:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,516:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:41:23,538:INFO:Calculating mean and std
2024-01-01 23:41:23,541:INFO:Creating metrics dataframe
2024-01-01 23:41:23,548:INFO:Uploading results into container
2024-01-01 23:41:23,549:INFO:Uploading model into container now
2024-01-01 23:41:23,550:INFO:_master_model_container: 5
2024-01-01 23:41:23,550:INFO:_display_container: 2
2024-01-01 23:41:23,551:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:41:23,551:INFO:create_model() successfully completed......................................
2024-01-01 23:41:23,851:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:23,851:INFO:Creating metrics dataframe
2024-01-01 23:41:23,862:INFO:Initializing Ridge Classifier
2024-01-01 23:41:23,862:INFO:Total runtime is 0.4400139609972636 minutes
2024-01-01 23:41:23,865:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:23,866:INFO:Initializing create_model()
2024-01-01 23:41:23,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:23,866:INFO:Checking exceptions
2024-01-01 23:41:23,866:INFO:Importing libraries
2024-01-01 23:41:23,866:INFO:Copying training dataset
2024-01-01 23:41:23,875:INFO:Defining folds
2024-01-01 23:41:23,876:INFO:Declaring metric variables
2024-01-01 23:41:23,879:INFO:Importing untrained model
2024-01-01 23:41:23,883:INFO:Ridge Classifier Imported successfully
2024-01-01 23:41:23,889:INFO:Starting cross validation
2024-01-01 23:41:23,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:25,363:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,371:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,376:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,397:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,399:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,413:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,429:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,433:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,435:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,437:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:41:25,457:INFO:Calculating mean and std
2024-01-01 23:41:25,458:INFO:Creating metrics dataframe
2024-01-01 23:41:25,462:INFO:Uploading results into container
2024-01-01 23:41:25,463:INFO:Uploading model into container now
2024-01-01 23:41:25,464:INFO:_master_model_container: 6
2024-01-01 23:41:25,464:INFO:_display_container: 2
2024-01-01 23:41:25,464:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:41:25,464:INFO:create_model() successfully completed......................................
2024-01-01 23:41:25,767:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:25,768:INFO:Creating metrics dataframe
2024-01-01 23:41:25,778:INFO:Initializing Random Forest Classifier
2024-01-01 23:41:25,778:INFO:Total runtime is 0.4719442129135132 minutes
2024-01-01 23:41:25,781:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:25,781:INFO:Initializing create_model()
2024-01-01 23:41:25,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:25,781:INFO:Checking exceptions
2024-01-01 23:41:25,781:INFO:Importing libraries
2024-01-01 23:41:25,781:INFO:Copying training dataset
2024-01-01 23:41:25,791:INFO:Defining folds
2024-01-01 23:41:25,791:INFO:Declaring metric variables
2024-01-01 23:41:25,794:INFO:Importing untrained model
2024-01-01 23:41:25,798:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:41:25,805:INFO:Starting cross validation
2024-01-01 23:41:25,807:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:29,486:INFO:Calculating mean and std
2024-01-01 23:41:29,488:INFO:Creating metrics dataframe
2024-01-01 23:41:29,493:INFO:Uploading results into container
2024-01-01 23:41:29,494:INFO:Uploading model into container now
2024-01-01 23:41:29,494:INFO:_master_model_container: 7
2024-01-01 23:41:29,495:INFO:_display_container: 2
2024-01-01 23:41:29,495:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:41:29,495:INFO:create_model() successfully completed......................................
2024-01-01 23:41:29,908:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:29,909:INFO:Creating metrics dataframe
2024-01-01 23:41:29,929:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:41:29,929:INFO:Total runtime is 0.5411344766616821 minutes
2024-01-01 23:41:29,934:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:29,934:INFO:Initializing create_model()
2024-01-01 23:41:29,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:29,935:INFO:Checking exceptions
2024-01-01 23:41:29,935:INFO:Importing libraries
2024-01-01 23:41:29,935:INFO:Copying training dataset
2024-01-01 23:41:29,953:INFO:Defining folds
2024-01-01 23:41:29,953:INFO:Declaring metric variables
2024-01-01 23:41:29,959:INFO:Importing untrained model
2024-01-01 23:41:29,964:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:41:29,973:INFO:Starting cross validation
2024-01-01 23:41:29,976:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:31,578:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,603:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,617:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,618:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,631:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,721:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,728:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,761:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,763:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:41:31,971:INFO:Calculating mean and std
2024-01-01 23:41:31,972:INFO:Creating metrics dataframe
2024-01-01 23:41:31,976:INFO:Uploading results into container
2024-01-01 23:41:31,977:INFO:Uploading model into container now
2024-01-01 23:41:31,977:INFO:_master_model_container: 8
2024-01-01 23:41:31,978:INFO:_display_container: 2
2024-01-01 23:41:31,978:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:41:31,978:INFO:create_model() successfully completed......................................
2024-01-01 23:41:32,285:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:32,285:INFO:Creating metrics dataframe
2024-01-01 23:41:32,296:INFO:Initializing Ada Boost Classifier
2024-01-01 23:41:32,296:INFO:Total runtime is 0.5805867155392964 minutes
2024-01-01 23:41:32,299:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:32,299:INFO:Initializing create_model()
2024-01-01 23:41:32,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:32,299:INFO:Checking exceptions
2024-01-01 23:41:32,299:INFO:Importing libraries
2024-01-01 23:41:32,300:INFO:Copying training dataset
2024-01-01 23:41:32,309:INFO:Defining folds
2024-01-01 23:41:32,310:INFO:Declaring metric variables
2024-01-01 23:41:32,314:INFO:Importing untrained model
2024-01-01 23:41:32,319:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:41:32,326:INFO:Starting cross validation
2024-01-01 23:41:32,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:33,963:INFO:Calculating mean and std
2024-01-01 23:41:33,965:INFO:Creating metrics dataframe
2024-01-01 23:41:33,972:INFO:Uploading results into container
2024-01-01 23:41:33,973:INFO:Uploading model into container now
2024-01-01 23:41:33,973:INFO:_master_model_container: 9
2024-01-01 23:41:33,974:INFO:_display_container: 2
2024-01-01 23:41:33,974:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:41:33,974:INFO:create_model() successfully completed......................................
2024-01-01 23:41:34,552:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:34,552:INFO:Creating metrics dataframe
2024-01-01 23:41:34,569:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:41:34,569:INFO:Total runtime is 0.6184736212094625 minutes
2024-01-01 23:41:34,576:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:34,577:INFO:Initializing create_model()
2024-01-01 23:41:34,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:34,577:INFO:Checking exceptions
2024-01-01 23:41:34,577:INFO:Importing libraries
2024-01-01 23:41:34,578:INFO:Copying training dataset
2024-01-01 23:41:34,593:INFO:Defining folds
2024-01-01 23:41:34,593:INFO:Declaring metric variables
2024-01-01 23:41:34,599:INFO:Importing untrained model
2024-01-01 23:41:34,606:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:41:34,617:INFO:Starting cross validation
2024-01-01 23:41:34,621:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:39,174:INFO:Calculating mean and std
2024-01-01 23:41:39,175:INFO:Creating metrics dataframe
2024-01-01 23:41:39,179:INFO:Uploading results into container
2024-01-01 23:41:39,180:INFO:Uploading model into container now
2024-01-01 23:41:39,180:INFO:_master_model_container: 10
2024-01-01 23:41:39,180:INFO:_display_container: 2
2024-01-01 23:41:39,181:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:41:39,181:INFO:create_model() successfully completed......................................
2024-01-01 23:41:39,499:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:39,499:INFO:Creating metrics dataframe
2024-01-01 23:41:39,511:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:41:39,512:INFO:Total runtime is 0.7008497714996338 minutes
2024-01-01 23:41:39,515:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:39,515:INFO:Initializing create_model()
2024-01-01 23:41:39,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:39,515:INFO:Checking exceptions
2024-01-01 23:41:39,515:INFO:Importing libraries
2024-01-01 23:41:39,515:INFO:Copying training dataset
2024-01-01 23:41:39,524:INFO:Defining folds
2024-01-01 23:41:39,525:INFO:Declaring metric variables
2024-01-01 23:41:39,528:INFO:Importing untrained model
2024-01-01 23:41:39,532:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:41:39,541:INFO:Starting cross validation
2024-01-01 23:41:39,543:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:41,853:INFO:Calculating mean and std
2024-01-01 23:41:41,854:INFO:Creating metrics dataframe
2024-01-01 23:41:41,858:INFO:Uploading results into container
2024-01-01 23:41:41,859:INFO:Uploading model into container now
2024-01-01 23:41:41,859:INFO:_master_model_container: 11
2024-01-01 23:41:41,859:INFO:_display_container: 2
2024-01-01 23:41:41,860:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:41:41,860:INFO:create_model() successfully completed......................................
2024-01-01 23:41:42,146:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:42,146:INFO:Creating metrics dataframe
2024-01-01 23:41:42,158:INFO:Initializing Extra Trees Classifier
2024-01-01 23:41:42,158:INFO:Total runtime is 0.7449503262837728 minutes
2024-01-01 23:41:42,161:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:42,162:INFO:Initializing create_model()
2024-01-01 23:41:42,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:42,162:INFO:Checking exceptions
2024-01-01 23:41:42,162:INFO:Importing libraries
2024-01-01 23:41:42,162:INFO:Copying training dataset
2024-01-01 23:41:42,171:INFO:Defining folds
2024-01-01 23:41:42,171:INFO:Declaring metric variables
2024-01-01 23:41:42,174:INFO:Importing untrained model
2024-01-01 23:41:42,177:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:41:42,185:INFO:Starting cross validation
2024-01-01 23:41:42,187:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:45,347:INFO:Calculating mean and std
2024-01-01 23:41:45,348:INFO:Creating metrics dataframe
2024-01-01 23:41:45,352:INFO:Uploading results into container
2024-01-01 23:41:45,352:INFO:Uploading model into container now
2024-01-01 23:41:45,353:INFO:_master_model_container: 12
2024-01-01 23:41:45,353:INFO:_display_container: 2
2024-01-01 23:41:45,353:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:41:45,353:INFO:create_model() successfully completed......................................
2024-01-01 23:41:45,638:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:45,638:INFO:Creating metrics dataframe
2024-01-01 23:41:45,649:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:41:45,649:INFO:Total runtime is 0.8031324307123819 minutes
2024-01-01 23:41:45,652:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:45,653:INFO:Initializing create_model()
2024-01-01 23:41:45,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:45,653:INFO:Checking exceptions
2024-01-01 23:41:45,653:INFO:Importing libraries
2024-01-01 23:41:45,653:INFO:Copying training dataset
2024-01-01 23:41:45,661:INFO:Defining folds
2024-01-01 23:41:45,662:INFO:Declaring metric variables
2024-01-01 23:41:45,665:INFO:Importing untrained model
2024-01-01 23:41:45,669:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:41:45,675:INFO:Starting cross validation
2024-01-01 23:41:45,677:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:48,088:INFO:Calculating mean and std
2024-01-01 23:41:48,090:INFO:Creating metrics dataframe
2024-01-01 23:41:48,096:INFO:Uploading results into container
2024-01-01 23:41:48,097:INFO:Uploading model into container now
2024-01-01 23:41:48,098:INFO:_master_model_container: 13
2024-01-01 23:41:48,098:INFO:_display_container: 2
2024-01-01 23:41:48,099:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:41:48,099:INFO:create_model() successfully completed......................................
2024-01-01 23:41:48,439:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:48,439:INFO:Creating metrics dataframe
2024-01-01 23:41:48,450:INFO:Initializing Dummy Classifier
2024-01-01 23:41:48,450:INFO:Total runtime is 0.8498092452685038 minutes
2024-01-01 23:41:48,453:INFO:SubProcess create_model() called ==================================
2024-01-01 23:41:48,453:INFO:Initializing create_model()
2024-01-01 23:41:48,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FA30C1E10>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:48,453:INFO:Checking exceptions
2024-01-01 23:41:48,454:INFO:Importing libraries
2024-01-01 23:41:48,454:INFO:Copying training dataset
2024-01-01 23:41:48,463:INFO:Defining folds
2024-01-01 23:41:48,463:INFO:Declaring metric variables
2024-01-01 23:41:48,466:INFO:Importing untrained model
2024-01-01 23:41:48,470:INFO:Dummy Classifier Imported successfully
2024-01-01 23:41:48,477:INFO:Starting cross validation
2024-01-01 23:41:48,480:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:41:49,776:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,796:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,799:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,832:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,849:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,852:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,852:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,866:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,868:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,873:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:41:49,882:INFO:Calculating mean and std
2024-01-01 23:41:49,883:INFO:Creating metrics dataframe
2024-01-01 23:41:49,887:INFO:Uploading results into container
2024-01-01 23:41:49,888:INFO:Uploading model into container now
2024-01-01 23:41:49,888:INFO:_master_model_container: 14
2024-01-01 23:41:49,888:INFO:_display_container: 2
2024-01-01 23:41:49,889:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:41:49,889:INFO:create_model() successfully completed......................................
2024-01-01 23:41:50,193:INFO:SubProcess create_model() end ==================================
2024-01-01 23:41:50,193:INFO:Creating metrics dataframe
2024-01-01 23:41:50,213:INFO:Initializing create_model()
2024-01-01 23:41:50,213:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:41:50,213:INFO:Checking exceptions
2024-01-01 23:41:50,216:INFO:Importing libraries
2024-01-01 23:41:50,216:INFO:Copying training dataset
2024-01-01 23:41:50,225:INFO:Defining folds
2024-01-01 23:41:50,225:INFO:Declaring metric variables
2024-01-01 23:41:50,226:INFO:Importing untrained model
2024-01-01 23:41:50,226:INFO:Declaring custom model
2024-01-01 23:41:50,226:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:41:50,228:INFO:Cross validation set to False
2024-01-01 23:41:50,228:INFO:Fitting Model
2024-01-01 23:41:50,539:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:41:50,539:INFO:create_model() successfully completed......................................
2024-01-01 23:41:50,841:INFO:_master_model_container: 14
2024-01-01 23:41:50,841:INFO:_display_container: 2
2024-01-01 23:41:50,841:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:41:50,841:INFO:compare_models() successfully completed......................................
2024-01-01 23:41:51,021:INFO:Initializing plot_model()
2024-01-01 23:41:51,021:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, system=True)
2024-01-01 23:41:51,021:INFO:Checking exceptions
2024-01-01 23:41:51,031:INFO:Preloading libraries
2024-01-01 23:41:51,031:INFO:Copying training dataset
2024-01-01 23:41:51,032:INFO:Plot type: auc
2024-01-01 23:41:51,335:INFO:Fitting Model
2024-01-01 23:41:51,335:INFO:Scoring test/hold-out set
2024-01-01 23:41:51,523:INFO:Visual Rendered Successfully
2024-01-01 23:41:51,818:INFO:plot_model() successfully completed......................................
2024-01-01 23:41:51,871:INFO:Initializing plot_model()
2024-01-01 23:41:51,871:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, system=True)
2024-01-01 23:41:51,871:INFO:Checking exceptions
2024-01-01 23:41:51,877:INFO:Preloading libraries
2024-01-01 23:41:51,878:INFO:Copying training dataset
2024-01-01 23:41:51,878:INFO:Plot type: confusion_matrix
2024-01-01 23:41:52,167:INFO:Fitting Model
2024-01-01 23:41:52,167:INFO:Scoring test/hold-out set
2024-01-01 23:41:52,271:INFO:Visual Rendered Successfully
2024-01-01 23:41:52,568:INFO:plot_model() successfully completed......................................
2024-01-01 23:41:52,599:INFO:Initializing plot_model()
2024-01-01 23:41:52,599:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, system=True)
2024-01-01 23:41:52,599:INFO:Checking exceptions
2024-01-01 23:41:52,605:INFO:Preloading libraries
2024-01-01 23:41:52,606:INFO:Copying training dataset
2024-01-01 23:41:52,606:INFO:Plot type: class_report
2024-01-01 23:41:52,902:INFO:Fitting Model
2024-01-01 23:41:52,902:INFO:Scoring test/hold-out set
2024-01-01 23:41:53,102:INFO:Visual Rendered Successfully
2024-01-01 23:41:53,399:INFO:plot_model() successfully completed......................................
2024-01-01 23:41:53,427:INFO:Initializing tune_model()
2024-01-01 23:41:53,428:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>)
2024-01-01 23:41:53,428:INFO:Checking exceptions
2024-01-01 23:41:53,450:INFO:Copying training dataset
2024-01-01 23:41:53,456:INFO:Checking base model
2024-01-01 23:41:53,457:INFO:Base model : Decision Tree Classifier
2024-01-01 23:41:53,460:INFO:Declaring metric variables
2024-01-01 23:41:53,464:INFO:Defining Hyperparameters
2024-01-01 23:41:53,818:INFO:Tuning with n_jobs=-1
2024-01-01 23:41:53,818:INFO:Initializing RandomizedSearchCV
2024-01-01 23:42:08,477:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2024-01-01 23:42:08,478:INFO:Hyperparameter search completed
2024-01-01 23:42:08,478:INFO:SubProcess create_model() called ==================================
2024-01-01 23:42:08,479:INFO:Initializing create_model()
2024-01-01 23:42:08,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020F8D7B5630>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2024-01-01 23:42:08,479:INFO:Checking exceptions
2024-01-01 23:42:08,480:INFO:Importing libraries
2024-01-01 23:42:08,480:INFO:Copying training dataset
2024-01-01 23:42:08,490:INFO:Defining folds
2024-01-01 23:42:08,490:INFO:Declaring metric variables
2024-01-01 23:42:08,494:INFO:Importing untrained model
2024-01-01 23:42:08,494:INFO:Declaring custom model
2024-01-01 23:42:08,498:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:42:08,505:INFO:Starting cross validation
2024-01-01 23:42:08,507:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:42:09,997:INFO:Calculating mean and std
2024-01-01 23:42:09,998:INFO:Creating metrics dataframe
2024-01-01 23:42:10,005:INFO:Finalizing model
2024-01-01 23:42:10,363:INFO:Uploading results into container
2024-01-01 23:42:10,364:INFO:Uploading model into container now
2024-01-01 23:42:10,364:INFO:_master_model_container: 15
2024-01-01 23:42:10,365:INFO:_display_container: 3
2024-01-01 23:42:10,365:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:42:10,365:INFO:create_model() successfully completed......................................
2024-01-01 23:42:10,696:INFO:SubProcess create_model() end ==================================
2024-01-01 23:42:10,696:INFO:choose_better activated
2024-01-01 23:42:10,699:INFO:SubProcess create_model() called ==================================
2024-01-01 23:42:10,700:INFO:Initializing create_model()
2024-01-01 23:42:10,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:42:10,700:INFO:Checking exceptions
2024-01-01 23:42:10,701:INFO:Importing libraries
2024-01-01 23:42:10,701:INFO:Copying training dataset
2024-01-01 23:42:10,710:INFO:Defining folds
2024-01-01 23:42:10,710:INFO:Declaring metric variables
2024-01-01 23:42:10,710:INFO:Importing untrained model
2024-01-01 23:42:10,710:INFO:Declaring custom model
2024-01-01 23:42:10,711:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:42:10,711:INFO:Starting cross validation
2024-01-01 23:42:10,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:42:12,182:INFO:Calculating mean and std
2024-01-01 23:42:12,184:INFO:Creating metrics dataframe
2024-01-01 23:42:12,192:INFO:Finalizing model
2024-01-01 23:42:12,575:INFO:Uploading results into container
2024-01-01 23:42:12,575:INFO:Uploading model into container now
2024-01-01 23:42:12,576:INFO:_master_model_container: 16
2024-01-01 23:42:12,576:INFO:_display_container: 4
2024-01-01 23:42:12,576:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:42:12,576:INFO:create_model() successfully completed......................................
2024-01-01 23:42:12,877:INFO:SubProcess create_model() end ==================================
2024-01-01 23:42:12,971:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 1.0
2024-01-01 23:42:12,972:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 1.0
2024-01-01 23:42:12,972:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') is best model
2024-01-01 23:42:12,972:INFO:choose_better completed
2024-01-01 23:42:12,972:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-01 23:42:12,982:INFO:_master_model_container: 16
2024-01-01 23:42:12,983:INFO:_display_container: 3
2024-01-01 23:42:12,983:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:42:12,983:INFO:tune_model() successfully completed......................................
2024-01-01 23:42:13,546:INFO:Initializing plot_model()
2024-01-01 23:42:13,546:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, system=True)
2024-01-01 23:42:13,546:INFO:Checking exceptions
2024-01-01 23:42:13,553:INFO:Preloading libraries
2024-01-01 23:42:13,554:INFO:Copying training dataset
2024-01-01 23:42:13,554:INFO:Plot type: auc
2024-01-01 23:42:13,839:INFO:Fitting Model
2024-01-01 23:42:13,840:INFO:Scoring test/hold-out set
2024-01-01 23:42:14,043:INFO:Visual Rendered Successfully
2024-01-01 23:42:14,347:INFO:plot_model() successfully completed......................................
2024-01-01 23:42:14,384:INFO:Initializing plot_model()
2024-01-01 23:42:14,384:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, system=True)
2024-01-01 23:42:14,384:INFO:Checking exceptions
2024-01-01 23:42:14,390:INFO:Preloading libraries
2024-01-01 23:42:14,391:INFO:Copying training dataset
2024-01-01 23:42:14,391:INFO:Plot type: confusion_matrix
2024-01-01 23:42:14,519:INFO:Fitting Model
2024-01-01 23:42:14,520:INFO:Scoring test/hold-out set
2024-01-01 23:42:14,632:INFO:Visual Rendered Successfully
2024-01-01 23:42:14,932:INFO:plot_model() successfully completed......................................
2024-01-01 23:42:14,962:INFO:Initializing plot_model()
2024-01-01 23:42:14,962:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, system=True)
2024-01-01 23:42:14,962:INFO:Checking exceptions
2024-01-01 23:42:14,967:INFO:Preloading libraries
2024-01-01 23:42:14,967:INFO:Copying training dataset
2024-01-01 23:42:14,968:INFO:Plot type: class_report
2024-01-01 23:42:15,085:INFO:Fitting Model
2024-01-01 23:42:15,085:INFO:Scoring test/hold-out set
2024-01-01 23:42:15,282:INFO:Visual Rendered Successfully
2024-01-01 23:42:15,578:INFO:plot_model() successfully completed......................................
2024-01-01 23:42:15,622:INFO:Initializing finalize_model()
2024-01-01 23:42:15,623:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-01 23:42:15,624:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:42:15,628:INFO:Initializing create_model()
2024-01-01 23:42:15,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-01 23:42:15,628:INFO:Checking exceptions
2024-01-01 23:42:15,630:INFO:Importing libraries
2024-01-01 23:42:15,630:INFO:Copying training dataset
2024-01-01 23:42:15,631:INFO:Defining folds
2024-01-01 23:42:15,631:INFO:Declaring metric variables
2024-01-01 23:42:15,631:INFO:Importing untrained model
2024-01-01 23:42:15,631:INFO:Declaring custom model
2024-01-01 23:42:15,632:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:42:15,633:INFO:Cross validation set to False
2024-01-01 23:42:15,633:INFO:Fitting Model
2024-01-01 23:42:16,084:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                (...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2024-01-01 23:42:16,084:INFO:create_model() successfully completed......................................
2024-01-01 23:42:16,460:INFO:_master_model_container: 16
2024-01-01 23:42:16,460:INFO:_display_container: 3
2024-01-01 23:42:16,497:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                (...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2024-01-01 23:42:16,497:INFO:finalize_model() successfully completed......................................
2024-01-01 23:42:17,020:INFO:Initializing predict_model()
2024-01-01 23:42:17,492:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FA309F5B0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                (...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020FA99F7880>)
2024-01-01 23:42:17,492:INFO:Checking exceptions
2024-01-01 23:42:17,492:INFO:Preloading libraries
2024-01-01 23:42:17,494:INFO:Set up data.
2024-01-01 23:42:17,535:INFO:Set up index.
2024-01-01 23:44:48,266:INFO:PyCaret ClassificationExperiment
2024-01-01 23:44:48,267:INFO:Logging name: clf-default-name
2024-01-01 23:44:48,267:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:44:48,267:INFO:version 3.1.0
2024-01-01 23:44:48,267:INFO:Initializing setup()
2024-01-01 23:44:48,267:INFO:self.USI: 7f8a
2024-01-01 23:44:48,267:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:44:48,267:INFO:Checking environment
2024-01-01 23:44:48,267:INFO:python_version: 3.10.9
2024-01-01 23:44:48,267:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:44:48,267:INFO:machine: AMD64
2024-01-01 23:44:48,267:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:44:48,267:INFO:Memory: svmem(total=16954372096, available=2297462784, percent=86.4, used=14656909312, free=2297462784)
2024-01-01 23:44:48,267:INFO:Physical Core: 8
2024-01-01 23:44:48,267:INFO:Logical Core: 16
2024-01-01 23:44:48,267:INFO:Checking libraries
2024-01-01 23:44:48,268:INFO:System:
2024-01-01 23:44:48,268:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:44:48,268:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:44:48,268:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:44:48,268:INFO:PyCaret required dependencies:
2024-01-01 23:44:48,268:INFO:                 pip: 22.3.1
2024-01-01 23:44:48,268:INFO:          setuptools: 65.6.3
2024-01-01 23:44:48,268:INFO:             pycaret: 3.1.0
2024-01-01 23:44:48,268:INFO:             IPython: 8.10.0
2024-01-01 23:44:48,268:INFO:          ipywidgets: 7.6.5
2024-01-01 23:44:48,268:INFO:                tqdm: 4.64.1
2024-01-01 23:44:48,268:INFO:               numpy: 1.23.5
2024-01-01 23:44:48,268:INFO:              pandas: 1.5.3
2024-01-01 23:44:48,268:INFO:              jinja2: 3.1.2
2024-01-01 23:44:48,268:INFO:               scipy: 1.10.1
2024-01-01 23:44:48,268:INFO:              joblib: 1.3.2
2024-01-01 23:44:48,268:INFO:             sklearn: 1.2.1
2024-01-01 23:44:48,268:INFO:                pyod: 1.1.0
2024-01-01 23:44:48,268:INFO:            imblearn: 0.10.1
2024-01-01 23:44:48,268:INFO:   category_encoders: 2.6.2
2024-01-01 23:44:48,268:INFO:            lightgbm: 4.1.0
2024-01-01 23:44:48,268:INFO:               numba: 0.56.4
2024-01-01 23:44:48,269:INFO:            requests: 2.28.1
2024-01-01 23:44:48,269:INFO:          matplotlib: 3.7.0
2024-01-01 23:44:48,269:INFO:          scikitplot: 0.3.7
2024-01-01 23:44:48,269:INFO:         yellowbrick: 1.5
2024-01-01 23:44:48,269:INFO:              plotly: 5.9.0
2024-01-01 23:44:48,269:INFO:    plotly-resampler: Not installed
2024-01-01 23:44:48,269:INFO:             kaleido: 0.2.1
2024-01-01 23:44:48,269:INFO:           schemdraw: 0.15
2024-01-01 23:44:48,269:INFO:         statsmodels: 0.13.5
2024-01-01 23:44:48,269:INFO:              sktime: 0.21.1
2024-01-01 23:44:48,269:INFO:               tbats: 1.1.3
2024-01-01 23:44:48,269:INFO:            pmdarima: 2.0.3
2024-01-01 23:44:48,269:INFO:              psutil: 5.9.0
2024-01-01 23:44:48,269:INFO:          markupsafe: 2.1.1
2024-01-01 23:44:48,269:INFO:             pickle5: Not installed
2024-01-01 23:44:48,269:INFO:         cloudpickle: 2.0.0
2024-01-01 23:44:48,269:INFO:         deprecation: 2.1.0
2024-01-01 23:44:48,269:INFO:              xxhash: 3.4.1
2024-01-01 23:44:48,269:INFO:           wurlitzer: Not installed
2024-01-01 23:44:48,269:INFO:PyCaret optional dependencies:
2024-01-01 23:44:48,269:INFO:                shap: Not installed
2024-01-01 23:44:48,269:INFO:           interpret: Not installed
2024-01-01 23:44:48,269:INFO:                umap: Not installed
2024-01-01 23:44:48,269:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:44:48,270:INFO:  explainerdashboard: Not installed
2024-01-01 23:44:48,270:INFO:             autoviz: Not installed
2024-01-01 23:44:48,270:INFO:           fairlearn: Not installed
2024-01-01 23:44:48,270:INFO:          deepchecks: Not installed
2024-01-01 23:44:48,270:INFO:             xgboost: Not installed
2024-01-01 23:44:48,270:INFO:            catboost: Not installed
2024-01-01 23:44:48,270:INFO:              kmodes: Not installed
2024-01-01 23:44:48,270:INFO:             mlxtend: Not installed
2024-01-01 23:44:48,270:INFO:       statsforecast: Not installed
2024-01-01 23:44:48,270:INFO:        tune_sklearn: Not installed
2024-01-01 23:44:48,270:INFO:                 ray: Not installed
2024-01-01 23:44:48,270:INFO:            hyperopt: Not installed
2024-01-01 23:44:48,270:INFO:              optuna: Not installed
2024-01-01 23:44:48,270:INFO:               skopt: Not installed
2024-01-01 23:44:48,270:INFO:              mlflow: Not installed
2024-01-01 23:44:48,270:INFO:              gradio: Not installed
2024-01-01 23:44:48,270:INFO:             fastapi: Not installed
2024-01-01 23:44:48,270:INFO:             uvicorn: Not installed
2024-01-01 23:44:48,270:INFO:              m2cgen: Not installed
2024-01-01 23:44:48,270:INFO:           evidently: Not installed
2024-01-01 23:44:48,270:INFO:               fugue: Not installed
2024-01-01 23:44:48,270:INFO:           streamlit: Not installed
2024-01-01 23:44:48,270:INFO:             prophet: Not installed
2024-01-01 23:44:48,270:INFO:None
2024-01-01 23:44:48,271:INFO:Set up data.
2024-01-01 23:44:48,330:INFO:Set up folding strategy.
2024-01-01 23:44:48,331:INFO:Set up train/test split.
2024-01-01 23:44:48,344:INFO:Set up index.
2024-01-01 23:44:48,345:INFO:Assigning column types.
2024-01-01 23:44:48,349:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:44:48,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:44:48,390:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:44:48,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:44:48,456:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:44:48,481:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,482:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:44:48,522:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:44:48,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,589:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:44:48,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,615:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:44:48,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,683:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:48,749:INFO:Preparing preprocessing pipeline...
2024-01-01 23:44:48,750:INFO:Set up simple imputation.
2024-01-01 23:44:48,757:INFO:Set up encoding of ordinal features.
2024-01-01 23:44:48,762:INFO:Set up encoding of categorical features.
2024-01-01 23:44:48,764:INFO:Set up column name cleaning.
2024-01-01 23:44:49,145:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:44:49,178:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              s...
                 TransformerWrapper(exclude=None, include=['country'],
                                    transformer=TargetEncoder(cols=['country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:44:49,178:INFO:Creating final display dataframe.
2024-01-01 23:44:49,289:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 14)
4        Transformed data shape       (31978, 38)
5   Transformed train set shape       (25582, 38)
6    Transformed test set shape        (6396, 38)
7              Ordinal features                 3
8              Numeric features                 6
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              7f8a
2024-01-01 23:44:49,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:49,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:49,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:49,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:44:49,433:INFO:setup() successfully completed in 1.17s...............
2024-01-01 23:44:49,470:INFO:Initializing compare_models()
2024-01-01 23:44:49,471:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:44:49,471:INFO:Checking exceptions
2024-01-01 23:44:49,478:INFO:Preparing display monitor
2024-01-01 23:44:49,503:INFO:Initializing Logistic Regression
2024-01-01 23:44:49,503:INFO:Total runtime is 0.0 minutes
2024-01-01 23:44:49,506:INFO:SubProcess create_model() called ==================================
2024-01-01 23:44:49,506:INFO:Initializing create_model()
2024-01-01 23:44:49,507:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:44:49,507:INFO:Checking exceptions
2024-01-01 23:44:49,507:INFO:Importing libraries
2024-01-01 23:44:49,507:INFO:Copying training dataset
2024-01-01 23:44:49,515:INFO:Defining folds
2024-01-01 23:44:49,515:INFO:Declaring metric variables
2024-01-01 23:44:49,518:INFO:Importing untrained model
2024-01-01 23:44:49,521:INFO:Logistic Regression Imported successfully
2024-01-01 23:44:49,529:INFO:Starting cross validation
2024-01-01 23:44:49,532:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:44:52,345:INFO:Calculating mean and std
2024-01-01 23:44:52,347:INFO:Creating metrics dataframe
2024-01-01 23:44:52,350:INFO:Uploading results into container
2024-01-01 23:44:52,350:INFO:Uploading model into container now
2024-01-01 23:44:52,351:INFO:_master_model_container: 1
2024-01-01 23:44:52,351:INFO:_display_container: 2
2024-01-01 23:44:52,351:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:44:52,351:INFO:create_model() successfully completed......................................
2024-01-01 23:44:52,736:INFO:SubProcess create_model() end ==================================
2024-01-01 23:44:52,736:INFO:Creating metrics dataframe
2024-01-01 23:44:52,745:INFO:Initializing K Neighbors Classifier
2024-01-01 23:44:52,745:INFO:Total runtime is 0.054031399885813396 minutes
2024-01-01 23:44:52,749:INFO:SubProcess create_model() called ==================================
2024-01-01 23:44:52,749:INFO:Initializing create_model()
2024-01-01 23:44:52,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:44:52,750:INFO:Checking exceptions
2024-01-01 23:44:52,750:INFO:Importing libraries
2024-01-01 23:44:52,750:INFO:Copying training dataset
2024-01-01 23:44:52,759:INFO:Defining folds
2024-01-01 23:44:52,759:INFO:Declaring metric variables
2024-01-01 23:44:52,763:INFO:Importing untrained model
2024-01-01 23:44:52,767:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:44:52,773:INFO:Starting cross validation
2024-01-01 23:44:52,775:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:44:55,748:INFO:Calculating mean and std
2024-01-01 23:44:55,749:INFO:Creating metrics dataframe
2024-01-01 23:44:55,753:INFO:Uploading results into container
2024-01-01 23:44:55,753:INFO:Uploading model into container now
2024-01-01 23:44:55,754:INFO:_master_model_container: 2
2024-01-01 23:44:55,754:INFO:_display_container: 2
2024-01-01 23:44:55,754:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:44:55,754:INFO:create_model() successfully completed......................................
2024-01-01 23:44:56,066:INFO:SubProcess create_model() end ==================================
2024-01-01 23:44:56,066:INFO:Creating metrics dataframe
2024-01-01 23:44:56,075:INFO:Initializing Naive Bayes
2024-01-01 23:44:56,076:INFO:Total runtime is 0.10953099330266317 minutes
2024-01-01 23:44:56,078:INFO:SubProcess create_model() called ==================================
2024-01-01 23:44:56,079:INFO:Initializing create_model()
2024-01-01 23:44:56,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:44:56,079:INFO:Checking exceptions
2024-01-01 23:44:56,079:INFO:Importing libraries
2024-01-01 23:44:56,079:INFO:Copying training dataset
2024-01-01 23:44:56,089:INFO:Defining folds
2024-01-01 23:44:56,089:INFO:Declaring metric variables
2024-01-01 23:44:56,092:INFO:Importing untrained model
2024-01-01 23:44:56,095:INFO:Naive Bayes Imported successfully
2024-01-01 23:44:56,101:INFO:Starting cross validation
2024-01-01 23:44:56,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:44:57,797:INFO:Calculating mean and std
2024-01-01 23:44:57,798:INFO:Creating metrics dataframe
2024-01-01 23:44:57,801:INFO:Uploading results into container
2024-01-01 23:44:57,802:INFO:Uploading model into container now
2024-01-01 23:44:57,802:INFO:_master_model_container: 3
2024-01-01 23:44:57,802:INFO:_display_container: 2
2024-01-01 23:44:57,802:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:44:57,803:INFO:create_model() successfully completed......................................
2024-01-01 23:44:58,119:INFO:SubProcess create_model() end ==================================
2024-01-01 23:44:58,119:INFO:Creating metrics dataframe
2024-01-01 23:44:58,129:INFO:Initializing Decision Tree Classifier
2024-01-01 23:44:58,129:INFO:Total runtime is 0.14376020034154258 minutes
2024-01-01 23:44:58,132:INFO:SubProcess create_model() called ==================================
2024-01-01 23:44:58,132:INFO:Initializing create_model()
2024-01-01 23:44:58,132:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:44:58,133:INFO:Checking exceptions
2024-01-01 23:44:58,133:INFO:Importing libraries
2024-01-01 23:44:58,133:INFO:Copying training dataset
2024-01-01 23:44:58,141:INFO:Defining folds
2024-01-01 23:44:58,142:INFO:Declaring metric variables
2024-01-01 23:44:58,145:INFO:Importing untrained model
2024-01-01 23:44:58,148:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:44:58,153:INFO:Starting cross validation
2024-01-01 23:44:58,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:44:59,659:INFO:Calculating mean and std
2024-01-01 23:44:59,660:INFO:Creating metrics dataframe
2024-01-01 23:44:59,664:INFO:Uploading results into container
2024-01-01 23:44:59,664:INFO:Uploading model into container now
2024-01-01 23:44:59,665:INFO:_master_model_container: 4
2024-01-01 23:44:59,665:INFO:_display_container: 2
2024-01-01 23:44:59,665:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:44:59,665:INFO:create_model() successfully completed......................................
2024-01-01 23:44:59,995:INFO:SubProcess create_model() end ==================================
2024-01-01 23:44:59,995:INFO:Creating metrics dataframe
2024-01-01 23:45:00,006:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:45:00,006:INFO:Total runtime is 0.17503657738367717 minutes
2024-01-01 23:45:00,011:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:00,012:INFO:Initializing create_model()
2024-01-01 23:45:00,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:00,012:INFO:Checking exceptions
2024-01-01 23:45:00,012:INFO:Importing libraries
2024-01-01 23:45:00,012:INFO:Copying training dataset
2024-01-01 23:45:00,025:INFO:Defining folds
2024-01-01 23:45:00,026:INFO:Declaring metric variables
2024-01-01 23:45:00,030:INFO:Importing untrained model
2024-01-01 23:45:00,034:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:45:00,042:INFO:Starting cross validation
2024-01-01 23:45:00,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:03,903:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,191:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,237:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,259:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,311:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,361:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,413:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,463:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,602:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,701:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:45:04,720:INFO:Calculating mean and std
2024-01-01 23:45:04,723:INFO:Creating metrics dataframe
2024-01-01 23:45:04,730:INFO:Uploading results into container
2024-01-01 23:45:04,731:INFO:Uploading model into container now
2024-01-01 23:45:04,731:INFO:_master_model_container: 5
2024-01-01 23:45:04,732:INFO:_display_container: 2
2024-01-01 23:45:04,732:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:45:04,733:INFO:create_model() successfully completed......................................
2024-01-01 23:45:05,043:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:05,043:INFO:Creating metrics dataframe
2024-01-01 23:45:05,054:INFO:Initializing Ridge Classifier
2024-01-01 23:45:05,054:INFO:Total runtime is 0.25917376279830934 minutes
2024-01-01 23:45:05,057:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:05,057:INFO:Initializing create_model()
2024-01-01 23:45:05,057:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:05,057:INFO:Checking exceptions
2024-01-01 23:45:05,057:INFO:Importing libraries
2024-01-01 23:45:05,057:INFO:Copying training dataset
2024-01-01 23:45:05,067:INFO:Defining folds
2024-01-01 23:45:05,067:INFO:Declaring metric variables
2024-01-01 23:45:05,071:INFO:Importing untrained model
2024-01-01 23:45:05,074:INFO:Ridge Classifier Imported successfully
2024-01-01 23:45:05,080:INFO:Starting cross validation
2024-01-01 23:45:05,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:06,522:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,523:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,524:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,525:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,553:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,554:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,555:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,560:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,576:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,582:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:45:06,604:INFO:Calculating mean and std
2024-01-01 23:45:06,607:INFO:Creating metrics dataframe
2024-01-01 23:45:06,616:INFO:Uploading results into container
2024-01-01 23:45:06,619:INFO:Uploading model into container now
2024-01-01 23:45:06,620:INFO:_master_model_container: 6
2024-01-01 23:45:06,620:INFO:_display_container: 2
2024-01-01 23:45:06,621:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:45:06,621:INFO:create_model() successfully completed......................................
2024-01-01 23:45:06,939:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:06,939:INFO:Creating metrics dataframe
2024-01-01 23:45:06,949:INFO:Initializing Random Forest Classifier
2024-01-01 23:45:06,949:INFO:Total runtime is 0.29076284964879356 minutes
2024-01-01 23:45:06,952:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:06,952:INFO:Initializing create_model()
2024-01-01 23:45:06,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:06,952:INFO:Checking exceptions
2024-01-01 23:45:06,952:INFO:Importing libraries
2024-01-01 23:45:06,952:INFO:Copying training dataset
2024-01-01 23:45:06,961:INFO:Defining folds
2024-01-01 23:45:06,962:INFO:Declaring metric variables
2024-01-01 23:45:06,965:INFO:Importing untrained model
2024-01-01 23:45:06,971:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:45:06,983:INFO:Starting cross validation
2024-01-01 23:45:06,986:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:11,088:INFO:Calculating mean and std
2024-01-01 23:45:11,090:INFO:Creating metrics dataframe
2024-01-01 23:45:11,094:INFO:Uploading results into container
2024-01-01 23:45:11,095:INFO:Uploading model into container now
2024-01-01 23:45:11,096:INFO:_master_model_container: 7
2024-01-01 23:45:11,096:INFO:_display_container: 2
2024-01-01 23:45:11,096:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:45:11,097:INFO:create_model() successfully completed......................................
2024-01-01 23:45:11,536:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:11,536:INFO:Creating metrics dataframe
2024-01-01 23:45:11,547:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:45:11,548:INFO:Total runtime is 0.3674074133237203 minutes
2024-01-01 23:45:11,551:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:11,551:INFO:Initializing create_model()
2024-01-01 23:45:11,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:11,551:INFO:Checking exceptions
2024-01-01 23:45:11,552:INFO:Importing libraries
2024-01-01 23:45:11,552:INFO:Copying training dataset
2024-01-01 23:45:11,562:INFO:Defining folds
2024-01-01 23:45:11,562:INFO:Declaring metric variables
2024-01-01 23:45:11,565:INFO:Importing untrained model
2024-01-01 23:45:11,569:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:45:11,576:INFO:Starting cross validation
2024-01-01 23:45:11,578:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:13,127:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,187:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,205:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,283:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,331:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,349:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,368:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,376:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,384:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,384:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:45:13,609:INFO:Calculating mean and std
2024-01-01 23:45:13,611:INFO:Creating metrics dataframe
2024-01-01 23:45:13,616:INFO:Uploading results into container
2024-01-01 23:45:13,617:INFO:Uploading model into container now
2024-01-01 23:45:13,617:INFO:_master_model_container: 8
2024-01-01 23:45:13,617:INFO:_display_container: 2
2024-01-01 23:45:13,618:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:45:13,618:INFO:create_model() successfully completed......................................
2024-01-01 23:45:13,987:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:13,987:INFO:Creating metrics dataframe
2024-01-01 23:45:13,999:INFO:Initializing Ada Boost Classifier
2024-01-01 23:45:13,999:INFO:Total runtime is 0.40825872818628944 minutes
2024-01-01 23:45:14,003:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:14,003:INFO:Initializing create_model()
2024-01-01 23:45:14,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:14,003:INFO:Checking exceptions
2024-01-01 23:45:14,003:INFO:Importing libraries
2024-01-01 23:45:14,003:INFO:Copying training dataset
2024-01-01 23:45:14,014:INFO:Defining folds
2024-01-01 23:45:14,014:INFO:Declaring metric variables
2024-01-01 23:45:14,018:INFO:Importing untrained model
2024-01-01 23:45:14,023:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:45:14,029:INFO:Starting cross validation
2024-01-01 23:45:14,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:15,772:INFO:Calculating mean and std
2024-01-01 23:45:15,773:INFO:Creating metrics dataframe
2024-01-01 23:45:15,778:INFO:Uploading results into container
2024-01-01 23:45:15,779:INFO:Uploading model into container now
2024-01-01 23:45:15,780:INFO:_master_model_container: 9
2024-01-01 23:45:15,780:INFO:_display_container: 2
2024-01-01 23:45:15,780:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:45:15,780:INFO:create_model() successfully completed......................................
2024-01-01 23:45:16,260:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:16,260:INFO:Creating metrics dataframe
2024-01-01 23:45:16,272:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:45:16,272:INFO:Total runtime is 0.446143356959025 minutes
2024-01-01 23:45:16,276:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:16,276:INFO:Initializing create_model()
2024-01-01 23:45:16,276:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:16,276:INFO:Checking exceptions
2024-01-01 23:45:16,276:INFO:Importing libraries
2024-01-01 23:45:16,277:INFO:Copying training dataset
2024-01-01 23:45:16,286:INFO:Defining folds
2024-01-01 23:45:16,286:INFO:Declaring metric variables
2024-01-01 23:45:16,290:INFO:Importing untrained model
2024-01-01 23:45:16,294:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:45:16,301:INFO:Starting cross validation
2024-01-01 23:45:16,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:20,458:INFO:Calculating mean and std
2024-01-01 23:45:20,460:INFO:Creating metrics dataframe
2024-01-01 23:45:20,466:INFO:Uploading results into container
2024-01-01 23:45:20,467:INFO:Uploading model into container now
2024-01-01 23:45:20,467:INFO:_master_model_container: 10
2024-01-01 23:45:20,467:INFO:_display_container: 2
2024-01-01 23:45:20,468:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:45:20,468:INFO:create_model() successfully completed......................................
2024-01-01 23:45:21,134:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:21,134:INFO:Creating metrics dataframe
2024-01-01 23:45:21,148:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:45:21,148:INFO:Total runtime is 0.5274129668871561 minutes
2024-01-01 23:45:21,152:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:21,153:INFO:Initializing create_model()
2024-01-01 23:45:21,153:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:21,153:INFO:Checking exceptions
2024-01-01 23:45:21,153:INFO:Importing libraries
2024-01-01 23:45:21,153:INFO:Copying training dataset
2024-01-01 23:45:21,163:INFO:Defining folds
2024-01-01 23:45:21,164:INFO:Declaring metric variables
2024-01-01 23:45:21,167:INFO:Importing untrained model
2024-01-01 23:45:21,171:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:45:21,178:INFO:Starting cross validation
2024-01-01 23:45:21,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:23,634:INFO:Calculating mean and std
2024-01-01 23:45:23,635:INFO:Creating metrics dataframe
2024-01-01 23:45:23,640:INFO:Uploading results into container
2024-01-01 23:45:23,640:INFO:Uploading model into container now
2024-01-01 23:45:23,641:INFO:_master_model_container: 11
2024-01-01 23:45:23,641:INFO:_display_container: 2
2024-01-01 23:45:23,641:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:45:23,642:INFO:create_model() successfully completed......................................
2024-01-01 23:45:23,982:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:23,982:INFO:Creating metrics dataframe
2024-01-01 23:45:23,993:INFO:Initializing Extra Trees Classifier
2024-01-01 23:45:23,993:INFO:Total runtime is 0.5748273571332295 minutes
2024-01-01 23:45:23,996:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:23,997:INFO:Initializing create_model()
2024-01-01 23:45:23,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:23,997:INFO:Checking exceptions
2024-01-01 23:45:23,997:INFO:Importing libraries
2024-01-01 23:45:23,997:INFO:Copying training dataset
2024-01-01 23:45:24,006:INFO:Defining folds
2024-01-01 23:45:24,006:INFO:Declaring metric variables
2024-01-01 23:45:24,010:INFO:Importing untrained model
2024-01-01 23:45:24,014:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:45:24,020:INFO:Starting cross validation
2024-01-01 23:45:24,022:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:27,417:INFO:Calculating mean and std
2024-01-01 23:45:27,419:INFO:Creating metrics dataframe
2024-01-01 23:45:27,425:INFO:Uploading results into container
2024-01-01 23:45:27,425:INFO:Uploading model into container now
2024-01-01 23:45:27,426:INFO:_master_model_container: 12
2024-01-01 23:45:27,426:INFO:_display_container: 2
2024-01-01 23:45:27,426:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:45:27,427:INFO:create_model() successfully completed......................................
2024-01-01 23:45:27,767:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:27,768:INFO:Creating metrics dataframe
2024-01-01 23:45:27,780:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:45:27,780:INFO:Total runtime is 0.6379401683807373 minutes
2024-01-01 23:45:27,784:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:27,784:INFO:Initializing create_model()
2024-01-01 23:45:27,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:27,785:INFO:Checking exceptions
2024-01-01 23:45:27,785:INFO:Importing libraries
2024-01-01 23:45:27,785:INFO:Copying training dataset
2024-01-01 23:45:27,793:INFO:Defining folds
2024-01-01 23:45:27,793:INFO:Declaring metric variables
2024-01-01 23:45:27,798:INFO:Importing untrained model
2024-01-01 23:45:27,801:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:45:27,807:INFO:Starting cross validation
2024-01-01 23:45:27,809:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:30,227:INFO:Calculating mean and std
2024-01-01 23:45:30,229:INFO:Creating metrics dataframe
2024-01-01 23:45:30,235:INFO:Uploading results into container
2024-01-01 23:45:30,236:INFO:Uploading model into container now
2024-01-01 23:45:30,237:INFO:_master_model_container: 13
2024-01-01 23:45:30,237:INFO:_display_container: 2
2024-01-01 23:45:30,237:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:45:30,238:INFO:create_model() successfully completed......................................
2024-01-01 23:45:30,591:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:30,591:INFO:Creating metrics dataframe
2024-01-01 23:45:30,603:INFO:Initializing Dummy Classifier
2024-01-01 23:45:30,603:INFO:Total runtime is 0.6849867661794027 minutes
2024-01-01 23:45:30,606:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:30,606:INFO:Initializing create_model()
2024-01-01 23:45:30,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB8E312A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:30,606:INFO:Checking exceptions
2024-01-01 23:45:30,606:INFO:Importing libraries
2024-01-01 23:45:30,606:INFO:Copying training dataset
2024-01-01 23:45:30,615:INFO:Defining folds
2024-01-01 23:45:30,615:INFO:Declaring metric variables
2024-01-01 23:45:30,618:INFO:Importing untrained model
2024-01-01 23:45:30,622:INFO:Dummy Classifier Imported successfully
2024-01-01 23:45:30,629:INFO:Starting cross validation
2024-01-01 23:45:30,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:32,003:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,034:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,042:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,043:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,044:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,047:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,069:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,074:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,078:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,086:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:45:32,099:INFO:Calculating mean and std
2024-01-01 23:45:32,100:INFO:Creating metrics dataframe
2024-01-01 23:45:32,105:INFO:Uploading results into container
2024-01-01 23:45:32,106:INFO:Uploading model into container now
2024-01-01 23:45:32,106:INFO:_master_model_container: 14
2024-01-01 23:45:32,106:INFO:_display_container: 2
2024-01-01 23:45:32,107:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:45:32,107:INFO:create_model() successfully completed......................................
2024-01-01 23:45:32,435:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:32,435:INFO:Creating metrics dataframe
2024-01-01 23:45:32,456:INFO:Initializing create_model()
2024-01-01 23:45:32,456:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:32,456:INFO:Checking exceptions
2024-01-01 23:45:32,458:INFO:Importing libraries
2024-01-01 23:45:32,458:INFO:Copying training dataset
2024-01-01 23:45:32,466:INFO:Defining folds
2024-01-01 23:45:32,466:INFO:Declaring metric variables
2024-01-01 23:45:32,466:INFO:Importing untrained model
2024-01-01 23:45:32,466:INFO:Declaring custom model
2024-01-01 23:45:32,467:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:45:32,468:INFO:Cross validation set to False
2024-01-01 23:45:32,468:INFO:Fitting Model
2024-01-01 23:45:32,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:45:32,802:INFO:create_model() successfully completed......................................
2024-01-01 23:45:33,152:INFO:_master_model_container: 14
2024-01-01 23:45:33,152:INFO:_display_container: 2
2024-01-01 23:45:33,153:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:45:33,153:INFO:compare_models() successfully completed......................................
2024-01-01 23:45:33,378:INFO:Initializing plot_model()
2024-01-01 23:45:33,378:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, system=True)
2024-01-01 23:45:33,378:INFO:Checking exceptions
2024-01-01 23:45:33,389:INFO:Preloading libraries
2024-01-01 23:45:33,390:INFO:Copying training dataset
2024-01-01 23:45:33,390:INFO:Plot type: auc
2024-01-01 23:45:33,526:INFO:Fitting Model
2024-01-01 23:45:33,527:INFO:Scoring test/hold-out set
2024-01-01 23:45:33,729:INFO:Visual Rendered Successfully
2024-01-01 23:45:34,066:INFO:plot_model() successfully completed......................................
2024-01-01 23:45:34,093:INFO:Initializing plot_model()
2024-01-01 23:45:34,093:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, system=True)
2024-01-01 23:45:34,093:INFO:Checking exceptions
2024-01-01 23:45:34,099:INFO:Preloading libraries
2024-01-01 23:45:34,100:INFO:Copying training dataset
2024-01-01 23:45:34,100:INFO:Plot type: confusion_matrix
2024-01-01 23:45:34,221:INFO:Fitting Model
2024-01-01 23:45:34,222:INFO:Scoring test/hold-out set
2024-01-01 23:45:34,333:INFO:Visual Rendered Successfully
2024-01-01 23:45:34,662:INFO:plot_model() successfully completed......................................
2024-01-01 23:45:34,704:INFO:Initializing plot_model()
2024-01-01 23:45:34,704:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, system=True)
2024-01-01 23:45:34,704:INFO:Checking exceptions
2024-01-01 23:45:34,710:INFO:Preloading libraries
2024-01-01 23:45:34,711:INFO:Copying training dataset
2024-01-01 23:45:34,711:INFO:Plot type: class_report
2024-01-01 23:45:34,832:INFO:Fitting Model
2024-01-01 23:45:34,832:INFO:Scoring test/hold-out set
2024-01-01 23:45:35,072:INFO:Visual Rendered Successfully
2024-01-01 23:45:35,400:INFO:plot_model() successfully completed......................................
2024-01-01 23:45:35,446:INFO:Initializing tune_model()
2024-01-01 23:45:35,446:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>)
2024-01-01 23:45:35,446:INFO:Checking exceptions
2024-01-01 23:45:35,468:INFO:Copying training dataset
2024-01-01 23:45:35,477:INFO:Checking base model
2024-01-01 23:45:35,477:INFO:Base model : Decision Tree Classifier
2024-01-01 23:45:35,481:INFO:Declaring metric variables
2024-01-01 23:45:35,485:INFO:Defining Hyperparameters
2024-01-01 23:45:35,905:INFO:Tuning with n_jobs=-1
2024-01-01 23:45:35,905:INFO:Initializing RandomizedSearchCV
2024-01-01 23:45:50,796:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2024-01-01 23:45:50,797:INFO:Hyperparameter search completed
2024-01-01 23:45:50,797:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:50,798:INFO:Initializing create_model()
2024-01-01 23:45:50,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FAF947910>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2024-01-01 23:45:50,798:INFO:Checking exceptions
2024-01-01 23:45:50,798:INFO:Importing libraries
2024-01-01 23:45:50,798:INFO:Copying training dataset
2024-01-01 23:45:50,807:INFO:Defining folds
2024-01-01 23:45:50,807:INFO:Declaring metric variables
2024-01-01 23:45:50,811:INFO:Importing untrained model
2024-01-01 23:45:50,811:INFO:Declaring custom model
2024-01-01 23:45:50,815:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:45:50,821:INFO:Starting cross validation
2024-01-01 23:45:50,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:52,464:INFO:Calculating mean and std
2024-01-01 23:45:52,465:INFO:Creating metrics dataframe
2024-01-01 23:45:52,472:INFO:Finalizing model
2024-01-01 23:45:52,877:INFO:Uploading results into container
2024-01-01 23:45:52,878:INFO:Uploading model into container now
2024-01-01 23:45:52,878:INFO:_master_model_container: 15
2024-01-01 23:45:52,878:INFO:_display_container: 3
2024-01-01 23:45:52,879:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:45:52,879:INFO:create_model() successfully completed......................................
2024-01-01 23:45:53,193:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:53,193:INFO:choose_better activated
2024-01-01 23:45:53,196:INFO:SubProcess create_model() called ==================================
2024-01-01 23:45:53,196:INFO:Initializing create_model()
2024-01-01 23:45:53,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:45:53,196:INFO:Checking exceptions
2024-01-01 23:45:53,198:INFO:Importing libraries
2024-01-01 23:45:53,198:INFO:Copying training dataset
2024-01-01 23:45:53,206:INFO:Defining folds
2024-01-01 23:45:53,207:INFO:Declaring metric variables
2024-01-01 23:45:53,207:INFO:Importing untrained model
2024-01-01 23:45:53,207:INFO:Declaring custom model
2024-01-01 23:45:53,207:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:45:53,207:INFO:Starting cross validation
2024-01-01 23:45:53,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:45:54,669:INFO:Calculating mean and std
2024-01-01 23:45:54,670:INFO:Creating metrics dataframe
2024-01-01 23:45:54,672:INFO:Finalizing model
2024-01-01 23:45:55,081:INFO:Uploading results into container
2024-01-01 23:45:55,082:INFO:Uploading model into container now
2024-01-01 23:45:55,082:INFO:_master_model_container: 16
2024-01-01 23:45:55,082:INFO:_display_container: 4
2024-01-01 23:45:55,083:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:45:55,083:INFO:create_model() successfully completed......................................
2024-01-01 23:45:55,382:INFO:SubProcess create_model() end ==================================
2024-01-01 23:45:55,383:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 1.0
2024-01-01 23:45:55,383:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 1.0
2024-01-01 23:45:55,383:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') is best model
2024-01-01 23:45:55,383:INFO:choose_better completed
2024-01-01 23:45:55,383:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-01 23:45:55,392:INFO:_master_model_container: 16
2024-01-01 23:45:55,392:INFO:_display_container: 3
2024-01-01 23:45:55,393:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:45:55,393:INFO:tune_model() successfully completed......................................
2024-01-01 23:45:55,855:INFO:Initializing plot_model()
2024-01-01 23:45:55,855:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, system=True)
2024-01-01 23:45:55,855:INFO:Checking exceptions
2024-01-01 23:45:55,862:INFO:Preloading libraries
2024-01-01 23:45:55,862:INFO:Copying training dataset
2024-01-01 23:45:55,862:INFO:Plot type: auc
2024-01-01 23:45:55,985:INFO:Fitting Model
2024-01-01 23:45:55,986:INFO:Scoring test/hold-out set
2024-01-01 23:45:56,196:INFO:Visual Rendered Successfully
2024-01-01 23:45:56,541:INFO:plot_model() successfully completed......................................
2024-01-01 23:45:56,578:INFO:Initializing plot_model()
2024-01-01 23:45:56,578:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, system=True)
2024-01-01 23:45:56,578:INFO:Checking exceptions
2024-01-01 23:45:56,590:INFO:Preloading libraries
2024-01-01 23:45:56,591:INFO:Copying training dataset
2024-01-01 23:45:56,591:INFO:Plot type: confusion_matrix
2024-01-01 23:45:56,738:INFO:Fitting Model
2024-01-01 23:45:56,738:INFO:Scoring test/hold-out set
2024-01-01 23:45:56,859:INFO:Visual Rendered Successfully
2024-01-01 23:45:57,271:INFO:plot_model() successfully completed......................................
2024-01-01 23:45:57,306:INFO:Initializing plot_model()
2024-01-01 23:45:57,307:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, system=True)
2024-01-01 23:45:57,307:INFO:Checking exceptions
2024-01-01 23:45:57,314:INFO:Preloading libraries
2024-01-01 23:45:57,315:INFO:Copying training dataset
2024-01-01 23:45:57,315:INFO:Plot type: class_report
2024-01-01 23:45:57,448:INFO:Fitting Model
2024-01-01 23:45:57,449:INFO:Scoring test/hold-out set
2024-01-01 23:45:57,672:INFO:Visual Rendered Successfully
2024-01-01 23:45:58,012:INFO:plot_model() successfully completed......................................
2024-01-01 23:45:58,468:INFO:Initializing finalize_model()
2024-01-01 23:45:58,468:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-01 23:45:58,468:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:45:58,474:INFO:Initializing create_model()
2024-01-01 23:45:58,474:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-01 23:45:58,474:INFO:Checking exceptions
2024-01-01 23:45:58,477:INFO:Importing libraries
2024-01-01 23:45:58,477:INFO:Copying training dataset
2024-01-01 23:45:58,477:INFO:Defining folds
2024-01-01 23:45:58,477:INFO:Declaring metric variables
2024-01-01 23:45:58,478:INFO:Importing untrained model
2024-01-01 23:45:58,478:INFO:Declaring custom model
2024-01-01 23:45:58,478:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:45:58,480:INFO:Cross validation set to False
2024-01-01 23:45:58,480:INFO:Fitting Model
2024-01-01 23:45:58,976:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                (...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2024-01-01 23:45:58,976:INFO:create_model() successfully completed......................................
2024-01-01 23:45:59,326:INFO:_master_model_container: 16
2024-01-01 23:45:59,326:INFO:_display_container: 3
2024-01-01 23:45:59,362:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                (...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2024-01-01 23:45:59,362:INFO:finalize_model() successfully completed......................................
2024-01-01 23:45:59,853:INFO:Initializing predict_model()
2024-01-01 23:45:59,854:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FAF9479A0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                (...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020FA68B5B40>)
2024-01-01 23:45:59,854:INFO:Checking exceptions
2024-01-01 23:45:59,854:INFO:Preloading libraries
2024-01-01 23:45:59,856:INFO:Set up data.
2024-01-01 23:45:59,918:INFO:Set up index.
2024-01-01 23:46:44,369:INFO:PyCaret ClassificationExperiment
2024-01-01 23:46:44,369:INFO:Logging name: clf-default-name
2024-01-01 23:46:44,369:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:46:44,369:INFO:version 3.1.0
2024-01-01 23:46:44,370:INFO:Initializing setup()
2024-01-01 23:46:44,370:INFO:self.USI: de59
2024-01-01 23:46:44,370:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:46:44,370:INFO:Checking environment
2024-01-01 23:46:44,370:INFO:python_version: 3.10.9
2024-01-01 23:46:44,370:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:46:44,370:INFO:machine: AMD64
2024-01-01 23:46:44,370:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:46:44,370:INFO:Memory: svmem(total=16954372096, available=2169139200, percent=87.2, used=14785232896, free=2169139200)
2024-01-01 23:46:44,370:INFO:Physical Core: 8
2024-01-01 23:46:44,370:INFO:Logical Core: 16
2024-01-01 23:46:44,370:INFO:Checking libraries
2024-01-01 23:46:44,370:INFO:System:
2024-01-01 23:46:44,370:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:46:44,370:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:46:44,370:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:46:44,370:INFO:PyCaret required dependencies:
2024-01-01 23:46:44,370:INFO:                 pip: 22.3.1
2024-01-01 23:46:44,370:INFO:          setuptools: 65.6.3
2024-01-01 23:46:44,370:INFO:             pycaret: 3.1.0
2024-01-01 23:46:44,370:INFO:             IPython: 8.10.0
2024-01-01 23:46:44,371:INFO:          ipywidgets: 7.6.5
2024-01-01 23:46:44,371:INFO:                tqdm: 4.64.1
2024-01-01 23:46:44,371:INFO:               numpy: 1.23.5
2024-01-01 23:46:44,371:INFO:              pandas: 1.5.3
2024-01-01 23:46:44,371:INFO:              jinja2: 3.1.2
2024-01-01 23:46:44,371:INFO:               scipy: 1.10.1
2024-01-01 23:46:44,371:INFO:              joblib: 1.3.2
2024-01-01 23:46:44,371:INFO:             sklearn: 1.2.1
2024-01-01 23:46:44,371:INFO:                pyod: 1.1.0
2024-01-01 23:46:44,371:INFO:            imblearn: 0.10.1
2024-01-01 23:46:44,371:INFO:   category_encoders: 2.6.2
2024-01-01 23:46:44,371:INFO:            lightgbm: 4.1.0
2024-01-01 23:46:44,371:INFO:               numba: 0.56.4
2024-01-01 23:46:44,371:INFO:            requests: 2.28.1
2024-01-01 23:46:44,371:INFO:          matplotlib: 3.7.0
2024-01-01 23:46:44,371:INFO:          scikitplot: 0.3.7
2024-01-01 23:46:44,371:INFO:         yellowbrick: 1.5
2024-01-01 23:46:44,371:INFO:              plotly: 5.9.0
2024-01-01 23:46:44,371:INFO:    plotly-resampler: Not installed
2024-01-01 23:46:44,371:INFO:             kaleido: 0.2.1
2024-01-01 23:46:44,371:INFO:           schemdraw: 0.15
2024-01-01 23:46:44,371:INFO:         statsmodels: 0.13.5
2024-01-01 23:46:44,371:INFO:              sktime: 0.21.1
2024-01-01 23:46:44,371:INFO:               tbats: 1.1.3
2024-01-01 23:46:44,371:INFO:            pmdarima: 2.0.3
2024-01-01 23:46:44,371:INFO:              psutil: 5.9.0
2024-01-01 23:46:44,372:INFO:          markupsafe: 2.1.1
2024-01-01 23:46:44,372:INFO:             pickle5: Not installed
2024-01-01 23:46:44,372:INFO:         cloudpickle: 2.0.0
2024-01-01 23:46:44,372:INFO:         deprecation: 2.1.0
2024-01-01 23:46:44,372:INFO:              xxhash: 3.4.1
2024-01-01 23:46:44,372:INFO:           wurlitzer: Not installed
2024-01-01 23:46:44,372:INFO:PyCaret optional dependencies:
2024-01-01 23:46:44,372:INFO:                shap: Not installed
2024-01-01 23:46:44,372:INFO:           interpret: Not installed
2024-01-01 23:46:44,372:INFO:                umap: Not installed
2024-01-01 23:46:44,372:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:46:44,372:INFO:  explainerdashboard: Not installed
2024-01-01 23:46:44,372:INFO:             autoviz: Not installed
2024-01-01 23:46:44,372:INFO:           fairlearn: Not installed
2024-01-01 23:46:44,372:INFO:          deepchecks: Not installed
2024-01-01 23:46:44,372:INFO:             xgboost: Not installed
2024-01-01 23:46:44,372:INFO:            catboost: Not installed
2024-01-01 23:46:44,372:INFO:              kmodes: Not installed
2024-01-01 23:46:44,372:INFO:             mlxtend: Not installed
2024-01-01 23:46:44,372:INFO:       statsforecast: Not installed
2024-01-01 23:46:44,372:INFO:        tune_sklearn: Not installed
2024-01-01 23:46:44,372:INFO:                 ray: Not installed
2024-01-01 23:46:44,372:INFO:            hyperopt: Not installed
2024-01-01 23:46:44,372:INFO:              optuna: Not installed
2024-01-01 23:46:44,372:INFO:               skopt: Not installed
2024-01-01 23:46:44,373:INFO:              mlflow: Not installed
2024-01-01 23:46:44,373:INFO:              gradio: Not installed
2024-01-01 23:46:44,373:INFO:             fastapi: Not installed
2024-01-01 23:46:44,373:INFO:             uvicorn: Not installed
2024-01-01 23:46:44,373:INFO:              m2cgen: Not installed
2024-01-01 23:46:44,373:INFO:           evidently: Not installed
2024-01-01 23:46:44,373:INFO:               fugue: Not installed
2024-01-01 23:46:44,373:INFO:           streamlit: Not installed
2024-01-01 23:46:44,373:INFO:             prophet: Not installed
2024-01-01 23:46:44,373:INFO:None
2024-01-01 23:46:44,373:INFO:Set up data.
2024-01-01 23:46:44,433:INFO:Set up folding strategy.
2024-01-01 23:46:44,433:INFO:Set up train/test split.
2024-01-01 23:46:44,447:INFO:Set up index.
2024-01-01 23:46:44,448:INFO:Assigning column types.
2024-01-01 23:46:44,453:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:46:44,496:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:46:44,498:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:46:44,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:46:44,571:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:46:44,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,599:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,599:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:46:44,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:46:44,674:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,674:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,720:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:46:44,747:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,748:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:46:44,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:44,891:INFO:Preparing preprocessing pipeline...
2024-01-01 23:46:44,892:INFO:Set up simple imputation.
2024-01-01 23:46:44,899:INFO:Set up encoding of ordinal features.
2024-01-01 23:46:44,903:INFO:Set up encoding of categorical features.
2024-01-01 23:46:44,904:INFO:Set up column name cleaning.
2024-01-01 23:46:45,681:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:46:45,718:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              s...
                 TransformerWrapper(exclude=None, include=['country'],
                                    transformer=TargetEncoder(cols=['country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:46:45,718:INFO:Creating final display dataframe.
2024-01-01 23:46:46,342:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 15)
4        Transformed data shape       (31978, 50)
5   Transformed train set shape       (25582, 50)
6    Transformed test set shape        (6396, 50)
7              Ordinal features                 2
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              de59
2024-01-01 23:46:46,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:46,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:46,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:46,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:46:46,508:INFO:setup() successfully completed in 2.14s...............
2024-01-01 23:46:46,556:INFO:Initializing compare_models()
2024-01-01 23:46:46,556:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBB85DA80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBB85DA80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:46:46,557:INFO:Checking exceptions
2024-01-01 23:46:46,565:INFO:Preparing display monitor
2024-01-01 23:46:46,600:INFO:Initializing Logistic Regression
2024-01-01 23:46:46,601:INFO:Total runtime is 1.6705195109049478e-05 minutes
2024-01-01 23:46:46,607:INFO:SubProcess create_model() called ==================================
2024-01-01 23:46:46,608:INFO:Initializing create_model()
2024-01-01 23:46:46,608:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBB85DA80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB6E89720>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:46:46,608:INFO:Checking exceptions
2024-01-01 23:46:46,608:INFO:Importing libraries
2024-01-01 23:46:46,608:INFO:Copying training dataset
2024-01-01 23:46:46,623:INFO:Defining folds
2024-01-01 23:46:46,623:INFO:Declaring metric variables
2024-01-01 23:46:46,627:INFO:Importing untrained model
2024-01-01 23:46:46,632:INFO:Logistic Regression Imported successfully
2024-01-01 23:46:46,641:INFO:Starting cross validation
2024-01-01 23:46:46,644:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:46:50,963:INFO:Calculating mean and std
2024-01-01 23:46:50,964:INFO:Creating metrics dataframe
2024-01-01 23:46:50,968:INFO:Uploading results into container
2024-01-01 23:46:50,968:INFO:Uploading model into container now
2024-01-01 23:46:50,969:INFO:_master_model_container: 1
2024-01-01 23:46:50,969:INFO:_display_container: 2
2024-01-01 23:46:50,970:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:46:50,970:INFO:create_model() successfully completed......................................
2024-01-01 23:46:51,304:INFO:SubProcess create_model() end ==================================
2024-01-01 23:46:51,305:INFO:Creating metrics dataframe
2024-01-01 23:46:51,313:INFO:Initializing K Neighbors Classifier
2024-01-01 23:46:51,313:INFO:Total runtime is 0.07856167952219645 minutes
2024-01-01 23:46:51,316:INFO:SubProcess create_model() called ==================================
2024-01-01 23:46:51,317:INFO:Initializing create_model()
2024-01-01 23:46:51,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBB85DA80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FB6E89720>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:46:51,317:INFO:Checking exceptions
2024-01-01 23:46:51,317:INFO:Importing libraries
2024-01-01 23:46:51,317:INFO:Copying training dataset
2024-01-01 23:46:51,326:INFO:Defining folds
2024-01-01 23:46:51,326:INFO:Declaring metric variables
2024-01-01 23:46:51,329:INFO:Importing untrained model
2024-01-01 23:46:51,333:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:46:51,339:INFO:Starting cross validation
2024-01-01 23:46:51,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:46:54,682:INFO:Calculating mean and std
2024-01-01 23:46:54,684:INFO:Creating metrics dataframe
2024-01-01 23:46:54,690:INFO:Uploading results into container
2024-01-01 23:46:54,691:INFO:Uploading model into container now
2024-01-01 23:46:54,692:INFO:_master_model_container: 2
2024-01-01 23:46:54,692:INFO:_display_container: 2
2024-01-01 23:46:54,692:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:46:54,693:INFO:create_model() successfully completed......................................
2024-01-01 23:46:55,107:INFO:SubProcess create_model() end ==================================
2024-01-01 23:46:55,107:INFO:Creating metrics dataframe
2024-01-01 23:46:55,118:INFO:Initializing Naive Bayes
2024-01-01 23:46:55,118:INFO:Total runtime is 0.141968842347463 minutes
2024-01-01 23:47:07,922:INFO:PyCaret ClassificationExperiment
2024-01-01 23:47:07,922:INFO:Logging name: clf-default-name
2024-01-01 23:47:07,922:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:47:07,922:INFO:version 3.1.0
2024-01-01 23:47:07,922:INFO:Initializing setup()
2024-01-01 23:47:07,922:INFO:self.USI: cc34
2024-01-01 23:47:07,922:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:47:07,922:INFO:Checking environment
2024-01-01 23:47:07,922:INFO:python_version: 3.10.9
2024-01-01 23:47:07,922:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:47:07,922:INFO:machine: AMD64
2024-01-01 23:47:07,922:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:47:07,922:INFO:Memory: svmem(total=16954372096, available=1977909248, percent=88.3, used=14976462848, free=1977909248)
2024-01-01 23:47:07,922:INFO:Physical Core: 8
2024-01-01 23:47:07,922:INFO:Logical Core: 16
2024-01-01 23:47:07,922:INFO:Checking libraries
2024-01-01 23:47:07,922:INFO:System:
2024-01-01 23:47:07,922:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:47:07,923:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:47:07,923:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:47:07,923:INFO:PyCaret required dependencies:
2024-01-01 23:47:07,923:INFO:                 pip: 22.3.1
2024-01-01 23:47:07,923:INFO:          setuptools: 65.6.3
2024-01-01 23:47:07,923:INFO:             pycaret: 3.1.0
2024-01-01 23:47:07,923:INFO:             IPython: 8.10.0
2024-01-01 23:47:07,923:INFO:          ipywidgets: 7.6.5
2024-01-01 23:47:07,923:INFO:                tqdm: 4.64.1
2024-01-01 23:47:07,923:INFO:               numpy: 1.23.5
2024-01-01 23:47:07,923:INFO:              pandas: 1.5.3
2024-01-01 23:47:07,923:INFO:              jinja2: 3.1.2
2024-01-01 23:47:07,923:INFO:               scipy: 1.10.1
2024-01-01 23:47:07,923:INFO:              joblib: 1.3.2
2024-01-01 23:47:07,923:INFO:             sklearn: 1.2.1
2024-01-01 23:47:07,923:INFO:                pyod: 1.1.0
2024-01-01 23:47:07,923:INFO:            imblearn: 0.10.1
2024-01-01 23:47:07,923:INFO:   category_encoders: 2.6.2
2024-01-01 23:47:07,923:INFO:            lightgbm: 4.1.0
2024-01-01 23:47:07,923:INFO:               numba: 0.56.4
2024-01-01 23:47:07,923:INFO:            requests: 2.28.1
2024-01-01 23:47:07,923:INFO:          matplotlib: 3.7.0
2024-01-01 23:47:07,924:INFO:          scikitplot: 0.3.7
2024-01-01 23:47:07,924:INFO:         yellowbrick: 1.5
2024-01-01 23:47:07,924:INFO:              plotly: 5.9.0
2024-01-01 23:47:07,924:INFO:    plotly-resampler: Not installed
2024-01-01 23:47:07,924:INFO:             kaleido: 0.2.1
2024-01-01 23:47:07,924:INFO:           schemdraw: 0.15
2024-01-01 23:47:07,924:INFO:         statsmodels: 0.13.5
2024-01-01 23:47:07,924:INFO:              sktime: 0.21.1
2024-01-01 23:47:07,924:INFO:               tbats: 1.1.3
2024-01-01 23:47:07,924:INFO:            pmdarima: 2.0.3
2024-01-01 23:47:07,924:INFO:              psutil: 5.9.0
2024-01-01 23:47:07,924:INFO:          markupsafe: 2.1.1
2024-01-01 23:47:07,924:INFO:             pickle5: Not installed
2024-01-01 23:47:07,924:INFO:         cloudpickle: 2.0.0
2024-01-01 23:47:07,924:INFO:         deprecation: 2.1.0
2024-01-01 23:47:07,924:INFO:              xxhash: 3.4.1
2024-01-01 23:47:07,924:INFO:           wurlitzer: Not installed
2024-01-01 23:47:07,924:INFO:PyCaret optional dependencies:
2024-01-01 23:47:07,924:INFO:                shap: Not installed
2024-01-01 23:47:07,924:INFO:           interpret: Not installed
2024-01-01 23:47:07,924:INFO:                umap: Not installed
2024-01-01 23:47:07,924:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:47:07,924:INFO:  explainerdashboard: Not installed
2024-01-01 23:47:07,925:INFO:             autoviz: Not installed
2024-01-01 23:47:07,925:INFO:           fairlearn: Not installed
2024-01-01 23:47:07,925:INFO:          deepchecks: Not installed
2024-01-01 23:47:07,925:INFO:             xgboost: Not installed
2024-01-01 23:47:07,925:INFO:            catboost: Not installed
2024-01-01 23:47:07,925:INFO:              kmodes: Not installed
2024-01-01 23:47:07,925:INFO:             mlxtend: Not installed
2024-01-01 23:47:07,925:INFO:       statsforecast: Not installed
2024-01-01 23:47:07,925:INFO:        tune_sklearn: Not installed
2024-01-01 23:47:07,925:INFO:                 ray: Not installed
2024-01-01 23:47:07,925:INFO:            hyperopt: Not installed
2024-01-01 23:47:07,925:INFO:              optuna: Not installed
2024-01-01 23:47:07,925:INFO:               skopt: Not installed
2024-01-01 23:47:07,925:INFO:              mlflow: Not installed
2024-01-01 23:47:07,925:INFO:              gradio: Not installed
2024-01-01 23:47:07,925:INFO:             fastapi: Not installed
2024-01-01 23:47:07,925:INFO:             uvicorn: Not installed
2024-01-01 23:47:07,925:INFO:              m2cgen: Not installed
2024-01-01 23:47:07,925:INFO:           evidently: Not installed
2024-01-01 23:47:07,925:INFO:               fugue: Not installed
2024-01-01 23:47:07,925:INFO:           streamlit: Not installed
2024-01-01 23:47:07,925:INFO:             prophet: Not installed
2024-01-01 23:47:07,925:INFO:None
2024-01-01 23:47:07,926:INFO:Set up data.
2024-01-01 23:47:07,989:INFO:Set up folding strategy.
2024-01-01 23:47:07,989:INFO:Set up train/test split.
2024-01-01 23:47:08,005:INFO:Set up index.
2024-01-01 23:47:08,006:INFO:Assigning column types.
2024-01-01 23:47:08,011:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:47:08,055:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:47:08,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:47:08,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:47:08,126:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:47:08,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,153:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,154:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:47:08,198:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:47:08,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,270:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:47:08,297:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,297:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,297:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:47:08,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,367:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:08,440:INFO:Preparing preprocessing pipeline...
2024-01-01 23:47:08,441:INFO:Set up simple imputation.
2024-01-01 23:47:08,448:INFO:Set up encoding of ordinal features.
2024-01-01 23:47:08,452:INFO:Set up encoding of categorical features.
2024-01-01 23:47:08,453:INFO:Set up column name cleaning.
2024-01-01 23:47:08,825:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:47:08,853:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'Education-num', 'capital-gain',
                                             'capital-loss', 'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              s...
                 TransformerWrapper(exclude=None, include=['country'],
                                    transformer=TargetEncoder(cols=['country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:47:08,853:INFO:Creating final display dataframe.
2024-01-01 23:47:09,581:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 15)
4        Transformed data shape       (31978, 50)
5   Transformed train set shape       (25582, 50)
6    Transformed test set shape        (6396, 50)
7              Ordinal features                 2
8              Numeric features                 6
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              cc34
2024-01-01 23:47:09,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:09,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:09,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:09,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:47:09,735:INFO:setup() successfully completed in 1.82s...............
2024-01-01 23:47:09,772:INFO:Initializing compare_models()
2024-01-01 23:47:09,772:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:47:09,772:INFO:Checking exceptions
2024-01-01 23:47:09,780:INFO:Preparing display monitor
2024-01-01 23:47:09,805:INFO:Initializing Logistic Regression
2024-01-01 23:47:09,805:INFO:Total runtime is 0.0 minutes
2024-01-01 23:47:09,809:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:09,809:INFO:Initializing create_model()
2024-01-01 23:47:09,810:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:09,810:INFO:Checking exceptions
2024-01-01 23:47:09,810:INFO:Importing libraries
2024-01-01 23:47:09,810:INFO:Copying training dataset
2024-01-01 23:47:09,820:INFO:Defining folds
2024-01-01 23:47:09,820:INFO:Declaring metric variables
2024-01-01 23:47:09,824:INFO:Importing untrained model
2024-01-01 23:47:09,828:INFO:Logistic Regression Imported successfully
2024-01-01 23:47:09,836:INFO:Starting cross validation
2024-01-01 23:47:09,839:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:13,863:INFO:Calculating mean and std
2024-01-01 23:47:13,864:INFO:Creating metrics dataframe
2024-01-01 23:47:13,868:INFO:Uploading results into container
2024-01-01 23:47:13,868:INFO:Uploading model into container now
2024-01-01 23:47:13,869:INFO:_master_model_container: 1
2024-01-01 23:47:13,869:INFO:_display_container: 2
2024-01-01 23:47:13,869:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:47:13,869:INFO:create_model() successfully completed......................................
2024-01-01 23:47:14,329:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:14,329:INFO:Creating metrics dataframe
2024-01-01 23:47:14,339:INFO:Initializing K Neighbors Classifier
2024-01-01 23:47:14,339:INFO:Total runtime is 0.07555928627649942 minutes
2024-01-01 23:47:14,341:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:14,342:INFO:Initializing create_model()
2024-01-01 23:47:14,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:14,342:INFO:Checking exceptions
2024-01-01 23:47:14,342:INFO:Importing libraries
2024-01-01 23:47:14,342:INFO:Copying training dataset
2024-01-01 23:47:14,353:INFO:Defining folds
2024-01-01 23:47:14,353:INFO:Declaring metric variables
2024-01-01 23:47:14,357:INFO:Importing untrained model
2024-01-01 23:47:14,361:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:47:14,366:INFO:Starting cross validation
2024-01-01 23:47:14,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:17,931:INFO:Calculating mean and std
2024-01-01 23:47:17,932:INFO:Creating metrics dataframe
2024-01-01 23:47:17,938:INFO:Uploading results into container
2024-01-01 23:47:17,938:INFO:Uploading model into container now
2024-01-01 23:47:17,939:INFO:_master_model_container: 2
2024-01-01 23:47:17,939:INFO:_display_container: 2
2024-01-01 23:47:17,939:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:47:17,940:INFO:create_model() successfully completed......................................
2024-01-01 23:47:18,377:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:18,377:INFO:Creating metrics dataframe
2024-01-01 23:47:18,387:INFO:Initializing Naive Bayes
2024-01-01 23:47:18,387:INFO:Total runtime is 0.14303175608317056 minutes
2024-01-01 23:47:18,390:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:18,391:INFO:Initializing create_model()
2024-01-01 23:47:18,391:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:18,391:INFO:Checking exceptions
2024-01-01 23:47:18,391:INFO:Importing libraries
2024-01-01 23:47:18,391:INFO:Copying training dataset
2024-01-01 23:47:18,401:INFO:Defining folds
2024-01-01 23:47:18,401:INFO:Declaring metric variables
2024-01-01 23:47:18,405:INFO:Importing untrained model
2024-01-01 23:47:18,409:INFO:Naive Bayes Imported successfully
2024-01-01 23:47:18,417:INFO:Starting cross validation
2024-01-01 23:47:18,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:20,715:INFO:Calculating mean and std
2024-01-01 23:47:20,719:INFO:Creating metrics dataframe
2024-01-01 23:47:20,725:INFO:Uploading results into container
2024-01-01 23:47:20,726:INFO:Uploading model into container now
2024-01-01 23:47:20,727:INFO:_master_model_container: 3
2024-01-01 23:47:20,727:INFO:_display_container: 2
2024-01-01 23:47:20,728:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:47:20,728:INFO:create_model() successfully completed......................................
2024-01-01 23:47:21,284:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:21,284:INFO:Creating metrics dataframe
2024-01-01 23:47:21,293:INFO:Initializing Decision Tree Classifier
2024-01-01 23:47:21,293:INFO:Total runtime is 0.19146721760431923 minutes
2024-01-01 23:47:21,296:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:21,296:INFO:Initializing create_model()
2024-01-01 23:47:21,297:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:21,297:INFO:Checking exceptions
2024-01-01 23:47:21,297:INFO:Importing libraries
2024-01-01 23:47:21,297:INFO:Copying training dataset
2024-01-01 23:47:21,306:INFO:Defining folds
2024-01-01 23:47:21,306:INFO:Declaring metric variables
2024-01-01 23:47:21,310:INFO:Importing untrained model
2024-01-01 23:47:21,314:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:47:21,321:INFO:Starting cross validation
2024-01-01 23:47:21,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:23,410:INFO:Calculating mean and std
2024-01-01 23:47:23,411:INFO:Creating metrics dataframe
2024-01-01 23:47:23,416:INFO:Uploading results into container
2024-01-01 23:47:23,417:INFO:Uploading model into container now
2024-01-01 23:47:23,417:INFO:_master_model_container: 4
2024-01-01 23:47:23,417:INFO:_display_container: 2
2024-01-01 23:47:23,418:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:47:23,418:INFO:create_model() successfully completed......................................
2024-01-01 23:47:23,821:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:23,821:INFO:Creating metrics dataframe
2024-01-01 23:47:23,831:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:47:23,831:INFO:Total runtime is 0.2337662537892659 minutes
2024-01-01 23:47:23,835:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:23,835:INFO:Initializing create_model()
2024-01-01 23:47:23,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:23,835:INFO:Checking exceptions
2024-01-01 23:47:23,835:INFO:Importing libraries
2024-01-01 23:47:23,835:INFO:Copying training dataset
2024-01-01 23:47:23,846:INFO:Defining folds
2024-01-01 23:47:23,847:INFO:Declaring metric variables
2024-01-01 23:47:23,851:INFO:Importing untrained model
2024-01-01 23:47:23,855:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:47:23,863:INFO:Starting cross validation
2024-01-01 23:47:23,866:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:28,075:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,088:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,397:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,529:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,608:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,616:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,693:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,889:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,933:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:28,991:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:47:29,015:INFO:Calculating mean and std
2024-01-01 23:47:29,017:INFO:Creating metrics dataframe
2024-01-01 23:47:29,020:INFO:Uploading results into container
2024-01-01 23:47:29,021:INFO:Uploading model into container now
2024-01-01 23:47:29,021:INFO:_master_model_container: 5
2024-01-01 23:47:29,021:INFO:_display_container: 2
2024-01-01 23:47:29,021:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:47:29,021:INFO:create_model() successfully completed......................................
2024-01-01 23:47:29,381:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:29,381:INFO:Creating metrics dataframe
2024-01-01 23:47:29,390:INFO:Initializing Ridge Classifier
2024-01-01 23:47:29,391:INFO:Total runtime is 0.32641341686248776 minutes
2024-01-01 23:47:29,394:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:29,394:INFO:Initializing create_model()
2024-01-01 23:47:29,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:29,394:INFO:Checking exceptions
2024-01-01 23:47:29,394:INFO:Importing libraries
2024-01-01 23:47:29,395:INFO:Copying training dataset
2024-01-01 23:47:29,404:INFO:Defining folds
2024-01-01 23:47:29,404:INFO:Declaring metric variables
2024-01-01 23:47:29,408:INFO:Importing untrained model
2024-01-01 23:47:29,412:INFO:Ridge Classifier Imported successfully
2024-01-01 23:47:29,418:INFO:Starting cross validation
2024-01-01 23:47:29,421:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:31,438:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,441:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,453:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,474:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,491:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,492:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,494:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,515:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,517:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,521:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:47:31,534:INFO:Calculating mean and std
2024-01-01 23:47:31,535:INFO:Creating metrics dataframe
2024-01-01 23:47:31,539:INFO:Uploading results into container
2024-01-01 23:47:31,540:INFO:Uploading model into container now
2024-01-01 23:47:31,540:INFO:_master_model_container: 6
2024-01-01 23:47:31,540:INFO:_display_container: 2
2024-01-01 23:47:31,541:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:47:31,541:INFO:create_model() successfully completed......................................
2024-01-01 23:47:31,919:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:31,919:INFO:Creating metrics dataframe
2024-01-01 23:47:31,930:INFO:Initializing Random Forest Classifier
2024-01-01 23:47:31,930:INFO:Total runtime is 0.36874761581420895 minutes
2024-01-01 23:47:31,933:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:31,933:INFO:Initializing create_model()
2024-01-01 23:47:31,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:31,933:INFO:Checking exceptions
2024-01-01 23:47:31,933:INFO:Importing libraries
2024-01-01 23:47:31,934:INFO:Copying training dataset
2024-01-01 23:47:31,944:INFO:Defining folds
2024-01-01 23:47:31,945:INFO:Declaring metric variables
2024-01-01 23:47:31,948:INFO:Importing untrained model
2024-01-01 23:47:31,954:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:47:31,960:INFO:Starting cross validation
2024-01-01 23:47:31,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:36,595:INFO:Calculating mean and std
2024-01-01 23:47:36,599:INFO:Creating metrics dataframe
2024-01-01 23:47:36,611:INFO:Uploading results into container
2024-01-01 23:47:36,612:INFO:Uploading model into container now
2024-01-01 23:47:36,613:INFO:_master_model_container: 7
2024-01-01 23:47:36,613:INFO:_display_container: 2
2024-01-01 23:47:36,614:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:47:36,614:INFO:create_model() successfully completed......................................
2024-01-01 23:47:37,007:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:37,007:INFO:Creating metrics dataframe
2024-01-01 23:47:37,019:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:47:37,019:INFO:Total runtime is 0.453572154045105 minutes
2024-01-01 23:47:37,023:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:37,023:INFO:Initializing create_model()
2024-01-01 23:47:37,023:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:37,023:INFO:Checking exceptions
2024-01-01 23:47:37,023:INFO:Importing libraries
2024-01-01 23:47:37,023:INFO:Copying training dataset
2024-01-01 23:47:37,033:INFO:Defining folds
2024-01-01 23:47:37,033:INFO:Declaring metric variables
2024-01-01 23:47:37,036:INFO:Importing untrained model
2024-01-01 23:47:37,041:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:47:37,048:INFO:Starting cross validation
2024-01-01 23:47:37,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:39,088:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,095:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,116:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,179:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,180:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,202:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,226:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,262:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,272:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,289:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:47:39,589:INFO:Calculating mean and std
2024-01-01 23:47:39,590:INFO:Creating metrics dataframe
2024-01-01 23:47:39,595:INFO:Uploading results into container
2024-01-01 23:47:39,596:INFO:Uploading model into container now
2024-01-01 23:47:39,597:INFO:_master_model_container: 8
2024-01-01 23:47:39,597:INFO:_display_container: 2
2024-01-01 23:47:39,597:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:47:39,598:INFO:create_model() successfully completed......................................
2024-01-01 23:47:39,997:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:39,997:INFO:Creating metrics dataframe
2024-01-01 23:47:40,008:INFO:Initializing Ada Boost Classifier
2024-01-01 23:47:40,008:INFO:Total runtime is 0.503374473253886 minutes
2024-01-01 23:47:40,012:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:40,012:INFO:Initializing create_model()
2024-01-01 23:47:40,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:40,012:INFO:Checking exceptions
2024-01-01 23:47:40,012:INFO:Importing libraries
2024-01-01 23:47:40,012:INFO:Copying training dataset
2024-01-01 23:47:40,022:INFO:Defining folds
2024-01-01 23:47:40,022:INFO:Declaring metric variables
2024-01-01 23:47:40,026:INFO:Importing untrained model
2024-01-01 23:47:40,030:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:47:40,038:INFO:Starting cross validation
2024-01-01 23:47:40,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:42,079:INFO:Calculating mean and std
2024-01-01 23:47:42,081:INFO:Creating metrics dataframe
2024-01-01 23:47:42,085:INFO:Uploading results into container
2024-01-01 23:47:42,085:INFO:Uploading model into container now
2024-01-01 23:47:42,086:INFO:_master_model_container: 9
2024-01-01 23:47:42,086:INFO:_display_container: 2
2024-01-01 23:47:42,087:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:47:42,087:INFO:create_model() successfully completed......................................
2024-01-01 23:47:42,503:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:42,503:INFO:Creating metrics dataframe
2024-01-01 23:47:42,514:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:47:42,514:INFO:Total runtime is 0.5451550324757894 minutes
2024-01-01 23:47:42,517:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:42,517:INFO:Initializing create_model()
2024-01-01 23:47:42,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:42,517:INFO:Checking exceptions
2024-01-01 23:47:42,518:INFO:Importing libraries
2024-01-01 23:47:42,518:INFO:Copying training dataset
2024-01-01 23:47:42,528:INFO:Defining folds
2024-01-01 23:47:42,528:INFO:Declaring metric variables
2024-01-01 23:47:42,532:INFO:Importing untrained model
2024-01-01 23:47:42,536:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:47:42,542:INFO:Starting cross validation
2024-01-01 23:47:42,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:47,293:INFO:Calculating mean and std
2024-01-01 23:47:47,294:INFO:Creating metrics dataframe
2024-01-01 23:47:47,298:INFO:Uploading results into container
2024-01-01 23:47:47,299:INFO:Uploading model into container now
2024-01-01 23:47:47,299:INFO:_master_model_container: 10
2024-01-01 23:47:47,300:INFO:_display_container: 2
2024-01-01 23:47:47,300:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:47:47,300:INFO:create_model() successfully completed......................................
2024-01-01 23:47:47,716:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:47,716:INFO:Creating metrics dataframe
2024-01-01 23:47:47,728:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:47:47,728:INFO:Total runtime is 0.6320451140403748 minutes
2024-01-01 23:47:47,731:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:47,732:INFO:Initializing create_model()
2024-01-01 23:47:47,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:47,732:INFO:Checking exceptions
2024-01-01 23:47:47,732:INFO:Importing libraries
2024-01-01 23:47:47,732:INFO:Copying training dataset
2024-01-01 23:47:47,743:INFO:Defining folds
2024-01-01 23:47:47,744:INFO:Declaring metric variables
2024-01-01 23:47:47,748:INFO:Importing untrained model
2024-01-01 23:47:47,752:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:47:47,758:INFO:Starting cross validation
2024-01-01 23:47:47,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:51,154:INFO:Calculating mean and std
2024-01-01 23:47:51,157:INFO:Creating metrics dataframe
2024-01-01 23:47:51,166:INFO:Uploading results into container
2024-01-01 23:47:51,167:INFO:Uploading model into container now
2024-01-01 23:47:51,168:INFO:_master_model_container: 11
2024-01-01 23:47:51,168:INFO:_display_container: 2
2024-01-01 23:47:51,169:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:47:51,169:INFO:create_model() successfully completed......................................
2024-01-01 23:47:51,595:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:51,595:INFO:Creating metrics dataframe
2024-01-01 23:47:51,609:INFO:Initializing Extra Trees Classifier
2024-01-01 23:47:51,610:INFO:Total runtime is 0.6967455387115479 minutes
2024-01-01 23:47:51,613:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:51,614:INFO:Initializing create_model()
2024-01-01 23:47:51,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:51,614:INFO:Checking exceptions
2024-01-01 23:47:51,614:INFO:Importing libraries
2024-01-01 23:47:51,614:INFO:Copying training dataset
2024-01-01 23:47:51,626:INFO:Defining folds
2024-01-01 23:47:51,626:INFO:Declaring metric variables
2024-01-01 23:47:51,630:INFO:Importing untrained model
2024-01-01 23:47:51,633:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:47:51,640:INFO:Starting cross validation
2024-01-01 23:47:51,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:55,962:INFO:Calculating mean and std
2024-01-01 23:47:55,964:INFO:Creating metrics dataframe
2024-01-01 23:47:55,970:INFO:Uploading results into container
2024-01-01 23:47:55,972:INFO:Uploading model into container now
2024-01-01 23:47:55,972:INFO:_master_model_container: 12
2024-01-01 23:47:55,973:INFO:_display_container: 2
2024-01-01 23:47:55,973:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:47:55,974:INFO:create_model() successfully completed......................................
2024-01-01 23:47:56,435:INFO:SubProcess create_model() end ==================================
2024-01-01 23:47:56,435:INFO:Creating metrics dataframe
2024-01-01 23:47:56,448:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:47:56,448:INFO:Total runtime is 0.7773733218510945 minutes
2024-01-01 23:47:56,452:INFO:SubProcess create_model() called ==================================
2024-01-01 23:47:56,452:INFO:Initializing create_model()
2024-01-01 23:47:56,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:47:56,453:INFO:Checking exceptions
2024-01-01 23:47:56,453:INFO:Importing libraries
2024-01-01 23:47:56,453:INFO:Copying training dataset
2024-01-01 23:47:56,465:INFO:Defining folds
2024-01-01 23:47:56,465:INFO:Declaring metric variables
2024-01-01 23:47:56,469:INFO:Importing untrained model
2024-01-01 23:47:56,473:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:47:56,480:INFO:Starting cross validation
2024-01-01 23:47:56,482:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:47:59,679:INFO:Calculating mean and std
2024-01-01 23:47:59,681:INFO:Creating metrics dataframe
2024-01-01 23:47:59,688:INFO:Uploading results into container
2024-01-01 23:47:59,689:INFO:Uploading model into container now
2024-01-01 23:47:59,689:INFO:_master_model_container: 13
2024-01-01 23:47:59,689:INFO:_display_container: 2
2024-01-01 23:47:59,690:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:47:59,690:INFO:create_model() successfully completed......................................
2024-01-01 23:48:00,157:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:00,157:INFO:Creating metrics dataframe
2024-01-01 23:48:00,169:INFO:Initializing Dummy Classifier
2024-01-01 23:48:00,169:INFO:Total runtime is 0.8393999179204304 minutes
2024-01-01 23:48:00,173:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:00,174:INFO:Initializing create_model()
2024-01-01 23:48:00,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FC02A7D90>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:00,174:INFO:Checking exceptions
2024-01-01 23:48:00,174:INFO:Importing libraries
2024-01-01 23:48:00,174:INFO:Copying training dataset
2024-01-01 23:48:00,184:INFO:Defining folds
2024-01-01 23:48:00,185:INFO:Declaring metric variables
2024-01-01 23:48:00,188:INFO:Importing untrained model
2024-01-01 23:48:00,192:INFO:Dummy Classifier Imported successfully
2024-01-01 23:48:00,199:INFO:Starting cross validation
2024-01-01 23:48:00,201:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:02,045:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,092:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,106:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,111:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,111:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,127:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,167:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,169:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,176:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,191:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:02,213:INFO:Calculating mean and std
2024-01-01 23:48:02,221:INFO:Creating metrics dataframe
2024-01-01 23:48:02,234:INFO:Uploading results into container
2024-01-01 23:48:02,235:INFO:Uploading model into container now
2024-01-01 23:48:02,236:INFO:_master_model_container: 14
2024-01-01 23:48:02,236:INFO:_display_container: 2
2024-01-01 23:48:02,236:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:48:02,236:INFO:create_model() successfully completed......................................
2024-01-01 23:48:02,788:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:02,788:INFO:Creating metrics dataframe
2024-01-01 23:48:02,811:INFO:Initializing create_model()
2024-01-01 23:48:02,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FB46F2410>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:02,812:INFO:Checking exceptions
2024-01-01 23:48:02,814:INFO:Importing libraries
2024-01-01 23:48:02,814:INFO:Copying training dataset
2024-01-01 23:48:02,824:INFO:Defining folds
2024-01-01 23:48:02,824:INFO:Declaring metric variables
2024-01-01 23:48:02,824:INFO:Importing untrained model
2024-01-01 23:48:02,824:INFO:Declaring custom model
2024-01-01 23:48:02,825:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:48:02,826:INFO:Cross validation set to False
2024-01-01 23:48:02,826:INFO:Fitting Model
2024-01-01 23:48:17,089:INFO:PyCaret ClassificationExperiment
2024-01-01 23:48:17,089:INFO:Logging name: clf-default-name
2024-01-01 23:48:17,089:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:48:17,089:INFO:version 3.1.0
2024-01-01 23:48:17,089:INFO:Initializing setup()
2024-01-01 23:48:17,089:INFO:self.USI: cf78
2024-01-01 23:48:17,089:INFO:self._variable_keys: {'target_param', 'idx', 'exp_id', 'y', 'gpu_n_jobs_param', 'data', 'USI', 'logging_param', 'y_test', 'is_multiclass', 'pipeline', 'seed', 'X', 'fold_shuffle_param', 'X_test', 'html_param', 'X_train', '_available_plots', 'gpu_param', 'fold_groups_param', 'fix_imbalance', 'y_train', 'n_jobs_param', 'memory', 'exp_name_log', '_ml_usecase', 'log_plots_param', 'fold_generator'}
2024-01-01 23:48:17,089:INFO:Checking environment
2024-01-01 23:48:17,090:INFO:python_version: 3.10.9
2024-01-01 23:48:17,090:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:48:17,090:INFO:machine: AMD64
2024-01-01 23:48:17,090:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:48:17,090:INFO:Memory: svmem(total=16954372096, available=1898221568, percent=88.8, used=15056150528, free=1898221568)
2024-01-01 23:48:17,090:INFO:Physical Core: 8
2024-01-01 23:48:17,090:INFO:Logical Core: 16
2024-01-01 23:48:17,090:INFO:Checking libraries
2024-01-01 23:48:17,090:INFO:System:
2024-01-01 23:48:17,090:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:48:17,090:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:48:17,090:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:48:17,090:INFO:PyCaret required dependencies:
2024-01-01 23:48:17,091:INFO:                 pip: 22.3.1
2024-01-01 23:48:17,091:INFO:          setuptools: 65.6.3
2024-01-01 23:48:17,091:INFO:             pycaret: 3.1.0
2024-01-01 23:48:17,091:INFO:             IPython: 8.10.0
2024-01-01 23:48:17,091:INFO:          ipywidgets: 7.6.5
2024-01-01 23:48:17,091:INFO:                tqdm: 4.64.1
2024-01-01 23:48:17,091:INFO:               numpy: 1.23.5
2024-01-01 23:48:17,091:INFO:              pandas: 1.5.3
2024-01-01 23:48:17,091:INFO:              jinja2: 3.1.2
2024-01-01 23:48:17,091:INFO:               scipy: 1.10.1
2024-01-01 23:48:17,091:INFO:              joblib: 1.3.2
2024-01-01 23:48:17,091:INFO:             sklearn: 1.2.1
2024-01-01 23:48:17,091:INFO:                pyod: 1.1.0
2024-01-01 23:48:17,091:INFO:            imblearn: 0.10.1
2024-01-01 23:48:17,092:INFO:   category_encoders: 2.6.2
2024-01-01 23:48:17,092:INFO:            lightgbm: 4.1.0
2024-01-01 23:48:17,092:INFO:               numba: 0.56.4
2024-01-01 23:48:17,092:INFO:            requests: 2.28.1
2024-01-01 23:48:17,092:INFO:          matplotlib: 3.7.0
2024-01-01 23:48:17,092:INFO:          scikitplot: 0.3.7
2024-01-01 23:48:17,092:INFO:         yellowbrick: 1.5
2024-01-01 23:48:17,092:INFO:              plotly: 5.9.0
2024-01-01 23:48:17,092:INFO:    plotly-resampler: Not installed
2024-01-01 23:48:17,092:INFO:             kaleido: 0.2.1
2024-01-01 23:48:17,092:INFO:           schemdraw: 0.15
2024-01-01 23:48:17,092:INFO:         statsmodels: 0.13.5
2024-01-01 23:48:17,092:INFO:              sktime: 0.21.1
2024-01-01 23:48:17,092:INFO:               tbats: 1.1.3
2024-01-01 23:48:17,092:INFO:            pmdarima: 2.0.3
2024-01-01 23:48:17,092:INFO:              psutil: 5.9.0
2024-01-01 23:48:17,092:INFO:          markupsafe: 2.1.1
2024-01-01 23:48:17,092:INFO:             pickle5: Not installed
2024-01-01 23:48:17,092:INFO:         cloudpickle: 2.0.0
2024-01-01 23:48:17,092:INFO:         deprecation: 2.1.0
2024-01-01 23:48:17,093:INFO:              xxhash: 3.4.1
2024-01-01 23:48:17,093:INFO:           wurlitzer: Not installed
2024-01-01 23:48:17,093:INFO:PyCaret optional dependencies:
2024-01-01 23:48:17,093:INFO:                shap: Not installed
2024-01-01 23:48:17,093:INFO:           interpret: Not installed
2024-01-01 23:48:17,093:INFO:                umap: Not installed
2024-01-01 23:48:17,093:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:48:17,093:INFO:  explainerdashboard: Not installed
2024-01-01 23:48:17,093:INFO:             autoviz: Not installed
2024-01-01 23:48:17,093:INFO:           fairlearn: Not installed
2024-01-01 23:48:17,093:INFO:          deepchecks: Not installed
2024-01-01 23:48:17,093:INFO:             xgboost: Not installed
2024-01-01 23:48:17,093:INFO:            catboost: Not installed
2024-01-01 23:48:17,094:INFO:              kmodes: Not installed
2024-01-01 23:48:17,094:INFO:             mlxtend: Not installed
2024-01-01 23:48:17,094:INFO:       statsforecast: Not installed
2024-01-01 23:48:17,094:INFO:        tune_sklearn: Not installed
2024-01-01 23:48:17,094:INFO:                 ray: Not installed
2024-01-01 23:48:17,094:INFO:            hyperopt: Not installed
2024-01-01 23:48:17,094:INFO:              optuna: Not installed
2024-01-01 23:48:17,094:INFO:               skopt: Not installed
2024-01-01 23:48:17,094:INFO:              mlflow: Not installed
2024-01-01 23:48:17,094:INFO:              gradio: Not installed
2024-01-01 23:48:17,094:INFO:             fastapi: Not installed
2024-01-01 23:48:17,094:INFO:             uvicorn: Not installed
2024-01-01 23:48:17,094:INFO:              m2cgen: Not installed
2024-01-01 23:48:17,094:INFO:           evidently: Not installed
2024-01-01 23:48:17,094:INFO:               fugue: Not installed
2024-01-01 23:48:17,094:INFO:           streamlit: Not installed
2024-01-01 23:48:17,094:INFO:             prophet: Not installed
2024-01-01 23:48:17,094:INFO:None
2024-01-01 23:48:17,094:INFO:Set up data.
2024-01-01 23:48:17,119:INFO:Set up folding strategy.
2024-01-01 23:48:17,120:INFO:Set up train/test split.
2024-01-01 23:48:17,138:INFO:Set up index.
2024-01-01 23:48:17,139:INFO:Assigning column types.
2024-01-01 23:48:17,147:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:48:17,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:48:17,201:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:48:17,230:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:48:17,278:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:48:17,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,307:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,308:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:48:17,356:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:48:17,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,431:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:48:17,460:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,460:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:48:17,535:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,536:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,613:INFO:Preparing preprocessing pipeline...
2024-01-01 23:48:17,614:INFO:Set up simple imputation.
2024-01-01 23:48:17,615:INFO:Set up column name cleaning.
2024-01-01 23:48:17,665:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:48:17,670:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'income',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spous...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:48:17,670:INFO:Creating final display dataframe.
2024-01-01 23:48:17,818:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 26)
4        Transformed data shape       (31978, 26)
5   Transformed train set shape       (25582, 26)
6    Transformed test set shape        (6396, 26)
7              Numeric features                25
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              cf78
2024-01-01 23:48:17,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:48:17,978:INFO:setup() successfully completed in 0.89s...............
2024-01-01 23:48:18,024:INFO:Initializing compare_models()
2024-01-01 23:48:18,024:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:48:18,025:INFO:Checking exceptions
2024-01-01 23:48:18,033:INFO:Preparing display monitor
2024-01-01 23:48:18,060:INFO:Initializing Logistic Regression
2024-01-01 23:48:18,060:INFO:Total runtime is 0.0 minutes
2024-01-01 23:48:18,064:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:18,065:INFO:Initializing create_model()
2024-01-01 23:48:18,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:18,065:INFO:Checking exceptions
2024-01-01 23:48:18,065:INFO:Importing libraries
2024-01-01 23:48:18,065:INFO:Copying training dataset
2024-01-01 23:48:18,084:INFO:Defining folds
2024-01-01 23:48:18,084:INFO:Declaring metric variables
2024-01-01 23:48:18,088:INFO:Importing untrained model
2024-01-01 23:48:18,092:INFO:Logistic Regression Imported successfully
2024-01-01 23:48:18,101:INFO:Starting cross validation
2024-01-01 23:48:18,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:19,025:INFO:Calculating mean and std
2024-01-01 23:48:19,025:INFO:Creating metrics dataframe
2024-01-01 23:48:19,029:INFO:Uploading results into container
2024-01-01 23:48:19,029:INFO:Uploading model into container now
2024-01-01 23:48:19,030:INFO:_master_model_container: 1
2024-01-01 23:48:19,030:INFO:_display_container: 2
2024-01-01 23:48:19,030:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:48:19,030:INFO:create_model() successfully completed......................................
2024-01-01 23:48:19,470:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:19,470:INFO:Creating metrics dataframe
2024-01-01 23:48:19,479:INFO:Initializing K Neighbors Classifier
2024-01-01 23:48:19,479:INFO:Total runtime is 0.023634020487467447 minutes
2024-01-01 23:48:19,482:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:19,482:INFO:Initializing create_model()
2024-01-01 23:48:19,482:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:19,482:INFO:Checking exceptions
2024-01-01 23:48:19,482:INFO:Importing libraries
2024-01-01 23:48:19,482:INFO:Copying training dataset
2024-01-01 23:48:19,501:INFO:Defining folds
2024-01-01 23:48:19,501:INFO:Declaring metric variables
2024-01-01 23:48:19,507:INFO:Importing untrained model
2024-01-01 23:48:19,511:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:48:19,519:INFO:Starting cross validation
2024-01-01 23:48:19,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:21,057:INFO:Calculating mean and std
2024-01-01 23:48:21,061:INFO:Creating metrics dataframe
2024-01-01 23:48:21,068:INFO:Uploading results into container
2024-01-01 23:48:21,069:INFO:Uploading model into container now
2024-01-01 23:48:21,070:INFO:_master_model_container: 2
2024-01-01 23:48:21,070:INFO:_display_container: 2
2024-01-01 23:48:21,070:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:48:21,070:INFO:create_model() successfully completed......................................
2024-01-01 23:48:21,481:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:21,481:INFO:Creating metrics dataframe
2024-01-01 23:48:21,491:INFO:Initializing Naive Bayes
2024-01-01 23:48:21,492:INFO:Total runtime is 0.05719451506932576 minutes
2024-01-01 23:48:21,495:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:21,495:INFO:Initializing create_model()
2024-01-01 23:48:21,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:21,496:INFO:Checking exceptions
2024-01-01 23:48:21,496:INFO:Importing libraries
2024-01-01 23:48:21,496:INFO:Copying training dataset
2024-01-01 23:48:21,511:INFO:Defining folds
2024-01-01 23:48:21,512:INFO:Declaring metric variables
2024-01-01 23:48:21,515:INFO:Importing untrained model
2024-01-01 23:48:21,519:INFO:Naive Bayes Imported successfully
2024-01-01 23:48:21,525:INFO:Starting cross validation
2024-01-01 23:48:21,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:21,907:INFO:Calculating mean and std
2024-01-01 23:48:21,910:INFO:Creating metrics dataframe
2024-01-01 23:48:21,919:INFO:Uploading results into container
2024-01-01 23:48:21,921:INFO:Uploading model into container now
2024-01-01 23:48:21,922:INFO:_master_model_container: 3
2024-01-01 23:48:21,922:INFO:_display_container: 2
2024-01-01 23:48:21,923:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:48:21,923:INFO:create_model() successfully completed......................................
2024-01-01 23:48:22,282:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:22,282:INFO:Creating metrics dataframe
2024-01-01 23:48:22,291:INFO:Initializing Decision Tree Classifier
2024-01-01 23:48:22,291:INFO:Total runtime is 0.07051627238591512 minutes
2024-01-01 23:48:22,294:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:22,294:INFO:Initializing create_model()
2024-01-01 23:48:22,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:22,295:INFO:Checking exceptions
2024-01-01 23:48:22,295:INFO:Importing libraries
2024-01-01 23:48:22,295:INFO:Copying training dataset
2024-01-01 23:48:22,308:INFO:Defining folds
2024-01-01 23:48:22,308:INFO:Declaring metric variables
2024-01-01 23:48:22,311:INFO:Importing untrained model
2024-01-01 23:48:22,315:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:48:22,322:INFO:Starting cross validation
2024-01-01 23:48:22,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:22,646:INFO:Calculating mean and std
2024-01-01 23:48:22,649:INFO:Creating metrics dataframe
2024-01-01 23:48:22,660:INFO:Uploading results into container
2024-01-01 23:48:22,663:INFO:Uploading model into container now
2024-01-01 23:48:22,664:INFO:_master_model_container: 4
2024-01-01 23:48:22,665:INFO:_display_container: 2
2024-01-01 23:48:22,666:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:48:22,667:INFO:create_model() successfully completed......................................
2024-01-01 23:48:23,021:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:23,021:INFO:Creating metrics dataframe
2024-01-01 23:48:23,030:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:48:23,031:INFO:Total runtime is 0.08284103075663249 minutes
2024-01-01 23:48:23,034:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:23,034:INFO:Initializing create_model()
2024-01-01 23:48:23,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:23,034:INFO:Checking exceptions
2024-01-01 23:48:23,035:INFO:Importing libraries
2024-01-01 23:48:23,035:INFO:Copying training dataset
2024-01-01 23:48:23,048:INFO:Defining folds
2024-01-01 23:48:23,048:INFO:Declaring metric variables
2024-01-01 23:48:23,051:INFO:Importing untrained model
2024-01-01 23:48:23,055:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:48:23,061:INFO:Starting cross validation
2024-01-01 23:48:23,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:24,763:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:24,925:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:24,946:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,056:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,074:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,163:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,188:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,245:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,265:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,283:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:48:25,300:INFO:Calculating mean and std
2024-01-01 23:48:25,303:INFO:Creating metrics dataframe
2024-01-01 23:48:25,310:INFO:Uploading results into container
2024-01-01 23:48:25,311:INFO:Uploading model into container now
2024-01-01 23:48:25,311:INFO:_master_model_container: 5
2024-01-01 23:48:25,311:INFO:_display_container: 2
2024-01-01 23:48:25,312:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:48:25,312:INFO:create_model() successfully completed......................................
2024-01-01 23:48:25,666:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:25,667:INFO:Creating metrics dataframe
2024-01-01 23:48:25,676:INFO:Initializing Ridge Classifier
2024-01-01 23:48:25,676:INFO:Total runtime is 0.1269290049870809 minutes
2024-01-01 23:48:25,679:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:25,679:INFO:Initializing create_model()
2024-01-01 23:48:25,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:25,679:INFO:Checking exceptions
2024-01-01 23:48:25,679:INFO:Importing libraries
2024-01-01 23:48:25,680:INFO:Copying training dataset
2024-01-01 23:48:25,693:INFO:Defining folds
2024-01-01 23:48:25,694:INFO:Declaring metric variables
2024-01-01 23:48:25,697:INFO:Importing untrained model
2024-01-01 23:48:25,701:INFO:Ridge Classifier Imported successfully
2024-01-01 23:48:25,708:INFO:Starting cross validation
2024-01-01 23:48:25,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:25,988:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,005:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,030:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,044:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,056:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,058:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,068:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,076:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,077:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:48:26,104:INFO:Calculating mean and std
2024-01-01 23:48:26,108:INFO:Creating metrics dataframe
2024-01-01 23:48:26,121:INFO:Uploading results into container
2024-01-01 23:48:26,123:INFO:Uploading model into container now
2024-01-01 23:48:26,123:INFO:_master_model_container: 6
2024-01-01 23:48:26,123:INFO:_display_container: 2
2024-01-01 23:48:26,123:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:48:26,123:INFO:create_model() successfully completed......................................
2024-01-01 23:48:26,469:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:26,470:INFO:Creating metrics dataframe
2024-01-01 23:48:26,480:INFO:Initializing Random Forest Classifier
2024-01-01 23:48:26,481:INFO:Total runtime is 0.1403497576713562 minutes
2024-01-01 23:48:26,484:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:26,484:INFO:Initializing create_model()
2024-01-01 23:48:26,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:26,485:INFO:Checking exceptions
2024-01-01 23:48:26,485:INFO:Importing libraries
2024-01-01 23:48:26,485:INFO:Copying training dataset
2024-01-01 23:48:26,498:INFO:Defining folds
2024-01-01 23:48:26,498:INFO:Declaring metric variables
2024-01-01 23:48:26,502:INFO:Importing untrained model
2024-01-01 23:48:26,505:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:48:26,513:INFO:Starting cross validation
2024-01-01 23:48:26,514:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:28,542:INFO:Calculating mean and std
2024-01-01 23:48:28,545:INFO:Creating metrics dataframe
2024-01-01 23:48:28,554:INFO:Uploading results into container
2024-01-01 23:48:28,555:INFO:Uploading model into container now
2024-01-01 23:48:28,556:INFO:_master_model_container: 7
2024-01-01 23:48:28,556:INFO:_display_container: 2
2024-01-01 23:48:28,557:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:48:28,557:INFO:create_model() successfully completed......................................
2024-01-01 23:48:28,921:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:28,921:INFO:Creating metrics dataframe
2024-01-01 23:48:28,932:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:48:28,932:INFO:Total runtime is 0.18119526704152428 minutes
2024-01-01 23:48:28,935:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:28,935:INFO:Initializing create_model()
2024-01-01 23:48:28,936:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:28,936:INFO:Checking exceptions
2024-01-01 23:48:28,936:INFO:Importing libraries
2024-01-01 23:48:28,936:INFO:Copying training dataset
2024-01-01 23:48:28,949:INFO:Defining folds
2024-01-01 23:48:28,949:INFO:Declaring metric variables
2024-01-01 23:48:28,953:INFO:Importing untrained model
2024-01-01 23:48:28,956:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:48:28,964:INFO:Starting cross validation
2024-01-01 23:48:28,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:29,241:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,256:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,279:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,284:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,310:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,332:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,349:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,369:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,388:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,391:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:48:29,440:INFO:Calculating mean and std
2024-01-01 23:48:29,443:INFO:Creating metrics dataframe
2024-01-01 23:48:29,455:INFO:Uploading results into container
2024-01-01 23:48:29,457:INFO:Uploading model into container now
2024-01-01 23:48:29,458:INFO:_master_model_container: 8
2024-01-01 23:48:29,459:INFO:_display_container: 2
2024-01-01 23:48:29,460:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:48:29,460:INFO:create_model() successfully completed......................................
2024-01-01 23:48:29,825:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:29,825:INFO:Creating metrics dataframe
2024-01-01 23:48:29,836:INFO:Initializing Ada Boost Classifier
2024-01-01 23:48:29,836:INFO:Total runtime is 0.1962656656901042 minutes
2024-01-01 23:48:29,839:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:29,839:INFO:Initializing create_model()
2024-01-01 23:48:29,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:29,839:INFO:Checking exceptions
2024-01-01 23:48:29,839:INFO:Importing libraries
2024-01-01 23:48:29,840:INFO:Copying training dataset
2024-01-01 23:48:29,853:INFO:Defining folds
2024-01-01 23:48:29,853:INFO:Declaring metric variables
2024-01-01 23:48:29,857:INFO:Importing untrained model
2024-01-01 23:48:29,861:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:48:29,869:INFO:Starting cross validation
2024-01-01 23:48:29,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:30,225:INFO:Calculating mean and std
2024-01-01 23:48:30,229:INFO:Creating metrics dataframe
2024-01-01 23:48:30,242:INFO:Uploading results into container
2024-01-01 23:48:30,245:INFO:Uploading model into container now
2024-01-01 23:48:30,247:INFO:_master_model_container: 9
2024-01-01 23:48:30,247:INFO:_display_container: 2
2024-01-01 23:48:30,249:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:48:30,249:INFO:create_model() successfully completed......................................
2024-01-01 23:48:30,615:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:30,615:INFO:Creating metrics dataframe
2024-01-01 23:48:30,626:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:48:30,626:INFO:Total runtime is 0.20942780176798506 minutes
2024-01-01 23:48:30,629:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:30,629:INFO:Initializing create_model()
2024-01-01 23:48:30,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:30,629:INFO:Checking exceptions
2024-01-01 23:48:30,629:INFO:Importing libraries
2024-01-01 23:48:30,629:INFO:Copying training dataset
2024-01-01 23:48:30,643:INFO:Defining folds
2024-01-01 23:48:30,644:INFO:Declaring metric variables
2024-01-01 23:48:30,647:INFO:Importing untrained model
2024-01-01 23:48:30,650:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:48:30,657:INFO:Starting cross validation
2024-01-01 23:48:30,658:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:32,875:INFO:Calculating mean and std
2024-01-01 23:48:32,876:INFO:Creating metrics dataframe
2024-01-01 23:48:32,880:INFO:Uploading results into container
2024-01-01 23:48:32,880:INFO:Uploading model into container now
2024-01-01 23:48:32,881:INFO:_master_model_container: 10
2024-01-01 23:48:32,881:INFO:_display_container: 2
2024-01-01 23:48:32,881:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:48:32,881:INFO:create_model() successfully completed......................................
2024-01-01 23:48:33,241:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:33,241:INFO:Creating metrics dataframe
2024-01-01 23:48:33,252:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:48:33,252:INFO:Total runtime is 0.2531962911287944 minutes
2024-01-01 23:48:33,256:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:33,256:INFO:Initializing create_model()
2024-01-01 23:48:33,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:33,256:INFO:Checking exceptions
2024-01-01 23:48:33,256:INFO:Importing libraries
2024-01-01 23:48:33,256:INFO:Copying training dataset
2024-01-01 23:48:33,271:INFO:Defining folds
2024-01-01 23:48:33,272:INFO:Declaring metric variables
2024-01-01 23:48:33,275:INFO:Importing untrained model
2024-01-01 23:48:33,279:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:48:33,286:INFO:Starting cross validation
2024-01-01 23:48:33,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:33,887:INFO:Calculating mean and std
2024-01-01 23:48:33,888:INFO:Creating metrics dataframe
2024-01-01 23:48:33,892:INFO:Uploading results into container
2024-01-01 23:48:33,892:INFO:Uploading model into container now
2024-01-01 23:48:33,893:INFO:_master_model_container: 11
2024-01-01 23:48:33,893:INFO:_display_container: 2
2024-01-01 23:48:33,893:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:48:33,893:INFO:create_model() successfully completed......................................
2024-01-01 23:48:34,252:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:34,252:INFO:Creating metrics dataframe
2024-01-01 23:48:34,264:INFO:Initializing Extra Trees Classifier
2024-01-01 23:48:34,264:INFO:Total runtime is 0.27005539735158285 minutes
2024-01-01 23:48:34,267:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:34,267:INFO:Initializing create_model()
2024-01-01 23:48:34,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:34,267:INFO:Checking exceptions
2024-01-01 23:48:34,267:INFO:Importing libraries
2024-01-01 23:48:34,267:INFO:Copying training dataset
2024-01-01 23:48:34,280:INFO:Defining folds
2024-01-01 23:48:34,280:INFO:Declaring metric variables
2024-01-01 23:48:34,284:INFO:Importing untrained model
2024-01-01 23:48:34,289:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:48:34,297:INFO:Starting cross validation
2024-01-01 23:48:34,298:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:35,968:INFO:Calculating mean and std
2024-01-01 23:48:35,969:INFO:Creating metrics dataframe
2024-01-01 23:48:35,973:INFO:Uploading results into container
2024-01-01 23:48:35,974:INFO:Uploading model into container now
2024-01-01 23:48:35,974:INFO:_master_model_container: 12
2024-01-01 23:48:35,974:INFO:_display_container: 2
2024-01-01 23:48:35,975:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:48:35,975:INFO:create_model() successfully completed......................................
2024-01-01 23:48:36,332:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:36,332:INFO:Creating metrics dataframe
2024-01-01 23:48:36,344:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:48:36,345:INFO:Total runtime is 0.30474241971969607 minutes
2024-01-01 23:48:36,348:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:36,348:INFO:Initializing create_model()
2024-01-01 23:48:36,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:36,349:INFO:Checking exceptions
2024-01-01 23:48:36,349:INFO:Importing libraries
2024-01-01 23:48:36,349:INFO:Copying training dataset
2024-01-01 23:48:36,364:INFO:Defining folds
2024-01-01 23:48:36,364:INFO:Declaring metric variables
2024-01-01 23:48:36,368:INFO:Importing untrained model
2024-01-01 23:48:36,371:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:48:36,378:INFO:Starting cross validation
2024-01-01 23:48:36,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:37,309:INFO:Calculating mean and std
2024-01-01 23:48:37,311:INFO:Creating metrics dataframe
2024-01-01 23:48:37,317:INFO:Uploading results into container
2024-01-01 23:48:37,318:INFO:Uploading model into container now
2024-01-01 23:48:37,319:INFO:_master_model_container: 13
2024-01-01 23:48:37,319:INFO:_display_container: 2
2024-01-01 23:48:37,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:48:37,320:INFO:create_model() successfully completed......................................
2024-01-01 23:48:37,767:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:37,767:INFO:Creating metrics dataframe
2024-01-01 23:48:37,779:INFO:Initializing Dummy Classifier
2024-01-01 23:48:37,779:INFO:Total runtime is 0.3286470731099447 minutes
2024-01-01 23:48:37,782:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:37,783:INFO:Initializing create_model()
2024-01-01 23:48:37,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FBB841360>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:37,783:INFO:Checking exceptions
2024-01-01 23:48:37,783:INFO:Importing libraries
2024-01-01 23:48:37,783:INFO:Copying training dataset
2024-01-01 23:48:37,798:INFO:Defining folds
2024-01-01 23:48:37,798:INFO:Declaring metric variables
2024-01-01 23:48:37,802:INFO:Importing untrained model
2024-01-01 23:48:37,806:INFO:Dummy Classifier Imported successfully
2024-01-01 23:48:37,813:INFO:Starting cross validation
2024-01-01 23:48:37,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:37,978:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,003:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,030:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,046:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,064:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,078:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,080:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,084:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,090:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,092:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:48:38,110:INFO:Calculating mean and std
2024-01-01 23:48:38,114:INFO:Creating metrics dataframe
2024-01-01 23:48:38,126:INFO:Uploading results into container
2024-01-01 23:48:38,128:INFO:Uploading model into container now
2024-01-01 23:48:38,128:INFO:_master_model_container: 14
2024-01-01 23:48:38,128:INFO:_display_container: 2
2024-01-01 23:48:38,130:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:48:38,130:INFO:create_model() successfully completed......................................
2024-01-01 23:48:38,505:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:38,505:INFO:Creating metrics dataframe
2024-01-01 23:48:38,529:INFO:Initializing create_model()
2024-01-01 23:48:38,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:38,530:INFO:Checking exceptions
2024-01-01 23:48:38,531:INFO:Importing libraries
2024-01-01 23:48:38,531:INFO:Copying training dataset
2024-01-01 23:48:38,545:INFO:Defining folds
2024-01-01 23:48:38,546:INFO:Declaring metric variables
2024-01-01 23:48:38,546:INFO:Importing untrained model
2024-01-01 23:48:38,546:INFO:Declaring custom model
2024-01-01 23:48:38,546:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:48:38,547:INFO:Cross validation set to False
2024-01-01 23:48:38,547:INFO:Fitting Model
2024-01-01 23:48:38,593:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:48:38,593:INFO:create_model() successfully completed......................................
2024-01-01 23:48:38,978:INFO:_master_model_container: 14
2024-01-01 23:48:38,978:INFO:_display_container: 2
2024-01-01 23:48:38,978:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:48:38,979:INFO:compare_models() successfully completed......................................
2024-01-01 23:48:39,140:INFO:Initializing plot_model()
2024-01-01 23:48:39,140:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, system=True)
2024-01-01 23:48:39,140:INFO:Checking exceptions
2024-01-01 23:48:39,152:INFO:Preloading libraries
2024-01-01 23:48:39,152:INFO:Copying training dataset
2024-01-01 23:48:39,153:INFO:Plot type: auc
2024-01-01 23:48:39,335:INFO:Fitting Model
2024-01-01 23:48:39,336:INFO:Scoring test/hold-out set
2024-01-01 23:48:39,554:INFO:Visual Rendered Successfully
2024-01-01 23:48:39,908:INFO:plot_model() successfully completed......................................
2024-01-01 23:48:39,961:INFO:Initializing plot_model()
2024-01-01 23:48:39,961:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, system=True)
2024-01-01 23:48:39,961:INFO:Checking exceptions
2024-01-01 23:48:39,972:INFO:Preloading libraries
2024-01-01 23:48:39,973:INFO:Copying training dataset
2024-01-01 23:48:39,973:INFO:Plot type: confusion_matrix
2024-01-01 23:48:40,129:INFO:Fitting Model
2024-01-01 23:48:40,129:INFO:Scoring test/hold-out set
2024-01-01 23:48:40,245:INFO:Visual Rendered Successfully
2024-01-01 23:48:40,599:INFO:plot_model() successfully completed......................................
2024-01-01 23:48:40,685:INFO:Initializing plot_model()
2024-01-01 23:48:40,685:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, system=True)
2024-01-01 23:48:40,685:INFO:Checking exceptions
2024-01-01 23:48:40,693:INFO:Preloading libraries
2024-01-01 23:48:40,693:INFO:Copying training dataset
2024-01-01 23:48:40,694:INFO:Plot type: class_report
2024-01-01 23:48:40,871:INFO:Fitting Model
2024-01-01 23:48:40,872:INFO:Scoring test/hold-out set
2024-01-01 23:48:41,086:INFO:Visual Rendered Successfully
2024-01-01 23:48:41,473:INFO:plot_model() successfully completed......................................
2024-01-01 23:48:41,506:INFO:Initializing tune_model()
2024-01-01 23:48:41,506:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>)
2024-01-01 23:48:41,506:INFO:Checking exceptions
2024-01-01 23:48:41,530:INFO:Copying training dataset
2024-01-01 23:48:41,545:INFO:Checking base model
2024-01-01 23:48:41,546:INFO:Base model : Decision Tree Classifier
2024-01-01 23:48:41,551:INFO:Declaring metric variables
2024-01-01 23:48:41,556:INFO:Defining Hyperparameters
2024-01-01 23:48:41,958:INFO:Tuning with n_jobs=-1
2024-01-01 23:48:41,959:INFO:Initializing RandomizedSearchCV
2024-01-01 23:48:47,468:INFO:Initializing compare_models()
2024-01-01 23:48:47,469:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:48:47,469:INFO:Checking exceptions
2024-01-01 23:48:47,475:INFO:Preparing display monitor
2024-01-01 23:48:47,500:INFO:Initializing Logistic Regression
2024-01-01 23:48:47,500:INFO:Total runtime is 0.0 minutes
2024-01-01 23:48:47,504:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:47,505:INFO:Initializing create_model()
2024-01-01 23:48:47,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FD30E0850>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:47,505:INFO:Checking exceptions
2024-01-01 23:48:47,505:INFO:Importing libraries
2024-01-01 23:48:47,505:INFO:Copying training dataset
2024-01-01 23:48:47,525:INFO:Defining folds
2024-01-01 23:48:47,525:INFO:Declaring metric variables
2024-01-01 23:48:47,529:INFO:Importing untrained model
2024-01-01 23:48:47,534:INFO:Logistic Regression Imported successfully
2024-01-01 23:48:47,541:INFO:Starting cross validation
2024-01-01 23:48:47,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:48:56,637:INFO:Calculating mean and std
2024-01-01 23:48:56,640:INFO:Creating metrics dataframe
2024-01-01 23:48:56,647:INFO:Uploading results into container
2024-01-01 23:48:56,648:INFO:Uploading model into container now
2024-01-01 23:48:56,648:INFO:_master_model_container: 15
2024-01-01 23:48:56,648:INFO:_display_container: 3
2024-01-01 23:48:56,649:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:48:56,650:INFO:create_model() successfully completed......................................
2024-01-01 23:48:57,165:INFO:SubProcess create_model() end ==================================
2024-01-01 23:48:57,165:INFO:Creating metrics dataframe
2024-01-01 23:48:57,177:INFO:Initializing K Neighbors Classifier
2024-01-01 23:48:57,177:INFO:Total runtime is 0.1612776041030884 minutes
2024-01-01 23:48:57,181:INFO:SubProcess create_model() called ==================================
2024-01-01 23:48:57,182:INFO:Initializing create_model()
2024-01-01 23:48:57,182:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020FBCB97C70>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020FD30E0850>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:48:57,182:INFO:Checking exceptions
2024-01-01 23:48:57,182:INFO:Importing libraries
2024-01-01 23:48:57,182:INFO:Copying training dataset
2024-01-01 23:48:57,202:INFO:Defining folds
2024-01-01 23:48:57,202:INFO:Declaring metric variables
2024-01-01 23:48:57,207:INFO:Importing untrained model
2024-01-01 23:48:57,211:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:48:57,218:INFO:Starting cross validation
2024-01-01 23:48:57,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:49:47,831:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:49:47,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:49:47,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:49:47,832:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:49:48,044:INFO:PyCaret ClassificationExperiment
2024-01-01 23:49:48,045:INFO:Logging name: clf-default-name
2024-01-01 23:49:48,045:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:49:48,045:INFO:version 3.1.0
2024-01-01 23:49:48,045:INFO:Initializing setup()
2024-01-01 23:49:48,045:INFO:self.USI: c220
2024-01-01 23:49:48,045:INFO:self._variable_keys: {'seed', 'fix_imbalance', 'y_train', 'fold_generator', 'fold_shuffle_param', '_available_plots', 'USI', 'n_jobs_param', 'exp_name_log', 'gpu_n_jobs_param', 'gpu_param', 'idx', 'data', 'html_param', '_ml_usecase', 'logging_param', 'X', 'y', 'fold_groups_param', 'X_train', 'is_multiclass', 'log_plots_param', 'memory', 'pipeline', 'exp_id', 'y_test', 'target_param', 'X_test'}
2024-01-01 23:49:48,045:INFO:Checking environment
2024-01-01 23:49:48,045:INFO:python_version: 3.10.9
2024-01-01 23:49:48,045:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:49:48,045:INFO:machine: AMD64
2024-01-01 23:49:48,045:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:49:48,045:INFO:Memory: svmem(total=16954372096, available=6169071616, percent=63.6, used=10785300480, free=6169071616)
2024-01-01 23:49:48,045:INFO:Physical Core: 8
2024-01-01 23:49:48,045:INFO:Logical Core: 16
2024-01-01 23:49:48,045:INFO:Checking libraries
2024-01-01 23:49:48,046:INFO:System:
2024-01-01 23:49:48,046:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:49:48,046:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:49:48,046:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:49:48,046:INFO:PyCaret required dependencies:
2024-01-01 23:49:48,734:INFO:                 pip: 22.3.1
2024-01-01 23:49:48,734:INFO:          setuptools: 65.6.3
2024-01-01 23:49:48,734:INFO:             pycaret: 3.1.0
2024-01-01 23:49:48,734:INFO:             IPython: 8.10.0
2024-01-01 23:49:48,734:INFO:          ipywidgets: 7.6.5
2024-01-01 23:49:48,734:INFO:                tqdm: 4.64.1
2024-01-01 23:49:48,734:INFO:               numpy: 1.23.5
2024-01-01 23:49:48,734:INFO:              pandas: 1.5.3
2024-01-01 23:49:48,734:INFO:              jinja2: 3.1.2
2024-01-01 23:49:48,734:INFO:               scipy: 1.10.1
2024-01-01 23:49:48,734:INFO:              joblib: 1.3.2
2024-01-01 23:49:48,734:INFO:             sklearn: 1.2.1
2024-01-01 23:49:48,734:INFO:                pyod: 1.1.0
2024-01-01 23:49:48,734:INFO:            imblearn: 0.10.1
2024-01-01 23:49:48,734:INFO:   category_encoders: 2.6.2
2024-01-01 23:49:48,734:INFO:            lightgbm: 4.1.0
2024-01-01 23:49:48,735:INFO:               numba: 0.56.4
2024-01-01 23:49:48,735:INFO:            requests: 2.28.1
2024-01-01 23:49:48,735:INFO:          matplotlib: 3.7.0
2024-01-01 23:49:48,735:INFO:          scikitplot: 0.3.7
2024-01-01 23:49:48,735:INFO:         yellowbrick: 1.5
2024-01-01 23:49:48,735:INFO:              plotly: 5.9.0
2024-01-01 23:49:48,735:INFO:    plotly-resampler: Not installed
2024-01-01 23:49:48,735:INFO:             kaleido: 0.2.1
2024-01-01 23:49:48,735:INFO:           schemdraw: 0.15
2024-01-01 23:49:48,735:INFO:         statsmodels: 0.13.5
2024-01-01 23:49:48,735:INFO:              sktime: 0.21.1
2024-01-01 23:49:48,735:INFO:               tbats: 1.1.3
2024-01-01 23:49:48,735:INFO:            pmdarima: 2.0.3
2024-01-01 23:49:48,735:INFO:              psutil: 5.9.0
2024-01-01 23:49:48,735:INFO:          markupsafe: 2.1.1
2024-01-01 23:49:48,735:INFO:             pickle5: Not installed
2024-01-01 23:49:48,735:INFO:         cloudpickle: 2.0.0
2024-01-01 23:49:48,735:INFO:         deprecation: 2.1.0
2024-01-01 23:49:48,735:INFO:              xxhash: 3.4.1
2024-01-01 23:49:48,735:INFO:           wurlitzer: Not installed
2024-01-01 23:49:48,735:INFO:PyCaret optional dependencies:
2024-01-01 23:49:48,751:INFO:                shap: Not installed
2024-01-01 23:49:48,751:INFO:           interpret: Not installed
2024-01-01 23:49:48,751:INFO:                umap: Not installed
2024-01-01 23:49:48,751:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:49:48,751:INFO:  explainerdashboard: Not installed
2024-01-01 23:49:48,751:INFO:             autoviz: Not installed
2024-01-01 23:49:48,751:INFO:           fairlearn: Not installed
2024-01-01 23:49:48,751:INFO:          deepchecks: Not installed
2024-01-01 23:49:48,751:INFO:             xgboost: Not installed
2024-01-01 23:49:48,751:INFO:            catboost: Not installed
2024-01-01 23:49:48,751:INFO:              kmodes: Not installed
2024-01-01 23:49:48,751:INFO:             mlxtend: Not installed
2024-01-01 23:49:48,751:INFO:       statsforecast: Not installed
2024-01-01 23:49:48,751:INFO:        tune_sklearn: Not installed
2024-01-01 23:49:48,751:INFO:                 ray: Not installed
2024-01-01 23:49:48,751:INFO:            hyperopt: Not installed
2024-01-01 23:49:48,751:INFO:              optuna: Not installed
2024-01-01 23:49:48,752:INFO:               skopt: Not installed
2024-01-01 23:49:48,752:INFO:              mlflow: Not installed
2024-01-01 23:49:48,752:INFO:              gradio: Not installed
2024-01-01 23:49:48,752:INFO:             fastapi: Not installed
2024-01-01 23:49:48,752:INFO:             uvicorn: Not installed
2024-01-01 23:49:48,752:INFO:              m2cgen: Not installed
2024-01-01 23:49:48,752:INFO:           evidently: Not installed
2024-01-01 23:49:48,752:INFO:               fugue: Not installed
2024-01-01 23:49:48,752:INFO:           streamlit: Not installed
2024-01-01 23:49:48,752:INFO:             prophet: Not installed
2024-01-01 23:49:48,752:INFO:None
2024-01-01 23:49:48,752:INFO:Set up data.
2024-01-01 23:49:48,769:INFO:Set up folding strategy.
2024-01-01 23:49:48,769:INFO:Set up train/test split.
2024-01-01 23:49:48,784:INFO:Set up index.
2024-01-01 23:49:48,785:INFO:Assigning column types.
2024-01-01 23:49:48,790:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:49:48,835:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:49:48,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:49:48,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:48,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:48,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:49:48,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:49:48,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:48,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:48,940:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:49:48,984:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:49:49,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,055:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:49:49,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,083:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:49:49,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,226:INFO:Preparing preprocessing pipeline...
2024-01-01 23:49:49,228:INFO:Set up simple imputation.
2024-01-01 23:49:49,229:INFO:Set up column name cleaning.
2024-01-01 23:49:49,282:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:49:49,288:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'income',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spous...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:49:49,288:INFO:Creating final display dataframe.
2024-01-01 23:49:49,439:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 26)
4        Transformed data shape       (31978, 26)
5   Transformed train set shape       (25582, 26)
6    Transformed test set shape        (6396, 26)
7              Numeric features                25
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              c220
2024-01-01 23:49:49,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:49:49,585:INFO:setup() successfully completed in 1.55s...............
2024-01-01 23:49:49,595:INFO:Initializing compare_models()
2024-01-01 23:49:49,595:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:49:49,595:INFO:Checking exceptions
2024-01-01 23:49:49,606:INFO:Preparing display monitor
2024-01-01 23:49:49,635:INFO:Initializing Logistic Regression
2024-01-01 23:49:49,635:INFO:Total runtime is 0.0 minutes
2024-01-01 23:49:49,638:INFO:SubProcess create_model() called ==================================
2024-01-01 23:49:49,638:INFO:Initializing create_model()
2024-01-01 23:49:49,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:49:49,639:INFO:Checking exceptions
2024-01-01 23:49:49,639:INFO:Importing libraries
2024-01-01 23:49:49,639:INFO:Copying training dataset
2024-01-01 23:49:49,654:INFO:Defining folds
2024-01-01 23:49:49,655:INFO:Declaring metric variables
2024-01-01 23:49:49,659:INFO:Importing untrained model
2024-01-01 23:49:49,663:INFO:Logistic Regression Imported successfully
2024-01-01 23:49:49,671:INFO:Starting cross validation
2024-01-01 23:49:49,678:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:49:58,631:INFO:Calculating mean and std
2024-01-01 23:49:58,634:INFO:Creating metrics dataframe
2024-01-01 23:49:58,641:INFO:Uploading results into container
2024-01-01 23:49:58,642:INFO:Uploading model into container now
2024-01-01 23:49:58,643:INFO:_master_model_container: 1
2024-01-01 23:49:58,643:INFO:_display_container: 2
2024-01-01 23:49:58,644:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:49:58,644:INFO:create_model() successfully completed......................................
2024-01-01 23:49:58,829:INFO:SubProcess create_model() end ==================================
2024-01-01 23:49:58,829:INFO:Creating metrics dataframe
2024-01-01 23:49:58,838:INFO:Initializing K Neighbors Classifier
2024-01-01 23:49:58,839:INFO:Total runtime is 0.15339240233103435 minutes
2024-01-01 23:49:58,842:INFO:SubProcess create_model() called ==================================
2024-01-01 23:49:58,842:INFO:Initializing create_model()
2024-01-01 23:49:58,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:49:58,842:INFO:Checking exceptions
2024-01-01 23:49:58,842:INFO:Importing libraries
2024-01-01 23:49:58,843:INFO:Copying training dataset
2024-01-01 23:49:58,858:INFO:Defining folds
2024-01-01 23:49:58,858:INFO:Declaring metric variables
2024-01-01 23:49:58,862:INFO:Importing untrained model
2024-01-01 23:49:58,865:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:49:58,874:INFO:Starting cross validation
2024-01-01 23:49:58,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:05,015:INFO:Calculating mean and std
2024-01-01 23:50:05,018:INFO:Creating metrics dataframe
2024-01-01 23:50:05,024:INFO:Uploading results into container
2024-01-01 23:50:05,026:INFO:Uploading model into container now
2024-01-01 23:50:05,026:INFO:_master_model_container: 2
2024-01-01 23:50:05,026:INFO:_display_container: 2
2024-01-01 23:50:05,027:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:50:05,027:INFO:create_model() successfully completed......................................
2024-01-01 23:50:05,211:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:05,211:INFO:Creating metrics dataframe
2024-01-01 23:50:05,220:INFO:Initializing Naive Bayes
2024-01-01 23:50:05,221:INFO:Total runtime is 0.2597730120023092 minutes
2024-01-01 23:50:05,224:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:05,224:INFO:Initializing create_model()
2024-01-01 23:50:05,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:05,224:INFO:Checking exceptions
2024-01-01 23:50:05,224:INFO:Importing libraries
2024-01-01 23:50:05,224:INFO:Copying training dataset
2024-01-01 23:50:05,239:INFO:Defining folds
2024-01-01 23:50:05,239:INFO:Declaring metric variables
2024-01-01 23:50:05,243:INFO:Importing untrained model
2024-01-01 23:50:05,246:INFO:Naive Bayes Imported successfully
2024-01-01 23:50:05,254:INFO:Starting cross validation
2024-01-01 23:50:05,255:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:05,658:INFO:Calculating mean and std
2024-01-01 23:50:05,662:INFO:Creating metrics dataframe
2024-01-01 23:50:05,672:INFO:Uploading results into container
2024-01-01 23:50:05,673:INFO:Uploading model into container now
2024-01-01 23:50:05,674:INFO:_master_model_container: 3
2024-01-01 23:50:05,674:INFO:_display_container: 2
2024-01-01 23:50:05,675:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:50:05,675:INFO:create_model() successfully completed......................................
2024-01-01 23:50:05,763:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:05,763:INFO:Creating metrics dataframe
2024-01-01 23:50:05,773:INFO:Initializing Decision Tree Classifier
2024-01-01 23:50:05,773:INFO:Total runtime is 0.26896684169769286 minutes
2024-01-01 23:50:05,777:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:05,777:INFO:Initializing create_model()
2024-01-01 23:50:05,777:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:05,777:INFO:Checking exceptions
2024-01-01 23:50:05,777:INFO:Importing libraries
2024-01-01 23:50:05,778:INFO:Copying training dataset
2024-01-01 23:50:05,792:INFO:Defining folds
2024-01-01 23:50:05,792:INFO:Declaring metric variables
2024-01-01 23:50:05,796:INFO:Importing untrained model
2024-01-01 23:50:05,801:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:50:05,809:INFO:Starting cross validation
2024-01-01 23:50:05,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:06,179:INFO:Calculating mean and std
2024-01-01 23:50:06,180:INFO:Creating metrics dataframe
2024-01-01 23:50:06,184:INFO:Uploading results into container
2024-01-01 23:50:06,185:INFO:Uploading model into container now
2024-01-01 23:50:06,185:INFO:_master_model_container: 4
2024-01-01 23:50:06,186:INFO:_display_container: 2
2024-01-01 23:50:06,186:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:06,186:INFO:create_model() successfully completed......................................
2024-01-01 23:50:06,290:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:06,290:INFO:Creating metrics dataframe
2024-01-01 23:50:06,300:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:50:06,300:INFO:Total runtime is 0.27775423526763915 minutes
2024-01-01 23:50:06,305:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:06,305:INFO:Initializing create_model()
2024-01-01 23:50:06,305:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:06,305:INFO:Checking exceptions
2024-01-01 23:50:06,305:INFO:Importing libraries
2024-01-01 23:50:06,305:INFO:Copying training dataset
2024-01-01 23:50:06,320:INFO:Defining folds
2024-01-01 23:50:06,321:INFO:Declaring metric variables
2024-01-01 23:50:06,325:INFO:Importing untrained model
2024-01-01 23:50:06,329:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:50:06,338:INFO:Starting cross validation
2024-01-01 23:50:06,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:08,453:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:08,686:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:08,726:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:08,805:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:08,854:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:08,897:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:08,942:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:09,032:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:09,040:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:09,081:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:50:09,106:INFO:Calculating mean and std
2024-01-01 23:50:09,107:INFO:Creating metrics dataframe
2024-01-01 23:50:09,109:INFO:Uploading results into container
2024-01-01 23:50:09,110:INFO:Uploading model into container now
2024-01-01 23:50:09,111:INFO:_master_model_container: 5
2024-01-01 23:50:09,111:INFO:_display_container: 2
2024-01-01 23:50:09,111:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:50:09,111:INFO:create_model() successfully completed......................................
2024-01-01 23:50:09,196:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:09,196:INFO:Creating metrics dataframe
2024-01-01 23:50:09,206:INFO:Initializing Ridge Classifier
2024-01-01 23:50:09,207:INFO:Total runtime is 0.3262095808982849 minutes
2024-01-01 23:50:09,210:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:09,211:INFO:Initializing create_model()
2024-01-01 23:50:09,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:09,211:INFO:Checking exceptions
2024-01-01 23:50:09,211:INFO:Importing libraries
2024-01-01 23:50:09,211:INFO:Copying training dataset
2024-01-01 23:50:09,225:INFO:Defining folds
2024-01-01 23:50:09,225:INFO:Declaring metric variables
2024-01-01 23:50:09,230:INFO:Importing untrained model
2024-01-01 23:50:09,234:INFO:Ridge Classifier Imported successfully
2024-01-01 23:50:09,241:INFO:Starting cross validation
2024-01-01 23:50:09,242:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:09,599:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,618:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,637:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,674:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,694:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,701:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,707:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,710:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,711:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:50:09,737:INFO:Calculating mean and std
2024-01-01 23:50:09,738:INFO:Creating metrics dataframe
2024-01-01 23:50:09,745:INFO:Uploading results into container
2024-01-01 23:50:09,747:INFO:Uploading model into container now
2024-01-01 23:50:09,748:INFO:_master_model_container: 6
2024-01-01 23:50:09,748:INFO:_display_container: 2
2024-01-01 23:50:09,749:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:50:09,749:INFO:create_model() successfully completed......................................
2024-01-01 23:50:09,868:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:09,869:INFO:Creating metrics dataframe
2024-01-01 23:50:09,879:INFO:Initializing Random Forest Classifier
2024-01-01 23:50:09,880:INFO:Total runtime is 0.33742674191792804 minutes
2024-01-01 23:50:09,883:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:09,883:INFO:Initializing create_model()
2024-01-01 23:50:09,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:09,884:INFO:Checking exceptions
2024-01-01 23:50:09,884:INFO:Importing libraries
2024-01-01 23:50:09,884:INFO:Copying training dataset
2024-01-01 23:50:09,901:INFO:Defining folds
2024-01-01 23:50:09,901:INFO:Declaring metric variables
2024-01-01 23:50:09,905:INFO:Importing untrained model
2024-01-01 23:50:09,911:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:50:09,919:INFO:Starting cross validation
2024-01-01 23:50:09,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:12,214:INFO:Calculating mean and std
2024-01-01 23:50:12,215:INFO:Creating metrics dataframe
2024-01-01 23:50:12,218:INFO:Uploading results into container
2024-01-01 23:50:12,219:INFO:Uploading model into container now
2024-01-01 23:50:12,219:INFO:_master_model_container: 7
2024-01-01 23:50:12,220:INFO:_display_container: 2
2024-01-01 23:50:12,220:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:50:12,220:INFO:create_model() successfully completed......................................
2024-01-01 23:50:12,309:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:12,309:INFO:Creating metrics dataframe
2024-01-01 23:50:12,319:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:50:12,319:INFO:Total runtime is 0.3780703822771708 minutes
2024-01-01 23:50:12,322:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:12,322:INFO:Initializing create_model()
2024-01-01 23:50:12,322:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:12,322:INFO:Checking exceptions
2024-01-01 23:50:12,322:INFO:Importing libraries
2024-01-01 23:50:12,322:INFO:Copying training dataset
2024-01-01 23:50:12,337:INFO:Defining folds
2024-01-01 23:50:12,337:INFO:Declaring metric variables
2024-01-01 23:50:12,340:INFO:Importing untrained model
2024-01-01 23:50:12,344:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:50:12,351:INFO:Starting cross validation
2024-01-01 23:50:12,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:12,646:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,665:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,688:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,703:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,732:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,747:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,782:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,798:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,804:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,805:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:50:12,860:INFO:Calculating mean and std
2024-01-01 23:50:12,864:INFO:Creating metrics dataframe
2024-01-01 23:50:12,879:INFO:Uploading results into container
2024-01-01 23:50:12,881:INFO:Uploading model into container now
2024-01-01 23:50:12,882:INFO:_master_model_container: 8
2024-01-01 23:50:12,883:INFO:_display_container: 2
2024-01-01 23:50:12,884:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:50:12,884:INFO:create_model() successfully completed......................................
2024-01-01 23:50:12,993:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:12,993:INFO:Creating metrics dataframe
2024-01-01 23:50:13,003:INFO:Initializing Ada Boost Classifier
2024-01-01 23:50:13,003:INFO:Total runtime is 0.3894677360852559 minutes
2024-01-01 23:50:13,007:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:13,007:INFO:Initializing create_model()
2024-01-01 23:50:13,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:13,007:INFO:Checking exceptions
2024-01-01 23:50:13,007:INFO:Importing libraries
2024-01-01 23:50:13,007:INFO:Copying training dataset
2024-01-01 23:50:13,022:INFO:Defining folds
2024-01-01 23:50:13,022:INFO:Declaring metric variables
2024-01-01 23:50:13,026:INFO:Importing untrained model
2024-01-01 23:50:13,030:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:50:13,037:INFO:Starting cross validation
2024-01-01 23:50:13,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:13,396:INFO:Calculating mean and std
2024-01-01 23:50:13,397:INFO:Creating metrics dataframe
2024-01-01 23:50:13,401:INFO:Uploading results into container
2024-01-01 23:50:13,402:INFO:Uploading model into container now
2024-01-01 23:50:13,402:INFO:_master_model_container: 9
2024-01-01 23:50:13,403:INFO:_display_container: 2
2024-01-01 23:50:13,403:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:50:13,403:INFO:create_model() successfully completed......................................
2024-01-01 23:50:13,491:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:13,491:INFO:Creating metrics dataframe
2024-01-01 23:50:13,502:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:50:13,502:INFO:Total runtime is 0.39778177738189696 minutes
2024-01-01 23:50:13,505:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:13,506:INFO:Initializing create_model()
2024-01-01 23:50:13,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:13,506:INFO:Checking exceptions
2024-01-01 23:50:13,506:INFO:Importing libraries
2024-01-01 23:50:13,506:INFO:Copying training dataset
2024-01-01 23:50:13,520:INFO:Defining folds
2024-01-01 23:50:13,520:INFO:Declaring metric variables
2024-01-01 23:50:13,524:INFO:Importing untrained model
2024-01-01 23:50:13,527:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:50:13,534:INFO:Starting cross validation
2024-01-01 23:50:13,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:15,834:INFO:Calculating mean and std
2024-01-01 23:50:15,838:INFO:Creating metrics dataframe
2024-01-01 23:50:15,846:INFO:Uploading results into container
2024-01-01 23:50:15,847:INFO:Uploading model into container now
2024-01-01 23:50:15,848:INFO:_master_model_container: 10
2024-01-01 23:50:15,848:INFO:_display_container: 2
2024-01-01 23:50:15,849:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:50:15,849:INFO:create_model() successfully completed......................................
2024-01-01 23:50:15,938:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:15,938:INFO:Creating metrics dataframe
2024-01-01 23:50:15,949:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:50:15,949:INFO:Total runtime is 0.43857287963231406 minutes
2024-01-01 23:50:15,953:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:15,953:INFO:Initializing create_model()
2024-01-01 23:50:15,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:15,953:INFO:Checking exceptions
2024-01-01 23:50:15,953:INFO:Importing libraries
2024-01-01 23:50:15,954:INFO:Copying training dataset
2024-01-01 23:50:15,971:INFO:Defining folds
2024-01-01 23:50:15,972:INFO:Declaring metric variables
2024-01-01 23:50:15,977:INFO:Importing untrained model
2024-01-01 23:50:15,983:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:50:15,990:INFO:Starting cross validation
2024-01-01 23:50:15,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:16,598:INFO:Calculating mean and std
2024-01-01 23:50:16,599:INFO:Creating metrics dataframe
2024-01-01 23:50:16,603:INFO:Uploading results into container
2024-01-01 23:50:16,603:INFO:Uploading model into container now
2024-01-01 23:50:16,604:INFO:_master_model_container: 11
2024-01-01 23:50:16,604:INFO:_display_container: 2
2024-01-01 23:50:16,604:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:50:16,604:INFO:create_model() successfully completed......................................
2024-01-01 23:50:16,694:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:16,694:INFO:Creating metrics dataframe
2024-01-01 23:50:16,706:INFO:Initializing Extra Trees Classifier
2024-01-01 23:50:16,706:INFO:Total runtime is 0.45118904511133834 minutes
2024-01-01 23:50:16,709:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:16,710:INFO:Initializing create_model()
2024-01-01 23:50:16,710:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:16,710:INFO:Checking exceptions
2024-01-01 23:50:16,710:INFO:Importing libraries
2024-01-01 23:50:16,710:INFO:Copying training dataset
2024-01-01 23:50:16,725:INFO:Defining folds
2024-01-01 23:50:16,726:INFO:Declaring metric variables
2024-01-01 23:50:16,730:INFO:Importing untrained model
2024-01-01 23:50:16,734:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:50:16,743:INFO:Starting cross validation
2024-01-01 23:50:16,744:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:18,582:INFO:Calculating mean and std
2024-01-01 23:50:18,583:INFO:Creating metrics dataframe
2024-01-01 23:50:18,587:INFO:Uploading results into container
2024-01-01 23:50:18,588:INFO:Uploading model into container now
2024-01-01 23:50:18,588:INFO:_master_model_container: 12
2024-01-01 23:50:18,588:INFO:_display_container: 2
2024-01-01 23:50:18,589:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:50:18,589:INFO:create_model() successfully completed......................................
2024-01-01 23:50:18,687:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:18,688:INFO:Creating metrics dataframe
2024-01-01 23:50:18,701:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:50:19,291:INFO:Total runtime is 0.4942650477091472 minutes
2024-01-01 23:50:19,295:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:19,295:INFO:Initializing create_model()
2024-01-01 23:50:19,295:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:19,295:INFO:Checking exceptions
2024-01-01 23:50:19,295:INFO:Importing libraries
2024-01-01 23:50:19,295:INFO:Copying training dataset
2024-01-01 23:50:19,308:INFO:Defining folds
2024-01-01 23:50:19,308:INFO:Declaring metric variables
2024-01-01 23:50:19,313:INFO:Importing untrained model
2024-01-01 23:50:19,316:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:50:19,323:INFO:Starting cross validation
2024-01-01 23:50:19,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:20,256:INFO:Calculating mean and std
2024-01-01 23:50:20,258:INFO:Creating metrics dataframe
2024-01-01 23:50:20,264:INFO:Uploading results into container
2024-01-01 23:50:20,265:INFO:Uploading model into container now
2024-01-01 23:50:20,266:INFO:_master_model_container: 13
2024-01-01 23:50:20,266:INFO:_display_container: 2
2024-01-01 23:50:20,266:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:50:20,267:INFO:create_model() successfully completed......................................
2024-01-01 23:50:20,400:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:20,400:INFO:Creating metrics dataframe
2024-01-01 23:50:20,414:INFO:Initializing Dummy Classifier
2024-01-01 23:50:20,414:INFO:Total runtime is 0.5129901806513469 minutes
2024-01-01 23:50:20,417:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:20,417:INFO:Initializing create_model()
2024-01-01 23:50:20,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221CF537640>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:20,418:INFO:Checking exceptions
2024-01-01 23:50:20,418:INFO:Importing libraries
2024-01-01 23:50:20,418:INFO:Copying training dataset
2024-01-01 23:50:20,433:INFO:Defining folds
2024-01-01 23:50:20,433:INFO:Declaring metric variables
2024-01-01 23:50:20,436:INFO:Importing untrained model
2024-01-01 23:50:20,439:INFO:Dummy Classifier Imported successfully
2024-01-01 23:50:20,446:INFO:Starting cross validation
2024-01-01 23:50:20,449:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:20,643:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,667:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,699:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,701:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,709:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,723:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,728:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,732:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,737:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,739:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:50:20,759:INFO:Calculating mean and std
2024-01-01 23:50:20,762:INFO:Creating metrics dataframe
2024-01-01 23:50:20,774:INFO:Uploading results into container
2024-01-01 23:50:20,776:INFO:Uploading model into container now
2024-01-01 23:50:20,777:INFO:_master_model_container: 14
2024-01-01 23:50:20,777:INFO:_display_container: 2
2024-01-01 23:50:20,778:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:50:20,778:INFO:create_model() successfully completed......................................
2024-01-01 23:50:20,866:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:20,866:INFO:Creating metrics dataframe
2024-01-01 23:50:20,887:INFO:Initializing create_model()
2024-01-01 23:50:20,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:20,887:INFO:Checking exceptions
2024-01-01 23:50:20,889:INFO:Importing libraries
2024-01-01 23:50:20,889:INFO:Copying training dataset
2024-01-01 23:50:20,904:INFO:Defining folds
2024-01-01 23:50:20,904:INFO:Declaring metric variables
2024-01-01 23:50:20,905:INFO:Importing untrained model
2024-01-01 23:50:20,905:INFO:Declaring custom model
2024-01-01 23:50:20,905:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:50:20,906:INFO:Cross validation set to False
2024-01-01 23:50:20,906:INFO:Fitting Model
2024-01-01 23:50:20,955:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:20,955:INFO:create_model() successfully completed......................................
2024-01-01 23:50:21,068:INFO:_master_model_container: 14
2024-01-01 23:50:21,068:INFO:_display_container: 2
2024-01-01 23:50:21,069:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:21,069:INFO:compare_models() successfully completed......................................
2024-01-01 23:50:21,216:INFO:Initializing plot_model()
2024-01-01 23:50:21,216:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, system=True)
2024-01-01 23:50:21,217:INFO:Checking exceptions
2024-01-01 23:50:21,228:INFO:Preloading libraries
2024-01-01 23:50:21,229:INFO:Copying training dataset
2024-01-01 23:50:21,229:INFO:Plot type: auc
2024-01-01 23:50:21,395:INFO:Fitting Model
2024-01-01 23:50:21,396:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-01-01 23:50:21,397:INFO:Scoring test/hold-out set
2024-01-01 23:50:21,615:INFO:Visual Rendered Successfully
2024-01-01 23:50:21,705:INFO:plot_model() successfully completed......................................
2024-01-01 23:50:21,744:INFO:Initializing plot_model()
2024-01-01 23:50:21,744:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, system=True)
2024-01-01 23:50:21,744:INFO:Checking exceptions
2024-01-01 23:50:21,755:INFO:Preloading libraries
2024-01-01 23:50:21,755:INFO:Copying training dataset
2024-01-01 23:50:21,755:INFO:Plot type: confusion_matrix
2024-01-01 23:50:21,930:INFO:Fitting Model
2024-01-01 23:50:21,930:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-01-01 23:50:21,931:INFO:Scoring test/hold-out set
2024-01-01 23:50:22,054:INFO:Visual Rendered Successfully
2024-01-01 23:50:22,142:INFO:plot_model() successfully completed......................................
2024-01-01 23:50:22,181:INFO:Initializing plot_model()
2024-01-01 23:50:22,181:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, system=True)
2024-01-01 23:50:22,182:INFO:Checking exceptions
2024-01-01 23:50:22,190:INFO:Preloading libraries
2024-01-01 23:50:22,190:INFO:Copying training dataset
2024-01-01 23:50:22,191:INFO:Plot type: class_report
2024-01-01 23:50:22,387:INFO:Fitting Model
2024-01-01 23:50:22,387:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-01-01 23:50:22,388:INFO:Scoring test/hold-out set
2024-01-01 23:50:22,613:INFO:Visual Rendered Successfully
2024-01-01 23:50:22,703:INFO:plot_model() successfully completed......................................
2024-01-01 23:50:22,743:INFO:Initializing tune_model()
2024-01-01 23:50:22,743:INFO:tune_model(estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>)
2024-01-01 23:50:22,743:INFO:Checking exceptions
2024-01-01 23:50:22,766:INFO:Copying training dataset
2024-01-01 23:50:22,780:INFO:Checking base model
2024-01-01 23:50:22,780:INFO:Base model : Decision Tree Classifier
2024-01-01 23:50:22,785:INFO:Declaring metric variables
2024-01-01 23:50:22,789:INFO:Defining Hyperparameters
2024-01-01 23:50:22,883:INFO:Tuning with n_jobs=-1
2024-01-01 23:50:22,883:INFO:Initializing RandomizedSearchCV
2024-01-01 23:50:25,759:INFO:best_params: {'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.01, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 1, 'actual_estimator__criterion': 'gini'}
2024-01-01 23:50:25,762:INFO:Hyperparameter search completed
2024-01-01 23:50:25,763:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:25,766:INFO:Initializing create_model()
2024-01-01 23:50:25,766:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D2E63280>, model_only=True, return_train_score=False, kwargs={'min_samples_split': 5, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.01, 'max_features': 1.0, 'max_depth': 1, 'criterion': 'gini'})
2024-01-01 23:50:25,766:INFO:Checking exceptions
2024-01-01 23:50:25,767:INFO:Importing libraries
2024-01-01 23:50:25,767:INFO:Copying training dataset
2024-01-01 23:50:25,827:INFO:Defining folds
2024-01-01 23:50:25,827:INFO:Declaring metric variables
2024-01-01 23:50:25,831:INFO:Importing untrained model
2024-01-01 23:50:25,832:INFO:Declaring custom model
2024-01-01 23:50:25,836:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:50:25,846:INFO:Starting cross validation
2024-01-01 23:50:25,847:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:26,212:INFO:Calculating mean and std
2024-01-01 23:50:26,214:INFO:Creating metrics dataframe
2024-01-01 23:50:26,219:INFO:Finalizing model
2024-01-01 23:50:26,279:INFO:Uploading results into container
2024-01-01 23:50:26,280:INFO:Uploading model into container now
2024-01-01 23:50:26,280:INFO:_master_model_container: 15
2024-01-01 23:50:26,280:INFO:_display_container: 3
2024-01-01 23:50:26,280:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:26,281:INFO:create_model() successfully completed......................................
2024-01-01 23:50:26,375:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:26,375:INFO:choose_better activated
2024-01-01 23:50:26,379:INFO:SubProcess create_model() called ==================================
2024-01-01 23:50:26,379:INFO:Initializing create_model()
2024-01-01 23:50:26,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:50:26,380:INFO:Checking exceptions
2024-01-01 23:50:26,381:INFO:Importing libraries
2024-01-01 23:50:26,381:INFO:Copying training dataset
2024-01-01 23:50:26,396:INFO:Defining folds
2024-01-01 23:50:26,396:INFO:Declaring metric variables
2024-01-01 23:50:26,396:INFO:Importing untrained model
2024-01-01 23:50:26,396:INFO:Declaring custom model
2024-01-01 23:50:26,397:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:50:26,397:INFO:Starting cross validation
2024-01-01 23:50:26,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:50:26,731:INFO:Calculating mean and std
2024-01-01 23:50:26,731:INFO:Creating metrics dataframe
2024-01-01 23:50:26,734:INFO:Finalizing model
2024-01-01 23:50:26,796:INFO:Uploading results into container
2024-01-01 23:50:26,798:INFO:Uploading model into container now
2024-01-01 23:50:26,798:INFO:_master_model_container: 16
2024-01-01 23:50:26,798:INFO:_display_container: 4
2024-01-01 23:50:26,798:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:26,798:INFO:create_model() successfully completed......................................
2024-01-01 23:50:26,904:INFO:SubProcess create_model() end ==================================
2024-01-01 23:50:26,905:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 1.0
2024-01-01 23:50:26,905:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=1, max_features=1.0, max_leaf_nodes=None,
                       min_impurity_decrease=0.01, min_samples_leaf=6,
                       min_samples_split=5, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') result for Accuracy is 1.0
2024-01-01 23:50:26,905:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best') is best model
2024-01-01 23:50:26,905:INFO:choose_better completed
2024-01-01 23:50:26,905:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-01 23:50:26,916:INFO:_master_model_container: 16
2024-01-01 23:50:26,917:INFO:_display_container: 3
2024-01-01 23:50:26,917:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:26,917:INFO:tune_model() successfully completed......................................
2024-01-01 23:50:27,210:INFO:Initializing plot_model()
2024-01-01 23:50:27,210:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, system=True)
2024-01-01 23:50:27,210:INFO:Checking exceptions
2024-01-01 23:50:27,224:INFO:Preloading libraries
2024-01-01 23:50:27,224:INFO:Copying training dataset
2024-01-01 23:50:27,225:INFO:Plot type: auc
2024-01-01 23:50:27,424:INFO:Fitting Model
2024-01-01 23:50:27,425:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-01-01 23:50:27,425:INFO:Scoring test/hold-out set
2024-01-01 23:50:27,651:INFO:Visual Rendered Successfully
2024-01-01 23:50:27,741:INFO:plot_model() successfully completed......................................
2024-01-01 23:50:27,780:INFO:Initializing plot_model()
2024-01-01 23:50:27,780:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, system=True)
2024-01-01 23:50:27,780:INFO:Checking exceptions
2024-01-01 23:50:27,789:INFO:Preloading libraries
2024-01-01 23:50:27,790:INFO:Copying training dataset
2024-01-01 23:50:27,790:INFO:Plot type: confusion_matrix
2024-01-01 23:50:27,948:INFO:Fitting Model
2024-01-01 23:50:27,949:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-01-01 23:50:27,949:INFO:Scoring test/hold-out set
2024-01-01 23:50:28,069:INFO:Visual Rendered Successfully
2024-01-01 23:50:28,162:INFO:plot_model() successfully completed......................................
2024-01-01 23:50:28,203:INFO:Initializing plot_model()
2024-01-01 23:50:28,203:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, system=True)
2024-01-01 23:50:28,203:INFO:Checking exceptions
2024-01-01 23:50:28,213:INFO:Preloading libraries
2024-01-01 23:50:28,213:INFO:Copying training dataset
2024-01-01 23:50:28,213:INFO:Plot type: class_report
2024-01-01 23:50:28,375:INFO:Fitting Model
2024-01-01 23:50:28,375:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but DecisionTreeClassifier was fitted with feature names
  warnings.warn(

2024-01-01 23:50:28,376:INFO:Scoring test/hold-out set
2024-01-01 23:50:28,610:INFO:Visual Rendered Successfully
2024-01-01 23:50:28,721:INFO:plot_model() successfully completed......................................
2024-01-01 23:50:28,758:INFO:Initializing finalize_model()
2024-01-01 23:50:28,758:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-01 23:50:28,758:INFO:Finalizing DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:50:28,765:INFO:Initializing create_model()
2024-01-01 23:50:28,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best'), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-01 23:50:28,765:INFO:Checking exceptions
2024-01-01 23:50:28,767:INFO:Importing libraries
2024-01-01 23:50:28,767:INFO:Copying training dataset
2024-01-01 23:50:28,768:INFO:Defining folds
2024-01-01 23:50:28,768:INFO:Declaring metric variables
2024-01-01 23:50:28,769:INFO:Importing untrained model
2024-01-01 23:50:28,769:INFO:Declaring custom model
2024-01-01 23:50:28,769:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:50:28,770:INFO:Cross validation set to False
2024-01-01 23:50:28,770:INFO:Fitting Model
2024-01-01 23:50:28,844:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'income',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married'...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2024-01-01 23:50:28,844:INFO:create_model() successfully completed......................................
2024-01-01 23:50:28,940:INFO:_master_model_container: 16
2024-01-01 23:50:28,940:INFO:_display_container: 3
2024-01-01 23:50:28,945:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'income',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married'...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False)
2024-01-01 23:50:28,946:INFO:finalize_model() successfully completed......................................
2024-01-01 23:50:29,130:INFO:Initializing predict_model()
2024-01-01 23:50:29,825:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221D251C250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week', 'income',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married'...
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('actual_estimator',
                 DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,
                                        criterion='gini', max_depth=None,
                                        max_features=None, max_leaf_nodes=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        random_state=123, splitter='best'))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000221D2E00F70>)
2024-01-01 23:50:29,825:INFO:Checking exceptions
2024-01-01 23:50:29,826:INFO:Preloading libraries
2024-01-01 23:50:29,832:INFO:Set up data.
2024-01-01 23:50:29,857:INFO:Set up index.
2024-01-01 23:52:09,588:INFO:PyCaret ClassificationExperiment
2024-01-01 23:52:09,588:INFO:Logging name: clf-default-name
2024-01-01 23:52:09,588:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:52:09,588:INFO:version 3.1.0
2024-01-01 23:52:09,588:INFO:Initializing setup()
2024-01-01 23:52:09,588:INFO:self.USI: 7380
2024-01-01 23:52:09,588:INFO:self._variable_keys: {'seed', 'fix_imbalance', 'y_train', 'fold_generator', 'fold_shuffle_param', '_available_plots', 'USI', 'n_jobs_param', 'exp_name_log', 'gpu_n_jobs_param', 'gpu_param', 'idx', 'data', 'html_param', '_ml_usecase', 'logging_param', 'X', 'y', 'fold_groups_param', 'X_train', 'is_multiclass', 'log_plots_param', 'memory', 'pipeline', 'exp_id', 'y_test', 'target_param', 'X_test'}
2024-01-01 23:52:09,588:INFO:Checking environment
2024-01-01 23:52:09,588:INFO:python_version: 3.10.9
2024-01-01 23:52:09,589:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:52:09,589:INFO:machine: AMD64
2024-01-01 23:52:09,589:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:52:09,589:INFO:Memory: svmem(total=16954372096, available=3030568960, percent=82.1, used=13923803136, free=3030568960)
2024-01-01 23:52:09,589:INFO:Physical Core: 8
2024-01-01 23:52:09,589:INFO:Logical Core: 16
2024-01-01 23:52:09,589:INFO:Checking libraries
2024-01-01 23:52:09,589:INFO:System:
2024-01-01 23:52:09,589:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:52:09,589:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:52:09,589:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:52:09,589:INFO:PyCaret required dependencies:
2024-01-01 23:52:09,589:INFO:                 pip: 22.3.1
2024-01-01 23:52:09,589:INFO:          setuptools: 65.6.3
2024-01-01 23:52:09,589:INFO:             pycaret: 3.1.0
2024-01-01 23:52:09,589:INFO:             IPython: 8.10.0
2024-01-01 23:52:09,589:INFO:          ipywidgets: 7.6.5
2024-01-01 23:52:09,590:INFO:                tqdm: 4.64.1
2024-01-01 23:52:09,590:INFO:               numpy: 1.23.5
2024-01-01 23:52:09,590:INFO:              pandas: 1.5.3
2024-01-01 23:52:09,590:INFO:              jinja2: 3.1.2
2024-01-01 23:52:09,590:INFO:               scipy: 1.10.1
2024-01-01 23:52:09,590:INFO:              joblib: 1.3.2
2024-01-01 23:52:09,590:INFO:             sklearn: 1.2.1
2024-01-01 23:52:09,590:INFO:                pyod: 1.1.0
2024-01-01 23:52:09,590:INFO:            imblearn: 0.10.1
2024-01-01 23:52:09,590:INFO:   category_encoders: 2.6.2
2024-01-01 23:52:09,590:INFO:            lightgbm: 4.1.0
2024-01-01 23:52:09,590:INFO:               numba: 0.56.4
2024-01-01 23:52:09,590:INFO:            requests: 2.28.1
2024-01-01 23:52:09,590:INFO:          matplotlib: 3.7.0
2024-01-01 23:52:09,590:INFO:          scikitplot: 0.3.7
2024-01-01 23:52:09,590:INFO:         yellowbrick: 1.5
2024-01-01 23:52:09,590:INFO:              plotly: 5.9.0
2024-01-01 23:52:09,590:INFO:    plotly-resampler: Not installed
2024-01-01 23:52:09,590:INFO:             kaleido: 0.2.1
2024-01-01 23:52:09,590:INFO:           schemdraw: 0.15
2024-01-01 23:52:09,590:INFO:         statsmodels: 0.13.5
2024-01-01 23:52:09,590:INFO:              sktime: 0.21.1
2024-01-01 23:52:09,590:INFO:               tbats: 1.1.3
2024-01-01 23:52:09,591:INFO:            pmdarima: 2.0.3
2024-01-01 23:52:09,591:INFO:              psutil: 5.9.0
2024-01-01 23:52:09,591:INFO:          markupsafe: 2.1.1
2024-01-01 23:52:09,591:INFO:             pickle5: Not installed
2024-01-01 23:52:09,591:INFO:         cloudpickle: 2.0.0
2024-01-01 23:52:09,591:INFO:         deprecation: 2.1.0
2024-01-01 23:52:09,591:INFO:              xxhash: 3.4.1
2024-01-01 23:52:09,591:INFO:           wurlitzer: Not installed
2024-01-01 23:52:09,591:INFO:PyCaret optional dependencies:
2024-01-01 23:52:09,591:INFO:                shap: Not installed
2024-01-01 23:52:09,591:INFO:           interpret: Not installed
2024-01-01 23:52:09,591:INFO:                umap: Not installed
2024-01-01 23:52:09,591:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:52:09,592:INFO:  explainerdashboard: Not installed
2024-01-01 23:52:09,592:INFO:             autoviz: Not installed
2024-01-01 23:52:09,592:INFO:           fairlearn: Not installed
2024-01-01 23:52:09,592:INFO:          deepchecks: Not installed
2024-01-01 23:52:09,592:INFO:             xgboost: Not installed
2024-01-01 23:52:09,592:INFO:            catboost: Not installed
2024-01-01 23:52:09,592:INFO:              kmodes: Not installed
2024-01-01 23:52:09,592:INFO:             mlxtend: Not installed
2024-01-01 23:52:09,592:INFO:       statsforecast: Not installed
2024-01-01 23:52:09,592:INFO:        tune_sklearn: Not installed
2024-01-01 23:52:09,592:INFO:                 ray: Not installed
2024-01-01 23:52:09,592:INFO:            hyperopt: Not installed
2024-01-01 23:52:09,592:INFO:              optuna: Not installed
2024-01-01 23:52:09,592:INFO:               skopt: Not installed
2024-01-01 23:52:09,592:INFO:              mlflow: Not installed
2024-01-01 23:52:09,592:INFO:              gradio: Not installed
2024-01-01 23:52:09,593:INFO:             fastapi: Not installed
2024-01-01 23:52:09,593:INFO:             uvicorn: Not installed
2024-01-01 23:52:09,593:INFO:              m2cgen: Not installed
2024-01-01 23:52:09,593:INFO:           evidently: Not installed
2024-01-01 23:52:09,593:INFO:               fugue: Not installed
2024-01-01 23:52:09,593:INFO:           streamlit: Not installed
2024-01-01 23:52:09,593:INFO:             prophet: Not installed
2024-01-01 23:52:09,593:INFO:None
2024-01-01 23:52:09,593:INFO:Set up data.
2024-01-01 23:53:04,404:WARNING:C:\Users\visha\AppData\Local\Temp\ipykernel_29104\2081779983.py:3: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.
  sns.heatmap(data.corr(),annot=True)

2024-01-01 23:53:05,417:INFO:PyCaret ClassificationExperiment
2024-01-01 23:53:05,417:INFO:Logging name: clf-default-name
2024-01-01 23:53:05,417:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:53:05,417:INFO:version 3.1.0
2024-01-01 23:53:05,417:INFO:Initializing setup()
2024-01-01 23:53:05,417:INFO:self.USI: 911c
2024-01-01 23:53:05,417:INFO:self._variable_keys: {'seed', 'fix_imbalance', 'y_train', 'fold_generator', 'fold_shuffle_param', '_available_plots', 'USI', 'n_jobs_param', 'exp_name_log', 'gpu_n_jobs_param', 'gpu_param', 'idx', 'data', 'html_param', '_ml_usecase', 'logging_param', 'X', 'y', 'fold_groups_param', 'X_train', 'is_multiclass', 'log_plots_param', 'memory', 'pipeline', 'exp_id', 'y_test', 'target_param', 'X_test'}
2024-01-01 23:53:05,417:INFO:Checking environment
2024-01-01 23:53:05,417:INFO:python_version: 3.10.9
2024-01-01 23:53:05,417:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:53:05,417:INFO:machine: AMD64
2024-01-01 23:53:05,417:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:53:05,417:INFO:Memory: svmem(total=16954372096, available=2980249600, percent=82.4, used=13974122496, free=2980249600)
2024-01-01 23:53:05,417:INFO:Physical Core: 8
2024-01-01 23:53:05,417:INFO:Logical Core: 16
2024-01-01 23:53:05,417:INFO:Checking libraries
2024-01-01 23:53:05,417:INFO:System:
2024-01-01 23:53:05,418:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:53:05,418:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:53:05,418:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:53:05,418:INFO:PyCaret required dependencies:
2024-01-01 23:53:05,418:INFO:                 pip: 22.3.1
2024-01-01 23:53:05,418:INFO:          setuptools: 65.6.3
2024-01-01 23:53:05,418:INFO:             pycaret: 3.1.0
2024-01-01 23:53:05,418:INFO:             IPython: 8.10.0
2024-01-01 23:53:05,418:INFO:          ipywidgets: 7.6.5
2024-01-01 23:53:05,418:INFO:                tqdm: 4.64.1
2024-01-01 23:53:05,418:INFO:               numpy: 1.23.5
2024-01-01 23:53:05,418:INFO:              pandas: 1.5.3
2024-01-01 23:53:05,418:INFO:              jinja2: 3.1.2
2024-01-01 23:53:05,418:INFO:               scipy: 1.10.1
2024-01-01 23:53:05,418:INFO:              joblib: 1.3.2
2024-01-01 23:53:05,418:INFO:             sklearn: 1.2.1
2024-01-01 23:53:05,418:INFO:                pyod: 1.1.0
2024-01-01 23:53:05,418:INFO:            imblearn: 0.10.1
2024-01-01 23:53:05,418:INFO:   category_encoders: 2.6.2
2024-01-01 23:53:05,418:INFO:            lightgbm: 4.1.0
2024-01-01 23:53:05,419:INFO:               numba: 0.56.4
2024-01-01 23:53:05,419:INFO:            requests: 2.28.1
2024-01-01 23:53:05,419:INFO:          matplotlib: 3.7.0
2024-01-01 23:53:05,419:INFO:          scikitplot: 0.3.7
2024-01-01 23:53:05,419:INFO:         yellowbrick: 1.5
2024-01-01 23:53:05,419:INFO:              plotly: 5.9.0
2024-01-01 23:53:05,419:INFO:    plotly-resampler: Not installed
2024-01-01 23:53:05,419:INFO:             kaleido: 0.2.1
2024-01-01 23:53:05,419:INFO:           schemdraw: 0.15
2024-01-01 23:53:05,419:INFO:         statsmodels: 0.13.5
2024-01-01 23:53:05,419:INFO:              sktime: 0.21.1
2024-01-01 23:53:05,419:INFO:               tbats: 1.1.3
2024-01-01 23:53:05,419:INFO:            pmdarima: 2.0.3
2024-01-01 23:53:05,419:INFO:              psutil: 5.9.0
2024-01-01 23:53:05,419:INFO:          markupsafe: 2.1.1
2024-01-01 23:53:05,419:INFO:             pickle5: Not installed
2024-01-01 23:53:05,419:INFO:         cloudpickle: 2.0.0
2024-01-01 23:53:05,419:INFO:         deprecation: 2.1.0
2024-01-01 23:53:05,419:INFO:              xxhash: 3.4.1
2024-01-01 23:53:05,419:INFO:           wurlitzer: Not installed
2024-01-01 23:53:05,419:INFO:PyCaret optional dependencies:
2024-01-01 23:53:05,419:INFO:                shap: Not installed
2024-01-01 23:53:05,420:INFO:           interpret: Not installed
2024-01-01 23:53:05,420:INFO:                umap: Not installed
2024-01-01 23:53:05,420:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:53:05,420:INFO:  explainerdashboard: Not installed
2024-01-01 23:53:05,420:INFO:             autoviz: Not installed
2024-01-01 23:53:05,420:INFO:           fairlearn: Not installed
2024-01-01 23:53:05,420:INFO:          deepchecks: Not installed
2024-01-01 23:53:05,420:INFO:             xgboost: Not installed
2024-01-01 23:53:05,420:INFO:            catboost: Not installed
2024-01-01 23:53:05,420:INFO:              kmodes: Not installed
2024-01-01 23:53:05,420:INFO:             mlxtend: Not installed
2024-01-01 23:53:05,420:INFO:       statsforecast: Not installed
2024-01-01 23:53:05,420:INFO:        tune_sklearn: Not installed
2024-01-01 23:53:05,420:INFO:                 ray: Not installed
2024-01-01 23:53:05,420:INFO:            hyperopt: Not installed
2024-01-01 23:53:05,420:INFO:              optuna: Not installed
2024-01-01 23:53:05,420:INFO:               skopt: Not installed
2024-01-01 23:53:05,420:INFO:              mlflow: Not installed
2024-01-01 23:53:05,420:INFO:              gradio: Not installed
2024-01-01 23:53:05,420:INFO:             fastapi: Not installed
2024-01-01 23:53:05,420:INFO:             uvicorn: Not installed
2024-01-01 23:53:05,421:INFO:              m2cgen: Not installed
2024-01-01 23:53:05,421:INFO:           evidently: Not installed
2024-01-01 23:53:05,421:INFO:               fugue: Not installed
2024-01-01 23:53:05,421:INFO:           streamlit: Not installed
2024-01-01 23:53:05,421:INFO:             prophet: Not installed
2024-01-01 23:53:05,421:INFO:None
2024-01-01 23:53:05,421:INFO:Set up data.
2024-01-01 23:53:05,434:INFO:Set up folding strategy.
2024-01-01 23:53:05,434:INFO:Set up train/test split.
2024-01-01 23:53:05,449:INFO:Set up index.
2024-01-01 23:53:05,450:INFO:Assigning column types.
2024-01-01 23:53:05,456:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:53:05,501:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:53:05,501:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:53:05,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:53:05,574:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:53:05,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,602:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:53:05,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:53:05,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:53:05,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,744:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:53:05,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:05,882:INFO:Preparing preprocessing pipeline...
2024-01-01 23:53:05,883:INFO:Set up simple imputation.
2024-01-01 23:53:05,884:INFO:Set up column name cleaning.
2024-01-01 23:53:05,926:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:53:05,931:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'income',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'mari...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:53:05,931:INFO:Creating final display dataframe.
2024-01-01 23:53:06,053:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (31978, 19)
4        Transformed data shape       (31978, 19)
5   Transformed train set shape       (25582, 19)
6    Transformed test set shape        (6396, 19)
7              Numeric features                18
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              911c
2024-01-01 23:53:06,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:06,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:06,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:06,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:53:06,203:INFO:setup() successfully completed in 0.79s...............
2024-01-01 23:53:06,236:INFO:Initializing compare_models()
2024-01-01 23:53:06,236:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:53:06,236:INFO:Checking exceptions
2024-01-01 23:53:06,244:INFO:Preparing display monitor
2024-01-01 23:53:06,269:INFO:Initializing Logistic Regression
2024-01-01 23:53:06,270:INFO:Total runtime is 1.6661485036214194e-05 minutes
2024-01-01 23:53:06,273:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:06,273:INFO:Initializing create_model()
2024-01-01 23:53:06,273:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:06,273:INFO:Checking exceptions
2024-01-01 23:53:06,273:INFO:Importing libraries
2024-01-01 23:53:06,273:INFO:Copying training dataset
2024-01-01 23:53:06,287:INFO:Defining folds
2024-01-01 23:53:06,287:INFO:Declaring metric variables
2024-01-01 23:53:06,291:INFO:Importing untrained model
2024-01-01 23:53:06,294:INFO:Logistic Regression Imported successfully
2024-01-01 23:53:06,300:INFO:Starting cross validation
2024-01-01 23:53:06,301:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:13,796:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:13,841:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:13,879:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:13,882:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:13,916:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:13,949:INFO:Calculating mean and std
2024-01-01 23:53:13,950:INFO:Creating metrics dataframe
2024-01-01 23:53:13,953:INFO:Uploading results into container
2024-01-01 23:53:13,954:INFO:Uploading model into container now
2024-01-01 23:53:13,954:INFO:_master_model_container: 1
2024-01-01 23:53:13,954:INFO:_display_container: 2
2024-01-01 23:53:13,955:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:53:13,955:INFO:create_model() successfully completed......................................
2024-01-01 23:53:14,162:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:14,162:INFO:Creating metrics dataframe
2024-01-01 23:53:14,170:INFO:Initializing K Neighbors Classifier
2024-01-01 23:53:14,171:INFO:Total runtime is 0.13169523874918618 minutes
2024-01-01 23:53:14,174:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:14,174:INFO:Initializing create_model()
2024-01-01 23:53:14,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:14,174:INFO:Checking exceptions
2024-01-01 23:53:14,174:INFO:Importing libraries
2024-01-01 23:53:14,174:INFO:Copying training dataset
2024-01-01 23:53:14,186:INFO:Defining folds
2024-01-01 23:53:14,187:INFO:Declaring metric variables
2024-01-01 23:53:14,190:INFO:Importing untrained model
2024-01-01 23:53:14,195:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:53:14,201:INFO:Starting cross validation
2024-01-01 23:53:14,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:15,968:INFO:Calculating mean and std
2024-01-01 23:53:15,971:INFO:Creating metrics dataframe
2024-01-01 23:53:15,983:INFO:Uploading results into container
2024-01-01 23:53:15,986:INFO:Uploading model into container now
2024-01-01 23:53:15,987:INFO:_master_model_container: 2
2024-01-01 23:53:15,988:INFO:_display_container: 2
2024-01-01 23:53:15,990:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:53:15,990:INFO:create_model() successfully completed......................................
2024-01-01 23:53:16,212:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:16,212:INFO:Creating metrics dataframe
2024-01-01 23:53:16,222:INFO:Initializing Naive Bayes
2024-01-01 23:53:16,222:INFO:Total runtime is 0.16587740182876584 minutes
2024-01-01 23:53:16,226:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:16,226:INFO:Initializing create_model()
2024-01-01 23:53:16,226:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:16,226:INFO:Checking exceptions
2024-01-01 23:53:16,227:INFO:Importing libraries
2024-01-01 23:53:16,227:INFO:Copying training dataset
2024-01-01 23:53:16,239:INFO:Defining folds
2024-01-01 23:53:16,240:INFO:Declaring metric variables
2024-01-01 23:53:16,243:INFO:Importing untrained model
2024-01-01 23:53:16,248:INFO:Naive Bayes Imported successfully
2024-01-01 23:53:16,254:INFO:Starting cross validation
2024-01-01 23:53:16,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:16,580:INFO:Calculating mean and std
2024-01-01 23:53:16,583:INFO:Creating metrics dataframe
2024-01-01 23:53:16,592:INFO:Uploading results into container
2024-01-01 23:53:16,594:INFO:Uploading model into container now
2024-01-01 23:53:16,594:INFO:_master_model_container: 3
2024-01-01 23:53:16,595:INFO:_display_container: 2
2024-01-01 23:53:16,595:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:53:16,596:INFO:create_model() successfully completed......................................
2024-01-01 23:53:16,791:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:16,791:INFO:Creating metrics dataframe
2024-01-01 23:53:16,801:INFO:Initializing Decision Tree Classifier
2024-01-01 23:53:16,801:INFO:Total runtime is 0.17553706169128416 minutes
2024-01-01 23:53:16,805:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:16,805:INFO:Initializing create_model()
2024-01-01 23:53:16,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:16,806:INFO:Checking exceptions
2024-01-01 23:53:16,806:INFO:Importing libraries
2024-01-01 23:53:16,806:INFO:Copying training dataset
2024-01-01 23:53:16,818:INFO:Defining folds
2024-01-01 23:53:16,818:INFO:Declaring metric variables
2024-01-01 23:53:16,822:INFO:Importing untrained model
2024-01-01 23:53:16,825:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:53:16,832:INFO:Starting cross validation
2024-01-01 23:53:16,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:17,099:INFO:Calculating mean and std
2024-01-01 23:53:17,100:INFO:Creating metrics dataframe
2024-01-01 23:53:17,105:INFO:Uploading results into container
2024-01-01 23:53:17,105:INFO:Uploading model into container now
2024-01-01 23:53:17,106:INFO:_master_model_container: 4
2024-01-01 23:53:17,106:INFO:_display_container: 2
2024-01-01 23:53:17,106:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:53:17,107:INFO:create_model() successfully completed......................................
2024-01-01 23:53:17,305:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:17,305:INFO:Creating metrics dataframe
2024-01-01 23:53:17,315:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:53:17,316:INFO:Total runtime is 0.18411543369293212 minutes
2024-01-01 23:53:17,320:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:17,320:INFO:Initializing create_model()
2024-01-01 23:53:17,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:17,321:INFO:Checking exceptions
2024-01-01 23:53:17,321:INFO:Importing libraries
2024-01-01 23:53:17,321:INFO:Copying training dataset
2024-01-01 23:53:17,333:INFO:Defining folds
2024-01-01 23:53:17,334:INFO:Declaring metric variables
2024-01-01 23:53:17,337:INFO:Importing untrained model
2024-01-01 23:53:17,341:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:53:17,348:INFO:Starting cross validation
2024-01-01 23:53:17,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:17,661:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,762:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,779:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,785:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,816:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,829:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,830:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,833:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,848:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,864:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:53:17,886:INFO:Calculating mean and std
2024-01-01 23:53:17,887:INFO:Creating metrics dataframe
2024-01-01 23:53:17,891:INFO:Uploading results into container
2024-01-01 23:53:17,891:INFO:Uploading model into container now
2024-01-01 23:53:17,892:INFO:_master_model_container: 5
2024-01-01 23:53:17,892:INFO:_display_container: 2
2024-01-01 23:53:17,893:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:53:17,893:INFO:create_model() successfully completed......................................
2024-01-01 23:53:18,082:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:18,083:INFO:Creating metrics dataframe
2024-01-01 23:53:18,092:INFO:Initializing Ridge Classifier
2024-01-01 23:53:18,092:INFO:Total runtime is 0.19705032507578532 minutes
2024-01-01 23:53:18,095:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:18,095:INFO:Initializing create_model()
2024-01-01 23:53:18,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:18,096:INFO:Checking exceptions
2024-01-01 23:53:18,096:INFO:Importing libraries
2024-01-01 23:53:18,096:INFO:Copying training dataset
2024-01-01 23:53:18,107:INFO:Defining folds
2024-01-01 23:53:18,107:INFO:Declaring metric variables
2024-01-01 23:53:18,111:INFO:Importing untrained model
2024-01-01 23:53:18,116:INFO:Ridge Classifier Imported successfully
2024-01-01 23:53:18,125:INFO:Starting cross validation
2024-01-01 23:53:18,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:18,355:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,356:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,381:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,387:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,387:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,399:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,410:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,411:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,415:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,423:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:53:18,437:INFO:Calculating mean and std
2024-01-01 23:53:18,441:INFO:Creating metrics dataframe
2024-01-01 23:53:18,450:INFO:Uploading results into container
2024-01-01 23:53:18,451:INFO:Uploading model into container now
2024-01-01 23:53:18,452:INFO:_master_model_container: 6
2024-01-01 23:53:18,453:INFO:_display_container: 2
2024-01-01 23:53:18,453:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:53:18,454:INFO:create_model() successfully completed......................................
2024-01-01 23:53:18,658:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:18,658:INFO:Creating metrics dataframe
2024-01-01 23:53:18,669:INFO:Initializing Random Forest Classifier
2024-01-01 23:53:18,669:INFO:Total runtime is 0.20666914780934653 minutes
2024-01-01 23:53:18,673:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:18,673:INFO:Initializing create_model()
2024-01-01 23:53:18,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:18,674:INFO:Checking exceptions
2024-01-01 23:53:18,674:INFO:Importing libraries
2024-01-01 23:53:18,674:INFO:Copying training dataset
2024-01-01 23:53:18,687:INFO:Defining folds
2024-01-01 23:53:18,687:INFO:Declaring metric variables
2024-01-01 23:53:18,691:INFO:Importing untrained model
2024-01-01 23:53:18,696:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:53:18,703:INFO:Starting cross validation
2024-01-01 23:53:18,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:20,983:INFO:Calculating mean and std
2024-01-01 23:53:20,984:INFO:Creating metrics dataframe
2024-01-01 23:53:20,988:INFO:Uploading results into container
2024-01-01 23:53:20,989:INFO:Uploading model into container now
2024-01-01 23:53:20,990:INFO:_master_model_container: 7
2024-01-01 23:53:20,990:INFO:_display_container: 2
2024-01-01 23:53:20,991:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:53:20,991:INFO:create_model() successfully completed......................................
2024-01-01 23:53:21,248:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:21,249:INFO:Creating metrics dataframe
2024-01-01 23:53:21,260:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:53:21,260:INFO:Total runtime is 0.24984610080718994 minutes
2024-01-01 23:53:21,264:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:21,264:INFO:Initializing create_model()
2024-01-01 23:53:21,264:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:21,264:INFO:Checking exceptions
2024-01-01 23:53:21,264:INFO:Importing libraries
2024-01-01 23:53:21,264:INFO:Copying training dataset
2024-01-01 23:53:21,277:INFO:Defining folds
2024-01-01 23:53:21,277:INFO:Declaring metric variables
2024-01-01 23:53:21,281:INFO:Importing untrained model
2024-01-01 23:53:21,285:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:53:21,292:INFO:Starting cross validation
2024-01-01 23:53:21,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:21,524:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,532:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,560:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,568:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,584:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,588:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,614:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,631:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,641:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,652:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:53:21,704:INFO:Calculating mean and std
2024-01-01 23:53:21,706:INFO:Creating metrics dataframe
2024-01-01 23:53:21,710:INFO:Uploading results into container
2024-01-01 23:53:21,711:INFO:Uploading model into container now
2024-01-01 23:53:21,712:INFO:_master_model_container: 8
2024-01-01 23:53:21,712:INFO:_display_container: 2
2024-01-01 23:53:21,713:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:53:21,713:INFO:create_model() successfully completed......................................
2024-01-01 23:53:21,983:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:21,983:INFO:Creating metrics dataframe
2024-01-01 23:53:21,994:INFO:Initializing Ada Boost Classifier
2024-01-01 23:53:21,995:INFO:Total runtime is 0.2620941519737244 minutes
2024-01-01 23:53:21,998:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:21,999:INFO:Initializing create_model()
2024-01-01 23:53:21,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:21,999:INFO:Checking exceptions
2024-01-01 23:53:21,999:INFO:Importing libraries
2024-01-01 23:53:21,999:INFO:Copying training dataset
2024-01-01 23:53:22,012:INFO:Defining folds
2024-01-01 23:53:22,012:INFO:Declaring metric variables
2024-01-01 23:53:22,015:INFO:Importing untrained model
2024-01-01 23:53:22,020:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:53:22,027:INFO:Starting cross validation
2024-01-01 23:53:22,028:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:22,333:INFO:Calculating mean and std
2024-01-01 23:53:22,334:INFO:Creating metrics dataframe
2024-01-01 23:53:22,338:INFO:Uploading results into container
2024-01-01 23:53:22,339:INFO:Uploading model into container now
2024-01-01 23:53:22,339:INFO:_master_model_container: 9
2024-01-01 23:53:22,339:INFO:_display_container: 2
2024-01-01 23:53:22,340:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:53:22,340:INFO:create_model() successfully completed......................................
2024-01-01 23:53:22,560:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:22,560:INFO:Creating metrics dataframe
2024-01-01 23:53:22,575:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:53:22,575:INFO:Total runtime is 0.2717641274134318 minutes
2024-01-01 23:53:22,579:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:22,579:INFO:Initializing create_model()
2024-01-01 23:53:22,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:22,580:INFO:Checking exceptions
2024-01-01 23:53:22,580:INFO:Importing libraries
2024-01-01 23:53:22,580:INFO:Copying training dataset
2024-01-01 23:53:22,595:INFO:Defining folds
2024-01-01 23:53:22,595:INFO:Declaring metric variables
2024-01-01 23:53:22,600:INFO:Importing untrained model
2024-01-01 23:53:22,605:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:53:22,613:INFO:Starting cross validation
2024-01-01 23:53:22,614:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:24,704:INFO:Calculating mean and std
2024-01-01 23:53:24,708:INFO:Creating metrics dataframe
2024-01-01 23:53:24,719:INFO:Uploading results into container
2024-01-01 23:53:24,721:INFO:Uploading model into container now
2024-01-01 23:53:24,722:INFO:_master_model_container: 10
2024-01-01 23:53:24,722:INFO:_display_container: 2
2024-01-01 23:53:24,724:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:53:24,724:INFO:create_model() successfully completed......................................
2024-01-01 23:53:24,938:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:24,939:INFO:Creating metrics dataframe
2024-01-01 23:53:24,951:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:53:24,951:INFO:Total runtime is 0.3113704840342204 minutes
2024-01-01 23:53:24,955:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:24,955:INFO:Initializing create_model()
2024-01-01 23:53:24,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:24,955:INFO:Checking exceptions
2024-01-01 23:53:24,955:INFO:Importing libraries
2024-01-01 23:53:24,955:INFO:Copying training dataset
2024-01-01 23:53:24,968:INFO:Defining folds
2024-01-01 23:53:24,968:INFO:Declaring metric variables
2024-01-01 23:53:24,972:INFO:Importing untrained model
2024-01-01 23:53:24,977:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:53:24,984:INFO:Starting cross validation
2024-01-01 23:53:24,985:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:25,491:INFO:Calculating mean and std
2024-01-01 23:53:25,493:INFO:Creating metrics dataframe
2024-01-01 23:53:25,497:INFO:Uploading results into container
2024-01-01 23:53:25,497:INFO:Uploading model into container now
2024-01-01 23:53:25,498:INFO:_master_model_container: 11
2024-01-01 23:53:25,499:INFO:_display_container: 2
2024-01-01 23:53:25,499:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:53:25,499:INFO:create_model() successfully completed......................................
2024-01-01 23:53:25,686:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:25,687:INFO:Creating metrics dataframe
2024-01-01 23:53:25,698:INFO:Initializing Extra Trees Classifier
2024-01-01 23:53:25,699:INFO:Total runtime is 0.32383812268575035 minutes
2024-01-01 23:53:25,702:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:25,702:INFO:Initializing create_model()
2024-01-01 23:53:25,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:25,702:INFO:Checking exceptions
2024-01-01 23:53:25,702:INFO:Importing libraries
2024-01-01 23:53:25,703:INFO:Copying training dataset
2024-01-01 23:53:25,714:INFO:Defining folds
2024-01-01 23:53:25,714:INFO:Declaring metric variables
2024-01-01 23:53:25,718:INFO:Importing untrained model
2024-01-01 23:53:25,722:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:53:25,728:INFO:Starting cross validation
2024-01-01 23:53:25,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:27,354:INFO:Calculating mean and std
2024-01-01 23:53:27,355:INFO:Creating metrics dataframe
2024-01-01 23:53:27,360:INFO:Uploading results into container
2024-01-01 23:53:27,360:INFO:Uploading model into container now
2024-01-01 23:53:27,361:INFO:_master_model_container: 12
2024-01-01 23:53:27,361:INFO:_display_container: 2
2024-01-01 23:53:27,361:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:53:27,361:INFO:create_model() successfully completed......................................
2024-01-01 23:53:27,610:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:27,610:INFO:Creating metrics dataframe
2024-01-01 23:53:27,623:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:53:27,623:INFO:Total runtime is 0.35590180953343714 minutes
2024-01-01 23:53:27,626:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:27,626:INFO:Initializing create_model()
2024-01-01 23:53:27,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:27,627:INFO:Checking exceptions
2024-01-01 23:53:27,627:INFO:Importing libraries
2024-01-01 23:53:27,627:INFO:Copying training dataset
2024-01-01 23:53:27,639:INFO:Defining folds
2024-01-01 23:53:27,640:INFO:Declaring metric variables
2024-01-01 23:53:27,644:INFO:Importing untrained model
2024-01-01 23:53:27,648:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:53:27,654:INFO:Starting cross validation
2024-01-01 23:53:27,655:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:28,540:INFO:Calculating mean and std
2024-01-01 23:53:28,542:INFO:Creating metrics dataframe
2024-01-01 23:53:28,548:INFO:Uploading results into container
2024-01-01 23:53:28,549:INFO:Uploading model into container now
2024-01-01 23:53:28,549:INFO:_master_model_container: 13
2024-01-01 23:53:28,550:INFO:_display_container: 2
2024-01-01 23:53:28,550:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:53:28,550:INFO:create_model() successfully completed......................................
2024-01-01 23:53:28,832:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:28,832:INFO:Creating metrics dataframe
2024-01-01 23:53:28,846:INFO:Initializing Dummy Classifier
2024-01-01 23:53:28,846:INFO:Total runtime is 0.3762847185134888 minutes
2024-01-01 23:53:28,849:INFO:SubProcess create_model() called ==================================
2024-01-01 23:53:28,850:INFO:Initializing create_model()
2024-01-01 23:53:28,850:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221D24657E0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:28,850:INFO:Checking exceptions
2024-01-01 23:53:28,850:INFO:Importing libraries
2024-01-01 23:53:28,850:INFO:Copying training dataset
2024-01-01 23:53:28,864:INFO:Defining folds
2024-01-01 23:53:28,864:INFO:Declaring metric variables
2024-01-01 23:53:28,870:INFO:Importing untrained model
2024-01-01 23:53:28,874:INFO:Dummy Classifier Imported successfully
2024-01-01 23:53:28,882:INFO:Starting cross validation
2024-01-01 23:53:28,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:53:29,043:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,063:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,089:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,101:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,108:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,118:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,124:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,133:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,138:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,146:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:53:29,166:INFO:Calculating mean and std
2024-01-01 23:53:29,167:INFO:Creating metrics dataframe
2024-01-01 23:53:29,171:INFO:Uploading results into container
2024-01-01 23:53:29,172:INFO:Uploading model into container now
2024-01-01 23:53:29,172:INFO:_master_model_container: 14
2024-01-01 23:53:29,172:INFO:_display_container: 2
2024-01-01 23:53:29,172:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:53:29,173:INFO:create_model() successfully completed......................................
2024-01-01 23:53:29,415:INFO:SubProcess create_model() end ==================================
2024-01-01 23:53:29,415:INFO:Creating metrics dataframe
2024-01-01 23:53:29,443:INFO:Initializing create_model()
2024-01-01 23:53:29,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:53:29,443:INFO:Checking exceptions
2024-01-01 23:53:29,445:INFO:Importing libraries
2024-01-01 23:53:29,445:INFO:Copying training dataset
2024-01-01 23:53:29,457:INFO:Defining folds
2024-01-01 23:53:29,457:INFO:Declaring metric variables
2024-01-01 23:53:29,457:INFO:Importing untrained model
2024-01-01 23:53:29,457:INFO:Declaring custom model
2024-01-01 23:53:29,458:INFO:Logistic Regression Imported successfully
2024-01-01 23:53:29,458:INFO:Cross validation set to False
2024-01-01 23:53:29,458:INFO:Fitting Model
2024-01-01 23:53:29,656:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:53:29,656:INFO:create_model() successfully completed......................................
2024-01-01 23:53:29,882:INFO:_master_model_container: 14
2024-01-01 23:53:29,882:INFO:_display_container: 2
2024-01-01 23:53:29,883:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:53:29,883:INFO:compare_models() successfully completed......................................
2024-01-01 23:53:30,039:INFO:Initializing plot_model()
2024-01-01 23:53:30,040:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, system=True)
2024-01-01 23:53:30,040:INFO:Checking exceptions
2024-01-01 23:53:30,049:INFO:Preloading libraries
2024-01-01 23:53:30,050:INFO:Copying training dataset
2024-01-01 23:53:30,050:INFO:Plot type: auc
2024-01-01 23:53:30,191:INFO:Fitting Model
2024-01-01 23:53:30,192:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-01-01 23:53:30,193:INFO:Scoring test/hold-out set
2024-01-01 23:53:30,442:INFO:Visual Rendered Successfully
2024-01-01 23:53:30,627:INFO:plot_model() successfully completed......................................
2024-01-01 23:53:30,664:INFO:Initializing plot_model()
2024-01-01 23:53:30,665:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, system=True)
2024-01-01 23:53:30,665:INFO:Checking exceptions
2024-01-01 23:53:30,672:INFO:Preloading libraries
2024-01-01 23:53:30,672:INFO:Copying training dataset
2024-01-01 23:53:30,673:INFO:Plot type: confusion_matrix
2024-01-01 23:53:30,807:INFO:Fitting Model
2024-01-01 23:53:30,807:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-01-01 23:53:30,808:INFO:Scoring test/hold-out set
2024-01-01 23:53:30,944:INFO:Visual Rendered Successfully
2024-01-01 23:53:31,234:INFO:plot_model() successfully completed......................................
2024-01-01 23:53:31,268:INFO:Initializing plot_model()
2024-01-01 23:53:32,009:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>, system=True)
2024-01-01 23:53:32,009:INFO:Checking exceptions
2024-01-01 23:53:32,015:INFO:Preloading libraries
2024-01-01 23:53:32,015:INFO:Copying training dataset
2024-01-01 23:53:32,015:INFO:Plot type: class_report
2024-01-01 23:53:32,131:INFO:Fitting Model
2024-01-01 23:53:32,132:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\base.py:420: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2024-01-01 23:53:32,132:INFO:Scoring test/hold-out set
2024-01-01 23:53:32,368:INFO:Visual Rendered Successfully
2024-01-01 23:53:32,549:INFO:plot_model() successfully completed......................................
2024-01-01 23:53:32,585:INFO:Initializing tune_model()
2024-01-01 23:53:32,585:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221E2C13D00>)
2024-01-01 23:53:32,585:INFO:Checking exceptions
2024-01-01 23:53:32,609:INFO:Copying training dataset
2024-01-01 23:53:32,619:INFO:Checking base model
2024-01-01 23:53:32,620:INFO:Base model : Logistic Regression
2024-01-01 23:53:32,624:INFO:Declaring metric variables
2024-01-01 23:53:32,628:INFO:Defining Hyperparameters
2024-01-01 23:53:32,817:INFO:Tuning with n_jobs=-1
2024-01-01 23:53:32,817:INFO:Initializing RandomizedSearchCV
2024-01-01 23:53:46,090:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:48,316:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:48,542:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:48,544:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:50,078:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:50,880:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:53:51,093:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-01 23:54:05,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:54:05,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:54:05,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:54:05,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-01 23:54:05,414:INFO:PyCaret ClassificationExperiment
2024-01-01 23:54:05,414:INFO:Logging name: clf-default-name
2024-01-01 23:54:05,414:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:54:05,414:INFO:version 3.1.0
2024-01-01 23:54:05,414:INFO:Initializing setup()
2024-01-01 23:54:05,414:INFO:self.USI: 3239
2024-01-01 23:54:05,414:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'y_test', 'logging_param', 'target_param', 'fix_imbalance', 'seed', 'y', 'is_multiclass', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', '_available_plots', 'gpu_param', 'n_jobs_param', 'log_plots_param', 'data', 'y_train', 'exp_id', 'exp_name_log', 'X', 'memory', 'fold_generator', 'X_test', '_ml_usecase', 'fold_shuffle_param', 'html_param'}
2024-01-01 23:54:05,414:INFO:Checking environment
2024-01-01 23:54:05,414:INFO:python_version: 3.10.9
2024-01-01 23:54:05,414:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:54:05,415:INFO:machine: AMD64
2024-01-01 23:54:05,415:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:54:05,415:INFO:Memory: svmem(total=16954372096, available=3382882304, percent=80.0, used=13571489792, free=3382882304)
2024-01-01 23:54:05,415:INFO:Physical Core: 8
2024-01-01 23:54:05,415:INFO:Logical Core: 16
2024-01-01 23:54:05,415:INFO:Checking libraries
2024-01-01 23:54:05,415:INFO:System:
2024-01-01 23:54:05,415:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:54:05,415:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:54:05,415:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:54:05,415:INFO:PyCaret required dependencies:
2024-01-01 23:54:06,136:INFO:                 pip: 22.3.1
2024-01-01 23:54:06,136:INFO:          setuptools: 65.6.3
2024-01-01 23:54:06,136:INFO:             pycaret: 3.1.0
2024-01-01 23:54:06,136:INFO:             IPython: 8.10.0
2024-01-01 23:54:06,136:INFO:          ipywidgets: 7.6.5
2024-01-01 23:54:06,136:INFO:                tqdm: 4.64.1
2024-01-01 23:54:06,136:INFO:               numpy: 1.23.5
2024-01-01 23:54:06,136:INFO:              pandas: 1.5.3
2024-01-01 23:54:06,136:INFO:              jinja2: 3.1.2
2024-01-01 23:54:06,136:INFO:               scipy: 1.10.1
2024-01-01 23:54:06,136:INFO:              joblib: 1.3.2
2024-01-01 23:54:06,136:INFO:             sklearn: 1.2.1
2024-01-01 23:54:06,136:INFO:                pyod: 1.1.0
2024-01-01 23:54:06,136:INFO:            imblearn: 0.10.1
2024-01-01 23:54:06,136:INFO:   category_encoders: 2.6.2
2024-01-01 23:54:06,136:INFO:            lightgbm: 4.1.0
2024-01-01 23:54:06,137:INFO:               numba: 0.56.4
2024-01-01 23:54:06,137:INFO:            requests: 2.28.1
2024-01-01 23:54:06,137:INFO:          matplotlib: 3.7.0
2024-01-01 23:54:06,137:INFO:          scikitplot: 0.3.7
2024-01-01 23:54:06,137:INFO:         yellowbrick: 1.5
2024-01-01 23:54:06,137:INFO:              plotly: 5.9.0
2024-01-01 23:54:06,137:INFO:    plotly-resampler: Not installed
2024-01-01 23:54:06,137:INFO:             kaleido: 0.2.1
2024-01-01 23:54:06,137:INFO:           schemdraw: 0.15
2024-01-01 23:54:06,137:INFO:         statsmodels: 0.13.5
2024-01-01 23:54:06,137:INFO:              sktime: 0.21.1
2024-01-01 23:54:06,137:INFO:               tbats: 1.1.3
2024-01-01 23:54:06,137:INFO:            pmdarima: 2.0.3
2024-01-01 23:54:06,137:INFO:              psutil: 5.9.0
2024-01-01 23:54:06,137:INFO:          markupsafe: 2.1.1
2024-01-01 23:54:06,137:INFO:             pickle5: Not installed
2024-01-01 23:54:06,137:INFO:         cloudpickle: 2.0.0
2024-01-01 23:54:06,137:INFO:         deprecation: 2.1.0
2024-01-01 23:54:06,137:INFO:              xxhash: 3.4.1
2024-01-01 23:54:06,137:INFO:           wurlitzer: Not installed
2024-01-01 23:54:06,137:INFO:PyCaret optional dependencies:
2024-01-01 23:54:06,154:INFO:                shap: Not installed
2024-01-01 23:54:06,154:INFO:           interpret: Not installed
2024-01-01 23:54:06,154:INFO:                umap: Not installed
2024-01-01 23:54:06,154:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:54:06,154:INFO:  explainerdashboard: Not installed
2024-01-01 23:54:06,154:INFO:             autoviz: Not installed
2024-01-01 23:54:06,154:INFO:           fairlearn: Not installed
2024-01-01 23:54:06,155:INFO:          deepchecks: Not installed
2024-01-01 23:54:06,155:INFO:             xgboost: Not installed
2024-01-01 23:54:06,155:INFO:            catboost: Not installed
2024-01-01 23:54:06,155:INFO:              kmodes: Not installed
2024-01-01 23:54:06,155:INFO:             mlxtend: Not installed
2024-01-01 23:54:06,155:INFO:       statsforecast: Not installed
2024-01-01 23:54:06,155:INFO:        tune_sklearn: Not installed
2024-01-01 23:54:06,155:INFO:                 ray: Not installed
2024-01-01 23:54:06,155:INFO:            hyperopt: Not installed
2024-01-01 23:54:06,155:INFO:              optuna: Not installed
2024-01-01 23:54:06,155:INFO:               skopt: Not installed
2024-01-01 23:54:06,155:INFO:              mlflow: Not installed
2024-01-01 23:54:06,155:INFO:              gradio: Not installed
2024-01-01 23:54:06,155:INFO:             fastapi: Not installed
2024-01-01 23:54:06,155:INFO:             uvicorn: Not installed
2024-01-01 23:54:06,155:INFO:              m2cgen: Not installed
2024-01-01 23:54:06,155:INFO:           evidently: Not installed
2024-01-01 23:54:06,155:INFO:               fugue: Not installed
2024-01-01 23:54:06,155:INFO:           streamlit: Not installed
2024-01-01 23:54:06,155:INFO:             prophet: Not installed
2024-01-01 23:54:06,155:INFO:None
2024-01-01 23:54:06,156:INFO:Set up data.
2024-01-01 23:54:12,640:INFO:PyCaret ClassificationExperiment
2024-01-01 23:54:12,640:INFO:Logging name: clf-default-name
2024-01-01 23:54:12,640:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:54:12,640:INFO:version 3.1.0
2024-01-01 23:54:12,640:INFO:Initializing setup()
2024-01-01 23:54:12,640:INFO:self.USI: 309c
2024-01-01 23:54:12,640:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'y_test', 'logging_param', 'target_param', 'fix_imbalance', 'seed', 'y', 'is_multiclass', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', '_available_plots', 'gpu_param', 'n_jobs_param', 'log_plots_param', 'data', 'y_train', 'exp_id', 'exp_name_log', 'X', 'memory', 'fold_generator', 'X_test', '_ml_usecase', 'fold_shuffle_param', 'html_param'}
2024-01-01 23:54:12,640:INFO:Checking environment
2024-01-01 23:54:12,640:INFO:python_version: 3.10.9
2024-01-01 23:54:12,640:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:54:12,640:INFO:machine: AMD64
2024-01-01 23:54:12,640:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:54:12,640:INFO:Memory: svmem(total=16954372096, available=3405979648, percent=79.9, used=13548392448, free=3405979648)
2024-01-01 23:54:12,640:INFO:Physical Core: 8
2024-01-01 23:54:12,640:INFO:Logical Core: 16
2024-01-01 23:54:12,640:INFO:Checking libraries
2024-01-01 23:54:12,640:INFO:System:
2024-01-01 23:54:12,640:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:54:12,640:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:54:12,640:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:54:12,640:INFO:PyCaret required dependencies:
2024-01-01 23:54:12,641:INFO:                 pip: 22.3.1
2024-01-01 23:54:12,641:INFO:          setuptools: 65.6.3
2024-01-01 23:54:12,641:INFO:             pycaret: 3.1.0
2024-01-01 23:54:12,641:INFO:             IPython: 8.10.0
2024-01-01 23:54:12,641:INFO:          ipywidgets: 7.6.5
2024-01-01 23:54:12,641:INFO:                tqdm: 4.64.1
2024-01-01 23:54:12,641:INFO:               numpy: 1.23.5
2024-01-01 23:54:12,641:INFO:              pandas: 1.5.3
2024-01-01 23:54:12,641:INFO:              jinja2: 3.1.2
2024-01-01 23:54:12,641:INFO:               scipy: 1.10.1
2024-01-01 23:54:12,641:INFO:              joblib: 1.3.2
2024-01-01 23:54:12,641:INFO:             sklearn: 1.2.1
2024-01-01 23:54:12,641:INFO:                pyod: 1.1.0
2024-01-01 23:54:12,642:INFO:            imblearn: 0.10.1
2024-01-01 23:54:12,642:INFO:   category_encoders: 2.6.2
2024-01-01 23:54:12,642:INFO:            lightgbm: 4.1.0
2024-01-01 23:54:12,642:INFO:               numba: 0.56.4
2024-01-01 23:54:12,642:INFO:            requests: 2.28.1
2024-01-01 23:54:12,642:INFO:          matplotlib: 3.7.0
2024-01-01 23:54:12,642:INFO:          scikitplot: 0.3.7
2024-01-01 23:54:12,642:INFO:         yellowbrick: 1.5
2024-01-01 23:54:12,642:INFO:              plotly: 5.9.0
2024-01-01 23:54:12,642:INFO:    plotly-resampler: Not installed
2024-01-01 23:54:12,642:INFO:             kaleido: 0.2.1
2024-01-01 23:54:12,642:INFO:           schemdraw: 0.15
2024-01-01 23:54:12,642:INFO:         statsmodels: 0.13.5
2024-01-01 23:54:12,642:INFO:              sktime: 0.21.1
2024-01-01 23:54:12,642:INFO:               tbats: 1.1.3
2024-01-01 23:54:12,642:INFO:            pmdarima: 2.0.3
2024-01-01 23:54:12,642:INFO:              psutil: 5.9.0
2024-01-01 23:54:12,642:INFO:          markupsafe: 2.1.1
2024-01-01 23:54:12,642:INFO:             pickle5: Not installed
2024-01-01 23:54:12,642:INFO:         cloudpickle: 2.0.0
2024-01-01 23:54:12,642:INFO:         deprecation: 2.1.0
2024-01-01 23:54:12,642:INFO:              xxhash: 3.4.1
2024-01-01 23:54:12,642:INFO:           wurlitzer: Not installed
2024-01-01 23:54:12,642:INFO:PyCaret optional dependencies:
2024-01-01 23:54:12,642:INFO:                shap: Not installed
2024-01-01 23:54:12,642:INFO:           interpret: Not installed
2024-01-01 23:54:12,642:INFO:                umap: Not installed
2024-01-01 23:54:12,642:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:54:12,642:INFO:  explainerdashboard: Not installed
2024-01-01 23:54:12,642:INFO:             autoviz: Not installed
2024-01-01 23:54:12,642:INFO:           fairlearn: Not installed
2024-01-01 23:54:12,642:INFO:          deepchecks: Not installed
2024-01-01 23:54:12,642:INFO:             xgboost: Not installed
2024-01-01 23:54:12,642:INFO:            catboost: Not installed
2024-01-01 23:54:12,642:INFO:              kmodes: Not installed
2024-01-01 23:54:12,643:INFO:             mlxtend: Not installed
2024-01-01 23:54:12,643:INFO:       statsforecast: Not installed
2024-01-01 23:54:12,643:INFO:        tune_sklearn: Not installed
2024-01-01 23:54:12,643:INFO:                 ray: Not installed
2024-01-01 23:54:12,643:INFO:            hyperopt: Not installed
2024-01-01 23:54:12,643:INFO:              optuna: Not installed
2024-01-01 23:54:12,643:INFO:               skopt: Not installed
2024-01-01 23:54:12,643:INFO:              mlflow: Not installed
2024-01-01 23:54:12,643:INFO:              gradio: Not installed
2024-01-01 23:54:12,643:INFO:             fastapi: Not installed
2024-01-01 23:54:12,643:INFO:             uvicorn: Not installed
2024-01-01 23:54:12,643:INFO:              m2cgen: Not installed
2024-01-01 23:54:12,644:INFO:           evidently: Not installed
2024-01-01 23:54:12,644:INFO:               fugue: Not installed
2024-01-01 23:54:12,644:INFO:           streamlit: Not installed
2024-01-01 23:54:12,644:INFO:             prophet: Not installed
2024-01-01 23:54:12,644:INFO:None
2024-01-01 23:54:12,644:INFO:Set up data.
2024-01-01 23:54:12,655:INFO:Set up folding strategy.
2024-01-01 23:54:12,656:INFO:Set up train/test split.
2024-01-01 23:54:12,671:INFO:Set up index.
2024-01-01 23:54:12,672:INFO:Assigning column types.
2024-01-01 23:54:12,678:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:54:12,722:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:54:12,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:12,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,801:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:54:12,802:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:12,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,830:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:54:12,875:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:12,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,947:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:12,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:12,975:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:54:13,047:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,047:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,122:INFO:Preparing preprocessing pipeline...
2024-01-01 23:54:13,124:INFO:Set up simple imputation.
2024-01-01 23:54:13,125:INFO:Set up column name cleaning.
2024-01-01 23:54:13,168:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:54:13,174:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-statu...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:54:13,174:INFO:Creating final display dataframe.
2024-01-01 23:54:13,297:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (31978, 18)
4        Transformed data shape       (31978, 18)
5   Transformed train set shape       (25582, 18)
6    Transformed test set shape        (6396, 18)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              309c
2024-01-01 23:54:13,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:13,448:INFO:setup() successfully completed in 0.81s...............
2024-01-01 23:54:15,454:INFO:PyCaret ClassificationExperiment
2024-01-01 23:54:15,454:INFO:Logging name: clf-default-name
2024-01-01 23:54:15,455:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-01 23:54:15,455:INFO:version 3.1.0
2024-01-01 23:54:15,455:INFO:Initializing setup()
2024-01-01 23:54:15,455:INFO:self.USI: 3e3b
2024-01-01 23:54:15,455:INFO:self._variable_keys: {'X_train', 'fold_groups_param', 'y_test', 'logging_param', 'target_param', 'fix_imbalance', 'seed', 'y', 'is_multiclass', 'pipeline', 'gpu_n_jobs_param', 'idx', 'USI', '_available_plots', 'gpu_param', 'n_jobs_param', 'log_plots_param', 'data', 'y_train', 'exp_id', 'exp_name_log', 'X', 'memory', 'fold_generator', 'X_test', '_ml_usecase', 'fold_shuffle_param', 'html_param'}
2024-01-01 23:54:15,455:INFO:Checking environment
2024-01-01 23:54:15,455:INFO:python_version: 3.10.9
2024-01-01 23:54:15,455:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-01 23:54:15,455:INFO:machine: AMD64
2024-01-01 23:54:15,455:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-01 23:54:15,455:INFO:Memory: svmem(total=16954372096, available=3402620928, percent=79.9, used=13551751168, free=3402620928)
2024-01-01 23:54:15,456:INFO:Physical Core: 8
2024-01-01 23:54:15,456:INFO:Logical Core: 16
2024-01-01 23:54:15,456:INFO:Checking libraries
2024-01-01 23:54:15,456:INFO:System:
2024-01-01 23:54:15,456:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-01 23:54:15,456:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-01 23:54:15,456:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-01 23:54:15,456:INFO:PyCaret required dependencies:
2024-01-01 23:54:15,456:INFO:                 pip: 22.3.1
2024-01-01 23:54:15,456:INFO:          setuptools: 65.6.3
2024-01-01 23:54:15,456:INFO:             pycaret: 3.1.0
2024-01-01 23:54:15,456:INFO:             IPython: 8.10.0
2024-01-01 23:54:15,456:INFO:          ipywidgets: 7.6.5
2024-01-01 23:54:15,456:INFO:                tqdm: 4.64.1
2024-01-01 23:54:15,456:INFO:               numpy: 1.23.5
2024-01-01 23:54:15,456:INFO:              pandas: 1.5.3
2024-01-01 23:54:15,456:INFO:              jinja2: 3.1.2
2024-01-01 23:54:15,456:INFO:               scipy: 1.10.1
2024-01-01 23:54:15,456:INFO:              joblib: 1.3.2
2024-01-01 23:54:15,457:INFO:             sklearn: 1.2.1
2024-01-01 23:54:15,457:INFO:                pyod: 1.1.0
2024-01-01 23:54:15,457:INFO:            imblearn: 0.10.1
2024-01-01 23:54:15,457:INFO:   category_encoders: 2.6.2
2024-01-01 23:54:15,457:INFO:            lightgbm: 4.1.0
2024-01-01 23:54:15,457:INFO:               numba: 0.56.4
2024-01-01 23:54:15,457:INFO:            requests: 2.28.1
2024-01-01 23:54:15,457:INFO:          matplotlib: 3.7.0
2024-01-01 23:54:15,457:INFO:          scikitplot: 0.3.7
2024-01-01 23:54:15,457:INFO:         yellowbrick: 1.5
2024-01-01 23:54:15,457:INFO:              plotly: 5.9.0
2024-01-01 23:54:15,457:INFO:    plotly-resampler: Not installed
2024-01-01 23:54:15,457:INFO:             kaleido: 0.2.1
2024-01-01 23:54:15,457:INFO:           schemdraw: 0.15
2024-01-01 23:54:15,457:INFO:         statsmodels: 0.13.5
2024-01-01 23:54:15,457:INFO:              sktime: 0.21.1
2024-01-01 23:54:15,457:INFO:               tbats: 1.1.3
2024-01-01 23:54:15,457:INFO:            pmdarima: 2.0.3
2024-01-01 23:54:15,457:INFO:              psutil: 5.9.0
2024-01-01 23:54:15,457:INFO:          markupsafe: 2.1.1
2024-01-01 23:54:15,457:INFO:             pickle5: Not installed
2024-01-01 23:54:15,457:INFO:         cloudpickle: 2.0.0
2024-01-01 23:54:15,458:INFO:         deprecation: 2.1.0
2024-01-01 23:54:15,458:INFO:              xxhash: 3.4.1
2024-01-01 23:54:15,458:INFO:           wurlitzer: Not installed
2024-01-01 23:54:15,458:INFO:PyCaret optional dependencies:
2024-01-01 23:54:15,458:INFO:                shap: Not installed
2024-01-01 23:54:15,458:INFO:           interpret: Not installed
2024-01-01 23:54:15,458:INFO:                umap: Not installed
2024-01-01 23:54:15,458:INFO:     ydata_profiling: 4.6.0
2024-01-01 23:54:15,458:INFO:  explainerdashboard: Not installed
2024-01-01 23:54:15,458:INFO:             autoviz: Not installed
2024-01-01 23:54:15,458:INFO:           fairlearn: Not installed
2024-01-01 23:54:15,458:INFO:          deepchecks: Not installed
2024-01-01 23:54:15,458:INFO:             xgboost: Not installed
2024-01-01 23:54:15,458:INFO:            catboost: Not installed
2024-01-01 23:54:15,458:INFO:              kmodes: Not installed
2024-01-01 23:54:15,458:INFO:             mlxtend: Not installed
2024-01-01 23:54:15,458:INFO:       statsforecast: Not installed
2024-01-01 23:54:15,458:INFO:        tune_sklearn: Not installed
2024-01-01 23:54:15,458:INFO:                 ray: Not installed
2024-01-01 23:54:15,458:INFO:            hyperopt: Not installed
2024-01-01 23:54:15,458:INFO:              optuna: Not installed
2024-01-01 23:54:15,458:INFO:               skopt: Not installed
2024-01-01 23:54:15,458:INFO:              mlflow: Not installed
2024-01-01 23:54:15,458:INFO:              gradio: Not installed
2024-01-01 23:54:15,459:INFO:             fastapi: Not installed
2024-01-01 23:54:15,459:INFO:             uvicorn: Not installed
2024-01-01 23:54:15,459:INFO:              m2cgen: Not installed
2024-01-01 23:54:15,459:INFO:           evidently: Not installed
2024-01-01 23:54:15,459:INFO:               fugue: Not installed
2024-01-01 23:54:15,459:INFO:           streamlit: Not installed
2024-01-01 23:54:15,459:INFO:             prophet: Not installed
2024-01-01 23:54:15,459:INFO:None
2024-01-01 23:54:15,459:INFO:Set up data.
2024-01-01 23:54:15,474:INFO:Set up folding strategy.
2024-01-01 23:54:15,474:INFO:Set up train/test split.
2024-01-01 23:54:15,489:INFO:Set up index.
2024-01-01 23:54:15,490:INFO:Assigning column types.
2024-01-01 23:54:15,494:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-01 23:54:15,541:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:54:15,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:15,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-01 23:54:15,615:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:15,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,644:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-01 23:54:15,690:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:15,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,764:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-01 23:54:15,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,792:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-01 23:54:15,865:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,940:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:15,941:INFO:Preparing preprocessing pipeline...
2024-01-01 23:54:15,943:INFO:Set up simple imputation.
2024-01-01 23:54:15,944:INFO:Set up column name cleaning.
2024-01-01 23:54:15,985:INFO:Finished creating preprocessing pipeline.
2024-01-01 23:54:15,990:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-statu...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-01 23:54:15,990:INFO:Creating final display dataframe.
2024-01-01 23:54:16,119:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (31978, 18)
4        Transformed data shape       (31978, 18)
5   Transformed train set shape       (25582, 18)
6    Transformed test set shape        (6396, 18)
7              Numeric features                17
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              3e3b
2024-01-01 23:54:16,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:16,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:16,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:16,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-01 23:54:16,275:INFO:setup() successfully completed in 0.83s...............
2024-01-01 23:54:16,319:INFO:Initializing compare_models()
2024-01-01 23:54:16,319:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:54:16,319:INFO:Checking exceptions
2024-01-01 23:54:16,328:INFO:Preparing display monitor
2024-01-01 23:54:16,361:INFO:Initializing Logistic Regression
2024-01-01 23:54:16,361:INFO:Total runtime is 0.0 minutes
2024-01-01 23:54:16,365:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:16,366:INFO:Initializing create_model()
2024-01-01 23:54:16,367:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:16,367:INFO:Checking exceptions
2024-01-01 23:54:16,367:INFO:Importing libraries
2024-01-01 23:54:16,367:INFO:Copying training dataset
2024-01-01 23:54:16,384:INFO:Defining folds
2024-01-01 23:54:16,384:INFO:Declaring metric variables
2024-01-01 23:54:16,388:INFO:Importing untrained model
2024-01-01 23:54:16,392:INFO:Logistic Regression Imported successfully
2024-01-01 23:54:16,401:INFO:Starting cross validation
2024-01-01 23:54:16,403:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:27,387:INFO:Calculating mean and std
2024-01-01 23:54:27,389:INFO:Creating metrics dataframe
2024-01-01 23:54:27,393:INFO:Uploading results into container
2024-01-01 23:54:27,394:INFO:Uploading model into container now
2024-01-01 23:54:27,395:INFO:_master_model_container: 1
2024-01-01 23:54:27,395:INFO:_display_container: 2
2024-01-01 23:54:27,396:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:54:27,396:INFO:create_model() successfully completed......................................
2024-01-01 23:54:27,551:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:27,551:INFO:Creating metrics dataframe
2024-01-01 23:54:27,560:INFO:Initializing K Neighbors Classifier
2024-01-01 23:54:27,560:INFO:Total runtime is 0.18666088183720905 minutes
2024-01-01 23:54:27,564:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:27,564:INFO:Initializing create_model()
2024-01-01 23:54:27,564:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:27,565:INFO:Checking exceptions
2024-01-01 23:54:27,565:INFO:Importing libraries
2024-01-01 23:54:27,565:INFO:Copying training dataset
2024-01-01 23:54:27,579:INFO:Defining folds
2024-01-01 23:54:27,579:INFO:Declaring metric variables
2024-01-01 23:54:27,584:INFO:Importing untrained model
2024-01-01 23:54:27,588:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:54:27,596:INFO:Starting cross validation
2024-01-01 23:54:27,597:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:34,658:INFO:Calculating mean and std
2024-01-01 23:54:34,659:INFO:Creating metrics dataframe
2024-01-01 23:54:34,665:INFO:Uploading results into container
2024-01-01 23:54:34,666:INFO:Uploading model into container now
2024-01-01 23:54:34,667:INFO:_master_model_container: 2
2024-01-01 23:54:34,667:INFO:_display_container: 2
2024-01-01 23:54:34,667:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:54:34,667:INFO:create_model() successfully completed......................................
2024-01-01 23:54:34,831:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:34,832:INFO:Creating metrics dataframe
2024-01-01 23:54:34,842:INFO:Initializing Naive Bayes
2024-01-01 23:54:34,842:INFO:Total runtime is 0.30801889101664226 minutes
2024-01-01 23:54:34,846:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:34,846:INFO:Initializing create_model()
2024-01-01 23:54:34,846:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:34,846:INFO:Checking exceptions
2024-01-01 23:54:34,846:INFO:Importing libraries
2024-01-01 23:54:34,846:INFO:Copying training dataset
2024-01-01 23:54:34,860:INFO:Defining folds
2024-01-01 23:54:34,860:INFO:Declaring metric variables
2024-01-01 23:54:34,864:INFO:Importing untrained model
2024-01-01 23:54:34,868:INFO:Naive Bayes Imported successfully
2024-01-01 23:54:34,875:INFO:Starting cross validation
2024-01-01 23:54:34,876:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:35,218:INFO:Calculating mean and std
2024-01-01 23:54:35,219:INFO:Creating metrics dataframe
2024-01-01 23:54:35,223:INFO:Uploading results into container
2024-01-01 23:54:35,223:INFO:Uploading model into container now
2024-01-01 23:54:35,223:INFO:_master_model_container: 3
2024-01-01 23:54:35,223:INFO:_display_container: 2
2024-01-01 23:54:35,224:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:54:35,224:INFO:create_model() successfully completed......................................
2024-01-01 23:54:35,346:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:35,346:INFO:Creating metrics dataframe
2024-01-01 23:54:35,356:INFO:Initializing Decision Tree Classifier
2024-01-01 23:54:35,356:INFO:Total runtime is 0.31659252643585206 minutes
2024-01-01 23:54:35,360:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:35,361:INFO:Initializing create_model()
2024-01-01 23:54:35,361:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:35,361:INFO:Checking exceptions
2024-01-01 23:54:35,361:INFO:Importing libraries
2024-01-01 23:54:35,361:INFO:Copying training dataset
2024-01-01 23:54:35,375:INFO:Defining folds
2024-01-01 23:54:35,375:INFO:Declaring metric variables
2024-01-01 23:54:35,379:INFO:Importing untrained model
2024-01-01 23:54:35,383:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:54:35,390:INFO:Starting cross validation
2024-01-01 23:54:35,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:35,765:INFO:Calculating mean and std
2024-01-01 23:54:35,766:INFO:Creating metrics dataframe
2024-01-01 23:54:35,770:INFO:Uploading results into container
2024-01-01 23:54:35,771:INFO:Uploading model into container now
2024-01-01 23:54:35,771:INFO:_master_model_container: 4
2024-01-01 23:54:35,771:INFO:_display_container: 2
2024-01-01 23:54:35,772:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:54:35,772:INFO:create_model() successfully completed......................................
2024-01-01 23:54:35,885:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:35,885:INFO:Creating metrics dataframe
2024-01-01 23:54:35,893:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:54:35,895:INFO:Total runtime is 0.3255446990331014 minutes
2024-01-01 23:54:35,897:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:35,898:INFO:Initializing create_model()
2024-01-01 23:54:35,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:35,898:INFO:Checking exceptions
2024-01-01 23:54:35,898:INFO:Importing libraries
2024-01-01 23:54:35,898:INFO:Copying training dataset
2024-01-01 23:54:35,909:INFO:Defining folds
2024-01-01 23:54:35,910:INFO:Declaring metric variables
2024-01-01 23:54:35,914:INFO:Importing untrained model
2024-01-01 23:54:35,917:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:54:35,925:INFO:Starting cross validation
2024-01-01 23:54:35,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:36,221:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,304:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,338:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,371:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,372:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,372:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,372:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,393:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,405:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,418:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:54:36,437:INFO:Calculating mean and std
2024-01-01 23:54:36,440:INFO:Creating metrics dataframe
2024-01-01 23:54:36,453:INFO:Uploading results into container
2024-01-01 23:54:36,455:INFO:Uploading model into container now
2024-01-01 23:54:36,457:INFO:_master_model_container: 5
2024-01-01 23:54:36,457:INFO:_display_container: 2
2024-01-01 23:54:36,459:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:54:36,459:INFO:create_model() successfully completed......................................
2024-01-01 23:54:36,575:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:36,575:INFO:Creating metrics dataframe
2024-01-01 23:54:36,583:INFO:Initializing Ridge Classifier
2024-01-01 23:54:36,585:INFO:Total runtime is 0.33706807295481367 minutes
2024-01-01 23:54:36,587:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:36,588:INFO:Initializing create_model()
2024-01-01 23:54:36,588:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:36,588:INFO:Checking exceptions
2024-01-01 23:54:36,588:INFO:Importing libraries
2024-01-01 23:54:36,588:INFO:Copying training dataset
2024-01-01 23:54:36,600:INFO:Defining folds
2024-01-01 23:54:36,601:INFO:Declaring metric variables
2024-01-01 23:54:36,605:INFO:Importing untrained model
2024-01-01 23:54:36,609:INFO:Ridge Classifier Imported successfully
2024-01-01 23:54:36,615:INFO:Starting cross validation
2024-01-01 23:54:36,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:36,818:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,834:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,835:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,852:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,865:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,874:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,875:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,881:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,886:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,886:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:54:36,906:INFO:Calculating mean and std
2024-01-01 23:54:36,910:INFO:Creating metrics dataframe
2024-01-01 23:54:36,919:INFO:Uploading results into container
2024-01-01 23:54:36,920:INFO:Uploading model into container now
2024-01-01 23:54:36,921:INFO:_master_model_container: 6
2024-01-01 23:54:36,921:INFO:_display_container: 2
2024-01-01 23:54:36,922:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:54:36,923:INFO:create_model() successfully completed......................................
2024-01-01 23:54:37,058:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:37,058:INFO:Creating metrics dataframe
2024-01-01 23:54:37,069:INFO:Initializing Random Forest Classifier
2024-01-01 23:54:37,069:INFO:Total runtime is 0.3451420783996582 minutes
2024-01-01 23:54:37,072:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:37,073:INFO:Initializing create_model()
2024-01-01 23:54:37,073:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D1787D00>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:37,073:INFO:Checking exceptions
2024-01-01 23:54:37,073:INFO:Importing libraries
2024-01-01 23:54:37,073:INFO:Copying training dataset
2024-01-01 23:54:37,085:INFO:Defining folds
2024-01-01 23:54:37,085:INFO:Declaring metric variables
2024-01-01 23:54:37,089:INFO:Importing untrained model
2024-01-01 23:54:37,095:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:54:37,105:INFO:Starting cross validation
2024-01-01 23:54:37,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:45,825:INFO:Initializing compare_models()
2024-01-01 23:54:45,825:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-01 23:54:45,826:INFO:Checking exceptions
2024-01-01 23:54:45,831:INFO:Preparing display monitor
2024-01-01 23:54:45,860:INFO:Initializing Logistic Regression
2024-01-01 23:54:45,860:INFO:Total runtime is 0.0 minutes
2024-01-01 23:54:45,864:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:45,865:INFO:Initializing create_model()
2024-01-01 23:54:45,865:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:45,865:INFO:Checking exceptions
2024-01-01 23:54:45,865:INFO:Importing libraries
2024-01-01 23:54:45,866:INFO:Copying training dataset
2024-01-01 23:54:45,880:INFO:Defining folds
2024-01-01 23:54:45,880:INFO:Declaring metric variables
2024-01-01 23:54:45,884:INFO:Importing untrained model
2024-01-01 23:54:45,890:INFO:Logistic Regression Imported successfully
2024-01-01 23:54:45,898:INFO:Starting cross validation
2024-01-01 23:54:45,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:54:56,298:INFO:Calculating mean and std
2024-01-01 23:54:56,300:INFO:Creating metrics dataframe
2024-01-01 23:54:56,303:INFO:Uploading results into container
2024-01-01 23:54:56,304:INFO:Uploading model into container now
2024-01-01 23:54:56,305:INFO:_master_model_container: 7
2024-01-01 23:54:56,305:INFO:_display_container: 2
2024-01-01 23:54:56,306:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-01 23:54:56,306:INFO:create_model() successfully completed......................................
2024-01-01 23:54:56,465:INFO:SubProcess create_model() end ==================================
2024-01-01 23:54:56,465:INFO:Creating metrics dataframe
2024-01-01 23:54:56,474:INFO:Initializing K Neighbors Classifier
2024-01-01 23:54:56,474:INFO:Total runtime is 0.1768898844718933 minutes
2024-01-01 23:54:56,477:INFO:SubProcess create_model() called ==================================
2024-01-01 23:54:56,477:INFO:Initializing create_model()
2024-01-01 23:54:56,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:54:56,477:INFO:Checking exceptions
2024-01-01 23:54:56,478:INFO:Importing libraries
2024-01-01 23:54:56,478:INFO:Copying training dataset
2024-01-01 23:54:56,489:INFO:Defining folds
2024-01-01 23:54:56,489:INFO:Declaring metric variables
2024-01-01 23:54:56,493:INFO:Importing untrained model
2024-01-01 23:54:56,497:INFO:K Neighbors Classifier Imported successfully
2024-01-01 23:54:56,505:INFO:Starting cross validation
2024-01-01 23:54:56,506:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:02,291:INFO:Calculating mean and std
2024-01-01 23:55:02,293:INFO:Creating metrics dataframe
2024-01-01 23:55:02,299:INFO:Uploading results into container
2024-01-01 23:55:02,301:INFO:Uploading model into container now
2024-01-01 23:55:02,302:INFO:_master_model_container: 8
2024-01-01 23:55:02,302:INFO:_display_container: 2
2024-01-01 23:55:02,303:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-01 23:55:02,303:INFO:create_model() successfully completed......................................
2024-01-01 23:55:02,483:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:02,483:INFO:Creating metrics dataframe
2024-01-01 23:55:02,492:INFO:Initializing Naive Bayes
2024-01-01 23:55:02,492:INFO:Total runtime is 0.2771889607111613 minutes
2024-01-01 23:55:02,494:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:02,495:INFO:Initializing create_model()
2024-01-01 23:55:02,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:02,495:INFO:Checking exceptions
2024-01-01 23:55:02,495:INFO:Importing libraries
2024-01-01 23:55:02,495:INFO:Copying training dataset
2024-01-01 23:55:02,507:INFO:Defining folds
2024-01-01 23:55:02,507:INFO:Declaring metric variables
2024-01-01 23:55:02,510:INFO:Importing untrained model
2024-01-01 23:55:02,514:INFO:Naive Bayes Imported successfully
2024-01-01 23:55:02,521:INFO:Starting cross validation
2024-01-01 23:55:02,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:02,840:INFO:Calculating mean and std
2024-01-01 23:55:02,843:INFO:Creating metrics dataframe
2024-01-01 23:55:02,854:INFO:Uploading results into container
2024-01-01 23:55:02,856:INFO:Uploading model into container now
2024-01-01 23:55:02,859:INFO:_master_model_container: 9
2024-01-01 23:55:02,859:INFO:_display_container: 2
2024-01-01 23:55:02,860:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-01 23:55:02,861:INFO:create_model() successfully completed......................................
2024-01-01 23:55:03,018:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:03,018:INFO:Creating metrics dataframe
2024-01-01 23:55:03,027:INFO:Initializing Decision Tree Classifier
2024-01-01 23:55:03,027:INFO:Total runtime is 0.2861197233200073 minutes
2024-01-01 23:55:03,030:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:03,030:INFO:Initializing create_model()
2024-01-01 23:55:03,030:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:03,030:INFO:Checking exceptions
2024-01-01 23:55:03,030:INFO:Importing libraries
2024-01-01 23:55:03,031:INFO:Copying training dataset
2024-01-01 23:55:03,041:INFO:Defining folds
2024-01-01 23:55:03,042:INFO:Declaring metric variables
2024-01-01 23:55:03,045:INFO:Importing untrained model
2024-01-01 23:55:03,049:INFO:Decision Tree Classifier Imported successfully
2024-01-01 23:55:03,056:INFO:Starting cross validation
2024-01-01 23:55:03,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:03,358:INFO:Calculating mean and std
2024-01-01 23:55:03,359:INFO:Creating metrics dataframe
2024-01-01 23:55:03,362:INFO:Uploading results into container
2024-01-01 23:55:03,363:INFO:Uploading model into container now
2024-01-01 23:55:03,363:INFO:_master_model_container: 10
2024-01-01 23:55:03,363:INFO:_display_container: 2
2024-01-01 23:55:03,364:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-01 23:55:03,364:INFO:create_model() successfully completed......................................
2024-01-01 23:55:03,492:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:03,492:INFO:Creating metrics dataframe
2024-01-01 23:55:03,501:INFO:Initializing SVM - Linear Kernel
2024-01-01 23:55:03,501:INFO:Total runtime is 0.29400651057561233 minutes
2024-01-01 23:55:03,504:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:03,504:INFO:Initializing create_model()
2024-01-01 23:55:03,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:03,504:INFO:Checking exceptions
2024-01-01 23:55:03,504:INFO:Importing libraries
2024-01-01 23:55:03,504:INFO:Copying training dataset
2024-01-01 23:55:03,517:INFO:Defining folds
2024-01-01 23:55:03,518:INFO:Declaring metric variables
2024-01-01 23:55:03,521:INFO:Importing untrained model
2024-01-01 23:55:03,525:INFO:SVM - Linear Kernel Imported successfully
2024-01-01 23:55:03,533:INFO:Starting cross validation
2024-01-01 23:55:03,534:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:03,849:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:03,951:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:03,971:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:03,999:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,002:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,002:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,015:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,019:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,041:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,056:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-01 23:55:04,080:INFO:Calculating mean and std
2024-01-01 23:55:04,084:INFO:Creating metrics dataframe
2024-01-01 23:55:04,096:INFO:Uploading results into container
2024-01-01 23:55:04,099:INFO:Uploading model into container now
2024-01-01 23:55:04,101:INFO:_master_model_container: 11
2024-01-01 23:55:04,101:INFO:_display_container: 2
2024-01-01 23:55:04,103:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-01 23:55:04,103:INFO:create_model() successfully completed......................................
2024-01-01 23:55:04,233:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:04,234:INFO:Creating metrics dataframe
2024-01-01 23:55:04,244:INFO:Initializing Ridge Classifier
2024-01-01 23:55:04,244:INFO:Total runtime is 0.30640391508738196 minutes
2024-01-01 23:55:04,247:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:04,248:INFO:Initializing create_model()
2024-01-01 23:55:04,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:04,248:INFO:Checking exceptions
2024-01-01 23:55:04,248:INFO:Importing libraries
2024-01-01 23:55:04,248:INFO:Copying training dataset
2024-01-01 23:55:04,260:INFO:Defining folds
2024-01-01 23:55:04,261:INFO:Declaring metric variables
2024-01-01 23:55:04,264:INFO:Importing untrained model
2024-01-01 23:55:04,268:INFO:Ridge Classifier Imported successfully
2024-01-01 23:55:04,275:INFO:Starting cross validation
2024-01-01 23:55:04,276:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:04,505:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,507:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,528:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,528:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,529:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,556:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,559:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,564:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,570:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,572:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-01 23:55:04,592:INFO:Calculating mean and std
2024-01-01 23:55:04,593:INFO:Creating metrics dataframe
2024-01-01 23:55:04,597:INFO:Uploading results into container
2024-01-01 23:55:04,598:INFO:Uploading model into container now
2024-01-01 23:55:04,598:INFO:_master_model_container: 12
2024-01-01 23:55:04,598:INFO:_display_container: 2
2024-01-01 23:55:04,599:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-01 23:55:04,599:INFO:create_model() successfully completed......................................
2024-01-01 23:55:04,739:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:04,739:INFO:Creating metrics dataframe
2024-01-01 23:55:04,749:INFO:Initializing Random Forest Classifier
2024-01-01 23:55:04,749:INFO:Total runtime is 0.3148118694623311 minutes
2024-01-01 23:55:04,753:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:04,753:INFO:Initializing create_model()
2024-01-01 23:55:04,753:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:04,754:INFO:Checking exceptions
2024-01-01 23:55:04,754:INFO:Importing libraries
2024-01-01 23:55:04,754:INFO:Copying training dataset
2024-01-01 23:55:04,766:INFO:Defining folds
2024-01-01 23:55:04,766:INFO:Declaring metric variables
2024-01-01 23:55:04,770:INFO:Importing untrained model
2024-01-01 23:55:04,774:INFO:Random Forest Classifier Imported successfully
2024-01-01 23:55:04,783:INFO:Starting cross validation
2024-01-01 23:55:04,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:08,112:INFO:Calculating mean and std
2024-01-01 23:55:08,113:INFO:Creating metrics dataframe
2024-01-01 23:55:08,117:INFO:Uploading results into container
2024-01-01 23:55:08,118:INFO:Uploading model into container now
2024-01-01 23:55:08,119:INFO:_master_model_container: 13
2024-01-01 23:55:08,119:INFO:_display_container: 2
2024-01-01 23:55:08,119:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-01 23:55:08,119:INFO:create_model() successfully completed......................................
2024-01-01 23:55:08,248:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:08,248:INFO:Creating metrics dataframe
2024-01-01 23:55:08,258:INFO:Initializing Quadratic Discriminant Analysis
2024-01-01 23:55:08,258:INFO:Total runtime is 0.37329502105712886 minutes
2024-01-01 23:55:08,263:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:08,263:INFO:Initializing create_model()
2024-01-01 23:55:08,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:08,263:INFO:Checking exceptions
2024-01-01 23:55:08,263:INFO:Importing libraries
2024-01-01 23:55:08,263:INFO:Copying training dataset
2024-01-01 23:55:08,280:INFO:Defining folds
2024-01-01 23:55:08,281:INFO:Declaring metric variables
2024-01-01 23:55:08,286:INFO:Importing untrained model
2024-01-01 23:55:08,293:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-01 23:55:08,302:INFO:Starting cross validation
2024-01-01 23:55:08,303:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:08,514:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,524:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,545:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,549:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,576:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,585:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,592:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,599:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,612:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,619:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-01 23:55:08,660:INFO:Calculating mean and std
2024-01-01 23:55:08,661:INFO:Creating metrics dataframe
2024-01-01 23:55:08,665:INFO:Uploading results into container
2024-01-01 23:55:08,665:INFO:Uploading model into container now
2024-01-01 23:55:08,666:INFO:_master_model_container: 14
2024-01-01 23:55:08,666:INFO:_display_container: 2
2024-01-01 23:55:08,666:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-01 23:55:08,666:INFO:create_model() successfully completed......................................
2024-01-01 23:55:08,796:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:08,796:INFO:Creating metrics dataframe
2024-01-01 23:55:08,807:INFO:Initializing Ada Boost Classifier
2024-01-01 23:55:08,807:INFO:Total runtime is 0.3824490785598754 minutes
2024-01-01 23:55:08,810:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:08,811:INFO:Initializing create_model()
2024-01-01 23:55:08,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:08,811:INFO:Checking exceptions
2024-01-01 23:55:08,811:INFO:Importing libraries
2024-01-01 23:55:08,811:INFO:Copying training dataset
2024-01-01 23:55:08,823:INFO:Defining folds
2024-01-01 23:55:08,823:INFO:Declaring metric variables
2024-01-01 23:55:08,827:INFO:Importing untrained model
2024-01-01 23:55:08,830:INFO:Ada Boost Classifier Imported successfully
2024-01-01 23:55:08,841:INFO:Starting cross validation
2024-01-01 23:55:08,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:10,735:INFO:Calculating mean and std
2024-01-01 23:55:10,736:INFO:Creating metrics dataframe
2024-01-01 23:55:10,741:INFO:Uploading results into container
2024-01-01 23:55:10,741:INFO:Uploading model into container now
2024-01-01 23:55:10,742:INFO:_master_model_container: 15
2024-01-01 23:55:10,742:INFO:_display_container: 2
2024-01-01 23:55:10,742:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-01 23:55:10,742:INFO:create_model() successfully completed......................................
2024-01-01 23:55:10,877:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:10,877:INFO:Creating metrics dataframe
2024-01-01 23:55:10,889:INFO:Initializing Gradient Boosting Classifier
2024-01-01 23:55:10,889:INFO:Total runtime is 0.4171482841173807 minutes
2024-01-01 23:55:10,893:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:10,893:INFO:Initializing create_model()
2024-01-01 23:55:10,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:10,894:INFO:Checking exceptions
2024-01-01 23:55:10,894:INFO:Importing libraries
2024-01-01 23:55:10,894:INFO:Copying training dataset
2024-01-01 23:55:10,906:INFO:Defining folds
2024-01-01 23:55:10,906:INFO:Declaring metric variables
2024-01-01 23:55:10,910:INFO:Importing untrained model
2024-01-01 23:55:10,914:INFO:Gradient Boosting Classifier Imported successfully
2024-01-01 23:55:10,922:INFO:Starting cross validation
2024-01-01 23:55:10,924:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:13,640:INFO:Calculating mean and std
2024-01-01 23:55:13,640:INFO:Creating metrics dataframe
2024-01-01 23:55:13,644:INFO:Uploading results into container
2024-01-01 23:55:13,644:INFO:Uploading model into container now
2024-01-01 23:55:13,645:INFO:_master_model_container: 16
2024-01-01 23:55:13,645:INFO:_display_container: 2
2024-01-01 23:55:13,645:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-01 23:55:13,646:INFO:create_model() successfully completed......................................
2024-01-01 23:55:13,778:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:13,778:INFO:Creating metrics dataframe
2024-01-01 23:55:13,789:INFO:Initializing Linear Discriminant Analysis
2024-01-01 23:55:13,789:INFO:Total runtime is 0.4654881834983825 minutes
2024-01-01 23:55:13,792:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:13,793:INFO:Initializing create_model()
2024-01-01 23:55:13,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:13,793:INFO:Checking exceptions
2024-01-01 23:55:13,793:INFO:Importing libraries
2024-01-01 23:55:13,793:INFO:Copying training dataset
2024-01-01 23:55:13,805:INFO:Defining folds
2024-01-01 23:55:13,805:INFO:Declaring metric variables
2024-01-01 23:55:13,809:INFO:Importing untrained model
2024-01-01 23:55:13,814:INFO:Linear Discriminant Analysis Imported successfully
2024-01-01 23:55:13,822:INFO:Starting cross validation
2024-01-01 23:55:13,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:14,301:INFO:Calculating mean and std
2024-01-01 23:55:14,303:INFO:Creating metrics dataframe
2024-01-01 23:55:14,307:INFO:Uploading results into container
2024-01-01 23:55:14,307:INFO:Uploading model into container now
2024-01-01 23:55:14,308:INFO:_master_model_container: 17
2024-01-01 23:55:14,308:INFO:_display_container: 2
2024-01-01 23:55:14,308:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-01 23:55:14,308:INFO:create_model() successfully completed......................................
2024-01-01 23:55:14,507:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:14,507:INFO:Creating metrics dataframe
2024-01-01 23:55:14,527:INFO:Initializing Extra Trees Classifier
2024-01-01 23:55:14,527:INFO:Total runtime is 0.47778278191884355 minutes
2024-01-01 23:55:14,533:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:14,533:INFO:Initializing create_model()
2024-01-01 23:55:14,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:14,533:INFO:Checking exceptions
2024-01-01 23:55:14,534:INFO:Importing libraries
2024-01-01 23:55:14,534:INFO:Copying training dataset
2024-01-01 23:55:14,549:INFO:Defining folds
2024-01-01 23:55:14,549:INFO:Declaring metric variables
2024-01-01 23:55:14,555:INFO:Importing untrained model
2024-01-01 23:55:14,561:INFO:Extra Trees Classifier Imported successfully
2024-01-01 23:55:14,570:INFO:Starting cross validation
2024-01-01 23:55:14,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:17,290:INFO:Calculating mean and std
2024-01-01 23:55:17,292:INFO:Creating metrics dataframe
2024-01-01 23:55:17,296:INFO:Uploading results into container
2024-01-01 23:55:17,297:INFO:Uploading model into container now
2024-01-01 23:55:17,298:INFO:_master_model_container: 18
2024-01-01 23:55:17,298:INFO:_display_container: 2
2024-01-01 23:55:17,299:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-01 23:55:17,299:INFO:create_model() successfully completed......................................
2024-01-01 23:55:17,452:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:17,452:INFO:Creating metrics dataframe
2024-01-01 23:55:17,463:INFO:Initializing Light Gradient Boosting Machine
2024-01-01 23:55:17,463:INFO:Total runtime is 0.5267099301020304 minutes
2024-01-01 23:55:17,467:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:17,467:INFO:Initializing create_model()
2024-01-01 23:55:17,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:17,467:INFO:Checking exceptions
2024-01-01 23:55:17,467:INFO:Importing libraries
2024-01-01 23:55:17,467:INFO:Copying training dataset
2024-01-01 23:55:17,479:INFO:Defining folds
2024-01-01 23:55:17,479:INFO:Declaring metric variables
2024-01-01 23:55:17,482:INFO:Importing untrained model
2024-01-01 23:55:17,491:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:55:17,509:INFO:Starting cross validation
2024-01-01 23:55:17,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:18,911:INFO:Calculating mean and std
2024-01-01 23:55:18,914:INFO:Creating metrics dataframe
2024-01-01 23:55:18,922:INFO:Uploading results into container
2024-01-01 23:55:18,923:INFO:Uploading model into container now
2024-01-01 23:55:18,923:INFO:_master_model_container: 19
2024-01-01 23:55:18,924:INFO:_display_container: 2
2024-01-01 23:55:18,924:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:18,924:INFO:create_model() successfully completed......................................
2024-01-01 23:55:19,085:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:19,085:INFO:Creating metrics dataframe
2024-01-01 23:55:19,097:INFO:Initializing Dummy Classifier
2024-01-01 23:55:19,097:INFO:Total runtime is 0.5539540410041809 minutes
2024-01-01 23:55:19,100:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:19,100:INFO:Initializing create_model()
2024-01-01 23:55:19,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DA0DB1F0>, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:19,101:INFO:Checking exceptions
2024-01-01 23:55:19,101:INFO:Importing libraries
2024-01-01 23:55:19,101:INFO:Copying training dataset
2024-01-01 23:55:19,129:INFO:Defining folds
2024-01-01 23:55:19,130:INFO:Declaring metric variables
2024-01-01 23:55:19,134:INFO:Importing untrained model
2024-01-01 23:55:19,139:INFO:Dummy Classifier Imported successfully
2024-01-01 23:55:19,147:INFO:Starting cross validation
2024-01-01 23:55:19,148:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:19,299:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,306:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,323:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,338:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,348:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,357:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,361:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,366:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,370:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,376:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-01 23:55:19,382:INFO:Calculating mean and std
2024-01-01 23:55:19,383:INFO:Creating metrics dataframe
2024-01-01 23:55:19,387:INFO:Uploading results into container
2024-01-01 23:55:19,388:INFO:Uploading model into container now
2024-01-01 23:55:19,388:INFO:_master_model_container: 20
2024-01-01 23:55:19,388:INFO:_display_container: 2
2024-01-01 23:55:19,389:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-01 23:55:19,389:INFO:create_model() successfully completed......................................
2024-01-01 23:55:19,517:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:19,517:INFO:Creating metrics dataframe
2024-01-01 23:55:19,539:INFO:Initializing create_model()
2024-01-01 23:55:19,540:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:19,540:INFO:Checking exceptions
2024-01-01 23:55:19,541:INFO:Importing libraries
2024-01-01 23:55:19,542:INFO:Copying training dataset
2024-01-01 23:55:19,553:INFO:Defining folds
2024-01-01 23:55:19,553:INFO:Declaring metric variables
2024-01-01 23:55:19,553:INFO:Importing untrained model
2024-01-01 23:55:19,553:INFO:Declaring custom model
2024-01-01 23:55:19,554:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:55:19,555:INFO:Cross validation set to False
2024-01-01 23:55:19,555:INFO:Fitting Model
2024-01-01 23:55:19,606:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:55:19,608:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000598 seconds.
2024-01-01 23:55:19,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:55:19,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:55:19,609:INFO:[LightGBM] [Info] Total Bins 342
2024-01-01 23:55:19,609:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 16
2024-01-01 23:55:19,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:55:19,609:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:55:19,712:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:19,712:INFO:create_model() successfully completed......................................
2024-01-01 23:55:19,901:INFO:_master_model_container: 20
2024-01-01 23:55:19,901:INFO:_display_container: 2
2024-01-01 23:55:19,902:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:19,902:INFO:compare_models() successfully completed......................................
2024-01-01 23:55:20,123:INFO:Initializing plot_model()
2024-01-01 23:55:20,123:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:55:20,123:INFO:Checking exceptions
2024-01-01 23:55:20,131:INFO:Preloading libraries
2024-01-01 23:55:20,138:INFO:Copying training dataset
2024-01-01 23:55:20,138:INFO:Plot type: auc
2024-01-01 23:55:20,306:INFO:Fitting Model
2024-01-01 23:55:20,307:INFO:Scoring test/hold-out set
2024-01-01 23:55:20,582:INFO:Visual Rendered Successfully
2024-01-01 23:55:20,716:INFO:plot_model() successfully completed......................................
2024-01-01 23:55:20,754:INFO:Initializing plot_model()
2024-01-01 23:55:20,755:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:55:20,755:INFO:Checking exceptions
2024-01-01 23:55:20,761:INFO:Preloading libraries
2024-01-01 23:55:20,767:INFO:Copying training dataset
2024-01-01 23:55:20,767:INFO:Plot type: confusion_matrix
2024-01-01 23:55:20,931:INFO:Fitting Model
2024-01-01 23:55:20,932:INFO:Scoring test/hold-out set
2024-01-01 23:55:21,099:INFO:Visual Rendered Successfully
2024-01-01 23:55:21,234:INFO:plot_model() successfully completed......................................
2024-01-01 23:55:21,270:INFO:Initializing plot_model()
2024-01-01 23:55:21,270:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:55:21,270:INFO:Checking exceptions
2024-01-01 23:55:21,277:INFO:Preloading libraries
2024-01-01 23:55:21,282:INFO:Copying training dataset
2024-01-01 23:55:21,282:INFO:Plot type: class_report
2024-01-01 23:55:21,443:INFO:Fitting Model
2024-01-01 23:55:21,443:INFO:Scoring test/hold-out set
2024-01-01 23:55:21,709:INFO:Visual Rendered Successfully
2024-01-01 23:55:21,844:INFO:plot_model() successfully completed......................................
2024-01-01 23:55:21,878:INFO:Initializing tune_model()
2024-01-01 23:55:21,878:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>)
2024-01-01 23:55:21,879:INFO:Checking exceptions
2024-01-01 23:55:21,903:INFO:Copying training dataset
2024-01-01 23:55:21,914:INFO:Checking base model
2024-01-01 23:55:21,914:INFO:Base model : Light Gradient Boosting Machine
2024-01-01 23:55:21,920:INFO:Declaring metric variables
2024-01-01 23:55:21,925:INFO:Defining Hyperparameters
2024-01-01 23:55:22,077:INFO:Tuning with n_jobs=-1
2024-01-01 23:55:22,077:INFO:Initializing RandomizedSearchCV
2024-01-01 23:55:42,990:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-01 23:55:42,991:INFO:Hyperparameter search completed
2024-01-01 23:55:42,991:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:42,992:INFO:Initializing create_model()
2024-01-01 23:55:42,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244D8731840>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-01 23:55:42,992:INFO:Checking exceptions
2024-01-01 23:55:42,992:INFO:Importing libraries
2024-01-01 23:55:42,992:INFO:Copying training dataset
2024-01-01 23:55:43,014:INFO:Defining folds
2024-01-01 23:55:43,014:INFO:Declaring metric variables
2024-01-01 23:55:43,019:INFO:Importing untrained model
2024-01-01 23:55:43,020:INFO:Declaring custom model
2024-01-01 23:55:43,027:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:55:43,036:INFO:Starting cross validation
2024-01-01 23:55:43,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:45,407:INFO:Calculating mean and std
2024-01-01 23:55:45,409:INFO:Creating metrics dataframe
2024-01-01 23:55:45,419:INFO:Finalizing model
2024-01-01 23:55:45,465:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-01 23:55:45,465:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-01 23:55:45,465:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-01 23:55:45,476:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-01 23:55:45,476:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-01 23:55:45,476:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-01 23:55:45,476:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:55:45,478:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000601 seconds.
2024-01-01 23:55:45,478:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:55:45,478:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:55:45,479:INFO:[LightGBM] [Info] Total Bins 342
2024-01-01 23:55:45,479:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 16
2024-01-01 23:55:45,479:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:55:45,479:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:55:45,481:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,490:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,492:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,493:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,494:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,496:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,497:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,499:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,500:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,502:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,503:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,504:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,506:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,507:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,509:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,531:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,580:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,587:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,600:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,601:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,603:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,609:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,615:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,620:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,622:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,626:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,637:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,643:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,644:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,647:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,654:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,657:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,660:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,661:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,661:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,662:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,669:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,670:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,671:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,674:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,675:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,676:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,677:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,677:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,680:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,680:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,685:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,686:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,688:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,689:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,691:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,692:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,692:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,693:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,694:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,700:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,702:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,705:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,706:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,707:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,708:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,709:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,709:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:55:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,711:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:55:45,729:INFO:Uploading results into container
2024-01-01 23:55:45,731:INFO:Uploading model into container now
2024-01-01 23:55:45,731:INFO:_master_model_container: 21
2024-01-01 23:55:45,732:INFO:_display_container: 3
2024-01-01 23:55:45,733:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:45,733:INFO:create_model() successfully completed......................................
2024-01-01 23:55:45,909:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:45,909:INFO:choose_better activated
2024-01-01 23:55:45,912:INFO:SubProcess create_model() called ==================================
2024-01-01 23:55:45,912:INFO:Initializing create_model()
2024-01-01 23:55:45,912:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:55:45,913:INFO:Checking exceptions
2024-01-01 23:55:45,914:INFO:Importing libraries
2024-01-01 23:55:45,914:INFO:Copying training dataset
2024-01-01 23:55:45,927:INFO:Defining folds
2024-01-01 23:55:45,927:INFO:Declaring metric variables
2024-01-01 23:55:45,927:INFO:Importing untrained model
2024-01-01 23:55:45,927:INFO:Declaring custom model
2024-01-01 23:55:45,928:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:55:45,928:INFO:Starting cross validation
2024-01-01 23:55:45,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:55:47,722:INFO:Calculating mean and std
2024-01-01 23:55:47,723:INFO:Creating metrics dataframe
2024-01-01 23:55:47,726:INFO:Finalizing model
2024-01-01 23:55:47,784:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:55:47,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000880 seconds.
2024-01-01 23:55:47,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:55:47,787:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:55:47,787:INFO:[LightGBM] [Info] Total Bins 342
2024-01-01 23:55:47,787:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 16
2024-01-01 23:55:47,787:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:55:47,788:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:55:47,949:INFO:Uploading results into container
2024-01-01 23:55:47,950:INFO:Uploading model into container now
2024-01-01 23:55:47,951:INFO:_master_model_container: 22
2024-01-01 23:55:47,951:INFO:_display_container: 4
2024-01-01 23:55:47,952:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:47,952:INFO:create_model() successfully completed......................................
2024-01-01 23:55:48,151:INFO:SubProcess create_model() end ==================================
2024-01-01 23:55:48,151:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8385
2024-01-01 23:55:48,152:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8377
2024-01-01 23:55:48,152:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-01 23:55:48,152:INFO:choose_better completed
2024-01-01 23:55:48,152:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-01 23:55:48,166:INFO:_master_model_container: 22
2024-01-01 23:55:48,166:INFO:_display_container: 3
2024-01-01 23:55:48,166:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:48,167:INFO:tune_model() successfully completed......................................
2024-01-01 23:55:48,503:INFO:Initializing plot_model()
2024-01-01 23:55:48,504:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:55:48,504:INFO:Checking exceptions
2024-01-01 23:55:48,520:INFO:Preloading libraries
2024-01-01 23:55:48,530:INFO:Copying training dataset
2024-01-01 23:55:48,531:INFO:Plot type: auc
2024-01-01 23:55:48,734:INFO:Fitting Model
2024-01-01 23:55:48,734:INFO:Scoring test/hold-out set
2024-01-01 23:55:49,014:INFO:Visual Rendered Successfully
2024-01-01 23:55:49,151:INFO:plot_model() successfully completed......................................
2024-01-01 23:55:49,189:INFO:Initializing plot_model()
2024-01-01 23:55:49,191:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:55:49,191:INFO:Checking exceptions
2024-01-01 23:55:49,197:INFO:Preloading libraries
2024-01-01 23:55:49,202:INFO:Copying training dataset
2024-01-01 23:55:49,203:INFO:Plot type: confusion_matrix
2024-01-01 23:55:49,363:INFO:Fitting Model
2024-01-01 23:55:49,364:INFO:Scoring test/hold-out set
2024-01-01 23:55:49,535:INFO:Visual Rendered Successfully
2024-01-01 23:55:49,673:INFO:plot_model() successfully completed......................................
2024-01-01 23:55:49,705:INFO:Initializing plot_model()
2024-01-01 23:55:49,705:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:55:49,705:INFO:Checking exceptions
2024-01-01 23:55:49,714:INFO:Preloading libraries
2024-01-01 23:55:49,719:INFO:Copying training dataset
2024-01-01 23:55:49,720:INFO:Plot type: class_report
2024-01-01 23:55:49,890:INFO:Fitting Model
2024-01-01 23:55:49,890:INFO:Scoring test/hold-out set
2024-01-01 23:55:50,173:INFO:Visual Rendered Successfully
2024-01-01 23:55:50,325:INFO:plot_model() successfully completed......................................
2024-01-01 23:55:50,363:INFO:Initializing finalize_model()
2024-01-01 23:55:50,363:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-01 23:55:50,363:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:55:50,369:INFO:Initializing create_model()
2024-01-01 23:55:50,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-01 23:55:50,370:INFO:Checking exceptions
2024-01-01 23:55:50,372:INFO:Importing libraries
2024-01-01 23:55:50,373:INFO:Copying training dataset
2024-01-01 23:55:50,373:INFO:Defining folds
2024-01-01 23:55:50,373:INFO:Declaring metric variables
2024-01-01 23:55:50,373:INFO:Importing untrained model
2024-01-01 23:55:50,373:INFO:Declaring custom model
2024-01-01 23:55:50,374:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:55:50,375:INFO:Cross validation set to False
2024-01-01 23:55:50,375:INFO:Fitting Model
2024-01-01 23:55:50,426:INFO:[LightGBM] [Info] Number of positive: 7695, number of negative: 24283
2024-01-01 23:55:50,429:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000824 seconds.
2024-01-01 23:55:50,429:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:55:50,429:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:55:50,429:INFO:[LightGBM] [Info] Total Bins 355
2024-01-01 23:55:50,429:INFO:[LightGBM] [Info] Number of data points in the train set: 31978, number of used features: 17
2024-01-01 23:55:50,430:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240634 -> initscore=-1.149206
2024-01-01 23:55:50,430:INFO:[LightGBM] [Info] Start training from score -1.149206
2024-01-01 23:55:50,574:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married',
                                             'marital-status_Separat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-01 23:55:50,574:INFO:create_model() successfully completed......................................
2024-01-01 23:55:50,737:INFO:_master_model_container: 22
2024-01-01 23:55:50,737:INFO:_display_container: 3
2024-01-01 23:55:50,743:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married',
                                             'marital-status_Separat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-01 23:55:50,743:INFO:finalize_model() successfully completed......................................
2024-01-01 23:55:50,974:INFO:Initializing predict_model()
2024-01-01 23:55:50,974:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married',
                                             'marital-status_Separat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244D6D85090>)
2024-01-01 23:55:50,974:INFO:Checking exceptions
2024-01-01 23:55:50,974:INFO:Preloading libraries
2024-01-01 23:55:50,977:INFO:Set up data.
2024-01-01 23:55:50,990:INFO:Set up index.
2024-01-01 23:55:58,551:INFO:Initializing tune_model()
2024-01-01 23:55:58,551:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>)
2024-01-01 23:55:58,551:INFO:Checking exceptions
2024-01-01 23:55:58,573:INFO:Copying training dataset
2024-01-01 23:55:58,584:INFO:Checking base model
2024-01-01 23:55:58,585:INFO:Base model : Light Gradient Boosting Machine
2024-01-01 23:55:58,589:INFO:Declaring metric variables
2024-01-01 23:55:58,593:INFO:Defining Hyperparameters
2024-01-01 23:55:58,846:INFO:Tuning with n_jobs=-1
2024-01-01 23:55:58,847:INFO:Initializing RandomizedSearchCV
2024-01-01 23:56:20,255:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-01 23:56:20,256:INFO:Hyperparameter search completed
2024-01-01 23:56:20,256:INFO:SubProcess create_model() called ==================================
2024-01-01 23:56:20,257:INFO:Initializing create_model()
2024-01-01 23:56:20,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000244DD4F5600>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-01 23:56:20,258:INFO:Checking exceptions
2024-01-01 23:56:20,258:INFO:Importing libraries
2024-01-01 23:56:20,258:INFO:Copying training dataset
2024-01-01 23:56:20,278:INFO:Defining folds
2024-01-01 23:56:20,278:INFO:Declaring metric variables
2024-01-01 23:56:20,284:INFO:Importing untrained model
2024-01-01 23:56:20,285:INFO:Declaring custom model
2024-01-01 23:56:20,292:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:56:20,304:INFO:Starting cross validation
2024-01-01 23:56:20,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:56:22,648:INFO:Calculating mean and std
2024-01-01 23:56:22,650:INFO:Creating metrics dataframe
2024-01-01 23:56:22,661:INFO:Finalizing model
2024-01-01 23:56:22,707:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-01 23:56:22,707:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-01 23:56:22,708:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-01 23:56:22,719:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-01 23:56:22,720:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-01 23:56:22,720:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-01 23:56:22,720:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:56:22,722:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000763 seconds.
2024-01-01 23:56:22,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:56:22,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:56:22,723:INFO:[LightGBM] [Info] Total Bins 342
2024-01-01 23:56:22,723:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 16
2024-01-01 23:56:22,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:56:22,724:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:56:22,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,798:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,804:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,805:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,851:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,894:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,895:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,903:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,910:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,916:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,918:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,924:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,936:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,943:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,944:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,947:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,957:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,962:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,966:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,967:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,969:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,977:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,979:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,983:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,986:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,987:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,990:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:22,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:22,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,001:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,004:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,007:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,008:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,009:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,010:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,049:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,051:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,056:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,057:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-01 23:56:23,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-01 23:56:23,080:INFO:Uploading results into container
2024-01-01 23:56:23,081:INFO:Uploading model into container now
2024-01-01 23:56:23,083:INFO:_master_model_container: 23
2024-01-01 23:56:23,083:INFO:_display_container: 5
2024-01-01 23:56:23,084:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:56:23,084:INFO:create_model() successfully completed......................................
2024-01-01 23:56:23,316:INFO:SubProcess create_model() end ==================================
2024-01-01 23:56:23,317:INFO:choose_better activated
2024-01-01 23:56:23,320:INFO:SubProcess create_model() called ==================================
2024-01-01 23:56:23,321:INFO:Initializing create_model()
2024-01-01 23:56:23,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-01 23:56:23,321:INFO:Checking exceptions
2024-01-01 23:56:23,322:INFO:Importing libraries
2024-01-01 23:56:23,322:INFO:Copying training dataset
2024-01-01 23:56:23,334:INFO:Defining folds
2024-01-01 23:56:23,334:INFO:Declaring metric variables
2024-01-01 23:56:23,334:INFO:Importing untrained model
2024-01-01 23:56:23,334:INFO:Declaring custom model
2024-01-01 23:56:23,335:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:56:23,335:INFO:Starting cross validation
2024-01-01 23:56:23,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-01 23:56:24,919:INFO:Calculating mean and std
2024-01-01 23:56:24,920:INFO:Creating metrics dataframe
2024-01-01 23:56:24,924:INFO:Finalizing model
2024-01-01 23:56:24,977:INFO:[LightGBM] [Info] Number of positive: 6156, number of negative: 19426
2024-01-01 23:56:24,980:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.
2024-01-01 23:56:24,980:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:56:24,980:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:56:24,980:INFO:[LightGBM] [Info] Total Bins 342
2024-01-01 23:56:24,981:INFO:[LightGBM] [Info] Number of data points in the train set: 25582, number of used features: 16
2024-01-01 23:56:24,981:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240638 -> initscore=-1.149185
2024-01-01 23:56:24,981:INFO:[LightGBM] [Info] Start training from score -1.149185
2024-01-01 23:56:25,119:INFO:Uploading results into container
2024-01-01 23:56:25,119:INFO:Uploading model into container now
2024-01-01 23:56:25,120:INFO:_master_model_container: 24
2024-01-01 23:56:25,120:INFO:_display_container: 6
2024-01-01 23:56:25,121:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:56:25,121:INFO:create_model() successfully completed......................................
2024-01-01 23:56:25,314:INFO:SubProcess create_model() end ==================================
2024-01-01 23:56:25,314:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8385
2024-01-01 23:56:25,315:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8377
2024-01-01 23:56:25,316:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-01 23:56:25,316:INFO:choose_better completed
2024-01-01 23:56:25,316:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-01 23:56:25,325:INFO:_master_model_container: 24
2024-01-01 23:56:25,325:INFO:_display_container: 5
2024-01-01 23:56:25,325:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:56:25,325:INFO:tune_model() successfully completed......................................
2024-01-01 23:56:34,459:INFO:Initializing plot_model()
2024-01-01 23:56:34,460:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:56:34,460:INFO:Checking exceptions
2024-01-01 23:56:34,471:INFO:Preloading libraries
2024-01-01 23:56:34,477:INFO:Copying training dataset
2024-01-01 23:56:34,478:INFO:Plot type: auc
2024-01-01 23:56:34,677:INFO:Fitting Model
2024-01-01 23:56:34,678:INFO:Scoring test/hold-out set
2024-01-01 23:56:34,958:INFO:Visual Rendered Successfully
2024-01-01 23:56:35,139:INFO:plot_model() successfully completed......................................
2024-01-01 23:56:35,196:INFO:Initializing plot_model()
2024-01-01 23:56:35,196:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:56:35,197:INFO:Checking exceptions
2024-01-01 23:56:35,207:INFO:Preloading libraries
2024-01-01 23:56:35,213:INFO:Copying training dataset
2024-01-01 23:56:35,213:INFO:Plot type: confusion_matrix
2024-01-01 23:56:35,382:INFO:Fitting Model
2024-01-01 23:56:35,382:INFO:Scoring test/hold-out set
2024-01-01 23:56:35,555:INFO:Visual Rendered Successfully
2024-01-01 23:56:35,765:INFO:plot_model() successfully completed......................................
2024-01-01 23:56:35,821:INFO:Initializing plot_model()
2024-01-01 23:56:35,822:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, system=True)
2024-01-01 23:56:35,822:INFO:Checking exceptions
2024-01-01 23:56:35,834:INFO:Preloading libraries
2024-01-01 23:56:35,842:INFO:Copying training dataset
2024-01-01 23:56:35,843:INFO:Plot type: class_report
2024-01-01 23:56:36,022:INFO:Fitting Model
2024-01-01 23:56:36,022:INFO:Scoring test/hold-out set
2024-01-01 23:56:36,333:INFO:Visual Rendered Successfully
2024-01-01 23:56:36,524:INFO:plot_model() successfully completed......................................
2024-01-01 23:56:36,564:INFO:Initializing finalize_model()
2024-01-01 23:56:36,564:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-01 23:56:36,565:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-01 23:56:36,571:INFO:Initializing create_model()
2024-01-01 23:56:36,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-01 23:56:36,571:INFO:Checking exceptions
2024-01-01 23:56:36,573:INFO:Importing libraries
2024-01-01 23:56:36,573:INFO:Copying training dataset
2024-01-01 23:56:36,574:INFO:Defining folds
2024-01-01 23:56:36,574:INFO:Declaring metric variables
2024-01-01 23:56:36,574:INFO:Importing untrained model
2024-01-01 23:56:36,574:INFO:Declaring custom model
2024-01-01 23:56:36,575:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-01 23:56:36,576:INFO:Cross validation set to False
2024-01-01 23:56:36,576:INFO:Fitting Model
2024-01-01 23:56:36,637:INFO:[LightGBM] [Info] Number of positive: 7695, number of negative: 24283
2024-01-01 23:56:36,640:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000806 seconds.
2024-01-01 23:56:36,640:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-01 23:56:36,640:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-01 23:56:36,640:INFO:[LightGBM] [Info] Total Bins 355
2024-01-01 23:56:36,640:INFO:[LightGBM] [Info] Number of data points in the train set: 31978, number of used features: 17
2024-01-01 23:56:36,640:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240634 -> initscore=-1.149206
2024-01-01 23:56:36,641:INFO:[LightGBM] [Info] Start training from score -1.149206
2024-01-01 23:56:36,809:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married',
                                             'marital-status_Separat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-01 23:56:36,810:INFO:create_model() successfully completed......................................
2024-01-01 23:56:37,032:INFO:_master_model_container: 24
2024-01-01 23:56:37,032:INFO:_display_container: 5
2024-01-01 23:56:37,039:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married',
                                             'marital-status_Separat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-01 23:56:37,039:INFO:finalize_model() successfully completed......................................
2024-01-01 23:56:37,535:INFO:Initializing predict_model()
2024-01-01 23:56:37,535:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000244CCA11AE0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'capital-gain',
                                             'capital-loss', 'hours-per-week',
                                             'marital-status_Divorced',
                                             'marital-status_Married-AF-spouse',
                                             'marital-status_Married-civ-spouse',
                                             'marital-status_Married-spouse-absent',
                                             'marital-status_Never-married',
                                             'marital-status_Separat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244DA370A60>)
2024-01-01 23:56:37,536:INFO:Checking exceptions
2024-01-01 23:56:37,536:INFO:Preloading libraries
2024-01-01 23:56:37,542:INFO:Set up data.
2024-01-01 23:56:37,561:INFO:Set up index.
2024-01-02 10:20:46,772:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-02 10:20:47,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-02 10:20:47,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-02 10:20:47,105:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-02 10:20:47,761:INFO:PyCaret ClassificationExperiment
2024-01-02 10:20:47,761:INFO:Logging name: clf-default-name
2024-01-02 10:20:47,761:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-02 10:20:47,761:INFO:version 3.1.0
2024-01-02 10:20:47,761:INFO:Initializing setup()
2024-01-02 10:20:47,761:INFO:self.USI: bcc4
2024-01-02 10:20:47,761:INFO:self._variable_keys: {'y_train', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'X_test', 'USI', 'pipeline', 'fix_imbalance', 'X_train', 'logging_param', 'y_test', 'memory', 'data', '_available_plots', 'target_param', 'is_multiclass', 'idx', 'fold_groups_param', 'gpu_param', 'exp_name_log', 'fold_generator', 'y', 'X', '_ml_usecase', 'log_plots_param', 'html_param'}
2024-01-02 10:20:47,761:INFO:Checking environment
2024-01-02 10:20:47,761:INFO:python_version: 3.10.9
2024-01-02 10:20:47,762:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-02 10:20:47,762:INFO:machine: AMD64
2024-01-02 10:20:47,762:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-02 10:20:47,762:INFO:Memory: svmem(total=16954372096, available=3078582272, percent=81.8, used=13875789824, free=3078582272)
2024-01-02 10:20:47,762:INFO:Physical Core: 8
2024-01-02 10:20:47,762:INFO:Logical Core: 16
2024-01-02 10:20:47,762:INFO:Checking libraries
2024-01-02 10:20:47,762:INFO:System:
2024-01-02 10:20:47,762:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-02 10:20:47,762:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-02 10:20:47,762:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-02 10:20:47,762:INFO:PyCaret required dependencies:
2024-01-02 10:20:48,541:INFO:                 pip: 22.3.1
2024-01-02 10:20:48,541:INFO:          setuptools: 65.6.3
2024-01-02 10:20:48,541:INFO:             pycaret: 3.1.0
2024-01-02 10:20:48,541:INFO:             IPython: 8.10.0
2024-01-02 10:20:48,541:INFO:          ipywidgets: 7.6.5
2024-01-02 10:20:48,541:INFO:                tqdm: 4.64.1
2024-01-02 10:20:48,542:INFO:               numpy: 1.23.5
2024-01-02 10:20:48,542:INFO:              pandas: 1.5.3
2024-01-02 10:20:48,542:INFO:              jinja2: 3.1.2
2024-01-02 10:20:48,542:INFO:               scipy: 1.10.1
2024-01-02 10:20:48,542:INFO:              joblib: 1.3.2
2024-01-02 10:20:48,542:INFO:             sklearn: 1.2.1
2024-01-02 10:20:48,542:INFO:                pyod: 1.1.0
2024-01-02 10:20:48,542:INFO:            imblearn: 0.10.1
2024-01-02 10:20:48,542:INFO:   category_encoders: 2.6.2
2024-01-02 10:20:48,542:INFO:            lightgbm: 4.1.0
2024-01-02 10:20:48,542:INFO:               numba: 0.56.4
2024-01-02 10:20:48,542:INFO:            requests: 2.28.1
2024-01-02 10:20:48,542:INFO:          matplotlib: 3.7.0
2024-01-02 10:20:48,542:INFO:          scikitplot: 0.3.7
2024-01-02 10:20:48,542:INFO:         yellowbrick: 1.5
2024-01-02 10:20:48,542:INFO:              plotly: 5.9.0
2024-01-02 10:20:48,542:INFO:    plotly-resampler: Not installed
2024-01-02 10:20:48,542:INFO:             kaleido: 0.2.1
2024-01-02 10:20:48,569:INFO:           schemdraw: 0.15
2024-01-02 10:20:48,569:INFO:         statsmodels: 0.13.5
2024-01-02 10:20:48,569:INFO:              sktime: 0.21.1
2024-01-02 10:20:48,569:INFO:               tbats: 1.1.3
2024-01-02 10:20:48,569:INFO:            pmdarima: 2.0.3
2024-01-02 10:20:48,569:INFO:              psutil: 5.9.0
2024-01-02 10:20:48,569:INFO:          markupsafe: 2.1.1
2024-01-02 10:20:48,569:INFO:             pickle5: Not installed
2024-01-02 10:20:48,569:INFO:         cloudpickle: 2.0.0
2024-01-02 10:20:48,569:INFO:         deprecation: 2.1.0
2024-01-02 10:20:48,569:INFO:              xxhash: 3.4.1
2024-01-02 10:20:48,569:INFO:           wurlitzer: Not installed
2024-01-02 10:20:48,569:INFO:PyCaret optional dependencies:
2024-01-02 10:20:48,584:INFO:                shap: Not installed
2024-01-02 10:20:48,585:INFO:           interpret: Not installed
2024-01-02 10:20:48,585:INFO:                umap: Not installed
2024-01-02 10:20:48,585:INFO:     ydata_profiling: 4.6.0
2024-01-02 10:20:48,585:INFO:  explainerdashboard: Not installed
2024-01-02 10:20:48,585:INFO:             autoviz: Not installed
2024-01-02 10:20:48,585:INFO:           fairlearn: Not installed
2024-01-02 10:20:48,585:INFO:          deepchecks: Not installed
2024-01-02 10:20:48,585:INFO:             xgboost: Not installed
2024-01-02 10:20:48,585:INFO:            catboost: Not installed
2024-01-02 10:20:48,585:INFO:              kmodes: Not installed
2024-01-02 10:20:48,585:INFO:             mlxtend: Not installed
2024-01-02 10:20:48,585:INFO:       statsforecast: Not installed
2024-01-02 10:20:48,585:INFO:        tune_sklearn: Not installed
2024-01-02 10:20:48,585:INFO:                 ray: Not installed
2024-01-02 10:20:48,585:INFO:            hyperopt: Not installed
2024-01-02 10:20:48,585:INFO:              optuna: Not installed
2024-01-02 10:20:48,585:INFO:               skopt: Not installed
2024-01-02 10:20:48,585:INFO:              mlflow: Not installed
2024-01-02 10:20:48,585:INFO:              gradio: Not installed
2024-01-02 10:20:48,585:INFO:             fastapi: Not installed
2024-01-02 10:20:48,585:INFO:             uvicorn: Not installed
2024-01-02 10:20:48,585:INFO:              m2cgen: Not installed
2024-01-02 10:20:48,585:INFO:           evidently: Not installed
2024-01-02 10:20:48,586:INFO:               fugue: Not installed
2024-01-02 10:20:48,586:INFO:           streamlit: Not installed
2024-01-02 10:20:48,586:INFO:             prophet: Not installed
2024-01-02 10:20:48,586:INFO:None
2024-01-02 10:20:48,586:INFO:Set up data.
2024-01-02 10:20:48,634:INFO:Set up folding strategy.
2024-01-02 10:20:48,634:INFO:Set up train/test split.
2024-01-02 10:20:48,672:INFO:Set up index.
2024-01-02 10:20:48,674:INFO:Assigning column types.
2024-01-02 10:20:48,700:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-02 10:20:48,739:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:20:48,751:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:20:48,783:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:20:48,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:20:48,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,848:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-02 10:20:48,886:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:20:48,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,911:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,949:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:20:48,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:48,974:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-02 10:20:49,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,109:INFO:Preparing preprocessing pipeline...
2024-01-02 10:20:49,112:INFO:Set up simple imputation.
2024-01-02 10:20:49,117:INFO:Set up column name cleaning.
2024-01-02 10:20:49,231:INFO:Finished creating preprocessing pipeline.
2024-01-02 10:20:49,238:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Federal-gov',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Sel...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-02 10:20:49,238:INFO:Creating final display dataframe.
2024-01-02 10:20:49,528:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (32561, 99)
4        Transformed data shape       (32561, 99)
5   Transformed train set shape       (26048, 99)
6    Transformed test set shape        (6513, 99)
7              Numeric features                98
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              bcc4
2024-01-02 10:20:49,595:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:20:49,658:INFO:setup() successfully completed in 1.91s...............
2024-01-02 10:20:58,916:INFO:Initializing compare_models()
2024-01-02 10:20:58,916:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-02 10:20:58,916:INFO:Checking exceptions
2024-01-02 10:20:58,942:INFO:Preparing display monitor
2024-01-02 10:20:58,969:INFO:Initializing Logistic Regression
2024-01-02 10:20:58,969:INFO:Total runtime is 0.0 minutes
2024-01-02 10:20:58,973:INFO:SubProcess create_model() called ==================================
2024-01-02 10:20:58,974:INFO:Initializing create_model()
2024-01-02 10:20:58,974:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:20:58,974:INFO:Checking exceptions
2024-01-02 10:20:58,974:INFO:Importing libraries
2024-01-02 10:20:58,974:INFO:Copying training dataset
2024-01-02 10:20:59,046:INFO:Defining folds
2024-01-02 10:20:59,046:INFO:Declaring metric variables
2024-01-02 10:20:59,053:INFO:Importing untrained model
2024-01-02 10:20:59,056:INFO:Logistic Regression Imported successfully
2024-01-02 10:20:59,065:INFO:Starting cross validation
2024-01-02 10:20:59,066:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:21:51,661:INFO:Calculating mean and std
2024-01-02 10:21:51,663:INFO:Creating metrics dataframe
2024-01-02 10:21:51,666:INFO:Uploading results into container
2024-01-02 10:21:51,666:INFO:Uploading model into container now
2024-01-02 10:21:51,666:INFO:_master_model_container: 1
2024-01-02 10:21:51,668:INFO:_display_container: 2
2024-01-02 10:21:51,668:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-02 10:21:51,668:INFO:create_model() successfully completed......................................
2024-01-02 10:21:51,871:INFO:SubProcess create_model() end ==================================
2024-01-02 10:21:51,871:INFO:Creating metrics dataframe
2024-01-02 10:21:51,878:INFO:Initializing K Neighbors Classifier
2024-01-02 10:21:51,878:INFO:Total runtime is 0.8818220734596253 minutes
2024-01-02 10:21:51,881:INFO:SubProcess create_model() called ==================================
2024-01-02 10:21:51,881:INFO:Initializing create_model()
2024-01-02 10:21:51,881:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:21:51,881:INFO:Checking exceptions
2024-01-02 10:21:51,881:INFO:Importing libraries
2024-01-02 10:21:51,882:INFO:Copying training dataset
2024-01-02 10:21:51,929:INFO:Defining folds
2024-01-02 10:21:51,929:INFO:Declaring metric variables
2024-01-02 10:21:51,934:INFO:Importing untrained model
2024-01-02 10:21:51,938:INFO:K Neighbors Classifier Imported successfully
2024-01-02 10:21:51,945:INFO:Starting cross validation
2024-01-02 10:21:51,946:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:21:59,065:INFO:Calculating mean and std
2024-01-02 10:21:59,067:INFO:Creating metrics dataframe
2024-01-02 10:21:59,070:INFO:Uploading results into container
2024-01-02 10:21:59,071:INFO:Uploading model into container now
2024-01-02 10:21:59,071:INFO:_master_model_container: 2
2024-01-02 10:21:59,072:INFO:_display_container: 2
2024-01-02 10:21:59,072:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-02 10:21:59,072:INFO:create_model() successfully completed......................................
2024-01-02 10:21:59,255:INFO:SubProcess create_model() end ==================================
2024-01-02 10:21:59,255:INFO:Creating metrics dataframe
2024-01-02 10:21:59,263:INFO:Initializing Naive Bayes
2024-01-02 10:21:59,263:INFO:Total runtime is 1.0049025694529217 minutes
2024-01-02 10:21:59,265:INFO:SubProcess create_model() called ==================================
2024-01-02 10:21:59,266:INFO:Initializing create_model()
2024-01-02 10:21:59,266:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:21:59,266:INFO:Checking exceptions
2024-01-02 10:21:59,266:INFO:Importing libraries
2024-01-02 10:21:59,266:INFO:Copying training dataset
2024-01-02 10:21:59,320:INFO:Defining folds
2024-01-02 10:21:59,320:INFO:Declaring metric variables
2024-01-02 10:21:59,323:INFO:Importing untrained model
2024-01-02 10:21:59,327:INFO:Naive Bayes Imported successfully
2024-01-02 10:21:59,334:INFO:Starting cross validation
2024-01-02 10:21:59,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:00,290:INFO:Calculating mean and std
2024-01-02 10:22:00,291:INFO:Creating metrics dataframe
2024-01-02 10:22:00,295:INFO:Uploading results into container
2024-01-02 10:22:00,295:INFO:Uploading model into container now
2024-01-02 10:22:00,296:INFO:_master_model_container: 3
2024-01-02 10:22:00,296:INFO:_display_container: 2
2024-01-02 10:22:00,296:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-02 10:22:00,296:INFO:create_model() successfully completed......................................
2024-01-02 10:22:00,482:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:00,482:INFO:Creating metrics dataframe
2024-01-02 10:22:00,490:INFO:Initializing Decision Tree Classifier
2024-01-02 10:22:00,490:INFO:Total runtime is 1.025352442264557 minutes
2024-01-02 10:22:00,493:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:00,493:INFO:Initializing create_model()
2024-01-02 10:22:00,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:00,493:INFO:Checking exceptions
2024-01-02 10:22:00,493:INFO:Importing libraries
2024-01-02 10:22:00,494:INFO:Copying training dataset
2024-01-02 10:22:00,540:INFO:Defining folds
2024-01-02 10:22:00,540:INFO:Declaring metric variables
2024-01-02 10:22:00,543:INFO:Importing untrained model
2024-01-02 10:22:00,547:INFO:Decision Tree Classifier Imported successfully
2024-01-02 10:22:00,553:INFO:Starting cross validation
2024-01-02 10:22:00,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:01,893:INFO:Calculating mean and std
2024-01-02 10:22:01,895:INFO:Creating metrics dataframe
2024-01-02 10:22:01,899:INFO:Uploading results into container
2024-01-02 10:22:01,899:INFO:Uploading model into container now
2024-01-02 10:22:01,900:INFO:_master_model_container: 4
2024-01-02 10:22:01,900:INFO:_display_container: 2
2024-01-02 10:22:01,901:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-02 10:22:01,901:INFO:create_model() successfully completed......................................
2024-01-02 10:22:02,085:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:02,086:INFO:Creating metrics dataframe
2024-01-02 10:22:02,096:INFO:Initializing SVM - Linear Kernel
2024-01-02 10:22:02,096:INFO:Total runtime is 1.0521071791648866 minutes
2024-01-02 10:22:02,099:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:02,099:INFO:Initializing create_model()
2024-01-02 10:22:02,100:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:02,100:INFO:Checking exceptions
2024-01-02 10:22:02,100:INFO:Importing libraries
2024-01-02 10:22:02,100:INFO:Copying training dataset
2024-01-02 10:22:02,147:INFO:Defining folds
2024-01-02 10:22:02,148:INFO:Declaring metric variables
2024-01-02 10:22:02,151:INFO:Importing untrained model
2024-01-02 10:22:02,155:INFO:SVM - Linear Kernel Imported successfully
2024-01-02 10:22:02,161:INFO:Starting cross validation
2024-01-02 10:22:02,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:03,455:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,497:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,534:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,558:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,562:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,607:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,619:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,649:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,649:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,673:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:22:03,792:INFO:Calculating mean and std
2024-01-02 10:22:03,793:INFO:Creating metrics dataframe
2024-01-02 10:22:03,796:INFO:Uploading results into container
2024-01-02 10:22:03,796:INFO:Uploading model into container now
2024-01-02 10:22:03,796:INFO:_master_model_container: 5
2024-01-02 10:22:03,797:INFO:_display_container: 2
2024-01-02 10:22:03,797:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-02 10:22:03,797:INFO:create_model() successfully completed......................................
2024-01-02 10:22:03,975:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:03,976:INFO:Creating metrics dataframe
2024-01-02 10:22:03,985:INFO:Initializing Ridge Classifier
2024-01-02 10:22:03,985:INFO:Total runtime is 1.083605225880941 minutes
2024-01-02 10:22:03,987:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:03,987:INFO:Initializing create_model()
2024-01-02 10:22:03,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:03,989:INFO:Checking exceptions
2024-01-02 10:22:03,989:INFO:Importing libraries
2024-01-02 10:22:03,989:INFO:Copying training dataset
2024-01-02 10:22:04,035:INFO:Defining folds
2024-01-02 10:22:04,035:INFO:Declaring metric variables
2024-01-02 10:22:04,038:INFO:Importing untrained model
2024-01-02 10:22:04,041:INFO:Ridge Classifier Imported successfully
2024-01-02 10:22:04,048:INFO:Starting cross validation
2024-01-02 10:22:04,049:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:04,724:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,725:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,725:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,726:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,737:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,741:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,751:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,753:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,754:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,757:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:22:04,889:INFO:Calculating mean and std
2024-01-02 10:22:04,891:INFO:Creating metrics dataframe
2024-01-02 10:22:04,895:INFO:Uploading results into container
2024-01-02 10:22:04,896:INFO:Uploading model into container now
2024-01-02 10:22:04,896:INFO:_master_model_container: 6
2024-01-02 10:22:04,896:INFO:_display_container: 2
2024-01-02 10:22:04,897:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-02 10:22:04,897:INFO:create_model() successfully completed......................................
2024-01-02 10:22:05,096:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:05,096:INFO:Creating metrics dataframe
2024-01-02 10:22:05,105:INFO:Initializing Random Forest Classifier
2024-01-02 10:22:05,105:INFO:Total runtime is 1.1022730429967247 minutes
2024-01-02 10:22:05,109:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:05,109:INFO:Initializing create_model()
2024-01-02 10:22:05,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:05,109:INFO:Checking exceptions
2024-01-02 10:22:05,109:INFO:Importing libraries
2024-01-02 10:22:05,109:INFO:Copying training dataset
2024-01-02 10:22:05,155:INFO:Defining folds
2024-01-02 10:22:05,156:INFO:Declaring metric variables
2024-01-02 10:22:05,159:INFO:Importing untrained model
2024-01-02 10:22:05,162:INFO:Random Forest Classifier Imported successfully
2024-01-02 10:22:05,169:INFO:Starting cross validation
2024-01-02 10:22:05,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:13,843:INFO:Calculating mean and std
2024-01-02 10:22:13,844:INFO:Creating metrics dataframe
2024-01-02 10:22:13,847:INFO:Uploading results into container
2024-01-02 10:22:13,848:INFO:Uploading model into container now
2024-01-02 10:22:13,848:INFO:_master_model_container: 7
2024-01-02 10:22:13,849:INFO:_display_container: 2
2024-01-02 10:22:13,849:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-02 10:22:13,849:INFO:create_model() successfully completed......................................
2024-01-02 10:22:14,064:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:14,064:INFO:Creating metrics dataframe
2024-01-02 10:22:14,074:INFO:Initializing Quadratic Discriminant Analysis
2024-01-02 10:22:14,074:INFO:Total runtime is 1.2517454663912457 minutes
2024-01-02 10:22:14,077:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:14,077:INFO:Initializing create_model()
2024-01-02 10:22:14,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:14,077:INFO:Checking exceptions
2024-01-02 10:22:14,078:INFO:Importing libraries
2024-01-02 10:22:14,078:INFO:Copying training dataset
2024-01-02 10:22:14,156:INFO:Defining folds
2024-01-02 10:22:14,156:INFO:Declaring metric variables
2024-01-02 10:22:14,160:INFO:Importing untrained model
2024-01-02 10:22:14,164:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-02 10:22:14,176:INFO:Starting cross validation
2024-01-02 10:22:14,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:14,860:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,870:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,871:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,873:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,876:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,876:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,877:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,903:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:14,908:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:22:16,363:INFO:Calculating mean and std
2024-01-02 10:22:16,364:INFO:Creating metrics dataframe
2024-01-02 10:22:16,368:INFO:Uploading results into container
2024-01-02 10:22:16,369:INFO:Uploading model into container now
2024-01-02 10:22:16,369:INFO:_master_model_container: 8
2024-01-02 10:22:16,369:INFO:_display_container: 2
2024-01-02 10:22:16,370:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-02 10:22:16,370:INFO:create_model() successfully completed......................................
2024-01-02 10:22:16,612:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:16,613:INFO:Creating metrics dataframe
2024-01-02 10:22:16,625:INFO:Initializing Ada Boost Classifier
2024-01-02 10:22:16,625:INFO:Total runtime is 1.294260915120443 minutes
2024-01-02 10:22:16,629:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:16,629:INFO:Initializing create_model()
2024-01-02 10:22:16,629:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:16,629:INFO:Checking exceptions
2024-01-02 10:22:16,630:INFO:Importing libraries
2024-01-02 10:22:16,630:INFO:Copying training dataset
2024-01-02 10:22:16,681:INFO:Defining folds
2024-01-02 10:22:16,681:INFO:Declaring metric variables
2024-01-02 10:22:16,685:INFO:Importing untrained model
2024-01-02 10:22:16,689:INFO:Ada Boost Classifier Imported successfully
2024-01-02 10:22:16,697:INFO:Starting cross validation
2024-01-02 10:22:16,699:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:19,423:INFO:Calculating mean and std
2024-01-02 10:22:19,424:INFO:Creating metrics dataframe
2024-01-02 10:22:19,427:INFO:Uploading results into container
2024-01-02 10:22:19,428:INFO:Uploading model into container now
2024-01-02 10:22:19,428:INFO:_master_model_container: 9
2024-01-02 10:22:19,428:INFO:_display_container: 2
2024-01-02 10:22:19,429:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-02 10:22:19,429:INFO:create_model() successfully completed......................................
2024-01-02 10:22:19,602:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:19,602:INFO:Creating metrics dataframe
2024-01-02 10:22:19,612:INFO:Initializing Gradient Boosting Classifier
2024-01-02 10:22:19,612:INFO:Total runtime is 1.344052577018738 minutes
2024-01-02 10:22:19,615:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:19,615:INFO:Initializing create_model()
2024-01-02 10:22:19,615:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:19,615:INFO:Checking exceptions
2024-01-02 10:22:19,615:INFO:Importing libraries
2024-01-02 10:22:19,615:INFO:Copying training dataset
2024-01-02 10:22:19,660:INFO:Defining folds
2024-01-02 10:22:19,660:INFO:Declaring metric variables
2024-01-02 10:22:19,664:INFO:Importing untrained model
2024-01-02 10:22:19,667:INFO:Gradient Boosting Classifier Imported successfully
2024-01-02 10:22:19,675:INFO:Starting cross validation
2024-01-02 10:22:19,676:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:28,088:INFO:Calculating mean and std
2024-01-02 10:22:28,092:INFO:Creating metrics dataframe
2024-01-02 10:22:28,103:INFO:Uploading results into container
2024-01-02 10:22:28,106:INFO:Uploading model into container now
2024-01-02 10:22:28,107:INFO:_master_model_container: 10
2024-01-02 10:22:28,107:INFO:_display_container: 2
2024-01-02 10:22:28,108:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-02 10:22:28,108:INFO:create_model() successfully completed......................................
2024-01-02 10:22:28,330:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:28,330:INFO:Creating metrics dataframe
2024-01-02 10:22:28,340:INFO:Initializing Linear Discriminant Analysis
2024-01-02 10:22:28,340:INFO:Total runtime is 1.4895082076390587 minutes
2024-01-02 10:22:28,343:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:28,343:INFO:Initializing create_model()
2024-01-02 10:22:28,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:28,343:INFO:Checking exceptions
2024-01-02 10:22:28,343:INFO:Importing libraries
2024-01-02 10:22:28,344:INFO:Copying training dataset
2024-01-02 10:22:28,389:INFO:Defining folds
2024-01-02 10:22:28,389:INFO:Declaring metric variables
2024-01-02 10:22:28,392:INFO:Importing untrained model
2024-01-02 10:22:28,396:INFO:Linear Discriminant Analysis Imported successfully
2024-01-02 10:22:28,403:INFO:Starting cross validation
2024-01-02 10:22:28,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:34,101:INFO:Calculating mean and std
2024-01-02 10:22:34,105:INFO:Creating metrics dataframe
2024-01-02 10:22:34,117:INFO:Uploading results into container
2024-01-02 10:22:34,120:INFO:Uploading model into container now
2024-01-02 10:22:34,122:INFO:_master_model_container: 11
2024-01-02 10:22:34,122:INFO:_display_container: 2
2024-01-02 10:22:34,123:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-02 10:22:34,124:INFO:create_model() successfully completed......................................
2024-01-02 10:22:34,334:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:34,334:INFO:Creating metrics dataframe
2024-01-02 10:22:34,346:INFO:Initializing Extra Trees Classifier
2024-01-02 10:22:34,346:INFO:Total runtime is 1.5896196444829307 minutes
2024-01-02 10:22:34,349:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:34,349:INFO:Initializing create_model()
2024-01-02 10:22:34,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:34,349:INFO:Checking exceptions
2024-01-02 10:22:34,349:INFO:Importing libraries
2024-01-02 10:22:34,349:INFO:Copying training dataset
2024-01-02 10:22:34,396:INFO:Defining folds
2024-01-02 10:22:34,396:INFO:Declaring metric variables
2024-01-02 10:22:34,400:INFO:Importing untrained model
2024-01-02 10:22:34,404:INFO:Extra Trees Classifier Imported successfully
2024-01-02 10:22:34,411:INFO:Starting cross validation
2024-01-02 10:22:34,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:45,799:INFO:Calculating mean and std
2024-01-02 10:22:45,800:INFO:Creating metrics dataframe
2024-01-02 10:22:45,804:INFO:Uploading results into container
2024-01-02 10:22:45,804:INFO:Uploading model into container now
2024-01-02 10:22:45,805:INFO:_master_model_container: 12
2024-01-02 10:22:45,805:INFO:_display_container: 2
2024-01-02 10:22:45,806:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-02 10:22:45,806:INFO:create_model() successfully completed......................................
2024-01-02 10:22:46,048:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:46,049:INFO:Creating metrics dataframe
2024-01-02 10:22:46,060:INFO:Initializing Light Gradient Boosting Machine
2024-01-02 10:22:46,060:INFO:Total runtime is 1.7848477323849998 minutes
2024-01-02 10:22:46,062:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:46,063:INFO:Initializing create_model()
2024-01-02 10:22:46,063:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:46,063:INFO:Checking exceptions
2024-01-02 10:22:46,063:INFO:Importing libraries
2024-01-02 10:22:46,063:INFO:Copying training dataset
2024-01-02 10:22:46,110:INFO:Defining folds
2024-01-02 10:22:46,111:INFO:Declaring metric variables
2024-01-02 10:22:46,115:INFO:Importing untrained model
2024-01-02 10:22:46,119:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:22:46,125:INFO:Starting cross validation
2024-01-02 10:22:46,126:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:48,242:INFO:Calculating mean and std
2024-01-02 10:22:48,243:INFO:Creating metrics dataframe
2024-01-02 10:22:48,247:INFO:Uploading results into container
2024-01-02 10:22:48,248:INFO:Uploading model into container now
2024-01-02 10:22:48,248:INFO:_master_model_container: 13
2024-01-02 10:22:48,248:INFO:_display_container: 2
2024-01-02 10:22:48,249:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:22:48,249:INFO:create_model() successfully completed......................................
2024-01-02 10:22:48,435:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:48,435:INFO:Creating metrics dataframe
2024-01-02 10:22:48,446:INFO:Initializing Dummy Classifier
2024-01-02 10:22:48,446:INFO:Total runtime is 1.82462162176768 minutes
2024-01-02 10:22:48,450:INFO:SubProcess create_model() called ==================================
2024-01-02 10:22:48,450:INFO:Initializing create_model()
2024-01-02 10:22:48,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A2260>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:48,450:INFO:Checking exceptions
2024-01-02 10:22:48,451:INFO:Importing libraries
2024-01-02 10:22:48,451:INFO:Copying training dataset
2024-01-02 10:22:48,497:INFO:Defining folds
2024-01-02 10:22:48,498:INFO:Declaring metric variables
2024-01-02 10:22:48,501:INFO:Importing untrained model
2024-01-02 10:22:48,504:INFO:Dummy Classifier Imported successfully
2024-01-02 10:22:48,511:INFO:Starting cross validation
2024-01-02 10:22:48,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:22:49,132:INFO:Calculating mean and std
2024-01-02 10:22:49,136:INFO:Creating metrics dataframe
2024-01-02 10:22:49,149:INFO:Uploading results into container
2024-01-02 10:22:49,152:INFO:Uploading model into container now
2024-01-02 10:22:49,153:INFO:_master_model_container: 14
2024-01-02 10:22:49,154:INFO:_display_container: 2
2024-01-02 10:22:49,154:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-02 10:22:49,155:INFO:create_model() successfully completed......................................
2024-01-02 10:22:49,358:INFO:SubProcess create_model() end ==================================
2024-01-02 10:22:49,358:INFO:Creating metrics dataframe
2024-01-02 10:22:49,378:INFO:Initializing create_model()
2024-01-02 10:22:49,378:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022192C15AE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:22:49,379:INFO:Checking exceptions
2024-01-02 10:22:49,380:INFO:Importing libraries
2024-01-02 10:22:49,380:INFO:Copying training dataset
2024-01-02 10:22:49,427:INFO:Defining folds
2024-01-02 10:22:49,427:INFO:Declaring metric variables
2024-01-02 10:22:49,428:INFO:Importing untrained model
2024-01-02 10:22:49,428:INFO:Declaring custom model
2024-01-02 10:22:49,428:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:22:49,429:INFO:Cross validation set to False
2024-01-02 10:22:49,429:INFO:Fitting Model
2024-01-02 10:22:49,533:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-02 10:22:49,533:INFO:[LightGBM] [Info] Number of positive: 19775, number of negative: 6273
2024-01-02 10:22:49,537:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001293 seconds.
2024-01-02 10:22:49,537:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-02 10:22:49,537:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-02 10:22:49,537:INFO:[LightGBM] [Info] Total Bins 733
2024-01-02 10:22:49,537:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 82
2024-01-02 10:22:49,538:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759175 -> initscore=1.148164
2024-01-02 10:22:49,538:INFO:[LightGBM] [Info] Start training from score 1.148164
2024-01-02 10:22:49,662:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:22:49,663:INFO:create_model() successfully completed......................................
2024-01-02 10:22:49,901:INFO:_master_model_container: 14
2024-01-02 10:22:49,901:INFO:_display_container: 2
2024-01-02 10:22:49,902:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:22:49,902:INFO:compare_models() successfully completed......................................
2024-01-02 10:24:21,152:INFO:PyCaret ClassificationExperiment
2024-01-02 10:24:21,152:INFO:Logging name: clf-default-name
2024-01-02 10:24:21,152:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-02 10:24:21,152:INFO:version 3.1.0
2024-01-02 10:24:21,152:INFO:Initializing setup()
2024-01-02 10:24:21,152:INFO:self.USI: aa7e
2024-01-02 10:24:21,152:INFO:self._variable_keys: {'y_train', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'X_test', 'USI', 'pipeline', 'fix_imbalance', 'X_train', 'logging_param', 'y_test', 'memory', 'data', '_available_plots', 'target_param', 'is_multiclass', 'idx', 'fold_groups_param', 'gpu_param', 'exp_name_log', 'fold_generator', 'y', 'X', '_ml_usecase', 'log_plots_param', 'html_param'}
2024-01-02 10:24:21,152:INFO:Checking environment
2024-01-02 10:24:21,152:INFO:python_version: 3.10.9
2024-01-02 10:24:21,152:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-02 10:24:21,152:INFO:machine: AMD64
2024-01-02 10:24:21,152:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-02 10:24:21,152:INFO:Memory: svmem(total=16954372096, available=1830576128, percent=89.2, used=15123795968, free=1830576128)
2024-01-02 10:24:21,152:INFO:Physical Core: 8
2024-01-02 10:24:21,152:INFO:Logical Core: 16
2024-01-02 10:24:21,152:INFO:Checking libraries
2024-01-02 10:24:21,153:INFO:System:
2024-01-02 10:24:21,153:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-02 10:24:21,153:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-02 10:24:21,153:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-02 10:24:21,153:INFO:PyCaret required dependencies:
2024-01-02 10:24:21,153:INFO:                 pip: 22.3.1
2024-01-02 10:24:21,153:INFO:          setuptools: 65.6.3
2024-01-02 10:24:21,153:INFO:             pycaret: 3.1.0
2024-01-02 10:24:21,153:INFO:             IPython: 8.10.0
2024-01-02 10:24:21,153:INFO:          ipywidgets: 7.6.5
2024-01-02 10:24:21,153:INFO:                tqdm: 4.64.1
2024-01-02 10:24:21,153:INFO:               numpy: 1.23.5
2024-01-02 10:24:21,153:INFO:              pandas: 1.5.3
2024-01-02 10:24:21,153:INFO:              jinja2: 3.1.2
2024-01-02 10:24:21,153:INFO:               scipy: 1.10.1
2024-01-02 10:24:21,153:INFO:              joblib: 1.3.2
2024-01-02 10:24:21,153:INFO:             sklearn: 1.2.1
2024-01-02 10:24:21,153:INFO:                pyod: 1.1.0
2024-01-02 10:24:21,153:INFO:            imblearn: 0.10.1
2024-01-02 10:24:21,153:INFO:   category_encoders: 2.6.2
2024-01-02 10:24:21,153:INFO:            lightgbm: 4.1.0
2024-01-02 10:24:21,153:INFO:               numba: 0.56.4
2024-01-02 10:24:21,153:INFO:            requests: 2.28.1
2024-01-02 10:24:21,153:INFO:          matplotlib: 3.7.0
2024-01-02 10:24:21,154:INFO:          scikitplot: 0.3.7
2024-01-02 10:24:21,154:INFO:         yellowbrick: 1.5
2024-01-02 10:24:21,154:INFO:              plotly: 5.9.0
2024-01-02 10:24:21,154:INFO:    plotly-resampler: Not installed
2024-01-02 10:24:21,154:INFO:             kaleido: 0.2.1
2024-01-02 10:24:21,154:INFO:           schemdraw: 0.15
2024-01-02 10:24:21,154:INFO:         statsmodels: 0.13.5
2024-01-02 10:24:21,154:INFO:              sktime: 0.21.1
2024-01-02 10:24:21,154:INFO:               tbats: 1.1.3
2024-01-02 10:24:21,154:INFO:            pmdarima: 2.0.3
2024-01-02 10:24:21,154:INFO:              psutil: 5.9.0
2024-01-02 10:24:21,154:INFO:          markupsafe: 2.1.1
2024-01-02 10:24:21,154:INFO:             pickle5: Not installed
2024-01-02 10:24:21,154:INFO:         cloudpickle: 2.0.0
2024-01-02 10:24:21,154:INFO:         deprecation: 2.1.0
2024-01-02 10:24:21,154:INFO:              xxhash: 3.4.1
2024-01-02 10:24:21,154:INFO:           wurlitzer: Not installed
2024-01-02 10:24:21,154:INFO:PyCaret optional dependencies:
2024-01-02 10:24:21,154:INFO:                shap: Not installed
2024-01-02 10:24:21,154:INFO:           interpret: Not installed
2024-01-02 10:24:21,154:INFO:                umap: Not installed
2024-01-02 10:24:21,154:INFO:     ydata_profiling: 4.6.0
2024-01-02 10:24:21,154:INFO:  explainerdashboard: Not installed
2024-01-02 10:24:21,154:INFO:             autoviz: Not installed
2024-01-02 10:24:21,154:INFO:           fairlearn: Not installed
2024-01-02 10:24:21,155:INFO:          deepchecks: Not installed
2024-01-02 10:24:21,155:INFO:             xgboost: Not installed
2024-01-02 10:24:21,155:INFO:            catboost: Not installed
2024-01-02 10:24:21,155:INFO:              kmodes: Not installed
2024-01-02 10:24:21,155:INFO:             mlxtend: Not installed
2024-01-02 10:24:21,155:INFO:       statsforecast: Not installed
2024-01-02 10:24:21,155:INFO:        tune_sklearn: Not installed
2024-01-02 10:24:21,155:INFO:                 ray: Not installed
2024-01-02 10:24:21,155:INFO:            hyperopt: Not installed
2024-01-02 10:24:21,155:INFO:              optuna: Not installed
2024-01-02 10:24:21,155:INFO:               skopt: Not installed
2024-01-02 10:24:21,155:INFO:              mlflow: Not installed
2024-01-02 10:24:21,155:INFO:              gradio: Not installed
2024-01-02 10:24:21,155:INFO:             fastapi: Not installed
2024-01-02 10:24:21,155:INFO:             uvicorn: Not installed
2024-01-02 10:24:21,155:INFO:              m2cgen: Not installed
2024-01-02 10:24:21,155:INFO:           evidently: Not installed
2024-01-02 10:24:21,155:INFO:               fugue: Not installed
2024-01-02 10:24:21,155:INFO:           streamlit: Not installed
2024-01-02 10:24:21,155:INFO:             prophet: Not installed
2024-01-02 10:24:21,155:INFO:None
2024-01-02 10:24:21,155:INFO:Set up data.
2024-01-02 10:24:21,191:INFO:Set up folding strategy.
2024-01-02 10:24:21,191:INFO:Set up train/test split.
2024-01-02 10:24:21,221:INFO:Set up index.
2024-01-02 10:24:21,222:INFO:Assigning column types.
2024-01-02 10:24:21,240:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-02 10:24:21,280:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:24:21,281:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:24:21,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,347:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:24:21,348:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:24:21,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,374:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-02 10:24:21,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:24:21,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,478:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:24:21,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,503:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-02 10:24:21,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:21,634:INFO:Preparing preprocessing pipeline...
2024-01-02 10:24:21,637:INFO:Set up simple imputation.
2024-01-02 10:24:21,640:INFO:Set up column name cleaning.
2024-01-02 10:24:21,751:INFO:Finished creating preprocessing pipeline.
2024-01-02 10:24:21,756:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Federal-gov',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Sel...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-02 10:24:21,756:INFO:Creating final display dataframe.
2024-01-02 10:24:22,039:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (32561, 99)
4        Transformed data shape       (32561, 99)
5   Transformed train set shape       (26048, 99)
6    Transformed test set shape        (6513, 99)
7              Numeric features                98
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              aa7e
2024-01-02 10:24:22,110:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:22,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:22,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:22,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:24:22,176:INFO:setup() successfully completed in 1.03s...............
2024-01-02 10:24:22,207:INFO:Initializing compare_models()
2024-01-02 10:24:22,207:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-02 10:24:22,207:INFO:Checking exceptions
2024-01-02 10:24:22,237:INFO:Preparing display monitor
2024-01-02 10:24:22,261:INFO:Initializing Logistic Regression
2024-01-02 10:24:22,261:INFO:Total runtime is 0.0 minutes
2024-01-02 10:24:22,264:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:22,265:INFO:Initializing create_model()
2024-01-02 10:24:22,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:22,265:INFO:Checking exceptions
2024-01-02 10:24:22,265:INFO:Importing libraries
2024-01-02 10:24:22,265:INFO:Copying training dataset
2024-01-02 10:24:22,317:INFO:Defining folds
2024-01-02 10:24:22,318:INFO:Declaring metric variables
2024-01-02 10:24:22,321:INFO:Importing untrained model
2024-01-02 10:24:22,325:INFO:Logistic Regression Imported successfully
2024-01-02 10:24:22,331:INFO:Starting cross validation
2024-01-02 10:24:22,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:30,175:INFO:Calculating mean and std
2024-01-02 10:24:30,176:INFO:Creating metrics dataframe
2024-01-02 10:24:30,179:INFO:Uploading results into container
2024-01-02 10:24:30,180:INFO:Uploading model into container now
2024-01-02 10:24:30,180:INFO:_master_model_container: 1
2024-01-02 10:24:30,181:INFO:_display_container: 2
2024-01-02 10:24:30,181:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-02 10:24:30,181:INFO:create_model() successfully completed......................................
2024-01-02 10:24:30,373:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:30,374:INFO:Creating metrics dataframe
2024-01-02 10:24:30,381:INFO:Initializing K Neighbors Classifier
2024-01-02 10:24:30,381:INFO:Total runtime is 0.1353358546892802 minutes
2024-01-02 10:24:30,384:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:30,385:INFO:Initializing create_model()
2024-01-02 10:24:30,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:30,385:INFO:Checking exceptions
2024-01-02 10:24:30,385:INFO:Importing libraries
2024-01-02 10:24:30,385:INFO:Copying training dataset
2024-01-02 10:24:30,432:INFO:Defining folds
2024-01-02 10:24:30,432:INFO:Declaring metric variables
2024-01-02 10:24:30,436:INFO:Importing untrained model
2024-01-02 10:24:30,439:INFO:K Neighbors Classifier Imported successfully
2024-01-02 10:24:30,445:INFO:Starting cross validation
2024-01-02 10:24:30,447:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:34,141:INFO:Calculating mean and std
2024-01-02 10:24:34,145:INFO:Creating metrics dataframe
2024-01-02 10:24:34,158:INFO:Uploading results into container
2024-01-02 10:24:34,160:INFO:Uploading model into container now
2024-01-02 10:24:34,160:INFO:_master_model_container: 2
2024-01-02 10:24:34,160:INFO:_display_container: 2
2024-01-02 10:24:34,161:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-02 10:24:34,161:INFO:create_model() successfully completed......................................
2024-01-02 10:24:34,336:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:34,336:INFO:Creating metrics dataframe
2024-01-02 10:24:34,345:INFO:Initializing Naive Bayes
2024-01-02 10:24:34,345:INFO:Total runtime is 0.20140462319056193 minutes
2024-01-02 10:24:34,349:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:34,349:INFO:Initializing create_model()
2024-01-02 10:24:34,349:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:34,349:INFO:Checking exceptions
2024-01-02 10:24:34,349:INFO:Importing libraries
2024-01-02 10:24:34,350:INFO:Copying training dataset
2024-01-02 10:24:34,396:INFO:Defining folds
2024-01-02 10:24:34,396:INFO:Declaring metric variables
2024-01-02 10:24:34,400:INFO:Importing untrained model
2024-01-02 10:24:34,403:INFO:Naive Bayes Imported successfully
2024-01-02 10:24:34,410:INFO:Starting cross validation
2024-01-02 10:24:34,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:35,298:INFO:Calculating mean and std
2024-01-02 10:24:35,303:INFO:Creating metrics dataframe
2024-01-02 10:24:35,317:INFO:Uploading results into container
2024-01-02 10:24:35,319:INFO:Uploading model into container now
2024-01-02 10:24:35,320:INFO:_master_model_container: 3
2024-01-02 10:24:35,320:INFO:_display_container: 2
2024-01-02 10:24:35,321:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-02 10:24:35,321:INFO:create_model() successfully completed......................................
2024-01-02 10:24:35,516:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:35,517:INFO:Creating metrics dataframe
2024-01-02 10:24:35,525:INFO:Initializing Decision Tree Classifier
2024-01-02 10:24:35,525:INFO:Total runtime is 0.2210748831431071 minutes
2024-01-02 10:24:35,528:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:35,528:INFO:Initializing create_model()
2024-01-02 10:24:35,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:35,528:INFO:Checking exceptions
2024-01-02 10:24:35,528:INFO:Importing libraries
2024-01-02 10:24:35,528:INFO:Copying training dataset
2024-01-02 10:24:35,573:INFO:Defining folds
2024-01-02 10:24:35,573:INFO:Declaring metric variables
2024-01-02 10:24:35,576:INFO:Importing untrained model
2024-01-02 10:24:35,580:INFO:Decision Tree Classifier Imported successfully
2024-01-02 10:24:35,587:INFO:Starting cross validation
2024-01-02 10:24:35,588:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:36,819:INFO:Calculating mean and std
2024-01-02 10:24:36,823:INFO:Creating metrics dataframe
2024-01-02 10:24:36,836:INFO:Uploading results into container
2024-01-02 10:24:36,838:INFO:Uploading model into container now
2024-01-02 10:24:36,839:INFO:_master_model_container: 4
2024-01-02 10:24:36,839:INFO:_display_container: 2
2024-01-02 10:24:36,840:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-02 10:24:36,841:INFO:create_model() successfully completed......................................
2024-01-02 10:24:37,030:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:37,030:INFO:Creating metrics dataframe
2024-01-02 10:24:37,039:INFO:Initializing SVM - Linear Kernel
2024-01-02 10:24:37,039:INFO:Total runtime is 0.24629817406336468 minutes
2024-01-02 10:24:37,042:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:37,042:INFO:Initializing create_model()
2024-01-02 10:24:37,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:37,043:INFO:Checking exceptions
2024-01-02 10:24:37,043:INFO:Importing libraries
2024-01-02 10:24:37,043:INFO:Copying training dataset
2024-01-02 10:24:37,091:INFO:Defining folds
2024-01-02 10:24:37,091:INFO:Declaring metric variables
2024-01-02 10:24:37,094:INFO:Importing untrained model
2024-01-02 10:24:37,097:INFO:SVM - Linear Kernel Imported successfully
2024-01-02 10:24:37,103:INFO:Starting cross validation
2024-01-02 10:24:37,104:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:38,176:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,218:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,263:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,282:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,291:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,298:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,321:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,326:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,345:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,362:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:24:38,483:INFO:Calculating mean and std
2024-01-02 10:24:38,487:INFO:Creating metrics dataframe
2024-01-02 10:24:38,500:INFO:Uploading results into container
2024-01-02 10:24:38,502:INFO:Uploading model into container now
2024-01-02 10:24:38,503:INFO:_master_model_container: 5
2024-01-02 10:24:38,504:INFO:_display_container: 2
2024-01-02 10:24:38,505:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-02 10:24:38,505:INFO:create_model() successfully completed......................................
2024-01-02 10:24:38,680:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:38,680:INFO:Creating metrics dataframe
2024-01-02 10:24:38,692:INFO:Initializing Ridge Classifier
2024-01-02 10:24:38,692:INFO:Total runtime is 0.27385164896647135 minutes
2024-01-02 10:24:38,695:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:38,696:INFO:Initializing create_model()
2024-01-02 10:24:38,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:38,696:INFO:Checking exceptions
2024-01-02 10:24:38,696:INFO:Importing libraries
2024-01-02 10:24:38,696:INFO:Copying training dataset
2024-01-02 10:24:38,747:INFO:Defining folds
2024-01-02 10:24:38,747:INFO:Declaring metric variables
2024-01-02 10:24:38,750:INFO:Importing untrained model
2024-01-02 10:24:38,754:INFO:Ridge Classifier Imported successfully
2024-01-02 10:24:38,761:INFO:Starting cross validation
2024-01-02 10:24:38,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:39,370:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,375:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,407:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,426:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,431:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,436:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,463:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,478:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,486:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,490:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:24:39,618:INFO:Calculating mean and std
2024-01-02 10:24:39,622:INFO:Creating metrics dataframe
2024-01-02 10:24:39,636:INFO:Uploading results into container
2024-01-02 10:24:39,639:INFO:Uploading model into container now
2024-01-02 10:24:39,640:INFO:_master_model_container: 6
2024-01-02 10:24:39,641:INFO:_display_container: 2
2024-01-02 10:24:39,642:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-02 10:24:39,642:INFO:create_model() successfully completed......................................
2024-01-02 10:24:39,841:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:39,841:INFO:Creating metrics dataframe
2024-01-02 10:24:39,851:INFO:Initializing Random Forest Classifier
2024-01-02 10:24:39,851:INFO:Total runtime is 0.2931744694709778 minutes
2024-01-02 10:24:39,855:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:39,855:INFO:Initializing create_model()
2024-01-02 10:24:39,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:39,855:INFO:Checking exceptions
2024-01-02 10:24:39,855:INFO:Importing libraries
2024-01-02 10:24:39,855:INFO:Copying training dataset
2024-01-02 10:24:39,903:INFO:Defining folds
2024-01-02 10:24:39,903:INFO:Declaring metric variables
2024-01-02 10:24:39,906:INFO:Importing untrained model
2024-01-02 10:24:39,910:INFO:Random Forest Classifier Imported successfully
2024-01-02 10:24:39,915:INFO:Starting cross validation
2024-01-02 10:24:39,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:48,215:INFO:Calculating mean and std
2024-01-02 10:24:48,216:INFO:Creating metrics dataframe
2024-01-02 10:24:48,220:INFO:Uploading results into container
2024-01-02 10:24:48,221:INFO:Uploading model into container now
2024-01-02 10:24:48,222:INFO:_master_model_container: 7
2024-01-02 10:24:48,222:INFO:_display_container: 2
2024-01-02 10:24:48,223:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-02 10:24:48,223:INFO:create_model() successfully completed......................................
2024-01-02 10:24:48,462:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:48,463:INFO:Creating metrics dataframe
2024-01-02 10:24:48,472:INFO:Initializing Quadratic Discriminant Analysis
2024-01-02 10:24:48,473:INFO:Total runtime is 0.4368690808614095 minutes
2024-01-02 10:24:48,475:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:48,476:INFO:Initializing create_model()
2024-01-02 10:24:48,476:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:48,476:INFO:Checking exceptions
2024-01-02 10:24:48,476:INFO:Importing libraries
2024-01-02 10:24:48,476:INFO:Copying training dataset
2024-01-02 10:24:48,522:INFO:Defining folds
2024-01-02 10:24:48,522:INFO:Declaring metric variables
2024-01-02 10:24:48,526:INFO:Importing untrained model
2024-01-02 10:24:48,531:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-02 10:24:48,538:INFO:Starting cross validation
2024-01-02 10:24:48,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:49,136:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,168:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,169:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,196:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,207:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,210:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,242:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,248:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,256:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:49,268:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:24:50,749:INFO:Calculating mean and std
2024-01-02 10:24:50,752:INFO:Creating metrics dataframe
2024-01-02 10:24:50,761:INFO:Uploading results into container
2024-01-02 10:24:50,763:INFO:Uploading model into container now
2024-01-02 10:24:50,763:INFO:_master_model_container: 8
2024-01-02 10:24:50,764:INFO:_display_container: 2
2024-01-02 10:24:50,764:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-02 10:24:50,764:INFO:create_model() successfully completed......................................
2024-01-02 10:24:51,099:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:51,099:INFO:Creating metrics dataframe
2024-01-02 10:24:51,112:INFO:Initializing Ada Boost Classifier
2024-01-02 10:24:51,112:INFO:Total runtime is 0.48085913658142093 minutes
2024-01-02 10:24:51,115:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:51,116:INFO:Initializing create_model()
2024-01-02 10:24:51,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:51,116:INFO:Checking exceptions
2024-01-02 10:24:51,116:INFO:Importing libraries
2024-01-02 10:24:51,116:INFO:Copying training dataset
2024-01-02 10:24:51,168:INFO:Defining folds
2024-01-02 10:24:51,168:INFO:Declaring metric variables
2024-01-02 10:24:51,172:INFO:Importing untrained model
2024-01-02 10:24:51,176:INFO:Ada Boost Classifier Imported successfully
2024-01-02 10:24:51,184:INFO:Starting cross validation
2024-01-02 10:24:51,185:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:24:54,383:INFO:Calculating mean and std
2024-01-02 10:24:54,387:INFO:Creating metrics dataframe
2024-01-02 10:24:54,399:INFO:Uploading results into container
2024-01-02 10:24:54,403:INFO:Uploading model into container now
2024-01-02 10:24:54,405:INFO:_master_model_container: 9
2024-01-02 10:24:54,405:INFO:_display_container: 2
2024-01-02 10:24:54,406:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-02 10:24:54,407:INFO:create_model() successfully completed......................................
2024-01-02 10:24:54,611:INFO:SubProcess create_model() end ==================================
2024-01-02 10:24:54,612:INFO:Creating metrics dataframe
2024-01-02 10:24:54,622:INFO:Initializing Gradient Boosting Classifier
2024-01-02 10:24:54,622:INFO:Total runtime is 0.5393540819485982 minutes
2024-01-02 10:24:54,625:INFO:SubProcess create_model() called ==================================
2024-01-02 10:24:54,625:INFO:Initializing create_model()
2024-01-02 10:24:54,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:24:54,625:INFO:Checking exceptions
2024-01-02 10:24:54,625:INFO:Importing libraries
2024-01-02 10:24:54,625:INFO:Copying training dataset
2024-01-02 10:24:54,673:INFO:Defining folds
2024-01-02 10:24:54,673:INFO:Declaring metric variables
2024-01-02 10:24:54,676:INFO:Importing untrained model
2024-01-02 10:24:54,680:INFO:Gradient Boosting Classifier Imported successfully
2024-01-02 10:24:54,686:INFO:Starting cross validation
2024-01-02 10:24:54,688:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:25:03,811:INFO:Calculating mean and std
2024-01-02 10:25:03,812:INFO:Creating metrics dataframe
2024-01-02 10:25:03,815:INFO:Uploading results into container
2024-01-02 10:25:03,816:INFO:Uploading model into container now
2024-01-02 10:25:03,816:INFO:_master_model_container: 10
2024-01-02 10:25:03,816:INFO:_display_container: 2
2024-01-02 10:25:03,817:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-02 10:25:03,817:INFO:create_model() successfully completed......................................
2024-01-02 10:25:04,012:INFO:SubProcess create_model() end ==================================
2024-01-02 10:25:04,012:INFO:Creating metrics dataframe
2024-01-02 10:25:04,023:INFO:Initializing Linear Discriminant Analysis
2024-01-02 10:25:04,023:INFO:Total runtime is 0.69603031873703 minutes
2024-01-02 10:25:04,026:INFO:SubProcess create_model() called ==================================
2024-01-02 10:25:04,026:INFO:Initializing create_model()
2024-01-02 10:25:04,026:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:25:04,026:INFO:Checking exceptions
2024-01-02 10:25:04,027:INFO:Importing libraries
2024-01-02 10:25:04,027:INFO:Copying training dataset
2024-01-02 10:25:04,072:INFO:Defining folds
2024-01-02 10:25:04,073:INFO:Declaring metric variables
2024-01-02 10:25:04,076:INFO:Importing untrained model
2024-01-02 10:25:04,080:INFO:Linear Discriminant Analysis Imported successfully
2024-01-02 10:25:04,087:INFO:Starting cross validation
2024-01-02 10:25:04,088:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:25:09,999:INFO:Calculating mean and std
2024-01-02 10:25:10,000:INFO:Creating metrics dataframe
2024-01-02 10:25:10,004:INFO:Uploading results into container
2024-01-02 10:25:10,004:INFO:Uploading model into container now
2024-01-02 10:25:10,005:INFO:_master_model_container: 11
2024-01-02 10:25:10,005:INFO:_display_container: 2
2024-01-02 10:25:10,005:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-02 10:25:10,006:INFO:create_model() successfully completed......................................
2024-01-02 10:25:10,224:INFO:SubProcess create_model() end ==================================
2024-01-02 10:25:10,224:INFO:Creating metrics dataframe
2024-01-02 10:25:10,236:INFO:Initializing Extra Trees Classifier
2024-01-02 10:25:10,236:INFO:Total runtime is 0.7995835979779562 minutes
2024-01-02 10:25:10,239:INFO:SubProcess create_model() called ==================================
2024-01-02 10:25:10,240:INFO:Initializing create_model()
2024-01-02 10:25:10,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:25:10,240:INFO:Checking exceptions
2024-01-02 10:25:10,240:INFO:Importing libraries
2024-01-02 10:25:10,240:INFO:Copying training dataset
2024-01-02 10:25:10,288:INFO:Defining folds
2024-01-02 10:25:10,288:INFO:Declaring metric variables
2024-01-02 10:25:10,292:INFO:Importing untrained model
2024-01-02 10:25:10,297:INFO:Extra Trees Classifier Imported successfully
2024-01-02 10:25:10,305:INFO:Starting cross validation
2024-01-02 10:25:10,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:25:23,262:INFO:Calculating mean and std
2024-01-02 10:25:23,264:INFO:Creating metrics dataframe
2024-01-02 10:25:23,269:INFO:Uploading results into container
2024-01-02 10:25:23,270:INFO:Uploading model into container now
2024-01-02 10:25:23,271:INFO:_master_model_container: 12
2024-01-02 10:25:23,271:INFO:_display_container: 2
2024-01-02 10:25:23,272:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-02 10:25:23,272:INFO:create_model() successfully completed......................................
2024-01-02 10:25:23,557:INFO:SubProcess create_model() end ==================================
2024-01-02 10:25:23,557:INFO:Creating metrics dataframe
2024-01-02 10:25:23,574:INFO:Initializing Light Gradient Boosting Machine
2024-01-02 10:25:23,574:INFO:Total runtime is 1.0218912680943808 minutes
2024-01-02 10:25:23,579:INFO:SubProcess create_model() called ==================================
2024-01-02 10:25:23,579:INFO:Initializing create_model()
2024-01-02 10:25:23,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:25:23,580:INFO:Checking exceptions
2024-01-02 10:25:23,580:INFO:Importing libraries
2024-01-02 10:25:23,580:INFO:Copying training dataset
2024-01-02 10:25:23,640:INFO:Defining folds
2024-01-02 10:25:23,640:INFO:Declaring metric variables
2024-01-02 10:25:23,647:INFO:Importing untrained model
2024-01-02 10:25:23,654:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:25:23,664:INFO:Starting cross validation
2024-01-02 10:25:23,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:25:26,841:INFO:Calculating mean and std
2024-01-02 10:25:26,843:INFO:Creating metrics dataframe
2024-01-02 10:25:26,853:INFO:Uploading results into container
2024-01-02 10:25:26,855:INFO:Uploading model into container now
2024-01-02 10:25:26,855:INFO:_master_model_container: 13
2024-01-02 10:25:26,856:INFO:_display_container: 2
2024-01-02 10:25:26,857:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:25:26,857:INFO:create_model() successfully completed......................................
2024-01-02 10:25:27,396:INFO:SubProcess create_model() end ==================================
2024-01-02 10:25:27,396:INFO:Creating metrics dataframe
2024-01-02 10:25:27,412:INFO:Initializing Dummy Classifier
2024-01-02 10:25:27,412:INFO:Total runtime is 1.0858567674954733 minutes
2024-01-02 10:25:27,417:INFO:SubProcess create_model() called ==================================
2024-01-02 10:25:27,417:INFO:Initializing create_model()
2024-01-02 10:25:27,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000221975A0760>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:25:27,418:INFO:Checking exceptions
2024-01-02 10:25:27,418:INFO:Importing libraries
2024-01-02 10:25:27,418:INFO:Copying training dataset
2024-01-02 10:25:27,475:INFO:Defining folds
2024-01-02 10:25:27,476:INFO:Declaring metric variables
2024-01-02 10:25:27,480:INFO:Importing untrained model
2024-01-02 10:25:27,486:INFO:Dummy Classifier Imported successfully
2024-01-02 10:25:27,495:INFO:Starting cross validation
2024-01-02 10:25:27,498:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:25:28,215:INFO:Calculating mean and std
2024-01-02 10:25:28,217:INFO:Creating metrics dataframe
2024-01-02 10:25:28,222:INFO:Uploading results into container
2024-01-02 10:25:28,223:INFO:Uploading model into container now
2024-01-02 10:25:28,223:INFO:_master_model_container: 14
2024-01-02 10:25:28,223:INFO:_display_container: 2
2024-01-02 10:25:28,224:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-02 10:25:28,224:INFO:create_model() successfully completed......................................
2024-01-02 10:25:28,609:INFO:SubProcess create_model() end ==================================
2024-01-02 10:25:28,609:INFO:Creating metrics dataframe
2024-01-02 10:25:28,634:INFO:Initializing create_model()
2024-01-02 10:25:28,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022189431990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:25:28,635:INFO:Checking exceptions
2024-01-02 10:25:28,638:INFO:Importing libraries
2024-01-02 10:25:28,638:INFO:Copying training dataset
2024-01-02 10:25:28,693:INFO:Defining folds
2024-01-02 10:25:28,694:INFO:Declaring metric variables
2024-01-02 10:25:28,694:INFO:Importing untrained model
2024-01-02 10:25:28,694:INFO:Declaring custom model
2024-01-02 10:25:28,694:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:25:28,696:INFO:Cross validation set to False
2024-01-02 10:25:28,696:INFO:Fitting Model
2024-01-02 10:25:28,819:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-02 10:25:28,820:INFO:[LightGBM] [Info] Number of positive: 19775, number of negative: 6273
2024-01-02 10:25:28,825:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001487 seconds.
2024-01-02 10:25:28,825:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-02 10:25:28,825:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-02 10:25:28,825:INFO:[LightGBM] [Info] Total Bins 729
2024-01-02 10:25:28,825:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 82
2024-01-02 10:25:28,826:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759175 -> initscore=1.148164
2024-01-02 10:25:28,826:INFO:[LightGBM] [Info] Start training from score 1.148164
2024-01-02 10:25:28,994:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:25:28,994:INFO:create_model() successfully completed......................................
2024-01-02 10:25:29,375:INFO:_master_model_container: 14
2024-01-02 10:25:29,375:INFO:_display_container: 2
2024-01-02 10:25:29,376:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:25:29,376:INFO:compare_models() successfully completed......................................
2024-01-02 10:26:34,644:INFO:PyCaret ClassificationExperiment
2024-01-02 10:26:34,644:INFO:Logging name: clf-default-name
2024-01-02 10:26:34,644:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-02 10:26:34,644:INFO:version 3.1.0
2024-01-02 10:26:34,644:INFO:Initializing setup()
2024-01-02 10:26:34,644:INFO:self.USI: fcda
2024-01-02 10:26:34,644:INFO:self._variable_keys: {'y_train', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'X_test', 'USI', 'pipeline', 'fix_imbalance', 'X_train', 'logging_param', 'y_test', 'memory', 'data', '_available_plots', 'target_param', 'is_multiclass', 'idx', 'fold_groups_param', 'gpu_param', 'exp_name_log', 'fold_generator', 'y', 'X', '_ml_usecase', 'log_plots_param', 'html_param'}
2024-01-02 10:26:34,644:INFO:Checking environment
2024-01-02 10:26:34,644:INFO:python_version: 3.10.9
2024-01-02 10:26:34,644:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-02 10:26:34,644:INFO:machine: AMD64
2024-01-02 10:26:34,644:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-02 10:26:34,644:INFO:Memory: svmem(total=16954372096, available=1887592448, percent=88.9, used=15066779648, free=1887592448)
2024-01-02 10:26:34,644:INFO:Physical Core: 8
2024-01-02 10:26:34,644:INFO:Logical Core: 16
2024-01-02 10:26:34,644:INFO:Checking libraries
2024-01-02 10:26:34,644:INFO:System:
2024-01-02 10:26:34,645:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-02 10:26:34,645:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-02 10:26:34,645:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-02 10:26:34,645:INFO:PyCaret required dependencies:
2024-01-02 10:26:34,645:INFO:                 pip: 22.3.1
2024-01-02 10:26:34,645:INFO:          setuptools: 65.6.3
2024-01-02 10:26:34,645:INFO:             pycaret: 3.1.0
2024-01-02 10:26:34,645:INFO:             IPython: 8.10.0
2024-01-02 10:26:34,645:INFO:          ipywidgets: 7.6.5
2024-01-02 10:26:34,645:INFO:                tqdm: 4.64.1
2024-01-02 10:26:34,645:INFO:               numpy: 1.23.5
2024-01-02 10:26:34,645:INFO:              pandas: 1.5.3
2024-01-02 10:26:34,645:INFO:              jinja2: 3.1.2
2024-01-02 10:26:34,645:INFO:               scipy: 1.10.1
2024-01-02 10:26:34,645:INFO:              joblib: 1.3.2
2024-01-02 10:26:34,645:INFO:             sklearn: 1.2.1
2024-01-02 10:26:34,645:INFO:                pyod: 1.1.0
2024-01-02 10:26:34,645:INFO:            imblearn: 0.10.1
2024-01-02 10:26:34,645:INFO:   category_encoders: 2.6.2
2024-01-02 10:26:34,645:INFO:            lightgbm: 4.1.0
2024-01-02 10:26:34,645:INFO:               numba: 0.56.4
2024-01-02 10:26:34,646:INFO:            requests: 2.28.1
2024-01-02 10:26:34,646:INFO:          matplotlib: 3.7.0
2024-01-02 10:26:34,646:INFO:          scikitplot: 0.3.7
2024-01-02 10:26:34,646:INFO:         yellowbrick: 1.5
2024-01-02 10:26:34,646:INFO:              plotly: 5.9.0
2024-01-02 10:26:34,646:INFO:    plotly-resampler: Not installed
2024-01-02 10:26:34,646:INFO:             kaleido: 0.2.1
2024-01-02 10:26:34,646:INFO:           schemdraw: 0.15
2024-01-02 10:26:34,646:INFO:         statsmodels: 0.13.5
2024-01-02 10:26:34,646:INFO:              sktime: 0.21.1
2024-01-02 10:26:34,646:INFO:               tbats: 1.1.3
2024-01-02 10:26:34,646:INFO:            pmdarima: 2.0.3
2024-01-02 10:26:34,646:INFO:              psutil: 5.9.0
2024-01-02 10:26:34,646:INFO:          markupsafe: 2.1.1
2024-01-02 10:26:34,646:INFO:             pickle5: Not installed
2024-01-02 10:26:34,646:INFO:         cloudpickle: 2.0.0
2024-01-02 10:26:34,646:INFO:         deprecation: 2.1.0
2024-01-02 10:26:34,646:INFO:              xxhash: 3.4.1
2024-01-02 10:26:34,646:INFO:           wurlitzer: Not installed
2024-01-02 10:26:34,646:INFO:PyCaret optional dependencies:
2024-01-02 10:26:34,646:INFO:                shap: Not installed
2024-01-02 10:26:34,646:INFO:           interpret: Not installed
2024-01-02 10:26:34,646:INFO:                umap: Not installed
2024-01-02 10:26:34,646:INFO:     ydata_profiling: 4.6.0
2024-01-02 10:26:34,647:INFO:  explainerdashboard: Not installed
2024-01-02 10:26:34,647:INFO:             autoviz: Not installed
2024-01-02 10:26:34,647:INFO:           fairlearn: Not installed
2024-01-02 10:26:34,647:INFO:          deepchecks: Not installed
2024-01-02 10:26:34,647:INFO:             xgboost: Not installed
2024-01-02 10:26:34,647:INFO:            catboost: Not installed
2024-01-02 10:26:34,647:INFO:              kmodes: Not installed
2024-01-02 10:26:34,647:INFO:             mlxtend: Not installed
2024-01-02 10:26:34,647:INFO:       statsforecast: Not installed
2024-01-02 10:26:34,647:INFO:        tune_sklearn: Not installed
2024-01-02 10:26:34,647:INFO:                 ray: Not installed
2024-01-02 10:26:34,647:INFO:            hyperopt: Not installed
2024-01-02 10:26:34,647:INFO:              optuna: Not installed
2024-01-02 10:26:34,647:INFO:               skopt: Not installed
2024-01-02 10:26:34,647:INFO:              mlflow: Not installed
2024-01-02 10:26:34,647:INFO:              gradio: Not installed
2024-01-02 10:26:34,647:INFO:             fastapi: Not installed
2024-01-02 10:26:34,647:INFO:             uvicorn: Not installed
2024-01-02 10:26:34,647:INFO:              m2cgen: Not installed
2024-01-02 10:26:34,647:INFO:           evidently: Not installed
2024-01-02 10:26:34,647:INFO:               fugue: Not installed
2024-01-02 10:26:34,647:INFO:           streamlit: Not installed
2024-01-02 10:26:34,647:INFO:             prophet: Not installed
2024-01-02 10:26:34,648:INFO:None
2024-01-02 10:26:34,648:INFO:Set up data.
2024-01-02 10:26:34,684:INFO:Set up folding strategy.
2024-01-02 10:26:34,684:INFO:Set up train/test split.
2024-01-02 10:26:34,719:INFO:Set up index.
2024-01-02 10:26:34,721:INFO:Assigning column types.
2024-01-02 10:26:34,743:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-02 10:26:34,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:26:34,788:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:26:34,815:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:34,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:34,858:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:26:34,858:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:26:34,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:34,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:34,885:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-02 10:26:34,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:26:34,953:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:34,953:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:34,995:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:26:35,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,022:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-02 10:26:35,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,158:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,158:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,159:INFO:Preparing preprocessing pipeline...
2024-01-02 10:26:35,162:INFO:Set up simple imputation.
2024-01-02 10:26:35,165:INFO:Set up column name cleaning.
2024-01-02 10:26:35,268:INFO:Finished creating preprocessing pipeline.
2024-01-02 10:26:35,273:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Federal-gov',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Sel...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-02 10:26:35,274:INFO:Creating final display dataframe.
2024-01-02 10:26:35,568:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (32561, 99)
4        Transformed data shape       (32561, 99)
5   Transformed train set shape       (26048, 99)
6    Transformed test set shape        (6513, 99)
7              Numeric features                98
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              fcda
2024-01-02 10:26:35,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:26:35,710:INFO:setup() successfully completed in 1.07s...............
2024-01-02 10:26:35,737:INFO:Initializing compare_models()
2024-01-02 10:26:35,737:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-02 10:26:35,738:INFO:Checking exceptions
2024-01-02 10:26:35,768:INFO:Preparing display monitor
2024-01-02 10:26:35,796:INFO:Initializing Logistic Regression
2024-01-02 10:26:35,796:INFO:Total runtime is 0.0 minutes
2024-01-02 10:26:35,800:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:35,800:INFO:Initializing create_model()
2024-01-02 10:26:35,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:35,800:INFO:Checking exceptions
2024-01-02 10:26:35,801:INFO:Importing libraries
2024-01-02 10:26:35,801:INFO:Copying training dataset
2024-01-02 10:26:35,855:INFO:Defining folds
2024-01-02 10:26:35,855:INFO:Declaring metric variables
2024-01-02 10:26:35,859:INFO:Importing untrained model
2024-01-02 10:26:35,863:INFO:Logistic Regression Imported successfully
2024-01-02 10:26:35,871:INFO:Starting cross validation
2024-01-02 10:26:35,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:26:44,977:INFO:Calculating mean and std
2024-01-02 10:26:44,978:INFO:Creating metrics dataframe
2024-01-02 10:26:44,981:INFO:Uploading results into container
2024-01-02 10:26:44,982:INFO:Uploading model into container now
2024-01-02 10:26:44,983:INFO:_master_model_container: 1
2024-01-02 10:26:44,984:INFO:_display_container: 2
2024-01-02 10:26:44,984:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-02 10:26:44,984:INFO:create_model() successfully completed......................................
2024-01-02 10:26:45,180:INFO:SubProcess create_model() end ==================================
2024-01-02 10:26:45,180:INFO:Creating metrics dataframe
2024-01-02 10:26:45,188:INFO:Initializing K Neighbors Classifier
2024-01-02 10:26:45,188:INFO:Total runtime is 0.15654095808664958 minutes
2024-01-02 10:26:45,191:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:45,191:INFO:Initializing create_model()
2024-01-02 10:26:45,191:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:45,191:INFO:Checking exceptions
2024-01-02 10:26:45,191:INFO:Importing libraries
2024-01-02 10:26:45,192:INFO:Copying training dataset
2024-01-02 10:26:45,241:INFO:Defining folds
2024-01-02 10:26:45,241:INFO:Declaring metric variables
2024-01-02 10:26:45,245:INFO:Importing untrained model
2024-01-02 10:26:45,249:INFO:K Neighbors Classifier Imported successfully
2024-01-02 10:26:45,255:INFO:Starting cross validation
2024-01-02 10:26:45,256:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:26:48,572:INFO:Calculating mean and std
2024-01-02 10:26:48,573:INFO:Creating metrics dataframe
2024-01-02 10:26:48,576:INFO:Uploading results into container
2024-01-02 10:26:48,577:INFO:Uploading model into container now
2024-01-02 10:26:48,577:INFO:_master_model_container: 2
2024-01-02 10:26:48,577:INFO:_display_container: 2
2024-01-02 10:26:48,578:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-02 10:26:48,578:INFO:create_model() successfully completed......................................
2024-01-02 10:26:48,766:INFO:SubProcess create_model() end ==================================
2024-01-02 10:26:48,766:INFO:Creating metrics dataframe
2024-01-02 10:26:48,775:INFO:Initializing Naive Bayes
2024-01-02 10:26:48,775:INFO:Total runtime is 0.21630948384602866 minutes
2024-01-02 10:26:48,778:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:48,778:INFO:Initializing create_model()
2024-01-02 10:26:48,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:48,778:INFO:Checking exceptions
2024-01-02 10:26:48,779:INFO:Importing libraries
2024-01-02 10:26:48,779:INFO:Copying training dataset
2024-01-02 10:26:48,828:INFO:Defining folds
2024-01-02 10:26:48,828:INFO:Declaring metric variables
2024-01-02 10:26:48,831:INFO:Importing untrained model
2024-01-02 10:26:48,834:INFO:Naive Bayes Imported successfully
2024-01-02 10:26:48,841:INFO:Starting cross validation
2024-01-02 10:26:48,842:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:26:49,751:INFO:Calculating mean and std
2024-01-02 10:26:49,755:INFO:Creating metrics dataframe
2024-01-02 10:26:49,768:INFO:Uploading results into container
2024-01-02 10:26:49,770:INFO:Uploading model into container now
2024-01-02 10:26:49,771:INFO:_master_model_container: 3
2024-01-02 10:26:49,771:INFO:_display_container: 2
2024-01-02 10:26:49,772:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-02 10:26:49,772:INFO:create_model() successfully completed......................................
2024-01-02 10:26:50,003:INFO:SubProcess create_model() end ==================================
2024-01-02 10:26:50,003:INFO:Creating metrics dataframe
2024-01-02 10:26:50,015:INFO:Initializing Decision Tree Classifier
2024-01-02 10:26:50,015:INFO:Total runtime is 0.2369808594385783 minutes
2024-01-02 10:26:50,018:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:50,018:INFO:Initializing create_model()
2024-01-02 10:26:50,018:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:50,018:INFO:Checking exceptions
2024-01-02 10:26:50,019:INFO:Importing libraries
2024-01-02 10:26:50,019:INFO:Copying training dataset
2024-01-02 10:26:50,068:INFO:Defining folds
2024-01-02 10:26:50,068:INFO:Declaring metric variables
2024-01-02 10:26:50,071:INFO:Importing untrained model
2024-01-02 10:26:50,075:INFO:Decision Tree Classifier Imported successfully
2024-01-02 10:26:50,082:INFO:Starting cross validation
2024-01-02 10:26:50,083:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:26:51,417:INFO:Calculating mean and std
2024-01-02 10:26:51,421:INFO:Creating metrics dataframe
2024-01-02 10:26:51,434:INFO:Uploading results into container
2024-01-02 10:26:51,437:INFO:Uploading model into container now
2024-01-02 10:26:51,438:INFO:_master_model_container: 4
2024-01-02 10:26:51,439:INFO:_display_container: 2
2024-01-02 10:26:51,440:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-02 10:26:51,440:INFO:create_model() successfully completed......................................
2024-01-02 10:26:51,635:INFO:SubProcess create_model() end ==================================
2024-01-02 10:26:51,635:INFO:Creating metrics dataframe
2024-01-02 10:26:51,647:INFO:Initializing SVM - Linear Kernel
2024-01-02 10:26:51,647:INFO:Total runtime is 0.26418119271596274 minutes
2024-01-02 10:26:51,650:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:51,650:INFO:Initializing create_model()
2024-01-02 10:26:51,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:51,650:INFO:Checking exceptions
2024-01-02 10:26:51,651:INFO:Importing libraries
2024-01-02 10:26:51,651:INFO:Copying training dataset
2024-01-02 10:26:51,700:INFO:Defining folds
2024-01-02 10:26:51,700:INFO:Declaring metric variables
2024-01-02 10:26:51,704:INFO:Importing untrained model
2024-01-02 10:26:51,707:INFO:SVM - Linear Kernel Imported successfully
2024-01-02 10:26:51,713:INFO:Starting cross validation
2024-01-02 10:26:51,715:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:26:53,014:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,033:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,075:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,080:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,085:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,140:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,167:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,173:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,187:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,203:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:26:53,329:INFO:Calculating mean and std
2024-01-02 10:26:53,333:INFO:Creating metrics dataframe
2024-01-02 10:26:53,347:INFO:Uploading results into container
2024-01-02 10:26:53,350:INFO:Uploading model into container now
2024-01-02 10:26:53,352:INFO:_master_model_container: 5
2024-01-02 10:26:53,353:INFO:_display_container: 2
2024-01-02 10:26:53,355:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-02 10:26:53,355:INFO:create_model() successfully completed......................................
2024-01-02 10:26:53,595:INFO:SubProcess create_model() end ==================================
2024-01-02 10:26:53,596:INFO:Creating metrics dataframe
2024-01-02 10:26:53,605:INFO:Initializing Ridge Classifier
2024-01-02 10:26:53,605:INFO:Total runtime is 0.29682385524113974 minutes
2024-01-02 10:26:53,609:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:53,609:INFO:Initializing create_model()
2024-01-02 10:26:53,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:53,609:INFO:Checking exceptions
2024-01-02 10:26:53,609:INFO:Importing libraries
2024-01-02 10:26:53,609:INFO:Copying training dataset
2024-01-02 10:26:53,660:INFO:Defining folds
2024-01-02 10:26:53,660:INFO:Declaring metric variables
2024-01-02 10:26:53,663:INFO:Importing untrained model
2024-01-02 10:26:53,667:INFO:Ridge Classifier Imported successfully
2024-01-02 10:26:53,674:INFO:Starting cross validation
2024-01-02 10:26:53,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:26:54,303:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,308:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,327:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,332:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,338:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,357:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,362:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,364:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,365:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,367:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:26:54,505:INFO:Calculating mean and std
2024-01-02 10:26:54,506:INFO:Creating metrics dataframe
2024-01-02 10:26:54,512:INFO:Uploading results into container
2024-01-02 10:26:54,512:INFO:Uploading model into container now
2024-01-02 10:26:54,513:INFO:_master_model_container: 6
2024-01-02 10:26:54,513:INFO:_display_container: 2
2024-01-02 10:26:54,514:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-02 10:26:54,514:INFO:create_model() successfully completed......................................
2024-01-02 10:26:54,720:INFO:SubProcess create_model() end ==================================
2024-01-02 10:26:54,720:INFO:Creating metrics dataframe
2024-01-02 10:26:54,730:INFO:Initializing Random Forest Classifier
2024-01-02 10:26:54,730:INFO:Total runtime is 0.31557313998540243 minutes
2024-01-02 10:26:54,733:INFO:SubProcess create_model() called ==================================
2024-01-02 10:26:54,733:INFO:Initializing create_model()
2024-01-02 10:26:54,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:26:54,733:INFO:Checking exceptions
2024-01-02 10:26:54,733:INFO:Importing libraries
2024-01-02 10:26:54,734:INFO:Copying training dataset
2024-01-02 10:26:54,798:INFO:Defining folds
2024-01-02 10:26:54,798:INFO:Declaring metric variables
2024-01-02 10:26:54,805:INFO:Importing untrained model
2024-01-02 10:26:54,812:INFO:Random Forest Classifier Imported successfully
2024-01-02 10:26:54,824:INFO:Starting cross validation
2024-01-02 10:26:54,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:03,999:INFO:Calculating mean and std
2024-01-02 10:27:04,000:INFO:Creating metrics dataframe
2024-01-02 10:27:04,006:INFO:Uploading results into container
2024-01-02 10:27:04,007:INFO:Uploading model into container now
2024-01-02 10:27:04,008:INFO:_master_model_container: 7
2024-01-02 10:27:04,008:INFO:_display_container: 2
2024-01-02 10:27:04,008:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-02 10:27:04,008:INFO:create_model() successfully completed......................................
2024-01-02 10:27:04,241:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:04,241:INFO:Creating metrics dataframe
2024-01-02 10:27:04,253:INFO:Initializing Quadratic Discriminant Analysis
2024-01-02 10:27:04,253:INFO:Total runtime is 0.4742789030075073 minutes
2024-01-02 10:27:04,257:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:04,258:INFO:Initializing create_model()
2024-01-02 10:27:04,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:04,258:INFO:Checking exceptions
2024-01-02 10:27:04,258:INFO:Importing libraries
2024-01-02 10:27:04,258:INFO:Copying training dataset
2024-01-02 10:27:04,313:INFO:Defining folds
2024-01-02 10:27:04,313:INFO:Declaring metric variables
2024-01-02 10:27:04,317:INFO:Importing untrained model
2024-01-02 10:27:04,321:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-02 10:27:04,327:INFO:Starting cross validation
2024-01-02 10:27:04,329:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:04,904:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:04,963:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:04,967:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:04,974:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:05,008:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:05,046:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:05,056:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:05,067:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:05,103:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:27:06,518:INFO:Calculating mean and std
2024-01-02 10:27:06,520:INFO:Creating metrics dataframe
2024-01-02 10:27:06,524:INFO:Uploading results into container
2024-01-02 10:27:06,525:INFO:Uploading model into container now
2024-01-02 10:27:06,526:INFO:_master_model_container: 8
2024-01-02 10:27:06,526:INFO:_display_container: 2
2024-01-02 10:27:06,526:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-02 10:27:06,526:INFO:create_model() successfully completed......................................
2024-01-02 10:27:06,819:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:06,819:INFO:Creating metrics dataframe
2024-01-02 10:27:06,833:INFO:Initializing Ada Boost Classifier
2024-01-02 10:27:06,833:INFO:Total runtime is 0.517289646466573 minutes
2024-01-02 10:27:06,837:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:06,838:INFO:Initializing create_model()
2024-01-02 10:27:06,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:06,838:INFO:Checking exceptions
2024-01-02 10:27:06,838:INFO:Importing libraries
2024-01-02 10:27:06,838:INFO:Copying training dataset
2024-01-02 10:27:06,906:INFO:Defining folds
2024-01-02 10:27:06,907:INFO:Declaring metric variables
2024-01-02 10:27:06,912:INFO:Importing untrained model
2024-01-02 10:27:06,918:INFO:Ada Boost Classifier Imported successfully
2024-01-02 10:27:06,928:INFO:Starting cross validation
2024-01-02 10:27:06,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:10,190:INFO:Calculating mean and std
2024-01-02 10:27:10,191:INFO:Creating metrics dataframe
2024-01-02 10:27:10,194:INFO:Uploading results into container
2024-01-02 10:27:10,195:INFO:Uploading model into container now
2024-01-02 10:27:10,196:INFO:_master_model_container: 9
2024-01-02 10:27:10,196:INFO:_display_container: 2
2024-01-02 10:27:10,196:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-02 10:27:10,196:INFO:create_model() successfully completed......................................
2024-01-02 10:27:10,403:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:10,403:INFO:Creating metrics dataframe
2024-01-02 10:27:10,414:INFO:Initializing Gradient Boosting Classifier
2024-01-02 10:27:10,414:INFO:Total runtime is 0.5769707242647807 minutes
2024-01-02 10:27:10,418:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:10,418:INFO:Initializing create_model()
2024-01-02 10:27:10,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:10,418:INFO:Checking exceptions
2024-01-02 10:27:10,419:INFO:Importing libraries
2024-01-02 10:27:10,419:INFO:Copying training dataset
2024-01-02 10:27:10,471:INFO:Defining folds
2024-01-02 10:27:10,471:INFO:Declaring metric variables
2024-01-02 10:27:10,476:INFO:Importing untrained model
2024-01-02 10:27:10,480:INFO:Gradient Boosting Classifier Imported successfully
2024-01-02 10:27:10,487:INFO:Starting cross validation
2024-01-02 10:27:10,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:19,943:INFO:Calculating mean and std
2024-01-02 10:27:19,944:INFO:Creating metrics dataframe
2024-01-02 10:27:19,948:INFO:Uploading results into container
2024-01-02 10:27:19,949:INFO:Uploading model into container now
2024-01-02 10:27:19,949:INFO:_master_model_container: 10
2024-01-02 10:27:19,949:INFO:_display_container: 2
2024-01-02 10:27:19,950:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-02 10:27:19,950:INFO:create_model() successfully completed......................................
2024-01-02 10:27:20,157:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:20,157:INFO:Creating metrics dataframe
2024-01-02 10:27:20,169:INFO:Initializing Linear Discriminant Analysis
2024-01-02 10:27:20,169:INFO:Total runtime is 0.7395416855812073 minutes
2024-01-02 10:27:20,172:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:20,172:INFO:Initializing create_model()
2024-01-02 10:27:20,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:20,173:INFO:Checking exceptions
2024-01-02 10:27:20,173:INFO:Importing libraries
2024-01-02 10:27:20,173:INFO:Copying training dataset
2024-01-02 10:27:20,226:INFO:Defining folds
2024-01-02 10:27:20,227:INFO:Declaring metric variables
2024-01-02 10:27:20,232:INFO:Importing untrained model
2024-01-02 10:27:20,238:INFO:Linear Discriminant Analysis Imported successfully
2024-01-02 10:27:20,245:INFO:Starting cross validation
2024-01-02 10:27:20,247:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:26,472:INFO:Calculating mean and std
2024-01-02 10:27:26,473:INFO:Creating metrics dataframe
2024-01-02 10:27:26,477:INFO:Uploading results into container
2024-01-02 10:27:26,478:INFO:Uploading model into container now
2024-01-02 10:27:26,478:INFO:_master_model_container: 11
2024-01-02 10:27:26,478:INFO:_display_container: 2
2024-01-02 10:27:26,479:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-02 10:27:26,479:INFO:create_model() successfully completed......................................
2024-01-02 10:27:26,692:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:26,692:INFO:Creating metrics dataframe
2024-01-02 10:27:26,705:INFO:Initializing Extra Trees Classifier
2024-01-02 10:27:26,705:INFO:Total runtime is 0.8484839955965677 minutes
2024-01-02 10:27:26,709:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:26,709:INFO:Initializing create_model()
2024-01-02 10:27:26,709:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:26,709:INFO:Checking exceptions
2024-01-02 10:27:26,709:INFO:Importing libraries
2024-01-02 10:27:26,709:INFO:Copying training dataset
2024-01-02 10:27:26,765:INFO:Defining folds
2024-01-02 10:27:26,765:INFO:Declaring metric variables
2024-01-02 10:27:26,769:INFO:Importing untrained model
2024-01-02 10:27:26,773:INFO:Extra Trees Classifier Imported successfully
2024-01-02 10:27:26,779:INFO:Starting cross validation
2024-01-02 10:27:26,781:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:39,197:INFO:Calculating mean and std
2024-01-02 10:27:39,198:INFO:Creating metrics dataframe
2024-01-02 10:27:39,202:INFO:Uploading results into container
2024-01-02 10:27:39,203:INFO:Uploading model into container now
2024-01-02 10:27:39,203:INFO:_master_model_container: 12
2024-01-02 10:27:39,204:INFO:_display_container: 2
2024-01-02 10:27:39,204:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-02 10:27:39,204:INFO:create_model() successfully completed......................................
2024-01-02 10:27:39,473:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:39,473:INFO:Creating metrics dataframe
2024-01-02 10:27:39,485:INFO:Initializing Light Gradient Boosting Machine
2024-01-02 10:27:39,486:INFO:Total runtime is 1.0615026434262593 minutes
2024-01-02 10:27:39,489:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:39,490:INFO:Initializing create_model()
2024-01-02 10:27:39,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:39,490:INFO:Checking exceptions
2024-01-02 10:27:39,490:INFO:Importing libraries
2024-01-02 10:27:39,490:INFO:Copying training dataset
2024-01-02 10:27:39,545:INFO:Defining folds
2024-01-02 10:27:39,545:INFO:Declaring metric variables
2024-01-02 10:27:39,550:INFO:Importing untrained model
2024-01-02 10:27:39,555:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:27:39,563:INFO:Starting cross validation
2024-01-02 10:27:39,565:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:42,055:INFO:Calculating mean and std
2024-01-02 10:27:42,056:INFO:Creating metrics dataframe
2024-01-02 10:27:42,061:INFO:Uploading results into container
2024-01-02 10:27:42,062:INFO:Uploading model into container now
2024-01-02 10:27:42,062:INFO:_master_model_container: 13
2024-01-02 10:27:42,063:INFO:_display_container: 2
2024-01-02 10:27:42,063:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:27:42,063:INFO:create_model() successfully completed......................................
2024-01-02 10:27:42,268:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:42,268:INFO:Creating metrics dataframe
2024-01-02 10:27:42,296:INFO:Initializing Dummy Classifier
2024-01-02 10:27:42,297:INFO:Total runtime is 1.1083428382873535 minutes
2024-01-02 10:27:42,311:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:42,313:INFO:Initializing create_model()
2024-01-02 10:27:42,313:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BAE2F80>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:42,313:INFO:Checking exceptions
2024-01-02 10:27:42,313:INFO:Importing libraries
2024-01-02 10:27:42,313:INFO:Copying training dataset
2024-01-02 10:27:42,364:INFO:Defining folds
2024-01-02 10:27:42,364:INFO:Declaring metric variables
2024-01-02 10:27:42,369:INFO:Importing untrained model
2024-01-02 10:27:42,374:INFO:Dummy Classifier Imported successfully
2024-01-02 10:27:42,381:INFO:Starting cross validation
2024-01-02 10:27:42,382:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:43,046:INFO:Calculating mean and std
2024-01-02 10:27:43,047:INFO:Creating metrics dataframe
2024-01-02 10:27:43,050:INFO:Uploading results into container
2024-01-02 10:27:43,050:INFO:Uploading model into container now
2024-01-02 10:27:43,051:INFO:_master_model_container: 14
2024-01-02 10:27:43,051:INFO:_display_container: 2
2024-01-02 10:27:43,051:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-02 10:27:43,051:INFO:create_model() successfully completed......................................
2024-01-02 10:27:43,259:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:43,260:INFO:Creating metrics dataframe
2024-01-02 10:27:43,283:INFO:Initializing create_model()
2024-01-02 10:27:43,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:43,283:INFO:Checking exceptions
2024-01-02 10:27:43,285:INFO:Importing libraries
2024-01-02 10:27:43,285:INFO:Copying training dataset
2024-01-02 10:27:43,338:INFO:Defining folds
2024-01-02 10:27:43,338:INFO:Declaring metric variables
2024-01-02 10:27:43,338:INFO:Importing untrained model
2024-01-02 10:27:43,338:INFO:Declaring custom model
2024-01-02 10:27:43,339:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:27:43,340:INFO:Cross validation set to False
2024-01-02 10:27:43,340:INFO:Fitting Model
2024-01-02 10:27:43,449:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-02 10:27:43,450:INFO:[LightGBM] [Info] Number of positive: 19775, number of negative: 6273
2024-01-02 10:27:43,454:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001610 seconds.
2024-01-02 10:27:43,454:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-02 10:27:43,454:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-02 10:27:43,454:INFO:[LightGBM] [Info] Total Bins 733
2024-01-02 10:27:43,454:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 82
2024-01-02 10:27:43,455:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759175 -> initscore=1.148164
2024-01-02 10:27:43,455:INFO:[LightGBM] [Info] Start training from score 1.148164
2024-01-02 10:27:43,598:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:27:43,598:INFO:create_model() successfully completed......................................
2024-01-02 10:27:43,853:INFO:_master_model_container: 14
2024-01-02 10:27:43,854:INFO:_display_container: 2
2024-01-02 10:27:43,854:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:27:43,854:INFO:compare_models() successfully completed......................................
2024-01-02 10:27:44,354:INFO:Initializing compare_models()
2024-01-02 10:27:44,354:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-02 10:27:44,354:INFO:Checking exceptions
2024-01-02 10:27:44,373:INFO:Preparing display monitor
2024-01-02 10:27:44,404:INFO:Initializing Logistic Regression
2024-01-02 10:27:44,404:INFO:Total runtime is 0.0 minutes
2024-01-02 10:27:44,408:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:44,409:INFO:Initializing create_model()
2024-01-02 10:27:44,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:44,409:INFO:Checking exceptions
2024-01-02 10:27:44,409:INFO:Importing libraries
2024-01-02 10:27:44,409:INFO:Copying training dataset
2024-01-02 10:27:44,468:INFO:Defining folds
2024-01-02 10:27:44,468:INFO:Declaring metric variables
2024-01-02 10:27:44,472:INFO:Importing untrained model
2024-01-02 10:27:44,476:INFO:Logistic Regression Imported successfully
2024-01-02 10:27:44,484:INFO:Starting cross validation
2024-01-02 10:27:44,485:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:54,068:INFO:Calculating mean and std
2024-01-02 10:27:54,069:INFO:Creating metrics dataframe
2024-01-02 10:27:54,072:INFO:Uploading results into container
2024-01-02 10:27:54,073:INFO:Uploading model into container now
2024-01-02 10:27:54,073:INFO:_master_model_container: 15
2024-01-02 10:27:54,073:INFO:_display_container: 3
2024-01-02 10:27:54,074:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-02 10:27:54,074:INFO:create_model() successfully completed......................................
2024-01-02 10:27:54,278:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:54,278:INFO:Creating metrics dataframe
2024-01-02 10:27:54,286:INFO:Initializing K Neighbors Classifier
2024-01-02 10:27:54,286:INFO:Total runtime is 0.1646937370300293 minutes
2024-01-02 10:27:54,289:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:54,290:INFO:Initializing create_model()
2024-01-02 10:27:54,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:54,290:INFO:Checking exceptions
2024-01-02 10:27:54,290:INFO:Importing libraries
2024-01-02 10:27:54,290:INFO:Copying training dataset
2024-01-02 10:27:54,342:INFO:Defining folds
2024-01-02 10:27:54,342:INFO:Declaring metric variables
2024-01-02 10:27:54,346:INFO:Importing untrained model
2024-01-02 10:27:54,349:INFO:K Neighbors Classifier Imported successfully
2024-01-02 10:27:54,357:INFO:Starting cross validation
2024-01-02 10:27:54,359:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:58,078:INFO:Calculating mean and std
2024-01-02 10:27:58,082:INFO:Creating metrics dataframe
2024-01-02 10:27:58,096:INFO:Uploading results into container
2024-01-02 10:27:58,098:INFO:Uploading model into container now
2024-01-02 10:27:58,100:INFO:_master_model_container: 16
2024-01-02 10:27:58,100:INFO:_display_container: 3
2024-01-02 10:27:58,101:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-02 10:27:58,102:INFO:create_model() successfully completed......................................
2024-01-02 10:27:58,313:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:58,313:INFO:Creating metrics dataframe
2024-01-02 10:27:58,322:INFO:Initializing Naive Bayes
2024-01-02 10:27:58,322:INFO:Total runtime is 0.23197355667750041 minutes
2024-01-02 10:27:58,325:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:58,325:INFO:Initializing create_model()
2024-01-02 10:27:58,325:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:58,325:INFO:Checking exceptions
2024-01-02 10:27:58,325:INFO:Importing libraries
2024-01-02 10:27:58,326:INFO:Copying training dataset
2024-01-02 10:27:58,378:INFO:Defining folds
2024-01-02 10:27:58,378:INFO:Declaring metric variables
2024-01-02 10:27:58,382:INFO:Importing untrained model
2024-01-02 10:27:58,386:INFO:Naive Bayes Imported successfully
2024-01-02 10:27:58,393:INFO:Starting cross validation
2024-01-02 10:27:58,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:27:59,367:INFO:Calculating mean and std
2024-01-02 10:27:59,370:INFO:Creating metrics dataframe
2024-01-02 10:27:59,383:INFO:Uploading results into container
2024-01-02 10:27:59,384:INFO:Uploading model into container now
2024-01-02 10:27:59,386:INFO:_master_model_container: 17
2024-01-02 10:27:59,386:INFO:_display_container: 3
2024-01-02 10:27:59,387:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-02 10:27:59,387:INFO:create_model() successfully completed......................................
2024-01-02 10:27:59,594:INFO:SubProcess create_model() end ==================================
2024-01-02 10:27:59,594:INFO:Creating metrics dataframe
2024-01-02 10:27:59,605:INFO:Initializing Decision Tree Classifier
2024-01-02 10:27:59,605:INFO:Total runtime is 0.2533470114072164 minutes
2024-01-02 10:27:59,608:INFO:SubProcess create_model() called ==================================
2024-01-02 10:27:59,609:INFO:Initializing create_model()
2024-01-02 10:27:59,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:27:59,609:INFO:Checking exceptions
2024-01-02 10:27:59,609:INFO:Importing libraries
2024-01-02 10:27:59,609:INFO:Copying training dataset
2024-01-02 10:27:59,658:INFO:Defining folds
2024-01-02 10:27:59,658:INFO:Declaring metric variables
2024-01-02 10:27:59,661:INFO:Importing untrained model
2024-01-02 10:27:59,666:INFO:Decision Tree Classifier Imported successfully
2024-01-02 10:27:59,672:INFO:Starting cross validation
2024-01-02 10:27:59,673:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:01,093:INFO:Calculating mean and std
2024-01-02 10:28:01,094:INFO:Creating metrics dataframe
2024-01-02 10:28:01,098:INFO:Uploading results into container
2024-01-02 10:28:01,098:INFO:Uploading model into container now
2024-01-02 10:28:01,099:INFO:_master_model_container: 18
2024-01-02 10:28:01,099:INFO:_display_container: 3
2024-01-02 10:28:01,099:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-02 10:28:01,099:INFO:create_model() successfully completed......................................
2024-01-02 10:28:01,322:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:01,322:INFO:Creating metrics dataframe
2024-01-02 10:28:01,333:INFO:Initializing SVM - Linear Kernel
2024-01-02 10:28:01,334:INFO:Total runtime is 0.28216809034347534 minutes
2024-01-02 10:28:01,338:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:01,338:INFO:Initializing create_model()
2024-01-02 10:28:01,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:01,339:INFO:Checking exceptions
2024-01-02 10:28:01,339:INFO:Importing libraries
2024-01-02 10:28:01,339:INFO:Copying training dataset
2024-01-02 10:28:01,393:INFO:Defining folds
2024-01-02 10:28:01,393:INFO:Declaring metric variables
2024-01-02 10:28:01,397:INFO:Importing untrained model
2024-01-02 10:28:01,401:INFO:SVM - Linear Kernel Imported successfully
2024-01-02 10:28:01,408:INFO:Starting cross validation
2024-01-02 10:28:01,409:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:02,751:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,791:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,829:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,846:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,871:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,903:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,938:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,942:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,965:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:02,994:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:28:03,114:INFO:Calculating mean and std
2024-01-02 10:28:03,115:INFO:Creating metrics dataframe
2024-01-02 10:28:03,119:INFO:Uploading results into container
2024-01-02 10:28:03,119:INFO:Uploading model into container now
2024-01-02 10:28:03,120:INFO:_master_model_container: 19
2024-01-02 10:28:03,120:INFO:_display_container: 3
2024-01-02 10:28:03,120:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-02 10:28:03,120:INFO:create_model() successfully completed......................................
2024-01-02 10:28:03,316:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:03,316:INFO:Creating metrics dataframe
2024-01-02 10:28:03,326:INFO:Initializing Ridge Classifier
2024-01-02 10:28:03,326:INFO:Total runtime is 0.3153689583142598 minutes
2024-01-02 10:28:03,330:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:03,330:INFO:Initializing create_model()
2024-01-02 10:28:03,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:03,330:INFO:Checking exceptions
2024-01-02 10:28:03,330:INFO:Importing libraries
2024-01-02 10:28:03,330:INFO:Copying training dataset
2024-01-02 10:28:03,379:INFO:Defining folds
2024-01-02 10:28:03,379:INFO:Declaring metric variables
2024-01-02 10:28:03,382:INFO:Importing untrained model
2024-01-02 10:28:03,386:INFO:Ridge Classifier Imported successfully
2024-01-02 10:28:03,393:INFO:Starting cross validation
2024-01-02 10:28:03,394:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:04,043:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,064:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,069:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,075:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,084:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,087:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,108:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,109:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,111:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,116:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:28:04,246:INFO:Calculating mean and std
2024-01-02 10:28:04,249:INFO:Creating metrics dataframe
2024-01-02 10:28:04,254:INFO:Uploading results into container
2024-01-02 10:28:04,256:INFO:Uploading model into container now
2024-01-02 10:28:04,256:INFO:_master_model_container: 20
2024-01-02 10:28:04,256:INFO:_display_container: 3
2024-01-02 10:28:04,257:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-02 10:28:04,257:INFO:create_model() successfully completed......................................
2024-01-02 10:28:04,541:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:04,541:INFO:Creating metrics dataframe
2024-01-02 10:28:04,552:INFO:Initializing Random Forest Classifier
2024-01-02 10:28:04,552:INFO:Total runtime is 0.33580356836318964 minutes
2024-01-02 10:28:04,556:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:04,556:INFO:Initializing create_model()
2024-01-02 10:28:04,556:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:04,556:INFO:Checking exceptions
2024-01-02 10:28:04,556:INFO:Importing libraries
2024-01-02 10:28:04,557:INFO:Copying training dataset
2024-01-02 10:28:04,610:INFO:Defining folds
2024-01-02 10:28:04,610:INFO:Declaring metric variables
2024-01-02 10:28:04,614:INFO:Importing untrained model
2024-01-02 10:28:04,618:INFO:Random Forest Classifier Imported successfully
2024-01-02 10:28:04,624:INFO:Starting cross validation
2024-01-02 10:28:04,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:13,668:INFO:Calculating mean and std
2024-01-02 10:28:13,670:INFO:Creating metrics dataframe
2024-01-02 10:28:13,675:INFO:Uploading results into container
2024-01-02 10:28:13,676:INFO:Uploading model into container now
2024-01-02 10:28:13,676:INFO:_master_model_container: 21
2024-01-02 10:28:13,677:INFO:_display_container: 3
2024-01-02 10:28:13,677:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-02 10:28:13,678:INFO:create_model() successfully completed......................................
2024-01-02 10:28:13,892:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:13,892:INFO:Creating metrics dataframe
2024-01-02 10:28:13,902:INFO:Initializing Quadratic Discriminant Analysis
2024-01-02 10:28:13,903:INFO:Total runtime is 0.4916578888893127 minutes
2024-01-02 10:28:13,906:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:13,906:INFO:Initializing create_model()
2024-01-02 10:28:13,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:13,907:INFO:Checking exceptions
2024-01-02 10:28:13,907:INFO:Importing libraries
2024-01-02 10:28:13,907:INFO:Copying training dataset
2024-01-02 10:28:13,958:INFO:Defining folds
2024-01-02 10:28:13,958:INFO:Declaring metric variables
2024-01-02 10:28:13,962:INFO:Importing untrained model
2024-01-02 10:28:13,966:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-02 10:28:13,973:INFO:Starting cross validation
2024-01-02 10:28:13,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:14,527:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,553:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,580:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,590:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,601:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,612:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,635:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,640:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,650:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:14,660:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:28:16,062:INFO:Calculating mean and std
2024-01-02 10:28:16,063:INFO:Creating metrics dataframe
2024-01-02 10:28:16,068:INFO:Uploading results into container
2024-01-02 10:28:16,068:INFO:Uploading model into container now
2024-01-02 10:28:16,069:INFO:_master_model_container: 22
2024-01-02 10:28:16,069:INFO:_display_container: 3
2024-01-02 10:28:16,069:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-02 10:28:16,069:INFO:create_model() successfully completed......................................
2024-01-02 10:28:16,320:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:16,320:INFO:Creating metrics dataframe
2024-01-02 10:28:16,334:INFO:Initializing Ada Boost Classifier
2024-01-02 10:28:16,334:INFO:Total runtime is 0.5321655472119649 minutes
2024-01-02 10:28:16,339:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:16,339:INFO:Initializing create_model()
2024-01-02 10:28:16,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:16,340:INFO:Checking exceptions
2024-01-02 10:28:16,340:INFO:Importing libraries
2024-01-02 10:28:16,340:INFO:Copying training dataset
2024-01-02 10:28:16,405:INFO:Defining folds
2024-01-02 10:28:16,405:INFO:Declaring metric variables
2024-01-02 10:28:16,410:INFO:Importing untrained model
2024-01-02 10:28:16,416:INFO:Ada Boost Classifier Imported successfully
2024-01-02 10:28:16,425:INFO:Starting cross validation
2024-01-02 10:28:16,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:19,567:INFO:Calculating mean and std
2024-01-02 10:28:19,571:INFO:Creating metrics dataframe
2024-01-02 10:28:19,584:INFO:Uploading results into container
2024-01-02 10:28:19,586:INFO:Uploading model into container now
2024-01-02 10:28:19,588:INFO:_master_model_container: 23
2024-01-02 10:28:19,588:INFO:_display_container: 3
2024-01-02 10:28:19,589:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-02 10:28:19,589:INFO:create_model() successfully completed......................................
2024-01-02 10:28:19,839:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:19,840:INFO:Creating metrics dataframe
2024-01-02 10:28:19,852:INFO:Initializing Gradient Boosting Classifier
2024-01-02 10:28:19,852:INFO:Total runtime is 0.5907980958620707 minutes
2024-01-02 10:28:19,855:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:19,855:INFO:Initializing create_model()
2024-01-02 10:28:19,856:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:19,856:INFO:Checking exceptions
2024-01-02 10:28:19,856:INFO:Importing libraries
2024-01-02 10:28:19,856:INFO:Copying training dataset
2024-01-02 10:28:19,904:INFO:Defining folds
2024-01-02 10:28:19,904:INFO:Declaring metric variables
2024-01-02 10:28:19,908:INFO:Importing untrained model
2024-01-02 10:28:19,912:INFO:Gradient Boosting Classifier Imported successfully
2024-01-02 10:28:19,918:INFO:Starting cross validation
2024-01-02 10:28:19,920:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:29,833:INFO:Calculating mean and std
2024-01-02 10:28:29,834:INFO:Creating metrics dataframe
2024-01-02 10:28:29,838:INFO:Uploading results into container
2024-01-02 10:28:29,839:INFO:Uploading model into container now
2024-01-02 10:28:29,839:INFO:_master_model_container: 24
2024-01-02 10:28:29,839:INFO:_display_container: 3
2024-01-02 10:28:29,840:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-02 10:28:29,840:INFO:create_model() successfully completed......................................
2024-01-02 10:28:30,056:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:30,056:INFO:Creating metrics dataframe
2024-01-02 10:28:30,067:INFO:Initializing Linear Discriminant Analysis
2024-01-02 10:28:30,068:INFO:Total runtime is 0.7610699613889058 minutes
2024-01-02 10:28:30,071:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:30,072:INFO:Initializing create_model()
2024-01-02 10:28:30,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:30,072:INFO:Checking exceptions
2024-01-02 10:28:30,072:INFO:Importing libraries
2024-01-02 10:28:30,072:INFO:Copying training dataset
2024-01-02 10:28:30,134:INFO:Defining folds
2024-01-02 10:28:30,134:INFO:Declaring metric variables
2024-01-02 10:28:30,139:INFO:Importing untrained model
2024-01-02 10:28:30,143:INFO:Linear Discriminant Analysis Imported successfully
2024-01-02 10:28:30,153:INFO:Starting cross validation
2024-01-02 10:28:30,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:36,476:INFO:Calculating mean and std
2024-01-02 10:28:36,477:INFO:Creating metrics dataframe
2024-01-02 10:28:36,481:INFO:Uploading results into container
2024-01-02 10:28:36,481:INFO:Uploading model into container now
2024-01-02 10:28:36,481:INFO:_master_model_container: 25
2024-01-02 10:28:36,482:INFO:_display_container: 3
2024-01-02 10:28:36,482:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-02 10:28:36,482:INFO:create_model() successfully completed......................................
2024-01-02 10:28:36,664:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:36,665:INFO:Creating metrics dataframe
2024-01-02 10:28:36,677:INFO:Initializing Extra Trees Classifier
2024-01-02 10:28:36,677:INFO:Total runtime is 0.8712151924769084 minutes
2024-01-02 10:28:36,680:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:36,680:INFO:Initializing create_model()
2024-01-02 10:28:36,680:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:36,680:INFO:Checking exceptions
2024-01-02 10:28:36,681:INFO:Importing libraries
2024-01-02 10:28:36,681:INFO:Copying training dataset
2024-01-02 10:28:36,731:INFO:Defining folds
2024-01-02 10:28:36,731:INFO:Declaring metric variables
2024-01-02 10:28:36,735:INFO:Importing untrained model
2024-01-02 10:28:36,738:INFO:Extra Trees Classifier Imported successfully
2024-01-02 10:28:36,745:INFO:Starting cross validation
2024-01-02 10:28:36,746:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:48,042:INFO:Calculating mean and std
2024-01-02 10:28:48,043:INFO:Creating metrics dataframe
2024-01-02 10:28:48,049:INFO:Uploading results into container
2024-01-02 10:28:48,050:INFO:Uploading model into container now
2024-01-02 10:28:48,050:INFO:_master_model_container: 26
2024-01-02 10:28:48,051:INFO:_display_container: 3
2024-01-02 10:28:48,051:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-02 10:28:48,051:INFO:create_model() successfully completed......................................
2024-01-02 10:28:48,279:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:48,280:INFO:Creating metrics dataframe
2024-01-02 10:28:48,315:INFO:Initializing Light Gradient Boosting Machine
2024-01-02 10:28:48,316:INFO:Total runtime is 1.0651897033055624 minutes
2024-01-02 10:28:48,328:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:48,329:INFO:Initializing create_model()
2024-01-02 10:28:48,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:48,329:INFO:Checking exceptions
2024-01-02 10:28:48,329:INFO:Importing libraries
2024-01-02 10:28:48,329:INFO:Copying training dataset
2024-01-02 10:28:48,381:INFO:Defining folds
2024-01-02 10:28:48,381:INFO:Declaring metric variables
2024-01-02 10:28:48,384:INFO:Importing untrained model
2024-01-02 10:28:48,389:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:28:48,396:INFO:Starting cross validation
2024-01-02 10:28:48,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:51,167:INFO:Calculating mean and std
2024-01-02 10:28:51,168:INFO:Creating metrics dataframe
2024-01-02 10:28:51,172:INFO:Uploading results into container
2024-01-02 10:28:51,173:INFO:Uploading model into container now
2024-01-02 10:28:51,174:INFO:_master_model_container: 27
2024-01-02 10:28:51,174:INFO:_display_container: 3
2024-01-02 10:28:51,175:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:28:51,175:INFO:create_model() successfully completed......................................
2024-01-02 10:28:51,431:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:51,431:INFO:Creating metrics dataframe
2024-01-02 10:28:51,448:INFO:Initializing Dummy Classifier
2024-01-02 10:28:51,449:INFO:Total runtime is 1.1173994223276775 minutes
2024-01-02 10:28:51,453:INFO:SubProcess create_model() called ==================================
2024-01-02 10:28:51,453:INFO:Initializing create_model()
2024-01-02 10:28:51,453:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218940AA10>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:51,454:INFO:Checking exceptions
2024-01-02 10:28:51,454:INFO:Importing libraries
2024-01-02 10:28:51,454:INFO:Copying training dataset
2024-01-02 10:28:51,525:INFO:Defining folds
2024-01-02 10:28:51,526:INFO:Declaring metric variables
2024-01-02 10:28:51,532:INFO:Importing untrained model
2024-01-02 10:28:51,537:INFO:Dummy Classifier Imported successfully
2024-01-02 10:28:51,546:INFO:Starting cross validation
2024-01-02 10:28:51,548:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:28:52,287:INFO:Calculating mean and std
2024-01-02 10:28:52,288:INFO:Creating metrics dataframe
2024-01-02 10:28:52,293:INFO:Uploading results into container
2024-01-02 10:28:52,294:INFO:Uploading model into container now
2024-01-02 10:28:52,294:INFO:_master_model_container: 28
2024-01-02 10:28:52,295:INFO:_display_container: 3
2024-01-02 10:28:52,295:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-02 10:28:52,295:INFO:create_model() successfully completed......................................
2024-01-02 10:28:52,514:INFO:SubProcess create_model() end ==================================
2024-01-02 10:28:52,515:INFO:Creating metrics dataframe
2024-01-02 10:28:52,538:INFO:Initializing create_model()
2024-01-02 10:28:52,538:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000221928200D0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:28:52,539:INFO:Checking exceptions
2024-01-02 10:28:52,541:INFO:Importing libraries
2024-01-02 10:28:52,541:INFO:Copying training dataset
2024-01-02 10:28:52,595:INFO:Defining folds
2024-01-02 10:28:52,596:INFO:Declaring metric variables
2024-01-02 10:28:52,596:INFO:Importing untrained model
2024-01-02 10:28:52,596:INFO:Declaring custom model
2024-01-02 10:28:52,597:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:28:52,598:INFO:Cross validation set to False
2024-01-02 10:28:52,598:INFO:Fitting Model
2024-01-02 10:28:52,712:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-02 10:28:52,714:INFO:[LightGBM] [Info] Number of positive: 19775, number of negative: 6273
2024-01-02 10:28:52,717:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001560 seconds.
2024-01-02 10:28:52,717:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-02 10:28:52,717:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-02 10:28:52,718:INFO:[LightGBM] [Info] Total Bins 733
2024-01-02 10:28:52,718:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 82
2024-01-02 10:28:52,718:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759175 -> initscore=1.148164
2024-01-02 10:28:52,719:INFO:[LightGBM] [Info] Start training from score 1.148164
2024-01-02 10:28:52,896:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:28:52,896:INFO:create_model() successfully completed......................................
2024-01-02 10:28:53,199:INFO:_master_model_container: 28
2024-01-02 10:28:53,450:INFO:_display_container: 3
2024-01-02 10:28:53,450:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:28:53,450:INFO:compare_models() successfully completed......................................
2024-01-02 10:29:01,554:INFO:PyCaret ClassificationExperiment
2024-01-02 10:29:01,554:INFO:Logging name: clf-default-name
2024-01-02 10:29:01,554:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-02 10:29:01,554:INFO:version 3.1.0
2024-01-02 10:29:01,554:INFO:Initializing setup()
2024-01-02 10:29:01,554:INFO:self.USI: 824b
2024-01-02 10:29:01,554:INFO:self._variable_keys: {'y_train', 'exp_id', 'n_jobs_param', 'gpu_n_jobs_param', 'seed', 'fold_shuffle_param', 'X_test', 'USI', 'pipeline', 'fix_imbalance', 'X_train', 'logging_param', 'y_test', 'memory', 'data', '_available_plots', 'target_param', 'is_multiclass', 'idx', 'fold_groups_param', 'gpu_param', 'exp_name_log', 'fold_generator', 'y', 'X', '_ml_usecase', 'log_plots_param', 'html_param'}
2024-01-02 10:29:01,554:INFO:Checking environment
2024-01-02 10:29:01,554:INFO:python_version: 3.10.9
2024-01-02 10:29:01,554:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-02 10:29:01,554:INFO:machine: AMD64
2024-01-02 10:29:01,554:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-02 10:29:01,554:INFO:Memory: svmem(total=16954372096, available=1837375488, percent=89.2, used=15116996608, free=1837375488)
2024-01-02 10:29:01,554:INFO:Physical Core: 8
2024-01-02 10:29:01,554:INFO:Logical Core: 16
2024-01-02 10:29:01,555:INFO:Checking libraries
2024-01-02 10:29:01,555:INFO:System:
2024-01-02 10:29:01,555:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-02 10:29:01,555:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-02 10:29:01,555:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-02 10:29:01,555:INFO:PyCaret required dependencies:
2024-01-02 10:29:01,555:INFO:                 pip: 22.3.1
2024-01-02 10:29:01,555:INFO:          setuptools: 65.6.3
2024-01-02 10:29:01,555:INFO:             pycaret: 3.1.0
2024-01-02 10:29:01,555:INFO:             IPython: 8.10.0
2024-01-02 10:29:01,555:INFO:          ipywidgets: 7.6.5
2024-01-02 10:29:01,555:INFO:                tqdm: 4.64.1
2024-01-02 10:29:01,555:INFO:               numpy: 1.23.5
2024-01-02 10:29:01,555:INFO:              pandas: 1.5.3
2024-01-02 10:29:01,555:INFO:              jinja2: 3.1.2
2024-01-02 10:29:01,555:INFO:               scipy: 1.10.1
2024-01-02 10:29:01,555:INFO:              joblib: 1.3.2
2024-01-02 10:29:01,555:INFO:             sklearn: 1.2.1
2024-01-02 10:29:01,555:INFO:                pyod: 1.1.0
2024-01-02 10:29:01,555:INFO:            imblearn: 0.10.1
2024-01-02 10:29:01,555:INFO:   category_encoders: 2.6.2
2024-01-02 10:29:01,556:INFO:            lightgbm: 4.1.0
2024-01-02 10:29:01,556:INFO:               numba: 0.56.4
2024-01-02 10:29:01,556:INFO:            requests: 2.28.1
2024-01-02 10:29:01,556:INFO:          matplotlib: 3.7.0
2024-01-02 10:29:01,556:INFO:          scikitplot: 0.3.7
2024-01-02 10:29:01,556:INFO:         yellowbrick: 1.5
2024-01-02 10:29:01,556:INFO:              plotly: 5.9.0
2024-01-02 10:29:01,556:INFO:    plotly-resampler: Not installed
2024-01-02 10:29:01,556:INFO:             kaleido: 0.2.1
2024-01-02 10:29:01,556:INFO:           schemdraw: 0.15
2024-01-02 10:29:01,556:INFO:         statsmodels: 0.13.5
2024-01-02 10:29:01,556:INFO:              sktime: 0.21.1
2024-01-02 10:29:01,556:INFO:               tbats: 1.1.3
2024-01-02 10:29:01,556:INFO:            pmdarima: 2.0.3
2024-01-02 10:29:01,556:INFO:              psutil: 5.9.0
2024-01-02 10:29:01,556:INFO:          markupsafe: 2.1.1
2024-01-02 10:29:01,556:INFO:             pickle5: Not installed
2024-01-02 10:29:01,556:INFO:         cloudpickle: 2.0.0
2024-01-02 10:29:01,556:INFO:         deprecation: 2.1.0
2024-01-02 10:29:01,556:INFO:              xxhash: 3.4.1
2024-01-02 10:29:01,556:INFO:           wurlitzer: Not installed
2024-01-02 10:29:01,557:INFO:PyCaret optional dependencies:
2024-01-02 10:29:01,557:INFO:                shap: Not installed
2024-01-02 10:29:01,557:INFO:           interpret: Not installed
2024-01-02 10:29:01,557:INFO:                umap: Not installed
2024-01-02 10:29:01,557:INFO:     ydata_profiling: 4.6.0
2024-01-02 10:29:01,557:INFO:  explainerdashboard: Not installed
2024-01-02 10:29:01,557:INFO:             autoviz: Not installed
2024-01-02 10:29:01,557:INFO:           fairlearn: Not installed
2024-01-02 10:29:01,557:INFO:          deepchecks: Not installed
2024-01-02 10:29:01,557:INFO:             xgboost: Not installed
2024-01-02 10:29:01,557:INFO:            catboost: Not installed
2024-01-02 10:29:01,557:INFO:              kmodes: Not installed
2024-01-02 10:29:01,557:INFO:             mlxtend: Not installed
2024-01-02 10:29:01,557:INFO:       statsforecast: Not installed
2024-01-02 10:29:01,557:INFO:        tune_sklearn: Not installed
2024-01-02 10:29:01,557:INFO:                 ray: Not installed
2024-01-02 10:29:01,557:INFO:            hyperopt: Not installed
2024-01-02 10:29:01,557:INFO:              optuna: Not installed
2024-01-02 10:29:01,557:INFO:               skopt: Not installed
2024-01-02 10:29:01,558:INFO:              mlflow: Not installed
2024-01-02 10:29:01,558:INFO:              gradio: Not installed
2024-01-02 10:29:01,558:INFO:             fastapi: Not installed
2024-01-02 10:29:01,558:INFO:             uvicorn: Not installed
2024-01-02 10:29:01,558:INFO:              m2cgen: Not installed
2024-01-02 10:29:01,558:INFO:           evidently: Not installed
2024-01-02 10:29:01,558:INFO:               fugue: Not installed
2024-01-02 10:29:01,558:INFO:           streamlit: Not installed
2024-01-02 10:29:01,558:INFO:             prophet: Not installed
2024-01-02 10:29:01,558:INFO:None
2024-01-02 10:29:01,558:INFO:Set up data.
2024-01-02 10:29:01,600:INFO:Set up folding strategy.
2024-01-02 10:29:01,600:INFO:Set up train/test split.
2024-01-02 10:29:01,635:INFO:Set up index.
2024-01-02 10:29:01,636:INFO:Assigning column types.
2024-01-02 10:29:01,654:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-02 10:29:01,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:29:01,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:29:01,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,781:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-02 10:29:01,782:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:29:01,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-02 10:29:01,861:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:29:01,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-02 10:29:01,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:01,969:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-02 10:29:02,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,119:INFO:Preparing preprocessing pipeline...
2024-01-02 10:29:02,123:INFO:Set up simple imputation.
2024-01-02 10:29:02,126:INFO:Set up column name cleaning.
2024-01-02 10:29:02,239:INFO:Finished creating preprocessing pipeline.
2024-01-02 10:29:02,244:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Final_census',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Federal-gov',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Sel...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-02 10:29:02,244:INFO:Creating final display dataframe.
2024-01-02 10:29:02,549:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            income
2                   Target type            Binary
3           Original data shape       (32561, 99)
4        Transformed data shape       (32561, 99)
5   Transformed train set shape       (26048, 99)
6    Transformed test set shape        (6513, 99)
7              Numeric features                98
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              824b
2024-01-02 10:29:02,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-02 10:29:02,706:INFO:setup() successfully completed in 1.16s...............
2024-01-02 10:29:02,748:INFO:Initializing compare_models()
2024-01-02 10:29:02,748:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-02 10:29:02,748:INFO:Checking exceptions
2024-01-02 10:29:02,776:INFO:Preparing display monitor
2024-01-02 10:29:02,804:INFO:Initializing Logistic Regression
2024-01-02 10:29:02,805:INFO:Total runtime is 1.6661485036214194e-05 minutes
2024-01-02 10:29:02,808:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:02,809:INFO:Initializing create_model()
2024-01-02 10:29:02,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:02,809:INFO:Checking exceptions
2024-01-02 10:29:02,809:INFO:Importing libraries
2024-01-02 10:29:02,809:INFO:Copying training dataset
2024-01-02 10:29:02,860:INFO:Defining folds
2024-01-02 10:29:02,860:INFO:Declaring metric variables
2024-01-02 10:29:02,863:INFO:Importing untrained model
2024-01-02 10:29:02,867:INFO:Logistic Regression Imported successfully
2024-01-02 10:29:02,874:INFO:Starting cross validation
2024-01-02 10:29:02,875:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:12,587:INFO:Calculating mean and std
2024-01-02 10:29:12,588:INFO:Creating metrics dataframe
2024-01-02 10:29:12,592:INFO:Uploading results into container
2024-01-02 10:29:12,593:INFO:Uploading model into container now
2024-01-02 10:29:12,594:INFO:_master_model_container: 1
2024-01-02 10:29:12,594:INFO:_display_container: 2
2024-01-02 10:29:12,595:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-02 10:29:12,595:INFO:create_model() successfully completed......................................
2024-01-02 10:29:12,842:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:12,843:INFO:Creating metrics dataframe
2024-01-02 10:29:12,854:INFO:Initializing K Neighbors Classifier
2024-01-02 10:29:12,855:INFO:Total runtime is 0.16749562422434489 minutes
2024-01-02 10:29:12,860:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:12,860:INFO:Initializing create_model()
2024-01-02 10:29:12,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:12,860:INFO:Checking exceptions
2024-01-02 10:29:12,861:INFO:Importing libraries
2024-01-02 10:29:12,861:INFO:Copying training dataset
2024-01-02 10:29:12,921:INFO:Defining folds
2024-01-02 10:29:12,922:INFO:Declaring metric variables
2024-01-02 10:29:12,926:INFO:Importing untrained model
2024-01-02 10:29:12,930:INFO:K Neighbors Classifier Imported successfully
2024-01-02 10:29:12,937:INFO:Starting cross validation
2024-01-02 10:29:12,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:17,114:INFO:Calculating mean and std
2024-01-02 10:29:17,116:INFO:Creating metrics dataframe
2024-01-02 10:29:17,120:INFO:Uploading results into container
2024-01-02 10:29:17,120:INFO:Uploading model into container now
2024-01-02 10:29:17,121:INFO:_master_model_container: 2
2024-01-02 10:29:17,121:INFO:_display_container: 2
2024-01-02 10:29:17,122:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-02 10:29:17,122:INFO:create_model() successfully completed......................................
2024-01-02 10:29:17,327:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:17,328:INFO:Creating metrics dataframe
2024-01-02 10:29:17,344:INFO:Initializing Naive Bayes
2024-01-02 10:29:17,344:INFO:Total runtime is 0.2423362612724304 minutes
2024-01-02 10:29:17,347:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:17,348:INFO:Initializing create_model()
2024-01-02 10:29:17,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:17,348:INFO:Checking exceptions
2024-01-02 10:29:17,348:INFO:Importing libraries
2024-01-02 10:29:17,348:INFO:Copying training dataset
2024-01-02 10:29:17,395:INFO:Defining folds
2024-01-02 10:29:17,396:INFO:Declaring metric variables
2024-01-02 10:29:17,399:INFO:Importing untrained model
2024-01-02 10:29:17,402:INFO:Naive Bayes Imported successfully
2024-01-02 10:29:17,408:INFO:Starting cross validation
2024-01-02 10:29:17,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:18,326:INFO:Calculating mean and std
2024-01-02 10:29:18,327:INFO:Creating metrics dataframe
2024-01-02 10:29:18,331:INFO:Uploading results into container
2024-01-02 10:29:18,331:INFO:Uploading model into container now
2024-01-02 10:29:18,331:INFO:_master_model_container: 3
2024-01-02 10:29:18,332:INFO:_display_container: 2
2024-01-02 10:29:18,332:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-02 10:29:18,332:INFO:create_model() successfully completed......................................
2024-01-02 10:29:18,557:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:18,558:INFO:Creating metrics dataframe
2024-01-02 10:29:18,568:INFO:Initializing Decision Tree Classifier
2024-01-02 10:29:18,568:INFO:Total runtime is 0.2627234856287638 minutes
2024-01-02 10:29:18,571:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:18,571:INFO:Initializing create_model()
2024-01-02 10:29:18,571:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:18,571:INFO:Checking exceptions
2024-01-02 10:29:18,571:INFO:Importing libraries
2024-01-02 10:29:18,571:INFO:Copying training dataset
2024-01-02 10:29:18,622:INFO:Defining folds
2024-01-02 10:29:18,622:INFO:Declaring metric variables
2024-01-02 10:29:18,626:INFO:Importing untrained model
2024-01-02 10:29:18,630:INFO:Decision Tree Classifier Imported successfully
2024-01-02 10:29:18,638:INFO:Starting cross validation
2024-01-02 10:29:18,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:20,275:INFO:Calculating mean and std
2024-01-02 10:29:20,276:INFO:Creating metrics dataframe
2024-01-02 10:29:20,279:INFO:Uploading results into container
2024-01-02 10:29:20,280:INFO:Uploading model into container now
2024-01-02 10:29:20,280:INFO:_master_model_container: 4
2024-01-02 10:29:20,280:INFO:_display_container: 2
2024-01-02 10:29:20,280:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-02 10:29:20,280:INFO:create_model() successfully completed......................................
2024-01-02 10:29:20,484:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:20,484:INFO:Creating metrics dataframe
2024-01-02 10:29:20,497:INFO:Initializing SVM - Linear Kernel
2024-01-02 10:29:20,497:INFO:Total runtime is 0.2948873321215311 minutes
2024-01-02 10:29:20,500:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:20,501:INFO:Initializing create_model()
2024-01-02 10:29:20,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:20,501:INFO:Checking exceptions
2024-01-02 10:29:20,501:INFO:Importing libraries
2024-01-02 10:29:20,501:INFO:Copying training dataset
2024-01-02 10:29:20,550:INFO:Defining folds
2024-01-02 10:29:20,550:INFO:Declaring metric variables
2024-01-02 10:29:20,554:INFO:Importing untrained model
2024-01-02 10:29:20,558:INFO:SVM - Linear Kernel Imported successfully
2024-01-02 10:29:20,564:INFO:Starting cross validation
2024-01-02 10:29:20,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:21,861:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:21,862:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:21,928:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:21,930:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:21,968:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:22,000:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:22,028:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:22,048:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:22,053:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:22,067:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:29:22,192:INFO:Calculating mean and std
2024-01-02 10:29:22,196:INFO:Creating metrics dataframe
2024-01-02 10:29:22,208:INFO:Uploading results into container
2024-01-02 10:29:22,210:INFO:Uploading model into container now
2024-01-02 10:29:22,211:INFO:_master_model_container: 5
2024-01-02 10:29:22,211:INFO:_display_container: 2
2024-01-02 10:29:22,213:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-02 10:29:22,213:INFO:create_model() successfully completed......................................
2024-01-02 10:29:22,397:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:22,397:INFO:Creating metrics dataframe
2024-01-02 10:29:22,407:INFO:Initializing Ridge Classifier
2024-01-02 10:29:22,407:INFO:Total runtime is 0.326714821656545 minutes
2024-01-02 10:29:22,410:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:22,410:INFO:Initializing create_model()
2024-01-02 10:29:22,410:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:22,410:INFO:Checking exceptions
2024-01-02 10:29:22,411:INFO:Importing libraries
2024-01-02 10:29:22,411:INFO:Copying training dataset
2024-01-02 10:29:22,458:INFO:Defining folds
2024-01-02 10:29:22,458:INFO:Declaring metric variables
2024-01-02 10:29:22,462:INFO:Importing untrained model
2024-01-02 10:29:22,465:INFO:Ridge Classifier Imported successfully
2024-01-02 10:29:22,471:INFO:Starting cross validation
2024-01-02 10:29:22,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:23,072:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,108:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,114:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,127:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,131:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,131:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,131:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,141:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,148:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,153:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:29:23,276:INFO:Calculating mean and std
2024-01-02 10:29:23,281:INFO:Creating metrics dataframe
2024-01-02 10:29:23,294:INFO:Uploading results into container
2024-01-02 10:29:23,296:INFO:Uploading model into container now
2024-01-02 10:29:23,298:INFO:_master_model_container: 6
2024-01-02 10:29:23,299:INFO:_display_container: 2
2024-01-02 10:29:23,300:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-02 10:29:23,301:INFO:create_model() successfully completed......................................
2024-01-02 10:29:23,481:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:23,481:INFO:Creating metrics dataframe
2024-01-02 10:29:23,492:INFO:Initializing Random Forest Classifier
2024-01-02 10:29:23,492:INFO:Total runtime is 0.3447995543479919 minutes
2024-01-02 10:29:23,496:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:23,496:INFO:Initializing create_model()
2024-01-02 10:29:23,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:23,496:INFO:Checking exceptions
2024-01-02 10:29:23,496:INFO:Importing libraries
2024-01-02 10:29:23,496:INFO:Copying training dataset
2024-01-02 10:29:23,544:INFO:Defining folds
2024-01-02 10:29:23,544:INFO:Declaring metric variables
2024-01-02 10:29:23,548:INFO:Importing untrained model
2024-01-02 10:29:23,551:INFO:Random Forest Classifier Imported successfully
2024-01-02 10:29:23,558:INFO:Starting cross validation
2024-01-02 10:29:23,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:32,629:INFO:Calculating mean and std
2024-01-02 10:29:32,630:INFO:Creating metrics dataframe
2024-01-02 10:29:32,634:INFO:Uploading results into container
2024-01-02 10:29:32,635:INFO:Uploading model into container now
2024-01-02 10:29:32,635:INFO:_master_model_container: 7
2024-01-02 10:29:32,635:INFO:_display_container: 2
2024-01-02 10:29:32,636:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-02 10:29:32,636:INFO:create_model() successfully completed......................................
2024-01-02 10:29:32,891:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:32,891:INFO:Creating metrics dataframe
2024-01-02 10:29:32,903:INFO:Initializing Quadratic Discriminant Analysis
2024-01-02 10:29:32,904:INFO:Total runtime is 0.5016704559326172 minutes
2024-01-02 10:29:32,907:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:32,908:INFO:Initializing create_model()
2024-01-02 10:29:32,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:32,908:INFO:Checking exceptions
2024-01-02 10:29:32,908:INFO:Importing libraries
2024-01-02 10:29:32,908:INFO:Copying training dataset
2024-01-02 10:29:32,960:INFO:Defining folds
2024-01-02 10:29:32,960:INFO:Declaring metric variables
2024-01-02 10:29:32,966:INFO:Importing untrained model
2024-01-02 10:29:32,970:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-02 10:29:32,978:INFO:Starting cross validation
2024-01-02 10:29:32,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:33,591:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,614:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,641:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,693:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,706:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,743:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,745:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,845:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,901:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:33,936:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:29:35,394:INFO:Calculating mean and std
2024-01-02 10:29:35,396:INFO:Creating metrics dataframe
2024-01-02 10:29:35,400:INFO:Uploading results into container
2024-01-02 10:29:35,401:INFO:Uploading model into container now
2024-01-02 10:29:35,401:INFO:_master_model_container: 8
2024-01-02 10:29:35,401:INFO:_display_container: 2
2024-01-02 10:29:35,402:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-02 10:29:35,402:INFO:create_model() successfully completed......................................
2024-01-02 10:29:35,695:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:35,695:INFO:Creating metrics dataframe
2024-01-02 10:29:35,708:INFO:Initializing Ada Boost Classifier
2024-01-02 10:29:35,708:INFO:Total runtime is 0.5484044790267945 minutes
2024-01-02 10:29:35,712:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:35,712:INFO:Initializing create_model()
2024-01-02 10:29:35,713:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:35,713:INFO:Checking exceptions
2024-01-02 10:29:35,713:INFO:Importing libraries
2024-01-02 10:29:35,713:INFO:Copying training dataset
2024-01-02 10:29:35,766:INFO:Defining folds
2024-01-02 10:29:35,766:INFO:Declaring metric variables
2024-01-02 10:29:35,771:INFO:Importing untrained model
2024-01-02 10:29:35,775:INFO:Ada Boost Classifier Imported successfully
2024-01-02 10:29:35,783:INFO:Starting cross validation
2024-01-02 10:29:35,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:38,835:INFO:Calculating mean and std
2024-01-02 10:29:38,839:INFO:Creating metrics dataframe
2024-01-02 10:29:38,851:INFO:Uploading results into container
2024-01-02 10:29:38,853:INFO:Uploading model into container now
2024-01-02 10:29:38,854:INFO:_master_model_container: 9
2024-01-02 10:29:38,854:INFO:_display_container: 2
2024-01-02 10:29:38,856:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-02 10:29:38,856:INFO:create_model() successfully completed......................................
2024-01-02 10:29:39,057:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:39,057:INFO:Creating metrics dataframe
2024-01-02 10:29:39,068:INFO:Initializing Gradient Boosting Classifier
2024-01-02 10:29:39,068:INFO:Total runtime is 0.6044005155563354 minutes
2024-01-02 10:29:39,071:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:39,072:INFO:Initializing create_model()
2024-01-02 10:29:39,072:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:39,072:INFO:Checking exceptions
2024-01-02 10:29:39,072:INFO:Importing libraries
2024-01-02 10:29:39,072:INFO:Copying training dataset
2024-01-02 10:29:39,118:INFO:Defining folds
2024-01-02 10:29:39,118:INFO:Declaring metric variables
2024-01-02 10:29:39,122:INFO:Importing untrained model
2024-01-02 10:29:39,126:INFO:Gradient Boosting Classifier Imported successfully
2024-01-02 10:29:39,132:INFO:Starting cross validation
2024-01-02 10:29:39,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:48,621:INFO:Calculating mean and std
2024-01-02 10:29:48,622:INFO:Creating metrics dataframe
2024-01-02 10:29:48,625:INFO:Uploading results into container
2024-01-02 10:29:48,626:INFO:Uploading model into container now
2024-01-02 10:29:48,626:INFO:_master_model_container: 10
2024-01-02 10:29:48,626:INFO:_display_container: 2
2024-01-02 10:29:48,627:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-02 10:29:48,627:INFO:create_model() successfully completed......................................
2024-01-02 10:29:48,828:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:48,828:INFO:Creating metrics dataframe
2024-01-02 10:29:48,840:INFO:Initializing Linear Discriminant Analysis
2024-01-02 10:29:48,840:INFO:Total runtime is 0.7672681848208109 minutes
2024-01-02 10:29:48,843:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:48,843:INFO:Initializing create_model()
2024-01-02 10:29:48,844:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:48,844:INFO:Checking exceptions
2024-01-02 10:29:48,844:INFO:Importing libraries
2024-01-02 10:29:48,844:INFO:Copying training dataset
2024-01-02 10:29:48,894:INFO:Defining folds
2024-01-02 10:29:48,894:INFO:Declaring metric variables
2024-01-02 10:29:48,898:INFO:Importing untrained model
2024-01-02 10:29:48,902:INFO:Linear Discriminant Analysis Imported successfully
2024-01-02 10:29:48,909:INFO:Starting cross validation
2024-01-02 10:29:48,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:29:55,077:INFO:Calculating mean and std
2024-01-02 10:29:55,079:INFO:Creating metrics dataframe
2024-01-02 10:29:55,082:INFO:Uploading results into container
2024-01-02 10:29:55,083:INFO:Uploading model into container now
2024-01-02 10:29:55,083:INFO:_master_model_container: 11
2024-01-02 10:29:55,083:INFO:_display_container: 2
2024-01-02 10:29:55,084:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-02 10:29:55,084:INFO:create_model() successfully completed......................................
2024-01-02 10:29:55,283:INFO:SubProcess create_model() end ==================================
2024-01-02 10:29:55,283:INFO:Creating metrics dataframe
2024-01-02 10:29:55,296:INFO:Initializing Extra Trees Classifier
2024-01-02 10:29:55,296:INFO:Total runtime is 0.8748682657877604 minutes
2024-01-02 10:29:55,299:INFO:SubProcess create_model() called ==================================
2024-01-02 10:29:55,300:INFO:Initializing create_model()
2024-01-02 10:29:55,300:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:29:55,300:INFO:Checking exceptions
2024-01-02 10:29:55,300:INFO:Importing libraries
2024-01-02 10:29:55,300:INFO:Copying training dataset
2024-01-02 10:29:55,354:INFO:Defining folds
2024-01-02 10:29:55,354:INFO:Declaring metric variables
2024-01-02 10:29:55,358:INFO:Importing untrained model
2024-01-02 10:29:55,362:INFO:Extra Trees Classifier Imported successfully
2024-01-02 10:29:55,369:INFO:Starting cross validation
2024-01-02 10:29:55,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:09,050:INFO:Calculating mean and std
2024-01-02 10:30:09,052:INFO:Creating metrics dataframe
2024-01-02 10:30:09,057:INFO:Uploading results into container
2024-01-02 10:30:09,058:INFO:Uploading model into container now
2024-01-02 10:30:09,058:INFO:_master_model_container: 12
2024-01-02 10:30:09,058:INFO:_display_container: 2
2024-01-02 10:30:09,059:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-02 10:30:09,059:INFO:create_model() successfully completed......................................
2024-01-02 10:30:09,362:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:09,362:INFO:Creating metrics dataframe
2024-01-02 10:30:09,376:INFO:Initializing Light Gradient Boosting Machine
2024-01-02 10:30:09,376:INFO:Total runtime is 1.1095355113347372 minutes
2024-01-02 10:30:09,380:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:09,380:INFO:Initializing create_model()
2024-01-02 10:30:09,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:09,380:INFO:Checking exceptions
2024-01-02 10:30:09,380:INFO:Importing libraries
2024-01-02 10:30:09,380:INFO:Copying training dataset
2024-01-02 10:30:09,431:INFO:Defining folds
2024-01-02 10:30:09,431:INFO:Declaring metric variables
2024-01-02 10:30:09,435:INFO:Importing untrained model
2024-01-02 10:30:09,438:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:30:09,446:INFO:Starting cross validation
2024-01-02 10:30:09,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:11,709:INFO:Calculating mean and std
2024-01-02 10:30:11,711:INFO:Creating metrics dataframe
2024-01-02 10:30:11,715:INFO:Uploading results into container
2024-01-02 10:30:11,716:INFO:Uploading model into container now
2024-01-02 10:30:11,716:INFO:_master_model_container: 13
2024-01-02 10:30:11,716:INFO:_display_container: 2
2024-01-02 10:30:11,717:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:30:11,718:INFO:create_model() successfully completed......................................
2024-01-02 10:30:11,941:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:11,941:INFO:Creating metrics dataframe
2024-01-02 10:30:11,956:INFO:Initializing Dummy Classifier
2024-01-02 10:30:11,956:INFO:Total runtime is 1.1525248924891154 minutes
2024-01-02 10:30:11,959:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:11,960:INFO:Initializing create_model()
2024-01-02 10:30:11,960:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002218BA15DB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:11,960:INFO:Checking exceptions
2024-01-02 10:30:11,960:INFO:Importing libraries
2024-01-02 10:30:11,960:INFO:Copying training dataset
2024-01-02 10:30:12,020:INFO:Defining folds
2024-01-02 10:30:12,020:INFO:Declaring metric variables
2024-01-02 10:30:12,024:INFO:Importing untrained model
2024-01-02 10:30:12,029:INFO:Dummy Classifier Imported successfully
2024-01-02 10:30:12,036:INFO:Starting cross validation
2024-01-02 10:30:12,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:12,693:INFO:Calculating mean and std
2024-01-02 10:30:12,695:INFO:Creating metrics dataframe
2024-01-02 10:30:12,698:INFO:Uploading results into container
2024-01-02 10:30:12,699:INFO:Uploading model into container now
2024-01-02 10:30:12,699:INFO:_master_model_container: 14
2024-01-02 10:30:12,699:INFO:_display_container: 2
2024-01-02 10:30:12,700:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-02 10:30:12,700:INFO:create_model() successfully completed......................................
2024-01-02 10:30:12,891:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:12,891:INFO:Creating metrics dataframe
2024-01-02 10:30:12,913:INFO:Initializing create_model()
2024-01-02 10:30:12,913:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:12,913:INFO:Checking exceptions
2024-01-02 10:30:12,915:INFO:Importing libraries
2024-01-02 10:30:12,915:INFO:Copying training dataset
2024-01-02 10:30:12,965:INFO:Defining folds
2024-01-02 10:30:12,965:INFO:Declaring metric variables
2024-01-02 10:30:12,966:INFO:Importing untrained model
2024-01-02 10:30:12,966:INFO:Declaring custom model
2024-01-02 10:30:12,966:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:30:12,968:INFO:Cross validation set to False
2024-01-02 10:30:12,968:INFO:Fitting Model
2024-01-02 10:30:13,098:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-02 10:30:13,098:INFO:[LightGBM] [Info] Number of positive: 19775, number of negative: 6273
2024-01-02 10:30:13,102:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001851 seconds.
2024-01-02 10:30:13,103:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-02 10:30:13,103:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-02 10:30:13,103:INFO:[LightGBM] [Info] Total Bins 733
2024-01-02 10:30:13,103:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 82
2024-01-02 10:30:13,104:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759175 -> initscore=1.148164
2024-01-02 10:30:13,104:INFO:[LightGBM] [Info] Start training from score 1.148164
2024-01-02 10:30:13,234:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:30:13,234:INFO:create_model() successfully completed......................................
2024-01-02 10:30:13,497:INFO:_master_model_container: 14
2024-01-02 10:30:13,498:INFO:_display_container: 2
2024-01-02 10:30:13,498:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:30:13,498:INFO:compare_models() successfully completed......................................
2024-01-02 10:30:14,075:INFO:Initializing compare_models()
2024-01-02 10:30:14,076:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-02 10:30:14,076:INFO:Checking exceptions
2024-01-02 10:30:14,098:INFO:Preparing display monitor
2024-01-02 10:30:14,132:INFO:Initializing Logistic Regression
2024-01-02 10:30:14,132:INFO:Total runtime is 0.0 minutes
2024-01-02 10:30:14,136:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:14,136:INFO:Initializing create_model()
2024-01-02 10:30:14,136:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:14,136:INFO:Checking exceptions
2024-01-02 10:30:14,136:INFO:Importing libraries
2024-01-02 10:30:14,137:INFO:Copying training dataset
2024-01-02 10:30:14,194:INFO:Defining folds
2024-01-02 10:30:14,194:INFO:Declaring metric variables
2024-01-02 10:30:14,198:INFO:Importing untrained model
2024-01-02 10:30:14,201:INFO:Logistic Regression Imported successfully
2024-01-02 10:30:14,208:INFO:Starting cross validation
2024-01-02 10:30:14,209:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:23,380:INFO:Calculating mean and std
2024-01-02 10:30:23,385:INFO:Creating metrics dataframe
2024-01-02 10:30:23,398:INFO:Uploading results into container
2024-01-02 10:30:23,402:INFO:Uploading model into container now
2024-01-02 10:30:23,403:INFO:_master_model_container: 15
2024-01-02 10:30:23,404:INFO:_display_container: 3
2024-01-02 10:30:23,405:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-02 10:30:23,405:INFO:create_model() successfully completed......................................
2024-01-02 10:30:23,584:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:23,584:INFO:Creating metrics dataframe
2024-01-02 10:30:23,593:INFO:Initializing K Neighbors Classifier
2024-01-02 10:30:23,593:INFO:Total runtime is 0.15769046942392986 minutes
2024-01-02 10:30:23,596:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:23,596:INFO:Initializing create_model()
2024-01-02 10:30:23,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:23,596:INFO:Checking exceptions
2024-01-02 10:30:23,597:INFO:Importing libraries
2024-01-02 10:30:23,597:INFO:Copying training dataset
2024-01-02 10:30:23,650:INFO:Defining folds
2024-01-02 10:30:23,650:INFO:Declaring metric variables
2024-01-02 10:30:23,653:INFO:Importing untrained model
2024-01-02 10:30:23,658:INFO:K Neighbors Classifier Imported successfully
2024-01-02 10:30:23,664:INFO:Starting cross validation
2024-01-02 10:30:23,666:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:27,388:INFO:Calculating mean and std
2024-01-02 10:30:27,389:INFO:Creating metrics dataframe
2024-01-02 10:30:27,393:INFO:Uploading results into container
2024-01-02 10:30:27,394:INFO:Uploading model into container now
2024-01-02 10:30:27,395:INFO:_master_model_container: 16
2024-01-02 10:30:27,395:INFO:_display_container: 3
2024-01-02 10:30:27,395:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-02 10:30:27,395:INFO:create_model() successfully completed......................................
2024-01-02 10:30:27,668:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:27,668:INFO:Creating metrics dataframe
2024-01-02 10:30:27,678:INFO:Initializing Naive Bayes
2024-01-02 10:30:27,679:INFO:Total runtime is 0.22578931252161663 minutes
2024-01-02 10:30:27,682:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:27,683:INFO:Initializing create_model()
2024-01-02 10:30:27,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:27,683:INFO:Checking exceptions
2024-01-02 10:30:27,683:INFO:Importing libraries
2024-01-02 10:30:27,683:INFO:Copying training dataset
2024-01-02 10:30:27,734:INFO:Defining folds
2024-01-02 10:30:27,734:INFO:Declaring metric variables
2024-01-02 10:30:27,738:INFO:Importing untrained model
2024-01-02 10:30:27,742:INFO:Naive Bayes Imported successfully
2024-01-02 10:30:27,750:INFO:Starting cross validation
2024-01-02 10:30:27,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:28,709:INFO:Calculating mean and std
2024-01-02 10:30:28,713:INFO:Creating metrics dataframe
2024-01-02 10:30:28,724:INFO:Uploading results into container
2024-01-02 10:30:28,727:INFO:Uploading model into container now
2024-01-02 10:30:28,728:INFO:_master_model_container: 17
2024-01-02 10:30:28,730:INFO:_display_container: 3
2024-01-02 10:30:28,730:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-02 10:30:28,731:INFO:create_model() successfully completed......................................
2024-01-02 10:30:28,956:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:28,956:INFO:Creating metrics dataframe
2024-01-02 10:30:28,966:INFO:Initializing Decision Tree Classifier
2024-01-02 10:30:28,966:INFO:Total runtime is 0.24722950458526613 minutes
2024-01-02 10:30:28,969:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:28,969:INFO:Initializing create_model()
2024-01-02 10:30:28,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:28,969:INFO:Checking exceptions
2024-01-02 10:30:28,969:INFO:Importing libraries
2024-01-02 10:30:28,969:INFO:Copying training dataset
2024-01-02 10:30:29,019:INFO:Defining folds
2024-01-02 10:30:29,019:INFO:Declaring metric variables
2024-01-02 10:30:29,023:INFO:Importing untrained model
2024-01-02 10:30:29,027:INFO:Decision Tree Classifier Imported successfully
2024-01-02 10:30:29,034:INFO:Starting cross validation
2024-01-02 10:30:29,035:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:30,371:INFO:Calculating mean and std
2024-01-02 10:30:30,373:INFO:Creating metrics dataframe
2024-01-02 10:30:30,376:INFO:Uploading results into container
2024-01-02 10:30:30,377:INFO:Uploading model into container now
2024-01-02 10:30:30,378:INFO:_master_model_container: 18
2024-01-02 10:30:30,378:INFO:_display_container: 3
2024-01-02 10:30:30,378:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-02 10:30:30,378:INFO:create_model() successfully completed......................................
2024-01-02 10:30:30,609:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:30,609:INFO:Creating metrics dataframe
2024-01-02 10:30:30,619:INFO:Initializing SVM - Linear Kernel
2024-01-02 10:30:30,619:INFO:Total runtime is 0.2747788389523824 minutes
2024-01-02 10:30:30,623:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:30,623:INFO:Initializing create_model()
2024-01-02 10:30:30,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:30,623:INFO:Checking exceptions
2024-01-02 10:30:30,624:INFO:Importing libraries
2024-01-02 10:30:30,624:INFO:Copying training dataset
2024-01-02 10:30:30,677:INFO:Defining folds
2024-01-02 10:30:30,677:INFO:Declaring metric variables
2024-01-02 10:30:30,681:INFO:Importing untrained model
2024-01-02 10:30:30,686:INFO:SVM - Linear Kernel Imported successfully
2024-01-02 10:30:30,692:INFO:Starting cross validation
2024-01-02 10:30:30,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:32,032:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,082:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,110:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,136:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,138:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,212:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,216:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,225:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,239:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,275:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-02 10:30:32,405:INFO:Calculating mean and std
2024-01-02 10:30:32,407:INFO:Creating metrics dataframe
2024-01-02 10:30:32,410:INFO:Uploading results into container
2024-01-02 10:30:32,410:INFO:Uploading model into container now
2024-01-02 10:30:32,411:INFO:_master_model_container: 19
2024-01-02 10:30:32,411:INFO:_display_container: 3
2024-01-02 10:30:32,411:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-02 10:30:32,411:INFO:create_model() successfully completed......................................
2024-01-02 10:30:32,621:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:32,621:INFO:Creating metrics dataframe
2024-01-02 10:30:32,631:INFO:Initializing Ridge Classifier
2024-01-02 10:30:32,631:INFO:Total runtime is 0.308320148785909 minutes
2024-01-02 10:30:32,634:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:32,635:INFO:Initializing create_model()
2024-01-02 10:30:32,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:32,635:INFO:Checking exceptions
2024-01-02 10:30:32,635:INFO:Importing libraries
2024-01-02 10:30:32,635:INFO:Copying training dataset
2024-01-02 10:30:32,693:INFO:Defining folds
2024-01-02 10:30:32,694:INFO:Declaring metric variables
2024-01-02 10:30:32,698:INFO:Importing untrained model
2024-01-02 10:30:32,702:INFO:Ridge Classifier Imported successfully
2024-01-02 10:30:32,710:INFO:Starting cross validation
2024-01-02 10:30:32,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:33,377:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,407:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,408:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,424:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,434:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,441:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,459:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,463:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,466:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,469:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-02 10:30:33,599:INFO:Calculating mean and std
2024-01-02 10:30:33,601:INFO:Creating metrics dataframe
2024-01-02 10:30:33,604:INFO:Uploading results into container
2024-01-02 10:30:33,605:INFO:Uploading model into container now
2024-01-02 10:30:33,605:INFO:_master_model_container: 20
2024-01-02 10:30:33,605:INFO:_display_container: 3
2024-01-02 10:30:33,606:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-02 10:30:33,606:INFO:create_model() successfully completed......................................
2024-01-02 10:30:33,806:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:33,806:INFO:Creating metrics dataframe
2024-01-02 10:30:33,816:INFO:Initializing Random Forest Classifier
2024-01-02 10:30:33,817:INFO:Total runtime is 0.3280907154083252 minutes
2024-01-02 10:30:33,819:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:33,820:INFO:Initializing create_model()
2024-01-02 10:30:33,820:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:33,820:INFO:Checking exceptions
2024-01-02 10:30:33,820:INFO:Importing libraries
2024-01-02 10:30:33,820:INFO:Copying training dataset
2024-01-02 10:30:33,876:INFO:Defining folds
2024-01-02 10:30:33,877:INFO:Declaring metric variables
2024-01-02 10:30:33,884:INFO:Importing untrained model
2024-01-02 10:30:33,892:INFO:Random Forest Classifier Imported successfully
2024-01-02 10:30:33,904:INFO:Starting cross validation
2024-01-02 10:30:33,907:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:42,886:INFO:Calculating mean and std
2024-01-02 10:30:42,887:INFO:Creating metrics dataframe
2024-01-02 10:30:42,891:INFO:Uploading results into container
2024-01-02 10:30:42,892:INFO:Uploading model into container now
2024-01-02 10:30:42,893:INFO:_master_model_container: 21
2024-01-02 10:30:42,893:INFO:_display_container: 3
2024-01-02 10:30:42,894:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-02 10:30:42,894:INFO:create_model() successfully completed......................................
2024-01-02 10:30:43,101:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:43,101:INFO:Creating metrics dataframe
2024-01-02 10:30:43,111:INFO:Initializing Quadratic Discriminant Analysis
2024-01-02 10:30:43,111:INFO:Total runtime is 0.4829850713411967 minutes
2024-01-02 10:30:43,114:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:43,114:INFO:Initializing create_model()
2024-01-02 10:30:43,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:43,115:INFO:Checking exceptions
2024-01-02 10:30:43,115:INFO:Importing libraries
2024-01-02 10:30:43,115:INFO:Copying training dataset
2024-01-02 10:30:43,170:INFO:Defining folds
2024-01-02 10:30:43,171:INFO:Declaring metric variables
2024-01-02 10:30:43,175:INFO:Importing untrained model
2024-01-02 10:30:43,179:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-02 10:30:43,186:INFO:Starting cross validation
2024-01-02 10:30:43,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:43,750:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,803:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,818:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,850:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,855:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,862:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,882:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,914:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:43,928:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-02 10:30:45,211:INFO:Calculating mean and std
2024-01-02 10:30:45,215:INFO:Creating metrics dataframe
2024-01-02 10:30:45,227:INFO:Uploading results into container
2024-01-02 10:30:45,230:INFO:Uploading model into container now
2024-01-02 10:30:45,231:INFO:_master_model_container: 22
2024-01-02 10:30:45,232:INFO:_display_container: 3
2024-01-02 10:30:45,232:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-02 10:30:45,233:INFO:create_model() successfully completed......................................
2024-01-02 10:30:45,433:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:45,434:INFO:Creating metrics dataframe
2024-01-02 10:30:45,445:INFO:Initializing Ada Boost Classifier
2024-01-02 10:30:45,445:INFO:Total runtime is 0.5218864003817241 minutes
2024-01-02 10:30:45,448:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:45,449:INFO:Initializing create_model()
2024-01-02 10:30:45,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:45,449:INFO:Checking exceptions
2024-01-02 10:30:45,449:INFO:Importing libraries
2024-01-02 10:30:45,449:INFO:Copying training dataset
2024-01-02 10:30:45,499:INFO:Defining folds
2024-01-02 10:30:45,499:INFO:Declaring metric variables
2024-01-02 10:30:45,503:INFO:Importing untrained model
2024-01-02 10:30:45,507:INFO:Ada Boost Classifier Imported successfully
2024-01-02 10:30:45,514:INFO:Starting cross validation
2024-01-02 10:30:45,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:48,348:INFO:Calculating mean and std
2024-01-02 10:30:48,352:INFO:Creating metrics dataframe
2024-01-02 10:30:48,366:INFO:Uploading results into container
2024-01-02 10:30:48,368:INFO:Uploading model into container now
2024-01-02 10:30:48,369:INFO:_master_model_container: 23
2024-01-02 10:30:48,369:INFO:_display_container: 3
2024-01-02 10:30:48,370:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-02 10:30:48,371:INFO:create_model() successfully completed......................................
2024-01-02 10:30:48,554:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:48,554:INFO:Creating metrics dataframe
2024-01-02 10:30:48,565:INFO:Initializing Gradient Boosting Classifier
2024-01-02 10:30:48,565:INFO:Total runtime is 0.5738903601964315 minutes
2024-01-02 10:30:48,568:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:48,569:INFO:Initializing create_model()
2024-01-02 10:30:48,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:48,569:INFO:Checking exceptions
2024-01-02 10:30:48,569:INFO:Importing libraries
2024-01-02 10:30:48,569:INFO:Copying training dataset
2024-01-02 10:30:48,620:INFO:Defining folds
2024-01-02 10:30:48,620:INFO:Declaring metric variables
2024-01-02 10:30:48,624:INFO:Importing untrained model
2024-01-02 10:30:48,628:INFO:Gradient Boosting Classifier Imported successfully
2024-01-02 10:30:48,634:INFO:Starting cross validation
2024-01-02 10:30:48,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:30:57,507:INFO:Calculating mean and std
2024-01-02 10:30:57,508:INFO:Creating metrics dataframe
2024-01-02 10:30:57,512:INFO:Uploading results into container
2024-01-02 10:30:57,513:INFO:Uploading model into container now
2024-01-02 10:30:57,514:INFO:_master_model_container: 24
2024-01-02 10:30:57,514:INFO:_display_container: 3
2024-01-02 10:30:57,514:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-02 10:30:57,514:INFO:create_model() successfully completed......................................
2024-01-02 10:30:57,719:INFO:SubProcess create_model() end ==================================
2024-01-02 10:30:57,719:INFO:Creating metrics dataframe
2024-01-02 10:30:57,730:INFO:Initializing Linear Discriminant Analysis
2024-01-02 10:30:57,730:INFO:Total runtime is 0.7266313592592875 minutes
2024-01-02 10:30:57,733:INFO:SubProcess create_model() called ==================================
2024-01-02 10:30:57,734:INFO:Initializing create_model()
2024-01-02 10:30:57,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:30:57,734:INFO:Checking exceptions
2024-01-02 10:30:57,734:INFO:Importing libraries
2024-01-02 10:30:57,734:INFO:Copying training dataset
2024-01-02 10:30:57,784:INFO:Defining folds
2024-01-02 10:30:57,784:INFO:Declaring metric variables
2024-01-02 10:30:57,788:INFO:Importing untrained model
2024-01-02 10:30:57,792:INFO:Linear Discriminant Analysis Imported successfully
2024-01-02 10:30:57,799:INFO:Starting cross validation
2024-01-02 10:30:57,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:31:03,958:INFO:Calculating mean and std
2024-01-02 10:31:03,959:INFO:Creating metrics dataframe
2024-01-02 10:31:03,964:INFO:Uploading results into container
2024-01-02 10:31:03,964:INFO:Uploading model into container now
2024-01-02 10:31:03,965:INFO:_master_model_container: 25
2024-01-02 10:31:03,965:INFO:_display_container: 3
2024-01-02 10:31:03,965:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-02 10:31:03,965:INFO:create_model() successfully completed......................................
2024-01-02 10:31:04,235:INFO:SubProcess create_model() end ==================================
2024-01-02 10:31:04,235:INFO:Creating metrics dataframe
2024-01-02 10:31:04,251:INFO:Initializing Extra Trees Classifier
2024-01-02 10:31:04,252:INFO:Total runtime is 0.835333502292633 minutes
2024-01-02 10:31:04,257:INFO:SubProcess create_model() called ==================================
2024-01-02 10:31:04,257:INFO:Initializing create_model()
2024-01-02 10:31:04,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:31:04,257:INFO:Checking exceptions
2024-01-02 10:31:04,257:INFO:Importing libraries
2024-01-02 10:31:04,257:INFO:Copying training dataset
2024-01-02 10:31:04,320:INFO:Defining folds
2024-01-02 10:31:04,321:INFO:Declaring metric variables
2024-01-02 10:31:04,326:INFO:Importing untrained model
2024-01-02 10:31:04,331:INFO:Extra Trees Classifier Imported successfully
2024-01-02 10:31:04,340:INFO:Starting cross validation
2024-01-02 10:31:04,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:31:16,876:INFO:Calculating mean and std
2024-01-02 10:31:16,884:INFO:Creating metrics dataframe
2024-01-02 10:31:16,897:INFO:Uploading results into container
2024-01-02 10:31:16,900:INFO:Uploading model into container now
2024-01-02 10:31:16,901:INFO:_master_model_container: 26
2024-01-02 10:31:16,902:INFO:_display_container: 3
2024-01-02 10:31:16,902:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-02 10:31:16,903:INFO:create_model() successfully completed......................................
2024-01-02 10:31:17,091:INFO:SubProcess create_model() end ==================================
2024-01-02 10:31:17,091:INFO:Creating metrics dataframe
2024-01-02 10:31:17,103:INFO:Initializing Light Gradient Boosting Machine
2024-01-02 10:31:17,103:INFO:Total runtime is 1.0495076020558676 minutes
2024-01-02 10:31:17,106:INFO:SubProcess create_model() called ==================================
2024-01-02 10:31:17,106:INFO:Initializing create_model()
2024-01-02 10:31:17,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:31:17,106:INFO:Checking exceptions
2024-01-02 10:31:17,106:INFO:Importing libraries
2024-01-02 10:31:17,106:INFO:Copying training dataset
2024-01-02 10:31:17,158:INFO:Defining folds
2024-01-02 10:31:17,158:INFO:Declaring metric variables
2024-01-02 10:31:17,162:INFO:Importing untrained model
2024-01-02 10:31:17,165:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:31:17,172:INFO:Starting cross validation
2024-01-02 10:31:17,173:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:31:19,381:INFO:Calculating mean and std
2024-01-02 10:31:19,382:INFO:Creating metrics dataframe
2024-01-02 10:31:19,386:INFO:Uploading results into container
2024-01-02 10:31:19,386:INFO:Uploading model into container now
2024-01-02 10:31:19,387:INFO:_master_model_container: 27
2024-01-02 10:31:19,387:INFO:_display_container: 3
2024-01-02 10:31:19,387:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:31:19,387:INFO:create_model() successfully completed......................................
2024-01-02 10:31:19,571:INFO:SubProcess create_model() end ==================================
2024-01-02 10:31:19,571:INFO:Creating metrics dataframe
2024-01-02 10:31:19,582:INFO:Initializing Dummy Classifier
2024-01-02 10:31:19,582:INFO:Total runtime is 1.0908354242642722 minutes
2024-01-02 10:31:19,586:INFO:SubProcess create_model() called ==================================
2024-01-02 10:31:19,586:INFO:Initializing create_model()
2024-01-02 10:31:19,586:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002219640F250>, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:31:19,586:INFO:Checking exceptions
2024-01-02 10:31:19,586:INFO:Importing libraries
2024-01-02 10:31:19,586:INFO:Copying training dataset
2024-01-02 10:31:19,638:INFO:Defining folds
2024-01-02 10:31:19,638:INFO:Declaring metric variables
2024-01-02 10:31:19,641:INFO:Importing untrained model
2024-01-02 10:31:19,645:INFO:Dummy Classifier Imported successfully
2024-01-02 10:31:19,652:INFO:Starting cross validation
2024-01-02 10:31:19,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-02 10:31:20,288:INFO:Calculating mean and std
2024-01-02 10:31:20,289:INFO:Creating metrics dataframe
2024-01-02 10:31:20,293:INFO:Uploading results into container
2024-01-02 10:31:20,293:INFO:Uploading model into container now
2024-01-02 10:31:20,294:INFO:_master_model_container: 28
2024-01-02 10:31:20,294:INFO:_display_container: 3
2024-01-02 10:31:20,294:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-02 10:31:20,294:INFO:create_model() successfully completed......................................
2024-01-02 10:31:20,476:INFO:SubProcess create_model() end ==================================
2024-01-02 10:31:20,476:INFO:Creating metrics dataframe
2024-01-02 10:31:20,497:INFO:Initializing create_model()
2024-01-02 10:31:20,497:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002219640F2B0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-02 10:31:20,497:INFO:Checking exceptions
2024-01-02 10:31:20,499:INFO:Importing libraries
2024-01-02 10:31:20,499:INFO:Copying training dataset
2024-01-02 10:31:20,549:INFO:Defining folds
2024-01-02 10:31:20,549:INFO:Declaring metric variables
2024-01-02 10:31:20,550:INFO:Importing untrained model
2024-01-02 10:31:20,550:INFO:Declaring custom model
2024-01-02 10:31:20,550:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-02 10:31:20,552:INFO:Cross validation set to False
2024-01-02 10:31:20,552:INFO:Fitting Model
2024-01-02 10:31:20,657:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-02 10:31:20,657:INFO:[LightGBM] [Info] Number of positive: 19775, number of negative: 6273
2024-01-02 10:31:20,660:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001152 seconds.
2024-01-02 10:31:20,660:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-02 10:31:20,660:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-02 10:31:20,661:INFO:[LightGBM] [Info] Total Bins 733
2024-01-02 10:31:20,661:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 82
2024-01-02 10:31:20,661:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.759175 -> initscore=1.148164
2024-01-02 10:31:20,661:INFO:[LightGBM] [Info] Start training from score 1.148164
2024-01-02 10:31:20,783:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:31:20,783:INFO:create_model() successfully completed......................................
2024-01-02 10:31:21,042:INFO:_master_model_container: 28
2024-01-02 10:31:21,042:INFO:_display_container: 3
2024-01-02 10:31:21,043:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-02 10:31:21,043:INFO:compare_models() successfully completed......................................
2024-01-03 05:13:09,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:13:09,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:13:09,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:13:09,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:13:09,916:INFO:PyCaret ClassificationExperiment
2024-01-03 05:13:09,916:INFO:Logging name: clf-default-name
2024-01-03 05:13:09,916:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:13:09,916:INFO:version 3.1.0
2024-01-03 05:13:09,916:INFO:Initializing setup()
2024-01-03 05:13:09,916:INFO:self.USI: 16af
2024-01-03 05:13:09,916:INFO:self._variable_keys: {'USI', 'X_train', 'exp_id', 'gpu_param', 'X', 'memory', 'fix_imbalance', 'n_jobs_param', 'fold_generator', 'html_param', '_ml_usecase', 'idx', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'y_train', 'y', 'y_test', 'X_test', 'target_param', 'logging_param', '_available_plots', 'data', 'is_multiclass', 'seed', 'pipeline', 'fold_groups_param', 'fold_shuffle_param'}
2024-01-03 05:13:09,916:INFO:Checking environment
2024-01-03 05:13:09,916:INFO:python_version: 3.10.9
2024-01-03 05:13:09,916:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:13:09,916:INFO:machine: AMD64
2024-01-03 05:13:09,916:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:13:09,917:INFO:Memory: svmem(total=16954372096, available=3255877632, percent=80.8, used=13698494464, free=3255877632)
2024-01-03 05:13:09,917:INFO:Physical Core: 8
2024-01-03 05:13:09,917:INFO:Logical Core: 16
2024-01-03 05:13:09,917:INFO:Checking libraries
2024-01-03 05:13:09,917:INFO:System:
2024-01-03 05:13:09,917:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:13:09,917:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:13:09,917:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:13:09,917:INFO:PyCaret required dependencies:
2024-01-03 05:13:10,642:INFO:                 pip: 22.3.1
2024-01-03 05:13:10,642:INFO:          setuptools: 65.6.3
2024-01-03 05:13:10,642:INFO:             pycaret: 3.1.0
2024-01-03 05:13:10,642:INFO:             IPython: 8.10.0
2024-01-03 05:13:10,643:INFO:          ipywidgets: 7.6.5
2024-01-03 05:13:10,643:INFO:                tqdm: 4.64.1
2024-01-03 05:13:10,643:INFO:               numpy: 1.23.5
2024-01-03 05:13:10,643:INFO:              pandas: 1.5.3
2024-01-03 05:13:10,643:INFO:              jinja2: 3.1.2
2024-01-03 05:13:10,643:INFO:               scipy: 1.10.1
2024-01-03 05:13:10,643:INFO:              joblib: 1.3.2
2024-01-03 05:13:10,643:INFO:             sklearn: 1.2.1
2024-01-03 05:13:10,643:INFO:                pyod: 1.1.0
2024-01-03 05:13:10,643:INFO:            imblearn: 0.10.1
2024-01-03 05:13:10,643:INFO:   category_encoders: 2.6.2
2024-01-03 05:13:10,643:INFO:            lightgbm: 4.1.0
2024-01-03 05:13:10,643:INFO:               numba: 0.56.4
2024-01-03 05:13:10,643:INFO:            requests: 2.28.1
2024-01-03 05:13:10,643:INFO:          matplotlib: 3.7.0
2024-01-03 05:13:10,643:INFO:          scikitplot: 0.3.7
2024-01-03 05:13:10,643:INFO:         yellowbrick: 1.5
2024-01-03 05:13:10,643:INFO:              plotly: 5.9.0
2024-01-03 05:13:10,643:INFO:    plotly-resampler: Not installed
2024-01-03 05:13:10,643:INFO:             kaleido: 0.2.1
2024-01-03 05:13:10,643:INFO:           schemdraw: 0.15
2024-01-03 05:13:10,643:INFO:         statsmodels: 0.13.5
2024-01-03 05:13:10,643:INFO:              sktime: 0.21.1
2024-01-03 05:13:10,643:INFO:               tbats: 1.1.3
2024-01-03 05:13:10,643:INFO:            pmdarima: 2.0.3
2024-01-03 05:13:10,644:INFO:              psutil: 5.9.0
2024-01-03 05:13:10,644:INFO:          markupsafe: 2.1.1
2024-01-03 05:13:10,644:INFO:             pickle5: Not installed
2024-01-03 05:13:10,644:INFO:         cloudpickle: 2.0.0
2024-01-03 05:13:10,644:INFO:         deprecation: 2.1.0
2024-01-03 05:13:10,644:INFO:              xxhash: 3.4.1
2024-01-03 05:13:10,644:INFO:           wurlitzer: Not installed
2024-01-03 05:13:10,644:INFO:PyCaret optional dependencies:
2024-01-03 05:13:10,658:INFO:                shap: Not installed
2024-01-03 05:13:10,658:INFO:           interpret: Not installed
2024-01-03 05:13:10,658:INFO:                umap: Not installed
2024-01-03 05:13:10,659:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:13:10,659:INFO:  explainerdashboard: Not installed
2024-01-03 05:13:10,659:INFO:             autoviz: Not installed
2024-01-03 05:13:10,659:INFO:           fairlearn: Not installed
2024-01-03 05:13:10,659:INFO:          deepchecks: Not installed
2024-01-03 05:13:10,659:INFO:             xgboost: Not installed
2024-01-03 05:13:10,659:INFO:            catboost: Not installed
2024-01-03 05:13:10,659:INFO:              kmodes: Not installed
2024-01-03 05:13:10,659:INFO:             mlxtend: Not installed
2024-01-03 05:13:10,659:INFO:       statsforecast: Not installed
2024-01-03 05:13:10,659:INFO:        tune_sklearn: Not installed
2024-01-03 05:13:10,659:INFO:                 ray: Not installed
2024-01-03 05:13:10,659:INFO:            hyperopt: Not installed
2024-01-03 05:13:10,659:INFO:              optuna: Not installed
2024-01-03 05:13:10,659:INFO:               skopt: Not installed
2024-01-03 05:13:10,659:INFO:              mlflow: Not installed
2024-01-03 05:13:10,659:INFO:              gradio: Not installed
2024-01-03 05:13:10,659:INFO:             fastapi: Not installed
2024-01-03 05:13:10,659:INFO:             uvicorn: Not installed
2024-01-03 05:13:10,659:INFO:              m2cgen: Not installed
2024-01-03 05:13:10,659:INFO:           evidently: Not installed
2024-01-03 05:13:10,659:INFO:               fugue: Not installed
2024-01-03 05:13:10,659:INFO:           streamlit: Not installed
2024-01-03 05:13:10,659:INFO:             prophet: Not installed
2024-01-03 05:13:10,660:INFO:None
2024-01-03 05:13:10,660:INFO:Set up data.
2024-01-03 05:13:23,257:INFO:PyCaret ClassificationExperiment
2024-01-03 05:13:23,257:INFO:Logging name: clf-default-name
2024-01-03 05:13:23,257:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:13:23,257:INFO:version 3.1.0
2024-01-03 05:13:23,257:INFO:Initializing setup()
2024-01-03 05:13:23,257:INFO:self.USI: 46ed
2024-01-03 05:13:23,257:INFO:self._variable_keys: {'USI', 'X_train', 'exp_id', 'gpu_param', 'X', 'memory', 'fix_imbalance', 'n_jobs_param', 'fold_generator', 'html_param', '_ml_usecase', 'idx', 'exp_name_log', 'gpu_n_jobs_param', 'log_plots_param', 'y_train', 'y', 'y_test', 'X_test', 'target_param', 'logging_param', '_available_plots', 'data', 'is_multiclass', 'seed', 'pipeline', 'fold_groups_param', 'fold_shuffle_param'}
2024-01-03 05:13:23,257:INFO:Checking environment
2024-01-03 05:13:23,258:INFO:python_version: 3.10.9
2024-01-03 05:13:23,258:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:13:23,258:INFO:machine: AMD64
2024-01-03 05:13:23,258:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:13:23,258:INFO:Memory: svmem(total=16954372096, available=3232751616, percent=80.9, used=13721620480, free=3232751616)
2024-01-03 05:13:23,258:INFO:Physical Core: 8
2024-01-03 05:13:23,258:INFO:Logical Core: 16
2024-01-03 05:13:23,258:INFO:Checking libraries
2024-01-03 05:13:23,258:INFO:System:
2024-01-03 05:13:23,258:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:13:23,258:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:13:23,258:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:13:23,258:INFO:PyCaret required dependencies:
2024-01-03 05:13:23,258:INFO:                 pip: 22.3.1
2024-01-03 05:13:23,258:INFO:          setuptools: 65.6.3
2024-01-03 05:13:23,258:INFO:             pycaret: 3.1.0
2024-01-03 05:13:23,258:INFO:             IPython: 8.10.0
2024-01-03 05:13:23,258:INFO:          ipywidgets: 7.6.5
2024-01-03 05:13:23,258:INFO:                tqdm: 4.64.1
2024-01-03 05:13:23,258:INFO:               numpy: 1.23.5
2024-01-03 05:13:23,258:INFO:              pandas: 1.5.3
2024-01-03 05:13:23,259:INFO:              jinja2: 3.1.2
2024-01-03 05:13:23,259:INFO:               scipy: 1.10.1
2024-01-03 05:13:23,259:INFO:              joblib: 1.3.2
2024-01-03 05:13:23,259:INFO:             sklearn: 1.2.1
2024-01-03 05:13:23,259:INFO:                pyod: 1.1.0
2024-01-03 05:13:23,259:INFO:            imblearn: 0.10.1
2024-01-03 05:13:23,259:INFO:   category_encoders: 2.6.2
2024-01-03 05:13:23,259:INFO:            lightgbm: 4.1.0
2024-01-03 05:13:23,259:INFO:               numba: 0.56.4
2024-01-03 05:13:23,259:INFO:            requests: 2.28.1
2024-01-03 05:13:23,259:INFO:          matplotlib: 3.7.0
2024-01-03 05:13:23,259:INFO:          scikitplot: 0.3.7
2024-01-03 05:13:23,259:INFO:         yellowbrick: 1.5
2024-01-03 05:13:23,259:INFO:              plotly: 5.9.0
2024-01-03 05:13:23,259:INFO:    plotly-resampler: Not installed
2024-01-03 05:13:23,357:INFO:             kaleido: 0.2.1
2024-01-03 05:13:23,357:INFO:           schemdraw: 0.15
2024-01-03 05:13:23,357:INFO:         statsmodels: 0.13.5
2024-01-03 05:13:23,357:INFO:              sktime: 0.21.1
2024-01-03 05:13:23,357:INFO:               tbats: 1.1.3
2024-01-03 05:13:23,357:INFO:            pmdarima: 2.0.3
2024-01-03 05:13:23,357:INFO:              psutil: 5.9.0
2024-01-03 05:13:23,357:INFO:          markupsafe: 2.1.1
2024-01-03 05:13:23,357:INFO:             pickle5: Not installed
2024-01-03 05:13:23,357:INFO:         cloudpickle: 2.0.0
2024-01-03 05:13:23,357:INFO:         deprecation: 2.1.0
2024-01-03 05:13:23,357:INFO:              xxhash: 3.4.1
2024-01-03 05:13:23,357:INFO:           wurlitzer: Not installed
2024-01-03 05:13:23,357:INFO:PyCaret optional dependencies:
2024-01-03 05:13:23,357:INFO:                shap: Not installed
2024-01-03 05:13:23,357:INFO:           interpret: Not installed
2024-01-03 05:13:23,357:INFO:                umap: Not installed
2024-01-03 05:13:23,357:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:13:23,358:INFO:  explainerdashboard: Not installed
2024-01-03 05:13:23,358:INFO:             autoviz: Not installed
2024-01-03 05:13:23,358:INFO:           fairlearn: Not installed
2024-01-03 05:13:23,358:INFO:          deepchecks: Not installed
2024-01-03 05:13:23,358:INFO:             xgboost: Not installed
2024-01-03 05:13:23,358:INFO:            catboost: Not installed
2024-01-03 05:13:23,358:INFO:              kmodes: Not installed
2024-01-03 05:13:23,358:INFO:             mlxtend: Not installed
2024-01-03 05:13:23,358:INFO:       statsforecast: Not installed
2024-01-03 05:13:23,358:INFO:        tune_sklearn: Not installed
2024-01-03 05:13:23,358:INFO:                 ray: Not installed
2024-01-03 05:13:23,358:INFO:            hyperopt: Not installed
2024-01-03 05:13:23,358:INFO:              optuna: Not installed
2024-01-03 05:13:23,358:INFO:               skopt: Not installed
2024-01-03 05:13:23,358:INFO:              mlflow: Not installed
2024-01-03 05:13:23,358:INFO:              gradio: Not installed
2024-01-03 05:13:23,358:INFO:             fastapi: Not installed
2024-01-03 05:13:23,358:INFO:             uvicorn: Not installed
2024-01-03 05:13:23,358:INFO:              m2cgen: Not installed
2024-01-03 05:13:23,358:INFO:           evidently: Not installed
2024-01-03 05:13:23,358:INFO:               fugue: Not installed
2024-01-03 05:13:23,359:INFO:           streamlit: Not installed
2024-01-03 05:13:23,359:INFO:             prophet: Not installed
2024-01-03 05:13:23,359:INFO:None
2024-01-03 05:13:23,359:INFO:Set up data.
2024-01-03 05:13:23,394:INFO:Set up folding strategy.
2024-01-03 05:13:23,394:INFO:Set up train/test split.
2024-01-03 05:13:23,426:INFO:Set up index.
2024-01-03 05:13:23,427:INFO:Assigning column types.
2024-01-03 05:13:23,445:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 05:13:23,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:13:23,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:13:23,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,553:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:13:23,554:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:13:23,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,577:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 05:13:23,615:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:13:23,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,678:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:13:23,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,702:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 05:13:23,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,763:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:23,836:INFO:Preparing preprocessing pipeline...
2024-01-03 05:13:23,841:INFO:Set up simple imputation.
2024-01-03 05:13:23,844:INFO:Set up column name cleaning.
2024-01-03 05:13:23,973:INFO:Finished creating preprocessing pipeline.
2024-01-03 05:13:23,978:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-03 05:13:24,008:INFO:Creating final display dataframe.
2024-01-03 05:13:24,420:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              46ed
2024-01-03 05:13:24,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:24,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:24,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:24,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:13:24,579:INFO:setup() successfully completed in 1.33s...............
2024-01-03 05:13:41,488:INFO:Initializing compare_models()
2024-01-03 05:13:41,488:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-03 05:13:41,488:INFO:Checking exceptions
2024-01-03 05:13:41,505:INFO:Preparing display monitor
2024-01-03 05:13:41,532:INFO:Initializing Logistic Regression
2024-01-03 05:13:41,532:INFO:Total runtime is 1.6597906748453774e-05 minutes
2024-01-03 05:13:41,535:INFO:SubProcess create_model() called ==================================
2024-01-03 05:13:41,536:INFO:Initializing create_model()
2024-01-03 05:13:41,536:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:13:41,536:INFO:Checking exceptions
2024-01-03 05:13:41,536:INFO:Importing libraries
2024-01-03 05:13:41,536:INFO:Copying training dataset
2024-01-03 05:13:41,579:INFO:Defining folds
2024-01-03 05:13:41,579:INFO:Declaring metric variables
2024-01-03 05:13:41,583:INFO:Importing untrained model
2024-01-03 05:13:41,586:INFO:Logistic Regression Imported successfully
2024-01-03 05:13:41,594:INFO:Starting cross validation
2024-01-03 05:13:41,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:17,074:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,422:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,613:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,697:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,822:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,869:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,949:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:17,995:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:18,042:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:14:18,203:INFO:Calculating mean and std
2024-01-03 05:14:18,207:INFO:Creating metrics dataframe
2024-01-03 05:14:18,219:INFO:Uploading results into container
2024-01-03 05:14:18,221:INFO:Uploading model into container now
2024-01-03 05:14:18,223:INFO:_master_model_container: 1
2024-01-03 05:14:18,223:INFO:_display_container: 2
2024-01-03 05:14:18,224:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 05:14:18,224:INFO:create_model() successfully completed......................................
2024-01-03 05:14:18,438:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:18,438:INFO:Creating metrics dataframe
2024-01-03 05:14:18,450:INFO:Initializing K Neighbors Classifier
2024-01-03 05:14:18,450:INFO:Total runtime is 0.6153186996777853 minutes
2024-01-03 05:14:18,454:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:18,455:INFO:Initializing create_model()
2024-01-03 05:14:18,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:18,455:INFO:Checking exceptions
2024-01-03 05:14:18,455:INFO:Importing libraries
2024-01-03 05:14:18,455:INFO:Copying training dataset
2024-01-03 05:14:18,506:INFO:Defining folds
2024-01-03 05:14:18,506:INFO:Declaring metric variables
2024-01-03 05:14:18,510:INFO:Importing untrained model
2024-01-03 05:14:18,514:INFO:K Neighbors Classifier Imported successfully
2024-01-03 05:14:18,520:INFO:Starting cross validation
2024-01-03 05:14:18,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:24,402:INFO:Calculating mean and std
2024-01-03 05:14:24,405:INFO:Creating metrics dataframe
2024-01-03 05:14:24,411:INFO:Uploading results into container
2024-01-03 05:14:24,412:INFO:Uploading model into container now
2024-01-03 05:14:24,413:INFO:_master_model_container: 2
2024-01-03 05:14:24,413:INFO:_display_container: 2
2024-01-03 05:14:24,414:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 05:14:24,414:INFO:create_model() successfully completed......................................
2024-01-03 05:14:24,627:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:24,627:INFO:Creating metrics dataframe
2024-01-03 05:14:24,635:INFO:Initializing Naive Bayes
2024-01-03 05:14:24,635:INFO:Total runtime is 0.7184025486310324 minutes
2024-01-03 05:14:24,638:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:24,639:INFO:Initializing create_model()
2024-01-03 05:14:24,639:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:24,639:INFO:Checking exceptions
2024-01-03 05:14:24,639:INFO:Importing libraries
2024-01-03 05:14:24,639:INFO:Copying training dataset
2024-01-03 05:14:24,680:INFO:Defining folds
2024-01-03 05:14:24,680:INFO:Declaring metric variables
2024-01-03 05:14:24,683:INFO:Importing untrained model
2024-01-03 05:14:24,688:INFO:Naive Bayes Imported successfully
2024-01-03 05:14:24,694:INFO:Starting cross validation
2024-01-03 05:14:24,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:25,925:INFO:Calculating mean and std
2024-01-03 05:14:25,927:INFO:Creating metrics dataframe
2024-01-03 05:14:25,932:INFO:Uploading results into container
2024-01-03 05:14:25,932:INFO:Uploading model into container now
2024-01-03 05:14:25,933:INFO:_master_model_container: 3
2024-01-03 05:14:25,933:INFO:_display_container: 2
2024-01-03 05:14:25,933:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 05:14:25,933:INFO:create_model() successfully completed......................................
2024-01-03 05:14:26,192:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:26,192:INFO:Creating metrics dataframe
2024-01-03 05:14:26,201:INFO:Initializing Decision Tree Classifier
2024-01-03 05:14:26,201:INFO:Total runtime is 0.744496238231659 minutes
2024-01-03 05:14:26,203:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:26,204:INFO:Initializing create_model()
2024-01-03 05:14:26,204:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:26,204:INFO:Checking exceptions
2024-01-03 05:14:26,204:INFO:Importing libraries
2024-01-03 05:14:26,204:INFO:Copying training dataset
2024-01-03 05:14:26,246:INFO:Defining folds
2024-01-03 05:14:26,246:INFO:Declaring metric variables
2024-01-03 05:14:26,250:INFO:Importing untrained model
2024-01-03 05:14:26,255:INFO:Decision Tree Classifier Imported successfully
2024-01-03 05:14:26,261:INFO:Starting cross validation
2024-01-03 05:14:26,263:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:27,659:INFO:Calculating mean and std
2024-01-03 05:14:27,663:INFO:Creating metrics dataframe
2024-01-03 05:14:27,675:INFO:Uploading results into container
2024-01-03 05:14:27,677:INFO:Uploading model into container now
2024-01-03 05:14:27,678:INFO:_master_model_container: 4
2024-01-03 05:14:27,678:INFO:_display_container: 2
2024-01-03 05:14:27,679:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-03 05:14:27,680:INFO:create_model() successfully completed......................................
2024-01-03 05:14:28,017:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:28,017:INFO:Creating metrics dataframe
2024-01-03 05:14:28,028:INFO:Initializing SVM - Linear Kernel
2024-01-03 05:14:28,029:INFO:Total runtime is 0.7749632120132447 minutes
2024-01-03 05:14:28,033:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:28,034:INFO:Initializing create_model()
2024-01-03 05:14:28,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:28,034:INFO:Checking exceptions
2024-01-03 05:14:28,034:INFO:Importing libraries
2024-01-03 05:14:28,035:INFO:Copying training dataset
2024-01-03 05:14:28,078:INFO:Defining folds
2024-01-03 05:14:28,078:INFO:Declaring metric variables
2024-01-03 05:14:28,082:INFO:Importing untrained model
2024-01-03 05:14:28,085:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 05:14:28,091:INFO:Starting cross validation
2024-01-03 05:14:28,093:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:29,300:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,453:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,485:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,529:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,562:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,577:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,588:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,615:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,629:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,675:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:14:29,810:INFO:Calculating mean and std
2024-01-03 05:14:29,811:INFO:Creating metrics dataframe
2024-01-03 05:14:29,814:INFO:Uploading results into container
2024-01-03 05:14:29,814:INFO:Uploading model into container now
2024-01-03 05:14:29,815:INFO:_master_model_container: 5
2024-01-03 05:14:29,815:INFO:_display_container: 2
2024-01-03 05:14:29,815:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 05:14:29,816:INFO:create_model() successfully completed......................................
2024-01-03 05:14:30,046:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:30,046:INFO:Creating metrics dataframe
2024-01-03 05:14:30,055:INFO:Initializing Ridge Classifier
2024-01-03 05:14:30,056:INFO:Total runtime is 0.8087462027867636 minutes
2024-01-03 05:14:30,058:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:30,059:INFO:Initializing create_model()
2024-01-03 05:14:30,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:30,059:INFO:Checking exceptions
2024-01-03 05:14:30,059:INFO:Importing libraries
2024-01-03 05:14:30,059:INFO:Copying training dataset
2024-01-03 05:14:30,113:INFO:Defining folds
2024-01-03 05:14:30,113:INFO:Declaring metric variables
2024-01-03 05:14:30,118:INFO:Importing untrained model
2024-01-03 05:14:30,122:INFO:Ridge Classifier Imported successfully
2024-01-03 05:14:30,128:INFO:Starting cross validation
2024-01-03 05:14:30,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:31,135:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,136:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,162:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,173:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,183:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,183:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,190:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,209:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,222:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:14:31,358:INFO:Calculating mean and std
2024-01-03 05:14:31,361:INFO:Creating metrics dataframe
2024-01-03 05:14:31,366:INFO:Uploading results into container
2024-01-03 05:14:31,367:INFO:Uploading model into container now
2024-01-03 05:14:31,368:INFO:_master_model_container: 6
2024-01-03 05:14:31,368:INFO:_display_container: 2
2024-01-03 05:14:31,369:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-03 05:14:31,369:INFO:create_model() successfully completed......................................
2024-01-03 05:14:31,662:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:31,662:INFO:Creating metrics dataframe
2024-01-03 05:14:31,672:INFO:Initializing Random Forest Classifier
2024-01-03 05:14:31,672:INFO:Total runtime is 0.8356740156809489 minutes
2024-01-03 05:14:31,675:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:31,675:INFO:Initializing create_model()
2024-01-03 05:14:31,675:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:31,675:INFO:Checking exceptions
2024-01-03 05:14:31,676:INFO:Importing libraries
2024-01-03 05:14:31,676:INFO:Copying training dataset
2024-01-03 05:14:31,723:INFO:Defining folds
2024-01-03 05:14:31,723:INFO:Declaring metric variables
2024-01-03 05:14:31,729:INFO:Importing untrained model
2024-01-03 05:14:31,733:INFO:Random Forest Classifier Imported successfully
2024-01-03 05:14:31,740:INFO:Starting cross validation
2024-01-03 05:14:31,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:39,909:INFO:Calculating mean and std
2024-01-03 05:14:39,911:INFO:Creating metrics dataframe
2024-01-03 05:14:39,916:INFO:Uploading results into container
2024-01-03 05:14:39,918:INFO:Uploading model into container now
2024-01-03 05:14:39,918:INFO:_master_model_container: 7
2024-01-03 05:14:39,918:INFO:_display_container: 2
2024-01-03 05:14:39,919:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-03 05:14:39,919:INFO:create_model() successfully completed......................................
2024-01-03 05:14:40,220:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:40,220:INFO:Creating metrics dataframe
2024-01-03 05:14:40,231:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 05:14:40,231:INFO:Total runtime is 0.9783200820287069 minutes
2024-01-03 05:14:40,234:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:40,234:INFO:Initializing create_model()
2024-01-03 05:14:40,234:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:40,234:INFO:Checking exceptions
2024-01-03 05:14:40,234:INFO:Importing libraries
2024-01-03 05:14:40,234:INFO:Copying training dataset
2024-01-03 05:14:40,273:INFO:Defining folds
2024-01-03 05:14:40,274:INFO:Declaring metric variables
2024-01-03 05:14:40,278:INFO:Importing untrained model
2024-01-03 05:14:40,283:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 05:14:40,292:INFO:Starting cross validation
2024-01-03 05:14:40,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:42,005:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,007:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,040:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,044:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,044:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,051:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,066:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,067:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,090:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,119:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:14:42,665:INFO:Calculating mean and std
2024-01-03 05:14:42,667:INFO:Creating metrics dataframe
2024-01-03 05:14:42,671:INFO:Uploading results into container
2024-01-03 05:14:42,671:INFO:Uploading model into container now
2024-01-03 05:14:42,672:INFO:_master_model_container: 8
2024-01-03 05:14:42,672:INFO:_display_container: 2
2024-01-03 05:14:42,672:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 05:14:42,672:INFO:create_model() successfully completed......................................
2024-01-03 05:14:43,083:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:43,083:INFO:Creating metrics dataframe
2024-01-03 05:14:43,098:INFO:Initializing Ada Boost Classifier
2024-01-03 05:14:43,098:INFO:Total runtime is 1.0261083046595256 minutes
2024-01-03 05:14:43,104:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:43,104:INFO:Initializing create_model()
2024-01-03 05:14:43,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:43,105:INFO:Checking exceptions
2024-01-03 05:14:43,105:INFO:Importing libraries
2024-01-03 05:14:43,105:INFO:Copying training dataset
2024-01-03 05:14:43,167:INFO:Defining folds
2024-01-03 05:14:43,167:INFO:Declaring metric variables
2024-01-03 05:14:43,174:INFO:Importing untrained model
2024-01-03 05:14:43,180:INFO:Ada Boost Classifier Imported successfully
2024-01-03 05:14:43,190:INFO:Starting cross validation
2024-01-03 05:14:43,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:50,080:INFO:Calculating mean and std
2024-01-03 05:14:50,081:INFO:Creating metrics dataframe
2024-01-03 05:14:50,085:INFO:Uploading results into container
2024-01-03 05:14:50,085:INFO:Uploading model into container now
2024-01-03 05:14:50,086:INFO:_master_model_container: 9
2024-01-03 05:14:50,086:INFO:_display_container: 2
2024-01-03 05:14:50,086:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-03 05:14:50,086:INFO:create_model() successfully completed......................................
2024-01-03 05:14:50,316:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:50,316:INFO:Creating metrics dataframe
2024-01-03 05:14:50,327:INFO:Initializing Gradient Boosting Classifier
2024-01-03 05:14:50,328:INFO:Total runtime is 1.1466103076934815 minutes
2024-01-03 05:14:50,331:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:50,331:INFO:Initializing create_model()
2024-01-03 05:14:50,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:50,331:INFO:Checking exceptions
2024-01-03 05:14:50,332:INFO:Importing libraries
2024-01-03 05:14:50,332:INFO:Copying training dataset
2024-01-03 05:14:50,372:INFO:Defining folds
2024-01-03 05:14:50,373:INFO:Declaring metric variables
2024-01-03 05:14:50,377:INFO:Importing untrained model
2024-01-03 05:14:50,382:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 05:14:50,390:INFO:Starting cross validation
2024-01-03 05:14:50,391:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:14:58,661:INFO:Calculating mean and std
2024-01-03 05:14:58,662:INFO:Creating metrics dataframe
2024-01-03 05:14:58,666:INFO:Uploading results into container
2024-01-03 05:14:58,667:INFO:Uploading model into container now
2024-01-03 05:14:58,668:INFO:_master_model_container: 10
2024-01-03 05:14:58,668:INFO:_display_container: 2
2024-01-03 05:14:58,669:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 05:14:58,669:INFO:create_model() successfully completed......................................
2024-01-03 05:14:59,078:INFO:SubProcess create_model() end ==================================
2024-01-03 05:14:59,078:INFO:Creating metrics dataframe
2024-01-03 05:14:59,091:INFO:Initializing Linear Discriminant Analysis
2024-01-03 05:14:59,091:INFO:Total runtime is 1.2926604270935058 minutes
2024-01-03 05:14:59,095:INFO:SubProcess create_model() called ==================================
2024-01-03 05:14:59,095:INFO:Initializing create_model()
2024-01-03 05:14:59,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:14:59,095:INFO:Checking exceptions
2024-01-03 05:14:59,095:INFO:Importing libraries
2024-01-03 05:14:59,095:INFO:Copying training dataset
2024-01-03 05:14:59,147:INFO:Defining folds
2024-01-03 05:14:59,147:INFO:Declaring metric variables
2024-01-03 05:14:59,153:INFO:Importing untrained model
2024-01-03 05:14:59,157:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 05:14:59,165:INFO:Starting cross validation
2024-01-03 05:14:59,166:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:15:03,605:INFO:Calculating mean and std
2024-01-03 05:15:03,607:INFO:Creating metrics dataframe
2024-01-03 05:15:03,613:INFO:Uploading results into container
2024-01-03 05:15:03,614:INFO:Uploading model into container now
2024-01-03 05:15:03,614:INFO:_master_model_container: 11
2024-01-03 05:15:03,614:INFO:_display_container: 2
2024-01-03 05:15:03,615:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 05:15:03,615:INFO:create_model() successfully completed......................................
2024-01-03 05:15:03,946:INFO:SubProcess create_model() end ==================================
2024-01-03 05:15:03,946:INFO:Creating metrics dataframe
2024-01-03 05:15:03,962:INFO:Initializing Extra Trees Classifier
2024-01-03 05:15:03,963:INFO:Total runtime is 1.3738624612490336 minutes
2024-01-03 05:15:03,968:INFO:SubProcess create_model() called ==================================
2024-01-03 05:15:03,968:INFO:Initializing create_model()
2024-01-03 05:15:03,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:15:03,969:INFO:Checking exceptions
2024-01-03 05:15:03,969:INFO:Importing libraries
2024-01-03 05:15:03,969:INFO:Copying training dataset
2024-01-03 05:15:04,044:INFO:Defining folds
2024-01-03 05:15:04,044:INFO:Declaring metric variables
2024-01-03 05:15:04,051:INFO:Importing untrained model
2024-01-03 05:15:04,057:INFO:Extra Trees Classifier Imported successfully
2024-01-03 05:15:04,065:INFO:Starting cross validation
2024-01-03 05:15:04,067:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:15:15,298:INFO:Calculating mean and std
2024-01-03 05:15:15,301:INFO:Creating metrics dataframe
2024-01-03 05:15:15,309:INFO:Uploading results into container
2024-01-03 05:15:15,311:INFO:Uploading model into container now
2024-01-03 05:15:15,312:INFO:_master_model_container: 12
2024-01-03 05:15:15,313:INFO:_display_container: 2
2024-01-03 05:15:15,314:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-03 05:15:15,314:INFO:create_model() successfully completed......................................
2024-01-03 05:15:15,810:INFO:SubProcess create_model() end ==================================
2024-01-03 05:15:15,810:INFO:Creating metrics dataframe
2024-01-03 05:15:15,823:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 05:15:15,823:INFO:Total runtime is 1.5715311368306477 minutes
2024-01-03 05:15:15,827:INFO:SubProcess create_model() called ==================================
2024-01-03 05:15:15,827:INFO:Initializing create_model()
2024-01-03 05:15:15,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:15:15,827:INFO:Checking exceptions
2024-01-03 05:15:15,827:INFO:Importing libraries
2024-01-03 05:15:15,827:INFO:Copying training dataset
2024-01-03 05:15:15,870:INFO:Defining folds
2024-01-03 05:15:15,870:INFO:Declaring metric variables
2024-01-03 05:15:15,875:INFO:Importing untrained model
2024-01-03 05:15:15,879:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:15:15,888:INFO:Starting cross validation
2024-01-03 05:15:15,890:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:15:18,881:INFO:Calculating mean and std
2024-01-03 05:15:18,883:INFO:Creating metrics dataframe
2024-01-03 05:15:18,888:INFO:Uploading results into container
2024-01-03 05:15:18,889:INFO:Uploading model into container now
2024-01-03 05:15:18,889:INFO:_master_model_container: 13
2024-01-03 05:15:18,890:INFO:_display_container: 2
2024-01-03 05:15:18,890:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:15:18,890:INFO:create_model() successfully completed......................................
2024-01-03 05:15:19,154:INFO:SubProcess create_model() end ==================================
2024-01-03 05:15:19,154:INFO:Creating metrics dataframe
2024-01-03 05:15:19,167:INFO:Initializing Dummy Classifier
2024-01-03 05:15:19,167:INFO:Total runtime is 1.6272672136624653 minutes
2024-01-03 05:15:19,171:INFO:SubProcess create_model() called ==================================
2024-01-03 05:15:19,171:INFO:Initializing create_model()
2024-01-03 05:15:19,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197D7CDB610>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:15:19,172:INFO:Checking exceptions
2024-01-03 05:15:19,172:INFO:Importing libraries
2024-01-03 05:15:19,172:INFO:Copying training dataset
2024-01-03 05:15:19,214:INFO:Defining folds
2024-01-03 05:15:19,214:INFO:Declaring metric variables
2024-01-03 05:15:19,218:INFO:Importing untrained model
2024-01-03 05:15:19,224:INFO:Dummy Classifier Imported successfully
2024-01-03 05:15:19,233:INFO:Starting cross validation
2024-01-03 05:15:19,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:15:19,861:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,861:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,881:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,896:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,905:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,921:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,923:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,924:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,930:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:19,934:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:15:20,062:INFO:Calculating mean and std
2024-01-03 05:15:20,064:INFO:Creating metrics dataframe
2024-01-03 05:15:20,067:INFO:Uploading results into container
2024-01-03 05:15:20,068:INFO:Uploading model into container now
2024-01-03 05:15:20,068:INFO:_master_model_container: 14
2024-01-03 05:15:20,069:INFO:_display_container: 2
2024-01-03 05:15:20,069:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-03 05:15:20,069:INFO:create_model() successfully completed......................................
2024-01-03 05:15:20,343:INFO:SubProcess create_model() end ==================================
2024-01-03 05:15:20,344:INFO:Creating metrics dataframe
2024-01-03 05:15:20,395:INFO:Initializing create_model()
2024-01-03 05:15:20,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:15:20,395:INFO:Checking exceptions
2024-01-03 05:15:20,398:INFO:Importing libraries
2024-01-03 05:15:20,398:INFO:Copying training dataset
2024-01-03 05:15:20,466:INFO:Defining folds
2024-01-03 05:15:20,466:INFO:Declaring metric variables
2024-01-03 05:15:20,466:INFO:Importing untrained model
2024-01-03 05:15:20,466:INFO:Declaring custom model
2024-01-03 05:15:20,467:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:15:20,468:INFO:Cross validation set to False
2024-01-03 05:15:20,468:INFO:Fitting Model
2024-01-03 05:15:20,601:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:15:20,602:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:15:20,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001697 seconds.
2024-01-03 05:15:20,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:15:20,606:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:15:20,606:INFO:[LightGBM] [Info] Total Bins 444
2024-01-03 05:15:20,606:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:15:20,607:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:15:20,607:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:15:20,761:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:15:20,761:INFO:create_model() successfully completed......................................
2024-01-03 05:15:21,064:INFO:_master_model_container: 14
2024-01-03 05:15:21,064:INFO:_display_container: 2
2024-01-03 05:15:21,064:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:15:21,065:INFO:compare_models() successfully completed......................................
2024-01-03 05:18:46,720:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:46,755:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:46,760:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,026:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,032:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,244:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,271:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,413:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,440:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:47,638:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:48,255:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:48,261:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:48,356:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:48,523:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:48,819:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:48,866:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:50,496:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:50,619:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,259:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,279:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,347:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,379:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,454:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,572:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,679:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,723:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,768:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,782:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,835:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:18:51,851:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:20:22,821:INFO:Initializing plot_model()
2024-01-03 05:20:22,822:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, system=True)
2024-01-03 05:20:22,822:INFO:Checking exceptions
2024-01-03 05:20:22,838:INFO:Preloading libraries
2024-01-03 05:20:22,845:INFO:Copying training dataset
2024-01-03 05:20:22,845:INFO:Plot type: auc
2024-01-03 05:20:23,206:INFO:Fitting Model
2024-01-03 05:20:23,207:INFO:Scoring test/hold-out set
2024-01-03 05:20:23,529:INFO:Visual Rendered Successfully
2024-01-03 05:20:23,768:INFO:plot_model() successfully completed......................................
2024-01-03 05:20:23,812:INFO:Initializing plot_model()
2024-01-03 05:20:23,812:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, system=True)
2024-01-03 05:20:23,812:INFO:Checking exceptions
2024-01-03 05:20:23,829:INFO:Preloading libraries
2024-01-03 05:20:23,834:INFO:Copying training dataset
2024-01-03 05:20:23,835:INFO:Plot type: confusion_matrix
2024-01-03 05:20:24,170:INFO:Fitting Model
2024-01-03 05:20:24,171:INFO:Scoring test/hold-out set
2024-01-03 05:20:24,356:INFO:Visual Rendered Successfully
2024-01-03 05:20:24,593:INFO:plot_model() successfully completed......................................
2024-01-03 05:20:24,635:INFO:Initializing plot_model()
2024-01-03 05:20:24,635:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, system=True)
2024-01-03 05:20:24,635:INFO:Checking exceptions
2024-01-03 05:20:24,652:INFO:Preloading libraries
2024-01-03 05:20:24,658:INFO:Copying training dataset
2024-01-03 05:20:24,658:INFO:Plot type: class_report
2024-01-03 05:20:24,998:INFO:Fitting Model
2024-01-03 05:20:24,998:INFO:Scoring test/hold-out set
2024-01-03 05:20:25,287:INFO:Visual Rendered Successfully
2024-01-03 05:20:25,511:INFO:plot_model() successfully completed......................................
2024-01-03 05:20:25,545:INFO:Initializing tune_model()
2024-01-03 05:20:25,546:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>)
2024-01-03 05:20:25,546:INFO:Checking exceptions
2024-01-03 05:20:25,578:INFO:Copying training dataset
2024-01-03 05:20:25,608:INFO:Checking base model
2024-01-03 05:20:25,608:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 05:20:25,616:INFO:Declaring metric variables
2024-01-03 05:20:25,621:INFO:Defining Hyperparameters
2024-01-03 05:20:25,892:INFO:Tuning with n_jobs=-1
2024-01-03 05:20:25,892:INFO:Initializing RandomizedSearchCV
2024-01-03 05:20:56,093:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-03 05:20:56,094:INFO:Hyperparameter search completed
2024-01-03 05:20:56,095:INFO:SubProcess create_model() called ==================================
2024-01-03 05:20:56,096:INFO:Initializing create_model()
2024-01-03 05:20:56,096:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197C97F5240>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-03 05:20:56,096:INFO:Checking exceptions
2024-01-03 05:20:56,096:INFO:Importing libraries
2024-01-03 05:20:56,096:INFO:Copying training dataset
2024-01-03 05:20:56,150:INFO:Defining folds
2024-01-03 05:20:56,151:INFO:Declaring metric variables
2024-01-03 05:20:56,161:INFO:Importing untrained model
2024-01-03 05:20:56,162:INFO:Declaring custom model
2024-01-03 05:20:56,175:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:20:56,198:INFO:Starting cross validation
2024-01-03 05:20:56,203:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:20:59,759:INFO:Calculating mean and std
2024-01-03 05:20:59,760:INFO:Creating metrics dataframe
2024-01-03 05:20:59,766:INFO:Finalizing model
2024-01-03 05:20:59,873:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-03 05:20:59,873:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-03 05:20:59,874:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-03 05:20:59,893:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:20:59,893:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-03 05:20:59,894:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-03 05:20:59,894:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-03 05:20:59,894:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:20:59,897:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001168 seconds.
2024-01-03 05:20:59,897:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:20:59,897:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:20:59,897:INFO:[LightGBM] [Info] Total Bins 428
2024-01-03 05:20:59,897:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 53
2024-01-03 05:20:59,898:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:20:59,898:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:20:59,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:20:59,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,058:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,087:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,089:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,105:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,120:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,127:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,132:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,132:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,134:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,148:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,149:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:21:00,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:21:00,179:INFO:Uploading results into container
2024-01-03 05:21:00,180:INFO:Uploading model into container now
2024-01-03 05:21:00,181:INFO:_master_model_container: 15
2024-01-03 05:21:00,181:INFO:_display_container: 3
2024-01-03 05:21:00,182:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:21:00,182:INFO:create_model() successfully completed......................................
2024-01-03 05:21:00,442:INFO:SubProcess create_model() end ==================================
2024-01-03 05:21:00,442:INFO:choose_better activated
2024-01-03 05:21:00,446:INFO:SubProcess create_model() called ==================================
2024-01-03 05:21:00,446:INFO:Initializing create_model()
2024-01-03 05:21:00,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:21:00,447:INFO:Checking exceptions
2024-01-03 05:21:00,448:INFO:Importing libraries
2024-01-03 05:21:00,448:INFO:Copying training dataset
2024-01-03 05:21:00,486:INFO:Defining folds
2024-01-03 05:21:00,486:INFO:Declaring metric variables
2024-01-03 05:21:00,487:INFO:Importing untrained model
2024-01-03 05:21:00,487:INFO:Declaring custom model
2024-01-03 05:21:00,487:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:21:00,488:INFO:Starting cross validation
2024-01-03 05:21:00,489:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:21:02,921:INFO:Calculating mean and std
2024-01-03 05:21:02,923:INFO:Creating metrics dataframe
2024-01-03 05:21:02,927:INFO:Finalizing model
2024-01-03 05:21:03,062:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:21:03,063:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:21:03,065:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001180 seconds.
2024-01-03 05:21:03,065:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:21:03,065:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:21:03,066:INFO:[LightGBM] [Info] Total Bins 444
2024-01-03 05:21:03,066:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:21:03,066:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:21:03,066:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:21:03,172:INFO:Uploading results into container
2024-01-03 05:21:03,173:INFO:Uploading model into container now
2024-01-03 05:21:03,174:INFO:_master_model_container: 16
2024-01-03 05:21:03,174:INFO:_display_container: 4
2024-01-03 05:21:03,175:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:21:03,175:INFO:create_model() successfully completed......................................
2024-01-03 05:21:03,430:INFO:SubProcess create_model() end ==================================
2024-01-03 05:21:03,431:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8707
2024-01-03 05:21:03,431:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8695
2024-01-03 05:21:03,432:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-03 05:21:03,432:INFO:choose_better completed
2024-01-03 05:21:03,432:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-03 05:21:03,441:INFO:_master_model_container: 16
2024-01-03 05:21:03,442:INFO:_display_container: 3
2024-01-03 05:21:03,442:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:21:03,442:INFO:tune_model() successfully completed......................................
2024-01-03 05:21:03,762:INFO:Initializing plot_model()
2024-01-03 05:21:03,762:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, system=True)
2024-01-03 05:21:03,763:INFO:Checking exceptions
2024-01-03 05:21:03,780:INFO:Preloading libraries
2024-01-03 05:21:03,785:INFO:Copying training dataset
2024-01-03 05:21:03,785:INFO:Plot type: auc
2024-01-03 05:21:04,160:INFO:Fitting Model
2024-01-03 05:21:04,160:INFO:Scoring test/hold-out set
2024-01-03 05:21:04,489:INFO:Visual Rendered Successfully
2024-01-03 05:21:04,710:INFO:plot_model() successfully completed......................................
2024-01-03 05:21:04,752:INFO:Initializing plot_model()
2024-01-03 05:21:04,752:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, system=True)
2024-01-03 05:21:04,752:INFO:Checking exceptions
2024-01-03 05:21:04,771:INFO:Preloading libraries
2024-01-03 05:21:04,776:INFO:Copying training dataset
2024-01-03 05:21:04,776:INFO:Plot type: confusion_matrix
2024-01-03 05:21:05,128:INFO:Fitting Model
2024-01-03 05:21:05,129:INFO:Scoring test/hold-out set
2024-01-03 05:21:05,316:INFO:Visual Rendered Successfully
2024-01-03 05:21:05,542:INFO:plot_model() successfully completed......................................
2024-01-03 05:21:05,576:INFO:Initializing plot_model()
2024-01-03 05:21:05,576:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, system=True)
2024-01-03 05:21:05,576:INFO:Checking exceptions
2024-01-03 05:21:05,593:INFO:Preloading libraries
2024-01-03 05:21:05,599:INFO:Copying training dataset
2024-01-03 05:21:05,600:INFO:Plot type: class_report
2024-01-03 05:21:05,953:INFO:Fitting Model
2024-01-03 05:21:05,953:INFO:Scoring test/hold-out set
2024-01-03 05:21:06,266:INFO:Visual Rendered Successfully
2024-01-03 05:21:06,481:INFO:plot_model() successfully completed......................................
2024-01-03 05:21:06,529:INFO:Initializing finalize_model()
2024-01-03 05:21:06,529:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-03 05:21:06,529:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:21:06,545:INFO:Initializing create_model()
2024-01-03 05:21:06,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-03 05:21:06,545:INFO:Checking exceptions
2024-01-03 05:21:06,547:INFO:Importing libraries
2024-01-03 05:21:06,547:INFO:Copying training dataset
2024-01-03 05:21:06,548:INFO:Defining folds
2024-01-03 05:21:06,548:INFO:Declaring metric variables
2024-01-03 05:21:06,548:INFO:Importing untrained model
2024-01-03 05:21:06,548:INFO:Declaring custom model
2024-01-03 05:21:06,549:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:21:06,550:INFO:Cross validation set to False
2024-01-03 05:21:06,550:INFO:Fitting Model
2024-01-03 05:21:06,695:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:21:06,696:INFO:[LightGBM] [Info] Number of positive: 7841, number of negative: 24720
2024-01-03 05:21:06,699:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001846 seconds.
2024-01-03 05:21:06,699:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-01-03 05:21:06,699:INFO:[LightGBM] [Info] Total Bins 464
2024-01-03 05:21:06,699:INFO:[LightGBM] [Info] Number of data points in the train set: 32561, number of used features: 64
2024-01-03 05:21:06,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240810 -> initscore=-1.148246
2024-01-03 05:21:06,700:INFO:[LightGBM] [Info] Start training from score -1.148246
2024-01-03 05:21:06,852:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-03 05:21:06,852:INFO:create_model() successfully completed......................................
2024-01-03 05:21:07,085:INFO:_master_model_container: 16
2024-01-03 05:21:07,085:INFO:_display_container: 3
2024-01-03 05:21:07,092:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-03 05:21:07,092:INFO:finalize_model() successfully completed......................................
2024-01-03 05:21:07,412:INFO:Initializing predict_model()
2024-01-03 05:21:07,412:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000197E0DCB760>)
2024-01-03 05:21:07,413:INFO:Checking exceptions
2024-01-03 05:21:07,413:INFO:Preloading libraries
2024-01-03 05:21:07,415:INFO:Set up data.
2024-01-03 05:21:07,455:INFO:Set up index.
2024-01-03 05:21:58,299:INFO:Initializing tune_model()
2024-01-03 05:21:58,299:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>)
2024-01-03 05:21:58,300:INFO:Checking exceptions
2024-01-03 05:21:58,331:INFO:Copying training dataset
2024-01-03 05:21:58,360:INFO:Checking base model
2024-01-03 05:21:58,360:INFO:Base model : Light Gradient Boosting Machine
2024-01-03 05:21:58,365:INFO:Declaring metric variables
2024-01-03 05:21:58,369:INFO:Defining Hyperparameters
2024-01-03 05:21:58,710:INFO:Tuning with n_jobs=-1
2024-01-03 05:21:58,710:INFO:Initializing RandomizedSearchCV
2024-01-03 05:22:29,908:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-03 05:22:29,911:INFO:Hyperparameter search completed
2024-01-03 05:22:29,912:INFO:SubProcess create_model() called ==================================
2024-01-03 05:22:29,914:INFO:Initializing create_model()
2024-01-03 05:22:29,915:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000197DF0D39D0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-03 05:22:29,915:INFO:Checking exceptions
2024-01-03 05:22:29,916:INFO:Importing libraries
2024-01-03 05:22:29,917:INFO:Copying training dataset
2024-01-03 05:22:29,985:INFO:Defining folds
2024-01-03 05:22:29,985:INFO:Declaring metric variables
2024-01-03 05:22:29,989:INFO:Importing untrained model
2024-01-03 05:22:29,989:INFO:Declaring custom model
2024-01-03 05:22:29,994:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:22:30,002:INFO:Starting cross validation
2024-01-03 05:22:30,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:22:33,962:INFO:Calculating mean and std
2024-01-03 05:22:33,963:INFO:Creating metrics dataframe
2024-01-03 05:22:33,969:INFO:Finalizing model
2024-01-03 05:22:34,086:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-03 05:22:34,087:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-03 05:22:34,087:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-03 05:22:34,105:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:22:34,106:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-03 05:22:34,106:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-03 05:22:34,106:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-03 05:22:34,106:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:22:34,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001289 seconds.
2024-01-03 05:22:34,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:22:34,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:22:34,110:INFO:[LightGBM] [Info] Total Bins 428
2024-01-03 05:22:34,110:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 53
2024-01-03 05:22:34,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:22:34,111:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:22:34,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,203:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,211:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,219:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,241:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,263:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,266:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,281:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,322:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,334:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,335:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,337:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,339:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,352:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,364:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,366:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,368:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,368:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,372:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,374:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,375:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,377:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,379:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,381:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,395:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,396:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-03 05:22:34,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-03 05:22:34,424:INFO:Uploading results into container
2024-01-03 05:22:34,426:INFO:Uploading model into container now
2024-01-03 05:22:34,426:INFO:_master_model_container: 17
2024-01-03 05:22:34,427:INFO:_display_container: 5
2024-01-03 05:22:34,427:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:22:34,428:INFO:create_model() successfully completed......................................
2024-01-03 05:22:34,715:INFO:SubProcess create_model() end ==================================
2024-01-03 05:22:34,715:INFO:choose_better activated
2024-01-03 05:22:34,719:INFO:SubProcess create_model() called ==================================
2024-01-03 05:22:34,719:INFO:Initializing create_model()
2024-01-03 05:22:34,719:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000197D7CD9990>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:22:34,719:INFO:Checking exceptions
2024-01-03 05:22:34,720:INFO:Importing libraries
2024-01-03 05:22:34,720:INFO:Copying training dataset
2024-01-03 05:22:34,764:INFO:Defining folds
2024-01-03 05:22:34,764:INFO:Declaring metric variables
2024-01-03 05:22:34,765:INFO:Importing untrained model
2024-01-03 05:22:34,765:INFO:Declaring custom model
2024-01-03 05:22:34,765:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:22:34,766:INFO:Starting cross validation
2024-01-03 05:22:34,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:22:37,558:INFO:Calculating mean and std
2024-01-03 05:22:37,560:INFO:Creating metrics dataframe
2024-01-03 05:22:37,566:INFO:Finalizing model
2024-01-03 05:22:37,718:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:22:37,719:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:22:37,723:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001757 seconds.
2024-01-03 05:22:37,723:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:22:37,723:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:22:37,723:INFO:[LightGBM] [Info] Total Bins 444
2024-01-03 05:22:37,723:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:22:37,724:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:22:37,724:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:22:37,940:INFO:Uploading results into container
2024-01-03 05:22:37,941:INFO:Uploading model into container now
2024-01-03 05:22:37,941:INFO:_master_model_container: 18
2024-01-03 05:22:37,942:INFO:_display_container: 6
2024-01-03 05:22:37,942:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:22:37,942:INFO:create_model() successfully completed......................................
2024-01-03 05:22:38,301:INFO:SubProcess create_model() end ==================================
2024-01-03 05:22:38,302:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8707
2024-01-03 05:22:38,303:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8695
2024-01-03 05:22:38,304:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-03 05:22:38,304:INFO:choose_better completed
2024-01-03 05:22:38,304:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-03 05:22:38,316:INFO:_master_model_container: 18
2024-01-03 05:22:38,317:INFO:_display_container: 5
2024-01-03 05:22:38,318:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:22:38,318:INFO:tune_model() successfully completed......................................
2024-01-03 05:26:37,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:26:37,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:26:37,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:26:37,875:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:27:07,371:INFO:PyCaret ClassificationExperiment
2024-01-03 05:27:07,371:INFO:Logging name: clf-default-name
2024-01-03 05:27:07,371:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:27:07,371:INFO:version 3.1.0
2024-01-03 05:27:07,371:INFO:Initializing setup()
2024-01-03 05:27:07,371:INFO:self.USI: 4e01
2024-01-03 05:27:07,371:INFO:self._variable_keys: {'X_train', 'logging_param', 'idx', 'exp_name_log', 'USI', '_ml_usecase', 'seed', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'fold_shuffle_param', 'fix_imbalance', 'y_train', 'memory', 'X_test', 'pipeline', 'X', 'html_param', 'fold_groups_param', 'y_test', '_available_plots', 'n_jobs_param', 'target_param', 'data', 'gpu_param', 'y', 'fold_generator', 'exp_id'}
2024-01-03 05:27:07,371:INFO:Checking environment
2024-01-03 05:27:07,371:INFO:python_version: 3.10.9
2024-01-03 05:27:07,371:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:27:07,371:INFO:machine: AMD64
2024-01-03 05:27:07,371:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:27:07,372:INFO:Memory: svmem(total=16954372096, available=2418135040, percent=85.7, used=14536237056, free=2418135040)
2024-01-03 05:27:07,372:INFO:Physical Core: 8
2024-01-03 05:27:07,372:INFO:Logical Core: 16
2024-01-03 05:27:07,372:INFO:Checking libraries
2024-01-03 05:27:07,372:INFO:System:
2024-01-03 05:27:07,372:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:27:07,372:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:27:07,372:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:27:07,372:INFO:PyCaret required dependencies:
2024-01-03 05:27:07,903:INFO:                 pip: 22.3.1
2024-01-03 05:27:07,903:INFO:          setuptools: 65.6.3
2024-01-03 05:27:07,903:INFO:             pycaret: 3.1.0
2024-01-03 05:27:07,903:INFO:             IPython: 8.10.0
2024-01-03 05:27:07,903:INFO:          ipywidgets: 7.6.5
2024-01-03 05:27:07,903:INFO:                tqdm: 4.64.1
2024-01-03 05:27:07,903:INFO:               numpy: 1.23.5
2024-01-03 05:27:07,903:INFO:              pandas: 1.5.3
2024-01-03 05:27:07,903:INFO:              jinja2: 3.1.2
2024-01-03 05:27:07,903:INFO:               scipy: 1.10.1
2024-01-03 05:27:07,903:INFO:              joblib: 1.3.2
2024-01-03 05:27:07,903:INFO:             sklearn: 1.2.1
2024-01-03 05:27:07,903:INFO:                pyod: 1.1.0
2024-01-03 05:27:07,903:INFO:            imblearn: 0.10.1
2024-01-03 05:27:07,903:INFO:   category_encoders: 2.6.2
2024-01-03 05:27:07,903:INFO:            lightgbm: 4.1.0
2024-01-03 05:27:07,904:INFO:               numba: 0.56.4
2024-01-03 05:27:07,904:INFO:            requests: 2.28.1
2024-01-03 05:27:07,904:INFO:          matplotlib: 3.7.0
2024-01-03 05:27:07,904:INFO:          scikitplot: 0.3.7
2024-01-03 05:27:07,904:INFO:         yellowbrick: 1.5
2024-01-03 05:27:07,904:INFO:              plotly: 5.9.0
2024-01-03 05:27:07,904:INFO:    plotly-resampler: Not installed
2024-01-03 05:27:07,904:INFO:             kaleido: 0.2.1
2024-01-03 05:27:07,904:INFO:           schemdraw: 0.15
2024-01-03 05:27:07,904:INFO:         statsmodels: 0.13.5
2024-01-03 05:27:07,904:INFO:              sktime: 0.21.1
2024-01-03 05:27:07,904:INFO:               tbats: 1.1.3
2024-01-03 05:27:07,904:INFO:            pmdarima: 2.0.3
2024-01-03 05:27:07,904:INFO:              psutil: 5.9.0
2024-01-03 05:27:07,904:INFO:          markupsafe: 2.1.1
2024-01-03 05:27:07,904:INFO:             pickle5: Not installed
2024-01-03 05:27:07,904:INFO:         cloudpickle: 2.0.0
2024-01-03 05:27:07,904:INFO:         deprecation: 2.1.0
2024-01-03 05:27:07,904:INFO:              xxhash: 3.4.1
2024-01-03 05:27:07,904:INFO:           wurlitzer: Not installed
2024-01-03 05:27:07,904:INFO:PyCaret optional dependencies:
2024-01-03 05:27:07,919:INFO:                shap: Not installed
2024-01-03 05:27:07,919:INFO:           interpret: Not installed
2024-01-03 05:27:07,919:INFO:                umap: Not installed
2024-01-03 05:27:07,919:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:27:07,919:INFO:  explainerdashboard: Not installed
2024-01-03 05:27:07,919:INFO:             autoviz: Not installed
2024-01-03 05:27:07,919:INFO:           fairlearn: Not installed
2024-01-03 05:27:07,919:INFO:          deepchecks: Not installed
2024-01-03 05:27:07,919:INFO:             xgboost: Not installed
2024-01-03 05:27:07,919:INFO:            catboost: Not installed
2024-01-03 05:27:07,919:INFO:              kmodes: Not installed
2024-01-03 05:27:07,919:INFO:             mlxtend: Not installed
2024-01-03 05:27:07,919:INFO:       statsforecast: Not installed
2024-01-03 05:27:07,919:INFO:        tune_sklearn: Not installed
2024-01-03 05:27:07,919:INFO:                 ray: Not installed
2024-01-03 05:27:07,919:INFO:            hyperopt: Not installed
2024-01-03 05:27:07,920:INFO:              optuna: Not installed
2024-01-03 05:27:07,920:INFO:               skopt: Not installed
2024-01-03 05:27:07,920:INFO:              mlflow: Not installed
2024-01-03 05:27:07,920:INFO:              gradio: Not installed
2024-01-03 05:27:07,920:INFO:             fastapi: Not installed
2024-01-03 05:27:07,920:INFO:             uvicorn: Not installed
2024-01-03 05:27:07,920:INFO:              m2cgen: Not installed
2024-01-03 05:27:07,920:INFO:           evidently: Not installed
2024-01-03 05:27:07,920:INFO:               fugue: Not installed
2024-01-03 05:27:07,920:INFO:           streamlit: Not installed
2024-01-03 05:27:07,920:INFO:             prophet: Not installed
2024-01-03 05:27:07,920:INFO:None
2024-01-03 05:27:07,920:INFO:Set up data.
2024-01-03 05:27:07,973:INFO:Set up folding strategy.
2024-01-03 05:27:07,973:INFO:Set up train/test split.
2024-01-03 05:27:08,003:INFO:Set up index.
2024-01-03 05:27:08,005:INFO:Assigning column types.
2024-01-03 05:27:08,029:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 05:27:08,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:27:08,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:27:08,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,144:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:27:08,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:27:08,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,169:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 05:27:08,207:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:27:08,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,272:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:27:08,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,296:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 05:27:08,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,419:INFO:Preparing preprocessing pipeline...
2024-01-03 05:27:08,422:INFO:Set up simple imputation.
2024-01-03 05:27:08,426:INFO:Set up column name cleaning.
2024-01-03 05:27:08,532:INFO:Finished creating preprocessing pipeline.
2024-01-03 05:27:08,538:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-03 05:27:08,538:INFO:Creating final display dataframe.
2024-01-03 05:27:08,840:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4e01
2024-01-03 05:27:08,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:27:08,974:INFO:setup() successfully completed in 1.61s...............
2024-01-03 05:32:30,277:INFO:PyCaret ClassificationExperiment
2024-01-03 05:32:30,277:INFO:Logging name: clf-default-name
2024-01-03 05:32:30,277:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:32:30,277:INFO:version 3.1.0
2024-01-03 05:32:30,277:INFO:Initializing setup()
2024-01-03 05:32:30,277:INFO:self.USI: 542e
2024-01-03 05:32:30,277:INFO:self._variable_keys: {'X_train', 'logging_param', 'idx', 'exp_name_log', 'USI', '_ml_usecase', 'seed', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'fold_shuffle_param', 'fix_imbalance', 'y_train', 'memory', 'X_test', 'pipeline', 'X', 'html_param', 'fold_groups_param', 'y_test', '_available_plots', 'n_jobs_param', 'target_param', 'data', 'gpu_param', 'y', 'fold_generator', 'exp_id'}
2024-01-03 05:32:30,277:INFO:Checking environment
2024-01-03 05:32:30,277:INFO:python_version: 3.10.9
2024-01-03 05:32:30,277:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:32:30,277:INFO:machine: AMD64
2024-01-03 05:32:30,277:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:32:30,278:INFO:Memory: svmem(total=16954372096, available=4956250112, percent=70.8, used=11998121984, free=4956250112)
2024-01-03 05:32:30,278:INFO:Physical Core: 8
2024-01-03 05:32:30,278:INFO:Logical Core: 16
2024-01-03 05:32:30,278:INFO:Checking libraries
2024-01-03 05:32:30,278:INFO:System:
2024-01-03 05:32:30,278:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:32:30,278:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:32:30,278:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:32:30,278:INFO:PyCaret required dependencies:
2024-01-03 05:32:30,278:INFO:                 pip: 22.3.1
2024-01-03 05:32:30,278:INFO:          setuptools: 65.6.3
2024-01-03 05:32:30,278:INFO:             pycaret: 3.1.0
2024-01-03 05:32:30,278:INFO:             IPython: 8.10.0
2024-01-03 05:32:30,278:INFO:          ipywidgets: 7.6.5
2024-01-03 05:32:30,278:INFO:                tqdm: 4.64.1
2024-01-03 05:32:30,278:INFO:               numpy: 1.23.5
2024-01-03 05:32:30,278:INFO:              pandas: 1.5.3
2024-01-03 05:32:30,278:INFO:              jinja2: 3.1.2
2024-01-03 05:32:30,278:INFO:               scipy: 1.10.1
2024-01-03 05:32:30,279:INFO:              joblib: 1.3.2
2024-01-03 05:32:30,279:INFO:             sklearn: 1.2.1
2024-01-03 05:32:30,279:INFO:                pyod: 1.1.0
2024-01-03 05:32:30,279:INFO:            imblearn: 0.10.1
2024-01-03 05:32:30,279:INFO:   category_encoders: 2.6.2
2024-01-03 05:32:30,279:INFO:            lightgbm: 4.1.0
2024-01-03 05:32:30,279:INFO:               numba: 0.56.4
2024-01-03 05:32:30,279:INFO:            requests: 2.28.1
2024-01-03 05:32:30,279:INFO:          matplotlib: 3.7.0
2024-01-03 05:32:30,279:INFO:          scikitplot: 0.3.7
2024-01-03 05:32:30,279:INFO:         yellowbrick: 1.5
2024-01-03 05:32:30,279:INFO:              plotly: 5.9.0
2024-01-03 05:32:30,279:INFO:    plotly-resampler: Not installed
2024-01-03 05:32:30,279:INFO:             kaleido: 0.2.1
2024-01-03 05:32:30,279:INFO:           schemdraw: 0.15
2024-01-03 05:32:30,279:INFO:         statsmodels: 0.13.5
2024-01-03 05:32:30,279:INFO:              sktime: 0.21.1
2024-01-03 05:32:30,279:INFO:               tbats: 1.1.3
2024-01-03 05:32:30,279:INFO:            pmdarima: 2.0.3
2024-01-03 05:32:30,279:INFO:              psutil: 5.9.0
2024-01-03 05:32:30,279:INFO:          markupsafe: 2.1.1
2024-01-03 05:32:30,279:INFO:             pickle5: Not installed
2024-01-03 05:32:30,279:INFO:         cloudpickle: 2.0.0
2024-01-03 05:32:30,279:INFO:         deprecation: 2.1.0
2024-01-03 05:32:30,279:INFO:              xxhash: 3.4.1
2024-01-03 05:32:30,280:INFO:           wurlitzer: Not installed
2024-01-03 05:32:30,280:INFO:PyCaret optional dependencies:
2024-01-03 05:32:30,280:INFO:                shap: Not installed
2024-01-03 05:32:30,280:INFO:           interpret: Not installed
2024-01-03 05:32:30,280:INFO:                umap: Not installed
2024-01-03 05:32:30,280:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:32:30,280:INFO:  explainerdashboard: Not installed
2024-01-03 05:32:30,280:INFO:             autoviz: Not installed
2024-01-03 05:32:30,280:INFO:           fairlearn: Not installed
2024-01-03 05:32:30,280:INFO:          deepchecks: Not installed
2024-01-03 05:32:30,280:INFO:             xgboost: Not installed
2024-01-03 05:32:30,280:INFO:            catboost: Not installed
2024-01-03 05:32:30,280:INFO:              kmodes: Not installed
2024-01-03 05:32:30,280:INFO:             mlxtend: Not installed
2024-01-03 05:32:30,280:INFO:       statsforecast: Not installed
2024-01-03 05:32:30,280:INFO:        tune_sklearn: Not installed
2024-01-03 05:32:30,280:INFO:                 ray: Not installed
2024-01-03 05:32:30,280:INFO:            hyperopt: Not installed
2024-01-03 05:32:30,280:INFO:              optuna: Not installed
2024-01-03 05:32:30,280:INFO:               skopt: Not installed
2024-01-03 05:32:30,280:INFO:              mlflow: Not installed
2024-01-03 05:32:30,280:INFO:              gradio: Not installed
2024-01-03 05:32:30,280:INFO:             fastapi: Not installed
2024-01-03 05:32:30,280:INFO:             uvicorn: Not installed
2024-01-03 05:32:30,281:INFO:              m2cgen: Not installed
2024-01-03 05:32:30,281:INFO:           evidently: Not installed
2024-01-03 05:32:30,281:INFO:               fugue: Not installed
2024-01-03 05:32:30,281:INFO:           streamlit: Not installed
2024-01-03 05:32:30,281:INFO:             prophet: Not installed
2024-01-03 05:32:30,281:INFO:None
2024-01-03 05:32:30,281:INFO:Set up data.
2024-01-03 05:33:27,147:INFO:PyCaret ClassificationExperiment
2024-01-03 05:33:27,147:INFO:Logging name: clf-default-name
2024-01-03 05:33:27,147:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:33:27,147:INFO:version 3.1.0
2024-01-03 05:33:27,147:INFO:Initializing setup()
2024-01-03 05:33:27,147:INFO:self.USI: 723f
2024-01-03 05:33:27,147:INFO:self._variable_keys: {'X_train', 'logging_param', 'idx', 'exp_name_log', 'USI', '_ml_usecase', 'seed', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'fold_shuffle_param', 'fix_imbalance', 'y_train', 'memory', 'X_test', 'pipeline', 'X', 'html_param', 'fold_groups_param', 'y_test', '_available_plots', 'n_jobs_param', 'target_param', 'data', 'gpu_param', 'y', 'fold_generator', 'exp_id'}
2024-01-03 05:33:27,147:INFO:Checking environment
2024-01-03 05:33:27,147:INFO:python_version: 3.10.9
2024-01-03 05:33:27,148:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:33:27,148:INFO:machine: AMD64
2024-01-03 05:33:27,148:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:33:27,148:INFO:Memory: svmem(total=16954372096, available=4975398912, percent=70.7, used=11978973184, free=4975398912)
2024-01-03 05:33:27,148:INFO:Physical Core: 8
2024-01-03 05:33:27,148:INFO:Logical Core: 16
2024-01-03 05:33:27,148:INFO:Checking libraries
2024-01-03 05:33:27,148:INFO:System:
2024-01-03 05:33:27,148:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:33:27,148:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:33:27,148:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:33:27,148:INFO:PyCaret required dependencies:
2024-01-03 05:33:27,148:INFO:                 pip: 22.3.1
2024-01-03 05:33:27,148:INFO:          setuptools: 65.6.3
2024-01-03 05:33:27,148:INFO:             pycaret: 3.1.0
2024-01-03 05:33:27,148:INFO:             IPython: 8.10.0
2024-01-03 05:33:27,148:INFO:          ipywidgets: 7.6.5
2024-01-03 05:33:27,148:INFO:                tqdm: 4.64.1
2024-01-03 05:33:27,148:INFO:               numpy: 1.23.5
2024-01-03 05:33:27,149:INFO:              pandas: 1.5.3
2024-01-03 05:33:27,149:INFO:              jinja2: 3.1.2
2024-01-03 05:33:27,149:INFO:               scipy: 1.10.1
2024-01-03 05:33:27,149:INFO:              joblib: 1.3.2
2024-01-03 05:33:27,149:INFO:             sklearn: 1.2.1
2024-01-03 05:33:27,149:INFO:                pyod: 1.1.0
2024-01-03 05:33:27,149:INFO:            imblearn: 0.10.1
2024-01-03 05:33:27,149:INFO:   category_encoders: 2.6.2
2024-01-03 05:33:27,149:INFO:            lightgbm: 4.1.0
2024-01-03 05:33:27,149:INFO:               numba: 0.56.4
2024-01-03 05:33:27,149:INFO:            requests: 2.28.1
2024-01-03 05:33:27,149:INFO:          matplotlib: 3.7.0
2024-01-03 05:33:27,149:INFO:          scikitplot: 0.3.7
2024-01-03 05:33:27,149:INFO:         yellowbrick: 1.5
2024-01-03 05:33:27,149:INFO:              plotly: 5.9.0
2024-01-03 05:33:27,149:INFO:    plotly-resampler: Not installed
2024-01-03 05:33:27,149:INFO:             kaleido: 0.2.1
2024-01-03 05:33:27,149:INFO:           schemdraw: 0.15
2024-01-03 05:33:27,149:INFO:         statsmodels: 0.13.5
2024-01-03 05:33:27,149:INFO:              sktime: 0.21.1
2024-01-03 05:33:27,149:INFO:               tbats: 1.1.3
2024-01-03 05:33:27,149:INFO:            pmdarima: 2.0.3
2024-01-03 05:33:27,149:INFO:              psutil: 5.9.0
2024-01-03 05:33:27,149:INFO:          markupsafe: 2.1.1
2024-01-03 05:33:27,149:INFO:             pickle5: Not installed
2024-01-03 05:33:27,150:INFO:         cloudpickle: 2.0.0
2024-01-03 05:33:27,150:INFO:         deprecation: 2.1.0
2024-01-03 05:33:27,150:INFO:              xxhash: 3.4.1
2024-01-03 05:33:27,150:INFO:           wurlitzer: Not installed
2024-01-03 05:33:27,150:INFO:PyCaret optional dependencies:
2024-01-03 05:33:27,150:INFO:                shap: Not installed
2024-01-03 05:33:27,150:INFO:           interpret: Not installed
2024-01-03 05:33:27,150:INFO:                umap: Not installed
2024-01-03 05:33:27,150:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:33:27,150:INFO:  explainerdashboard: Not installed
2024-01-03 05:33:27,150:INFO:             autoviz: Not installed
2024-01-03 05:33:27,150:INFO:           fairlearn: Not installed
2024-01-03 05:33:27,150:INFO:          deepchecks: Not installed
2024-01-03 05:33:27,150:INFO:             xgboost: Not installed
2024-01-03 05:33:27,150:INFO:            catboost: Not installed
2024-01-03 05:33:27,150:INFO:              kmodes: Not installed
2024-01-03 05:33:27,150:INFO:             mlxtend: Not installed
2024-01-03 05:33:27,150:INFO:       statsforecast: Not installed
2024-01-03 05:33:27,150:INFO:        tune_sklearn: Not installed
2024-01-03 05:33:27,150:INFO:                 ray: Not installed
2024-01-03 05:33:27,150:INFO:            hyperopt: Not installed
2024-01-03 05:33:27,150:INFO:              optuna: Not installed
2024-01-03 05:33:27,150:INFO:               skopt: Not installed
2024-01-03 05:33:27,150:INFO:              mlflow: Not installed
2024-01-03 05:33:27,151:INFO:              gradio: Not installed
2024-01-03 05:33:27,151:INFO:             fastapi: Not installed
2024-01-03 05:33:27,151:INFO:             uvicorn: Not installed
2024-01-03 05:33:27,151:INFO:              m2cgen: Not installed
2024-01-03 05:33:27,151:INFO:           evidently: Not installed
2024-01-03 05:33:27,151:INFO:               fugue: Not installed
2024-01-03 05:33:27,151:INFO:           streamlit: Not installed
2024-01-03 05:33:27,151:INFO:             prophet: Not installed
2024-01-03 05:33:27,151:INFO:None
2024-01-03 05:33:27,151:INFO:Set up data.
2024-01-03 05:33:27,209:INFO:Set up folding strategy.
2024-01-03 05:33:27,209:INFO:Set up train/test split.
2024-01-03 05:33:27,246:INFO:Set up index.
2024-01-03 05:33:27,248:INFO:Assigning column types.
2024-01-03 05:33:27,274:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 05:33:27,312:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:33:27,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:33:27,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,374:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:33:27,375:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:33:27,399:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,399:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,399:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 05:33:27,438:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:33:27,462:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,462:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,503:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:33:27,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,527:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 05:33:27,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:27,652:INFO:Preparing preprocessing pipeline...
2024-01-03 05:33:27,656:INFO:Set up simple imputation.
2024-01-03 05:33:27,731:INFO:Finished creating preprocessing pipeline.
2024-01-03 05:33:27,735:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['0', '1', '2', '3', '4', '6', '7',
                                             '8', '9', '10', '11', '12', '13',
                                             '14', '15', '16', '17', '18', '19',
                                             '20', '21', '22', '23', '24', '25',
                                             '26', '27', '28', '29', '30', ...],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated')))],
         verbose=False)
2024-01-03 05:33:27,735:INFO:Creating final display dataframe.
2024-01-03 05:33:27,940:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target                 5
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              723f
2024-01-03 05:33:28,011:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:28,011:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:28,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:28,078:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:33:28,079:INFO:setup() successfully completed in 0.94s...............
2024-01-03 05:33:52,009:INFO:Initializing compare_models()
2024-01-03 05:33:52,009:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-03 05:33:52,009:INFO:Checking exceptions
2024-01-03 05:33:52,036:INFO:Preparing display monitor
2024-01-03 05:33:52,061:INFO:Initializing Logistic Regression
2024-01-03 05:33:52,061:INFO:Total runtime is 0.0 minutes
2024-01-03 05:33:52,065:INFO:SubProcess create_model() called ==================================
2024-01-03 05:33:52,065:INFO:Initializing create_model()
2024-01-03 05:33:52,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:33:52,065:INFO:Checking exceptions
2024-01-03 05:33:52,065:INFO:Importing libraries
2024-01-03 05:33:52,066:INFO:Copying training dataset
2024-01-03 05:33:52,120:INFO:Defining folds
2024-01-03 05:33:52,120:INFO:Declaring metric variables
2024-01-03 05:33:52,125:INFO:Importing untrained model
2024-01-03 05:33:52,131:INFO:Logistic Regression Imported successfully
2024-01-03 05:33:52,140:INFO:Starting cross validation
2024-01-03 05:33:52,141:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:38,887:INFO:Calculating mean and std
2024-01-03 05:34:38,888:INFO:Creating metrics dataframe
2024-01-03 05:34:38,893:INFO:Uploading results into container
2024-01-03 05:34:38,894:INFO:Uploading model into container now
2024-01-03 05:34:38,894:INFO:_master_model_container: 1
2024-01-03 05:34:38,895:INFO:_display_container: 2
2024-01-03 05:34:38,895:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 05:34:38,895:INFO:create_model() successfully completed......................................
2024-01-03 05:34:39,184:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:39,184:INFO:Creating metrics dataframe
2024-01-03 05:34:39,195:INFO:Initializing K Neighbors Classifier
2024-01-03 05:34:39,196:INFO:Total runtime is 0.7855748653411865 minutes
2024-01-03 05:34:39,200:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:39,201:INFO:Initializing create_model()
2024-01-03 05:34:39,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:39,201:INFO:Checking exceptions
2024-01-03 05:34:39,202:INFO:Importing libraries
2024-01-03 05:34:39,202:INFO:Copying training dataset
2024-01-03 05:34:39,252:INFO:Defining folds
2024-01-03 05:34:39,252:INFO:Declaring metric variables
2024-01-03 05:34:39,256:INFO:Importing untrained model
2024-01-03 05:34:39,260:INFO:K Neighbors Classifier Imported successfully
2024-01-03 05:34:39,272:INFO:Starting cross validation
2024-01-03 05:34:39,273:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:45,867:INFO:Calculating mean and std
2024-01-03 05:34:45,868:INFO:Creating metrics dataframe
2024-01-03 05:34:45,871:INFO:Uploading results into container
2024-01-03 05:34:45,872:INFO:Uploading model into container now
2024-01-03 05:34:45,872:INFO:_master_model_container: 2
2024-01-03 05:34:45,872:INFO:_display_container: 2
2024-01-03 05:34:45,873:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 05:34:45,873:INFO:create_model() successfully completed......................................
2024-01-03 05:34:46,058:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:46,058:INFO:Creating metrics dataframe
2024-01-03 05:34:46,073:INFO:Initializing Naive Bayes
2024-01-03 05:34:46,073:INFO:Total runtime is 0.9001878341039021 minutes
2024-01-03 05:34:46,076:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:46,077:INFO:Initializing create_model()
2024-01-03 05:34:46,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:46,077:INFO:Checking exceptions
2024-01-03 05:34:46,077:INFO:Importing libraries
2024-01-03 05:34:46,077:INFO:Copying training dataset
2024-01-03 05:34:46,111:INFO:Defining folds
2024-01-03 05:34:46,111:INFO:Declaring metric variables
2024-01-03 05:34:46,114:INFO:Importing untrained model
2024-01-03 05:34:46,118:INFO:Naive Bayes Imported successfully
2024-01-03 05:34:46,130:INFO:Starting cross validation
2024-01-03 05:34:46,132:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:46,904:INFO:Calculating mean and std
2024-01-03 05:34:46,904:INFO:Creating metrics dataframe
2024-01-03 05:34:46,908:INFO:Uploading results into container
2024-01-03 05:34:46,908:INFO:Uploading model into container now
2024-01-03 05:34:46,908:INFO:_master_model_container: 3
2024-01-03 05:34:46,909:INFO:_display_container: 2
2024-01-03 05:34:46,909:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 05:34:46,909:INFO:create_model() successfully completed......................................
2024-01-03 05:34:47,096:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:47,096:INFO:Creating metrics dataframe
2024-01-03 05:34:47,105:INFO:Initializing Decision Tree Classifier
2024-01-03 05:34:47,105:INFO:Total runtime is 0.9173984964688618 minutes
2024-01-03 05:34:47,109:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:47,109:INFO:Initializing create_model()
2024-01-03 05:34:47,109:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:47,109:INFO:Checking exceptions
2024-01-03 05:34:47,109:INFO:Importing libraries
2024-01-03 05:34:47,109:INFO:Copying training dataset
2024-01-03 05:34:47,148:INFO:Defining folds
2024-01-03 05:34:47,148:INFO:Declaring metric variables
2024-01-03 05:34:47,151:INFO:Importing untrained model
2024-01-03 05:34:47,155:INFO:Decision Tree Classifier Imported successfully
2024-01-03 05:34:47,162:INFO:Starting cross validation
2024-01-03 05:34:47,163:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:48,206:INFO:Calculating mean and std
2024-01-03 05:34:48,207:INFO:Creating metrics dataframe
2024-01-03 05:34:48,210:INFO:Uploading results into container
2024-01-03 05:34:48,211:INFO:Uploading model into container now
2024-01-03 05:34:48,211:INFO:_master_model_container: 4
2024-01-03 05:34:48,211:INFO:_display_container: 2
2024-01-03 05:34:48,212:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-03 05:34:48,212:INFO:create_model() successfully completed......................................
2024-01-03 05:34:48,386:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:48,387:INFO:Creating metrics dataframe
2024-01-03 05:34:48,397:INFO:Initializing SVM - Linear Kernel
2024-01-03 05:34:48,397:INFO:Total runtime is 0.938934580485026 minutes
2024-01-03 05:34:48,401:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:48,401:INFO:Initializing create_model()
2024-01-03 05:34:48,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:48,401:INFO:Checking exceptions
2024-01-03 05:34:48,401:INFO:Importing libraries
2024-01-03 05:34:48,401:INFO:Copying training dataset
2024-01-03 05:34:48,441:INFO:Defining folds
2024-01-03 05:34:48,441:INFO:Declaring metric variables
2024-01-03 05:34:48,445:INFO:Importing untrained model
2024-01-03 05:34:48,450:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 05:34:48,459:INFO:Starting cross validation
2024-01-03 05:34:48,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:49,451:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,516:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,533:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,560:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,583:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,592:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,598:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,602:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,605:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,658:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:34:49,792:INFO:Calculating mean and std
2024-01-03 05:34:49,793:INFO:Creating metrics dataframe
2024-01-03 05:34:49,796:INFO:Uploading results into container
2024-01-03 05:34:49,796:INFO:Uploading model into container now
2024-01-03 05:34:49,797:INFO:_master_model_container: 5
2024-01-03 05:34:49,797:INFO:_display_container: 2
2024-01-03 05:34:49,798:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 05:34:49,798:INFO:create_model() successfully completed......................................
2024-01-03 05:34:50,051:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:50,051:INFO:Creating metrics dataframe
2024-01-03 05:34:50,061:INFO:Initializing Ridge Classifier
2024-01-03 05:34:50,061:INFO:Total runtime is 0.9666620214780172 minutes
2024-01-03 05:34:50,064:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:50,064:INFO:Initializing create_model()
2024-01-03 05:34:50,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:50,065:INFO:Checking exceptions
2024-01-03 05:34:50,065:INFO:Importing libraries
2024-01-03 05:34:50,065:INFO:Copying training dataset
2024-01-03 05:34:50,101:INFO:Defining folds
2024-01-03 05:34:50,102:INFO:Declaring metric variables
2024-01-03 05:34:50,105:INFO:Importing untrained model
2024-01-03 05:34:50,108:INFO:Ridge Classifier Imported successfully
2024-01-03 05:34:50,114:INFO:Starting cross validation
2024-01-03 05:34:50,116:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:50,578:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,579:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,579:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,579:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,585:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,593:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,596:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,596:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,597:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,599:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:34:50,747:INFO:Calculating mean and std
2024-01-03 05:34:50,751:INFO:Creating metrics dataframe
2024-01-03 05:34:50,764:INFO:Uploading results into container
2024-01-03 05:34:50,767:INFO:Uploading model into container now
2024-01-03 05:34:50,768:INFO:_master_model_container: 6
2024-01-03 05:34:50,768:INFO:_display_container: 2
2024-01-03 05:34:50,769:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-03 05:34:50,770:INFO:create_model() successfully completed......................................
2024-01-03 05:34:50,960:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:50,960:INFO:Creating metrics dataframe
2024-01-03 05:34:50,972:INFO:Initializing Random Forest Classifier
2024-01-03 05:34:50,972:INFO:Total runtime is 0.9818505962689718 minutes
2024-01-03 05:34:50,978:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:50,978:INFO:Initializing create_model()
2024-01-03 05:34:50,979:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:50,979:INFO:Checking exceptions
2024-01-03 05:34:50,979:INFO:Importing libraries
2024-01-03 05:34:50,979:INFO:Copying training dataset
2024-01-03 05:34:51,025:INFO:Defining folds
2024-01-03 05:34:51,026:INFO:Declaring metric variables
2024-01-03 05:34:51,031:INFO:Importing untrained model
2024-01-03 05:34:51,035:INFO:Random Forest Classifier Imported successfully
2024-01-03 05:34:51,042:INFO:Starting cross validation
2024-01-03 05:34:51,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:34:58,611:INFO:Calculating mean and std
2024-01-03 05:34:58,616:INFO:Creating metrics dataframe
2024-01-03 05:34:58,622:INFO:Uploading results into container
2024-01-03 05:34:58,622:INFO:Uploading model into container now
2024-01-03 05:34:58,623:INFO:_master_model_container: 7
2024-01-03 05:34:58,623:INFO:_display_container: 2
2024-01-03 05:34:58,624:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-03 05:34:58,624:INFO:create_model() successfully completed......................................
2024-01-03 05:34:58,818:INFO:SubProcess create_model() end ==================================
2024-01-03 05:34:58,818:INFO:Creating metrics dataframe
2024-01-03 05:34:58,830:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 05:34:58,830:INFO:Total runtime is 1.1128079533576964 minutes
2024-01-03 05:34:58,834:INFO:SubProcess create_model() called ==================================
2024-01-03 05:34:58,834:INFO:Initializing create_model()
2024-01-03 05:34:58,834:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:34:58,835:INFO:Checking exceptions
2024-01-03 05:34:58,835:INFO:Importing libraries
2024-01-03 05:34:58,835:INFO:Copying training dataset
2024-01-03 05:34:58,883:INFO:Defining folds
2024-01-03 05:34:58,883:INFO:Declaring metric variables
2024-01-03 05:34:58,886:INFO:Importing untrained model
2024-01-03 05:34:58,891:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 05:34:58,898:INFO:Starting cross validation
2024-01-03 05:34:58,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:00,061:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,061:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,097:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,100:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,145:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,158:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,159:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,188:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,204:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,207:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:35:00,540:INFO:Calculating mean and std
2024-01-03 05:35:00,542:INFO:Creating metrics dataframe
2024-01-03 05:35:00,546:INFO:Uploading results into container
2024-01-03 05:35:00,546:INFO:Uploading model into container now
2024-01-03 05:35:00,547:INFO:_master_model_container: 8
2024-01-03 05:35:00,547:INFO:_display_container: 2
2024-01-03 05:35:00,548:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 05:35:00,548:INFO:create_model() successfully completed......................................
2024-01-03 05:35:00,921:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:00,921:INFO:Creating metrics dataframe
2024-01-03 05:35:00,933:INFO:Initializing Ada Boost Classifier
2024-01-03 05:35:00,933:INFO:Total runtime is 1.1478633721669513 minutes
2024-01-03 05:35:00,937:INFO:SubProcess create_model() called ==================================
2024-01-03 05:35:00,938:INFO:Initializing create_model()
2024-01-03 05:35:00,938:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:00,938:INFO:Checking exceptions
2024-01-03 05:35:00,938:INFO:Importing libraries
2024-01-03 05:35:00,938:INFO:Copying training dataset
2024-01-03 05:35:00,982:INFO:Defining folds
2024-01-03 05:35:00,982:INFO:Declaring metric variables
2024-01-03 05:35:00,985:INFO:Importing untrained model
2024-01-03 05:35:00,989:INFO:Ada Boost Classifier Imported successfully
2024-01-03 05:35:00,996:INFO:Starting cross validation
2024-01-03 05:35:00,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:03,661:INFO:Calculating mean and std
2024-01-03 05:35:03,662:INFO:Creating metrics dataframe
2024-01-03 05:35:03,667:INFO:Uploading results into container
2024-01-03 05:35:03,667:INFO:Uploading model into container now
2024-01-03 05:35:03,668:INFO:_master_model_container: 9
2024-01-03 05:35:03,668:INFO:_display_container: 2
2024-01-03 05:35:03,668:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-03 05:35:03,668:INFO:create_model() successfully completed......................................
2024-01-03 05:35:03,852:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:03,853:INFO:Creating metrics dataframe
2024-01-03 05:35:03,863:INFO:Initializing Gradient Boosting Classifier
2024-01-03 05:35:03,864:INFO:Total runtime is 1.1967150489489236 minutes
2024-01-03 05:35:03,868:INFO:SubProcess create_model() called ==================================
2024-01-03 05:35:03,868:INFO:Initializing create_model()
2024-01-03 05:35:03,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:03,869:INFO:Checking exceptions
2024-01-03 05:35:03,869:INFO:Importing libraries
2024-01-03 05:35:03,869:INFO:Copying training dataset
2024-01-03 05:35:03,903:INFO:Defining folds
2024-01-03 05:35:03,903:INFO:Declaring metric variables
2024-01-03 05:35:03,906:INFO:Importing untrained model
2024-01-03 05:35:03,910:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 05:35:03,918:INFO:Starting cross validation
2024-01-03 05:35:03,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:11,028:INFO:Calculating mean and std
2024-01-03 05:35:11,032:INFO:Creating metrics dataframe
2024-01-03 05:35:11,046:INFO:Uploading results into container
2024-01-03 05:35:11,049:INFO:Uploading model into container now
2024-01-03 05:35:11,050:INFO:_master_model_container: 10
2024-01-03 05:35:11,051:INFO:_display_container: 2
2024-01-03 05:35:11,053:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 05:35:11,054:INFO:create_model() successfully completed......................................
2024-01-03 05:35:11,244:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:11,244:INFO:Creating metrics dataframe
2024-01-03 05:35:11,255:INFO:Initializing Linear Discriminant Analysis
2024-01-03 05:35:11,255:INFO:Total runtime is 1.3198924263318377 minutes
2024-01-03 05:35:11,258:INFO:SubProcess create_model() called ==================================
2024-01-03 05:35:11,258:INFO:Initializing create_model()
2024-01-03 05:35:11,258:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:11,258:INFO:Checking exceptions
2024-01-03 05:35:11,258:INFO:Importing libraries
2024-01-03 05:35:11,259:INFO:Copying training dataset
2024-01-03 05:35:11,293:INFO:Defining folds
2024-01-03 05:35:11,293:INFO:Declaring metric variables
2024-01-03 05:35:11,296:INFO:Importing untrained model
2024-01-03 05:35:11,299:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 05:35:11,304:INFO:Starting cross validation
2024-01-03 05:35:11,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:15,625:INFO:Calculating mean and std
2024-01-03 05:35:15,626:INFO:Creating metrics dataframe
2024-01-03 05:35:15,630:INFO:Uploading results into container
2024-01-03 05:35:15,630:INFO:Uploading model into container now
2024-01-03 05:35:15,631:INFO:_master_model_container: 11
2024-01-03 05:35:15,631:INFO:_display_container: 2
2024-01-03 05:35:15,631:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 05:35:15,631:INFO:create_model() successfully completed......................................
2024-01-03 05:35:15,800:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:15,800:INFO:Creating metrics dataframe
2024-01-03 05:35:15,811:INFO:Initializing Extra Trees Classifier
2024-01-03 05:35:15,811:INFO:Total runtime is 1.3958225448926287 minutes
2024-01-03 05:35:15,813:INFO:SubProcess create_model() called ==================================
2024-01-03 05:35:15,814:INFO:Initializing create_model()
2024-01-03 05:35:15,814:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:15,815:INFO:Checking exceptions
2024-01-03 05:35:15,815:INFO:Importing libraries
2024-01-03 05:35:15,816:INFO:Copying training dataset
2024-01-03 05:35:15,846:INFO:Defining folds
2024-01-03 05:35:15,847:INFO:Declaring metric variables
2024-01-03 05:35:15,849:INFO:Importing untrained model
2024-01-03 05:35:15,852:INFO:Extra Trees Classifier Imported successfully
2024-01-03 05:35:15,862:INFO:Starting cross validation
2024-01-03 05:35:15,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:25,796:INFO:Calculating mean and std
2024-01-03 05:35:25,798:INFO:Creating metrics dataframe
2024-01-03 05:35:25,803:INFO:Uploading results into container
2024-01-03 05:35:25,805:INFO:Uploading model into container now
2024-01-03 05:35:25,806:INFO:_master_model_container: 12
2024-01-03 05:35:25,806:INFO:_display_container: 2
2024-01-03 05:35:25,807:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-03 05:35:25,807:INFO:create_model() successfully completed......................................
2024-01-03 05:35:26,190:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:26,190:INFO:Creating metrics dataframe
2024-01-03 05:35:26,203:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 05:35:26,203:INFO:Total runtime is 1.5690192262331641 minutes
2024-01-03 05:35:26,208:INFO:SubProcess create_model() called ==================================
2024-01-03 05:35:26,209:INFO:Initializing create_model()
2024-01-03 05:35:26,209:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:26,209:INFO:Checking exceptions
2024-01-03 05:35:26,209:INFO:Importing libraries
2024-01-03 05:35:26,209:INFO:Copying training dataset
2024-01-03 05:35:26,249:INFO:Defining folds
2024-01-03 05:35:26,249:INFO:Declaring metric variables
2024-01-03 05:35:26,252:INFO:Importing untrained model
2024-01-03 05:35:26,257:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:35:26,265:INFO:Starting cross validation
2024-01-03 05:35:26,266:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:28,112:INFO:Calculating mean and std
2024-01-03 05:35:28,114:INFO:Creating metrics dataframe
2024-01-03 05:35:28,118:INFO:Uploading results into container
2024-01-03 05:35:28,119:INFO:Uploading model into container now
2024-01-03 05:35:28,119:INFO:_master_model_container: 13
2024-01-03 05:35:28,119:INFO:_display_container: 2
2024-01-03 05:35:28,120:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:35:28,120:INFO:create_model() successfully completed......................................
2024-01-03 05:35:28,302:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:28,302:INFO:Creating metrics dataframe
2024-01-03 05:35:28,314:INFO:Initializing Dummy Classifier
2024-01-03 05:35:28,314:INFO:Total runtime is 1.604207901159922 minutes
2024-01-03 05:35:28,319:INFO:SubProcess create_model() called ==================================
2024-01-03 05:35:28,320:INFO:Initializing create_model()
2024-01-03 05:35:28,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB71AAFE0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:28,320:INFO:Checking exceptions
2024-01-03 05:35:28,320:INFO:Importing libraries
2024-01-03 05:35:28,320:INFO:Copying training dataset
2024-01-03 05:35:28,353:INFO:Defining folds
2024-01-03 05:35:28,353:INFO:Declaring metric variables
2024-01-03 05:35:28,356:INFO:Importing untrained model
2024-01-03 05:35:28,362:INFO:Dummy Classifier Imported successfully
2024-01-03 05:35:28,371:INFO:Starting cross validation
2024-01-03 05:35:28,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:35:28,687:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,700:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,720:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,730:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,743:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,750:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,761:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,762:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,767:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:35:28,898:INFO:Calculating mean and std
2024-01-03 05:35:28,902:INFO:Creating metrics dataframe
2024-01-03 05:35:28,910:INFO:Uploading results into container
2024-01-03 05:35:28,911:INFO:Uploading model into container now
2024-01-03 05:35:28,912:INFO:_master_model_container: 14
2024-01-03 05:35:28,912:INFO:_display_container: 2
2024-01-03 05:35:28,912:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-03 05:35:28,912:INFO:create_model() successfully completed......................................
2024-01-03 05:35:29,077:INFO:SubProcess create_model() end ==================================
2024-01-03 05:35:29,077:INFO:Creating metrics dataframe
2024-01-03 05:35:29,098:INFO:Initializing create_model()
2024-01-03 05:35:29,099:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA4C7970>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:35:29,099:INFO:Checking exceptions
2024-01-03 05:35:29,100:INFO:Importing libraries
2024-01-03 05:35:29,100:INFO:Copying training dataset
2024-01-03 05:35:29,131:INFO:Defining folds
2024-01-03 05:35:29,132:INFO:Declaring metric variables
2024-01-03 05:35:29,132:INFO:Importing untrained model
2024-01-03 05:35:29,132:INFO:Declaring custom model
2024-01-03 05:35:29,132:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:35:29,133:INFO:Cross validation set to False
2024-01-03 05:35:29,133:INFO:Fitting Model
2024-01-03 05:35:29,197:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:35:29,200:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001506 seconds.
2024-01-03 05:35:29,200:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:35:29,200:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:35:29,201:INFO:[LightGBM] [Info] Total Bins 156
2024-01-03 05:35:29,201:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:35:29,201:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:35:29,201:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:35:29,290:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:35:29,291:INFO:create_model() successfully completed......................................
2024-01-03 05:35:29,529:INFO:_master_model_container: 14
2024-01-03 05:35:29,529:INFO:_display_container: 2
2024-01-03 05:35:29,529:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:35:29,529:INFO:compare_models() successfully completed......................................
2024-01-03 05:49:49,875:INFO:PyCaret ClassificationExperiment
2024-01-03 05:49:49,875:INFO:Logging name: clf-default-name
2024-01-03 05:49:49,875:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:49:49,875:INFO:version 3.1.0
2024-01-03 05:49:49,875:INFO:Initializing setup()
2024-01-03 05:49:49,875:INFO:self.USI: 1000
2024-01-03 05:49:49,875:INFO:self._variable_keys: {'X_train', 'logging_param', 'idx', 'exp_name_log', 'USI', '_ml_usecase', 'seed', 'log_plots_param', 'gpu_n_jobs_param', 'is_multiclass', 'fold_shuffle_param', 'fix_imbalance', 'y_train', 'memory', 'X_test', 'pipeline', 'X', 'html_param', 'fold_groups_param', 'y_test', '_available_plots', 'n_jobs_param', 'target_param', 'data', 'gpu_param', 'y', 'fold_generator', 'exp_id'}
2024-01-03 05:49:49,875:INFO:Checking environment
2024-01-03 05:49:49,875:INFO:python_version: 3.10.9
2024-01-03 05:49:49,875:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:49:49,875:INFO:machine: AMD64
2024-01-03 05:49:49,875:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:49:49,875:INFO:Memory: svmem(total=16954372096, available=5374406656, percent=68.3, used=11579965440, free=5374406656)
2024-01-03 05:49:49,875:INFO:Physical Core: 8
2024-01-03 05:49:49,875:INFO:Logical Core: 16
2024-01-03 05:49:49,875:INFO:Checking libraries
2024-01-03 05:49:49,875:INFO:System:
2024-01-03 05:49:49,876:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:49:49,876:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:49:49,876:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:49:49,876:INFO:PyCaret required dependencies:
2024-01-03 05:49:49,876:INFO:                 pip: 22.3.1
2024-01-03 05:49:49,876:INFO:          setuptools: 65.6.3
2024-01-03 05:49:49,876:INFO:             pycaret: 3.1.0
2024-01-03 05:49:49,876:INFO:             IPython: 8.10.0
2024-01-03 05:49:49,876:INFO:          ipywidgets: 7.6.5
2024-01-03 05:49:49,876:INFO:                tqdm: 4.64.1
2024-01-03 05:49:49,876:INFO:               numpy: 1.23.5
2024-01-03 05:49:49,876:INFO:              pandas: 1.5.3
2024-01-03 05:49:49,876:INFO:              jinja2: 3.1.2
2024-01-03 05:49:49,876:INFO:               scipy: 1.10.1
2024-01-03 05:49:49,876:INFO:              joblib: 1.3.2
2024-01-03 05:49:49,876:INFO:             sklearn: 1.2.1
2024-01-03 05:49:49,876:INFO:                pyod: 1.1.0
2024-01-03 05:49:49,876:INFO:            imblearn: 0.10.1
2024-01-03 05:49:49,876:INFO:   category_encoders: 2.6.2
2024-01-03 05:49:49,876:INFO:            lightgbm: 4.1.0
2024-01-03 05:49:49,877:INFO:               numba: 0.56.4
2024-01-03 05:49:49,877:INFO:            requests: 2.28.1
2024-01-03 05:49:49,877:INFO:          matplotlib: 3.7.0
2024-01-03 05:49:49,877:INFO:          scikitplot: 0.3.7
2024-01-03 05:49:49,877:INFO:         yellowbrick: 1.5
2024-01-03 05:49:49,877:INFO:              plotly: 5.9.0
2024-01-03 05:49:49,877:INFO:    plotly-resampler: Not installed
2024-01-03 05:49:49,877:INFO:             kaleido: 0.2.1
2024-01-03 05:49:49,877:INFO:           schemdraw: 0.15
2024-01-03 05:49:49,877:INFO:         statsmodels: 0.13.5
2024-01-03 05:49:49,877:INFO:              sktime: 0.21.1
2024-01-03 05:49:49,877:INFO:               tbats: 1.1.3
2024-01-03 05:49:49,877:INFO:            pmdarima: 2.0.3
2024-01-03 05:49:49,877:INFO:              psutil: 5.9.0
2024-01-03 05:49:49,877:INFO:          markupsafe: 2.1.1
2024-01-03 05:49:49,877:INFO:             pickle5: Not installed
2024-01-03 05:49:49,877:INFO:         cloudpickle: 2.0.0
2024-01-03 05:49:49,877:INFO:         deprecation: 2.1.0
2024-01-03 05:49:49,877:INFO:              xxhash: 3.4.1
2024-01-03 05:49:49,877:INFO:           wurlitzer: Not installed
2024-01-03 05:49:49,877:INFO:PyCaret optional dependencies:
2024-01-03 05:49:49,877:INFO:                shap: Not installed
2024-01-03 05:49:49,877:INFO:           interpret: Not installed
2024-01-03 05:49:49,878:INFO:                umap: Not installed
2024-01-03 05:49:49,878:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:49:49,878:INFO:  explainerdashboard: Not installed
2024-01-03 05:49:49,878:INFO:             autoviz: Not installed
2024-01-03 05:49:49,878:INFO:           fairlearn: Not installed
2024-01-03 05:49:49,878:INFO:          deepchecks: Not installed
2024-01-03 05:49:49,878:INFO:             xgboost: Not installed
2024-01-03 05:49:49,878:INFO:            catboost: Not installed
2024-01-03 05:49:49,878:INFO:              kmodes: Not installed
2024-01-03 05:49:49,878:INFO:             mlxtend: Not installed
2024-01-03 05:49:49,878:INFO:       statsforecast: Not installed
2024-01-03 05:49:49,879:INFO:        tune_sklearn: Not installed
2024-01-03 05:49:49,879:INFO:                 ray: Not installed
2024-01-03 05:49:49,879:INFO:            hyperopt: Not installed
2024-01-03 05:49:49,879:INFO:              optuna: Not installed
2024-01-03 05:49:49,879:INFO:               skopt: Not installed
2024-01-03 05:49:49,879:INFO:              mlflow: Not installed
2024-01-03 05:49:49,879:INFO:              gradio: Not installed
2024-01-03 05:49:49,879:INFO:             fastapi: Not installed
2024-01-03 05:49:49,879:INFO:             uvicorn: Not installed
2024-01-03 05:49:49,879:INFO:              m2cgen: Not installed
2024-01-03 05:49:49,879:INFO:           evidently: Not installed
2024-01-03 05:49:49,879:INFO:               fugue: Not installed
2024-01-03 05:49:49,879:INFO:           streamlit: Not installed
2024-01-03 05:49:49,879:INFO:             prophet: Not installed
2024-01-03 05:49:49,879:INFO:None
2024-01-03 05:49:49,879:INFO:Set up data.
2024-01-03 05:49:49,938:INFO:Set up folding strategy.
2024-01-03 05:49:49,939:INFO:Set up train/test split.
2024-01-03 05:49:49,970:INFO:Set up index.
2024-01-03 05:49:49,973:INFO:Assigning column types.
2024-01-03 05:49:49,997:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 05:49:50,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:49:50,036:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:49:50,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:49:50,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:49:50,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,123:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 05:49:50,161:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:49:50,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,223:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:49:50,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,248:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,248:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 05:49:50,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,388:INFO:Preparing preprocessing pipeline...
2024-01-03 05:49:50,391:INFO:Set up simple imputation.
2024-01-03 05:49:50,394:INFO:Set up column name cleaning.
2024-01-03 05:49:50,501:INFO:Finished creating preprocessing pipeline.
2024-01-03 05:49:50,506:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-03 05:49:50,506:INFO:Creating final display dataframe.
2024-01-03 05:49:50,817:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              1000
2024-01-03 05:49:50,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,886:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:49:50,948:INFO:setup() successfully completed in 1.08s...............
2024-01-03 05:49:50,979:INFO:Initializing compare_models()
2024-01-03 05:49:50,979:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-03 05:49:50,979:INFO:Checking exceptions
2024-01-03 05:49:50,999:INFO:Preparing display monitor
2024-01-03 05:49:51,028:INFO:Initializing Logistic Regression
2024-01-03 05:49:51,028:INFO:Total runtime is 0.0 minutes
2024-01-03 05:49:51,031:INFO:SubProcess create_model() called ==================================
2024-01-03 05:49:51,032:INFO:Initializing create_model()
2024-01-03 05:49:51,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:49:51,032:INFO:Checking exceptions
2024-01-03 05:49:51,032:INFO:Importing libraries
2024-01-03 05:49:51,032:INFO:Copying training dataset
2024-01-03 05:49:51,061:INFO:Defining folds
2024-01-03 05:49:51,061:INFO:Declaring metric variables
2024-01-03 05:49:51,067:INFO:Importing untrained model
2024-01-03 05:49:51,073:INFO:Logistic Regression Imported successfully
2024-01-03 05:49:51,085:INFO:Starting cross validation
2024-01-03 05:49:51,087:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:50:29,454:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:53,975:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:53,992:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,132:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,282:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,300:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,484:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,590:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,715:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:50:54,861:INFO:Calculating mean and std
2024-01-03 05:50:54,862:INFO:Creating metrics dataframe
2024-01-03 05:50:54,866:INFO:Uploading results into container
2024-01-03 05:50:54,866:INFO:Uploading model into container now
2024-01-03 05:50:54,867:INFO:_master_model_container: 1
2024-01-03 05:50:54,867:INFO:_display_container: 2
2024-01-03 05:50:54,868:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 05:50:54,868:INFO:create_model() successfully completed......................................
2024-01-03 05:50:55,050:INFO:SubProcess create_model() end ==================================
2024-01-03 05:50:55,051:INFO:Creating metrics dataframe
2024-01-03 05:50:55,058:INFO:Initializing K Neighbors Classifier
2024-01-03 05:50:55,059:INFO:Total runtime is 1.0671802679697673 minutes
2024-01-03 05:50:55,062:INFO:SubProcess create_model() called ==================================
2024-01-03 05:50:55,062:INFO:Initializing create_model()
2024-01-03 05:50:55,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:50:55,062:INFO:Checking exceptions
2024-01-03 05:50:55,062:INFO:Importing libraries
2024-01-03 05:50:55,062:INFO:Copying training dataset
2024-01-03 05:50:55,092:INFO:Defining folds
2024-01-03 05:50:55,092:INFO:Declaring metric variables
2024-01-03 05:50:55,095:INFO:Importing untrained model
2024-01-03 05:50:55,099:INFO:K Neighbors Classifier Imported successfully
2024-01-03 05:50:55,106:INFO:Starting cross validation
2024-01-03 05:50:55,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:02,703:INFO:Calculating mean and std
2024-01-03 05:51:02,704:INFO:Creating metrics dataframe
2024-01-03 05:51:02,709:INFO:Uploading results into container
2024-01-03 05:51:02,709:INFO:Uploading model into container now
2024-01-03 05:51:02,710:INFO:_master_model_container: 2
2024-01-03 05:51:02,710:INFO:_display_container: 2
2024-01-03 05:51:02,711:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 05:51:02,711:INFO:create_model() successfully completed......................................
2024-01-03 05:51:02,905:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:02,905:INFO:Creating metrics dataframe
2024-01-03 05:51:02,915:INFO:Initializing Naive Bayes
2024-01-03 05:51:02,915:INFO:Total runtime is 1.1981030543645224 minutes
2024-01-03 05:51:02,918:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:02,918:INFO:Initializing create_model()
2024-01-03 05:51:02,918:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:02,918:INFO:Checking exceptions
2024-01-03 05:51:02,919:INFO:Importing libraries
2024-01-03 05:51:02,919:INFO:Copying training dataset
2024-01-03 05:51:02,949:INFO:Defining folds
2024-01-03 05:51:02,949:INFO:Declaring metric variables
2024-01-03 05:51:02,953:INFO:Importing untrained model
2024-01-03 05:51:02,957:INFO:Naive Bayes Imported successfully
2024-01-03 05:51:02,965:INFO:Starting cross validation
2024-01-03 05:51:02,967:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:04,130:INFO:Calculating mean and std
2024-01-03 05:51:04,131:INFO:Creating metrics dataframe
2024-01-03 05:51:04,135:INFO:Uploading results into container
2024-01-03 05:51:04,135:INFO:Uploading model into container now
2024-01-03 05:51:04,135:INFO:_master_model_container: 3
2024-01-03 05:51:04,135:INFO:_display_container: 2
2024-01-03 05:51:04,135:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 05:51:04,136:INFO:create_model() successfully completed......................................
2024-01-03 05:51:04,316:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:04,317:INFO:Creating metrics dataframe
2024-01-03 05:51:04,327:INFO:Initializing Decision Tree Classifier
2024-01-03 05:51:04,327:INFO:Total runtime is 1.2216365178426107 minutes
2024-01-03 05:51:04,330:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:04,331:INFO:Initializing create_model()
2024-01-03 05:51:04,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:04,331:INFO:Checking exceptions
2024-01-03 05:51:04,331:INFO:Importing libraries
2024-01-03 05:51:04,331:INFO:Copying training dataset
2024-01-03 05:51:04,360:INFO:Defining folds
2024-01-03 05:51:04,360:INFO:Declaring metric variables
2024-01-03 05:51:04,364:INFO:Importing untrained model
2024-01-03 05:51:04,369:INFO:Decision Tree Classifier Imported successfully
2024-01-03 05:51:04,376:INFO:Starting cross validation
2024-01-03 05:51:04,377:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:05,703:INFO:Calculating mean and std
2024-01-03 05:51:05,707:INFO:Creating metrics dataframe
2024-01-03 05:51:05,716:INFO:Uploading results into container
2024-01-03 05:51:05,717:INFO:Uploading model into container now
2024-01-03 05:51:05,717:INFO:_master_model_container: 4
2024-01-03 05:51:05,717:INFO:_display_container: 2
2024-01-03 05:51:05,717:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-03 05:51:05,718:INFO:create_model() successfully completed......................................
2024-01-03 05:51:05,888:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:05,889:INFO:Creating metrics dataframe
2024-01-03 05:51:05,899:INFO:Initializing SVM - Linear Kernel
2024-01-03 05:51:05,899:INFO:Total runtime is 1.2478416442871094 minutes
2024-01-03 05:51:05,902:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:05,902:INFO:Initializing create_model()
2024-01-03 05:51:05,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:05,902:INFO:Checking exceptions
2024-01-03 05:51:05,902:INFO:Importing libraries
2024-01-03 05:51:05,902:INFO:Copying training dataset
2024-01-03 05:51:05,931:INFO:Defining folds
2024-01-03 05:51:05,932:INFO:Declaring metric variables
2024-01-03 05:51:05,935:INFO:Importing untrained model
2024-01-03 05:51:05,939:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 05:51:05,947:INFO:Starting cross validation
2024-01-03 05:51:05,949:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:07,030:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,189:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,215:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,259:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,303:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,321:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,335:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,386:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,387:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,437:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:51:07,568:INFO:Calculating mean and std
2024-01-03 05:51:07,570:INFO:Creating metrics dataframe
2024-01-03 05:51:07,575:INFO:Uploading results into container
2024-01-03 05:51:07,575:INFO:Uploading model into container now
2024-01-03 05:51:07,576:INFO:_master_model_container: 5
2024-01-03 05:51:07,576:INFO:_display_container: 2
2024-01-03 05:51:07,576:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 05:51:07,577:INFO:create_model() successfully completed......................................
2024-01-03 05:51:07,742:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:07,743:INFO:Creating metrics dataframe
2024-01-03 05:51:07,752:INFO:Initializing Ridge Classifier
2024-01-03 05:51:07,752:INFO:Total runtime is 1.2787333647410075 minutes
2024-01-03 05:51:07,754:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:07,755:INFO:Initializing create_model()
2024-01-03 05:51:07,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:07,755:INFO:Checking exceptions
2024-01-03 05:51:07,755:INFO:Importing libraries
2024-01-03 05:51:07,755:INFO:Copying training dataset
2024-01-03 05:51:07,784:INFO:Defining folds
2024-01-03 05:51:07,784:INFO:Declaring metric variables
2024-01-03 05:51:07,787:INFO:Importing untrained model
2024-01-03 05:51:07,791:INFO:Ridge Classifier Imported successfully
2024-01-03 05:51:07,799:INFO:Starting cross validation
2024-01-03 05:51:07,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:08,643:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,662:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,664:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,683:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,696:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,702:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,706:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,709:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,712:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,720:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:51:08,856:INFO:Calculating mean and std
2024-01-03 05:51:08,857:INFO:Creating metrics dataframe
2024-01-03 05:51:08,860:INFO:Uploading results into container
2024-01-03 05:51:08,861:INFO:Uploading model into container now
2024-01-03 05:51:08,861:INFO:_master_model_container: 6
2024-01-03 05:51:08,862:INFO:_display_container: 2
2024-01-03 05:51:08,862:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-03 05:51:08,862:INFO:create_model() successfully completed......................................
2024-01-03 05:51:09,030:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:09,031:INFO:Creating metrics dataframe
2024-01-03 05:51:09,040:INFO:Initializing Random Forest Classifier
2024-01-03 05:51:09,040:INFO:Total runtime is 1.300192165374756 minutes
2024-01-03 05:51:09,043:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:09,043:INFO:Initializing create_model()
2024-01-03 05:51:09,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:09,043:INFO:Checking exceptions
2024-01-03 05:51:09,043:INFO:Importing libraries
2024-01-03 05:51:09,043:INFO:Copying training dataset
2024-01-03 05:51:09,072:INFO:Defining folds
2024-01-03 05:51:09,073:INFO:Declaring metric variables
2024-01-03 05:51:09,076:INFO:Importing untrained model
2024-01-03 05:51:09,080:INFO:Random Forest Classifier Imported successfully
2024-01-03 05:51:09,087:INFO:Starting cross validation
2024-01-03 05:51:09,089:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:16,358:INFO:Calculating mean and std
2024-01-03 05:51:16,361:INFO:Creating metrics dataframe
2024-01-03 05:51:16,367:INFO:Uploading results into container
2024-01-03 05:51:16,368:INFO:Uploading model into container now
2024-01-03 05:51:16,368:INFO:_master_model_container: 7
2024-01-03 05:51:16,368:INFO:_display_container: 2
2024-01-03 05:51:16,369:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-03 05:51:16,369:INFO:create_model() successfully completed......................................
2024-01-03 05:51:16,565:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:16,565:INFO:Creating metrics dataframe
2024-01-03 05:51:16,576:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 05:51:16,577:INFO:Total runtime is 1.425804634888967 minutes
2024-01-03 05:51:16,580:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:16,580:INFO:Initializing create_model()
2024-01-03 05:51:16,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:16,581:INFO:Checking exceptions
2024-01-03 05:51:16,581:INFO:Importing libraries
2024-01-03 05:51:16,581:INFO:Copying training dataset
2024-01-03 05:51:16,613:INFO:Defining folds
2024-01-03 05:51:16,613:INFO:Declaring metric variables
2024-01-03 05:51:16,618:INFO:Importing untrained model
2024-01-03 05:51:16,622:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 05:51:16,629:INFO:Starting cross validation
2024-01-03 05:51:16,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:17,929:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,015:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,015:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,034:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,036:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,039:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,040:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,051:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,051:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,054:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:51:18,533:INFO:Calculating mean and std
2024-01-03 05:51:18,534:INFO:Creating metrics dataframe
2024-01-03 05:51:18,538:INFO:Uploading results into container
2024-01-03 05:51:18,539:INFO:Uploading model into container now
2024-01-03 05:51:18,539:INFO:_master_model_container: 8
2024-01-03 05:51:18,539:INFO:_display_container: 2
2024-01-03 05:51:18,540:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 05:51:18,540:INFO:create_model() successfully completed......................................
2024-01-03 05:51:18,728:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:18,728:INFO:Creating metrics dataframe
2024-01-03 05:51:18,741:INFO:Initializing Ada Boost Classifier
2024-01-03 05:51:18,742:INFO:Total runtime is 1.4619001905123394 minutes
2024-01-03 05:51:18,745:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:18,745:INFO:Initializing create_model()
2024-01-03 05:51:18,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:18,746:INFO:Checking exceptions
2024-01-03 05:51:18,746:INFO:Importing libraries
2024-01-03 05:51:18,746:INFO:Copying training dataset
2024-01-03 05:51:18,776:INFO:Defining folds
2024-01-03 05:51:18,777:INFO:Declaring metric variables
2024-01-03 05:51:18,780:INFO:Importing untrained model
2024-01-03 05:51:18,784:INFO:Ada Boost Classifier Imported successfully
2024-01-03 05:51:18,791:INFO:Starting cross validation
2024-01-03 05:51:18,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:24,270:INFO:Calculating mean and std
2024-01-03 05:51:24,271:INFO:Creating metrics dataframe
2024-01-03 05:51:24,274:INFO:Uploading results into container
2024-01-03 05:51:24,274:INFO:Uploading model into container now
2024-01-03 05:51:24,275:INFO:_master_model_container: 9
2024-01-03 05:51:24,275:INFO:_display_container: 2
2024-01-03 05:51:24,275:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-03 05:51:24,275:INFO:create_model() successfully completed......................................
2024-01-03 05:51:24,431:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:24,432:INFO:Creating metrics dataframe
2024-01-03 05:51:24,442:INFO:Initializing Gradient Boosting Classifier
2024-01-03 05:51:24,442:INFO:Total runtime is 1.5569005211194358 minutes
2024-01-03 05:51:24,445:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:24,445:INFO:Initializing create_model()
2024-01-03 05:51:24,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:24,445:INFO:Checking exceptions
2024-01-03 05:51:24,445:INFO:Importing libraries
2024-01-03 05:51:24,445:INFO:Copying training dataset
2024-01-03 05:51:24,475:INFO:Defining folds
2024-01-03 05:51:24,476:INFO:Declaring metric variables
2024-01-03 05:51:24,480:INFO:Importing untrained model
2024-01-03 05:51:24,484:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 05:51:24,491:INFO:Starting cross validation
2024-01-03 05:51:24,493:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:30,697:INFO:Calculating mean and std
2024-01-03 05:51:30,701:INFO:Creating metrics dataframe
2024-01-03 05:51:30,714:INFO:Uploading results into container
2024-01-03 05:51:30,717:INFO:Uploading model into container now
2024-01-03 05:51:30,718:INFO:_master_model_container: 10
2024-01-03 05:51:30,719:INFO:_display_container: 2
2024-01-03 05:51:30,720:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 05:51:30,720:INFO:create_model() successfully completed......................................
2024-01-03 05:51:30,903:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:30,903:INFO:Creating metrics dataframe
2024-01-03 05:51:30,915:INFO:Initializing Linear Discriminant Analysis
2024-01-03 05:51:30,915:INFO:Total runtime is 1.6647682388623557 minutes
2024-01-03 05:51:30,918:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:30,919:INFO:Initializing create_model()
2024-01-03 05:51:30,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:30,919:INFO:Checking exceptions
2024-01-03 05:51:30,919:INFO:Importing libraries
2024-01-03 05:51:30,919:INFO:Copying training dataset
2024-01-03 05:51:30,949:INFO:Defining folds
2024-01-03 05:51:30,950:INFO:Declaring metric variables
2024-01-03 05:51:30,954:INFO:Importing untrained model
2024-01-03 05:51:30,957:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 05:51:30,964:INFO:Starting cross validation
2024-01-03 05:51:30,965:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:35,150:INFO:Calculating mean and std
2024-01-03 05:51:35,151:INFO:Creating metrics dataframe
2024-01-03 05:51:35,155:INFO:Uploading results into container
2024-01-03 05:51:35,155:INFO:Uploading model into container now
2024-01-03 05:51:35,156:INFO:_master_model_container: 11
2024-01-03 05:51:35,156:INFO:_display_container: 2
2024-01-03 05:51:35,156:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 05:51:35,156:INFO:create_model() successfully completed......................................
2024-01-03 05:51:35,328:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:35,328:INFO:Creating metrics dataframe
2024-01-03 05:51:35,340:INFO:Initializing Extra Trees Classifier
2024-01-03 05:51:35,340:INFO:Total runtime is 1.7385217785835267 minutes
2024-01-03 05:51:35,343:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:35,343:INFO:Initializing create_model()
2024-01-03 05:51:35,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:35,343:INFO:Checking exceptions
2024-01-03 05:51:35,343:INFO:Importing libraries
2024-01-03 05:51:35,343:INFO:Copying training dataset
2024-01-03 05:51:35,370:INFO:Defining folds
2024-01-03 05:51:35,371:INFO:Declaring metric variables
2024-01-03 05:51:35,374:INFO:Importing untrained model
2024-01-03 05:51:35,378:INFO:Extra Trees Classifier Imported successfully
2024-01-03 05:51:35,385:INFO:Starting cross validation
2024-01-03 05:51:35,386:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:45,840:INFO:Calculating mean and std
2024-01-03 05:51:45,841:INFO:Creating metrics dataframe
2024-01-03 05:51:45,845:INFO:Uploading results into container
2024-01-03 05:51:45,845:INFO:Uploading model into container now
2024-01-03 05:51:45,846:INFO:_master_model_container: 12
2024-01-03 05:51:45,846:INFO:_display_container: 2
2024-01-03 05:51:45,846:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-03 05:51:45,847:INFO:create_model() successfully completed......................................
2024-01-03 05:51:46,070:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:46,071:INFO:Creating metrics dataframe
2024-01-03 05:51:46,097:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 05:51:46,097:INFO:Total runtime is 1.9178163011868796 minutes
2024-01-03 05:51:46,100:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:46,100:INFO:Initializing create_model()
2024-01-03 05:51:46,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:46,101:INFO:Checking exceptions
2024-01-03 05:51:46,101:INFO:Importing libraries
2024-01-03 05:51:46,101:INFO:Copying training dataset
2024-01-03 05:51:46,132:INFO:Defining folds
2024-01-03 05:51:46,132:INFO:Declaring metric variables
2024-01-03 05:51:46,135:INFO:Importing untrained model
2024-01-03 05:51:46,139:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:51:46,145:INFO:Starting cross validation
2024-01-03 05:51:46,146:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:48,391:INFO:Calculating mean and std
2024-01-03 05:51:48,393:INFO:Creating metrics dataframe
2024-01-03 05:51:48,403:INFO:Uploading results into container
2024-01-03 05:51:48,404:INFO:Uploading model into container now
2024-01-03 05:51:48,404:INFO:_master_model_container: 13
2024-01-03 05:51:48,404:INFO:_display_container: 2
2024-01-03 05:51:48,406:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:51:48,406:INFO:create_model() successfully completed......................................
2024-01-03 05:51:48,601:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:48,601:INFO:Creating metrics dataframe
2024-01-03 05:51:48,613:INFO:Initializing Dummy Classifier
2024-01-03 05:51:48,613:INFO:Total runtime is 1.9597367087999982 minutes
2024-01-03 05:51:48,617:INFO:SubProcess create_model() called ==================================
2024-01-03 05:51:48,617:INFO:Initializing create_model()
2024-01-03 05:51:48,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019EB955F3A0>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:48,618:INFO:Checking exceptions
2024-01-03 05:51:48,618:INFO:Importing libraries
2024-01-03 05:51:48,618:INFO:Copying training dataset
2024-01-03 05:51:48,648:INFO:Defining folds
2024-01-03 05:51:48,648:INFO:Declaring metric variables
2024-01-03 05:51:48,652:INFO:Importing untrained model
2024-01-03 05:51:48,655:INFO:Dummy Classifier Imported successfully
2024-01-03 05:51:48,661:INFO:Starting cross validation
2024-01-03 05:51:48,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:51:49,224:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,238:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,239:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,251:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,265:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,266:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,274:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,278:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,278:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,284:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:51:49,407:INFO:Calculating mean and std
2024-01-03 05:51:49,411:INFO:Creating metrics dataframe
2024-01-03 05:51:49,424:INFO:Uploading results into container
2024-01-03 05:51:49,425:INFO:Uploading model into container now
2024-01-03 05:51:49,425:INFO:_master_model_container: 14
2024-01-03 05:51:49,425:INFO:_display_container: 2
2024-01-03 05:51:49,425:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-03 05:51:49,426:INFO:create_model() successfully completed......................................
2024-01-03 05:51:49,605:INFO:SubProcess create_model() end ==================================
2024-01-03 05:51:49,605:INFO:Creating metrics dataframe
2024-01-03 05:51:49,627:INFO:Initializing create_model()
2024-01-03 05:51:49,627:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019EBA856920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:51:49,627:INFO:Checking exceptions
2024-01-03 05:51:49,628:INFO:Importing libraries
2024-01-03 05:51:49,629:INFO:Copying training dataset
2024-01-03 05:51:49,658:INFO:Defining folds
2024-01-03 05:51:49,658:INFO:Declaring metric variables
2024-01-03 05:51:49,658:INFO:Importing untrained model
2024-01-03 05:51:49,658:INFO:Declaring custom model
2024-01-03 05:51:49,659:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:51:49,659:INFO:Cross validation set to False
2024-01-03 05:51:49,659:INFO:Fitting Model
2024-01-03 05:51:49,769:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:51:49,769:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:51:49,772:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001070 seconds.
2024-01-03 05:51:49,772:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:51:49,772:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:51:49,772:INFO:[LightGBM] [Info] Total Bins 444
2024-01-03 05:51:49,772:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:51:49,773:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:51:49,773:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:51:49,879:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:51:49,879:INFO:create_model() successfully completed......................................
2024-01-03 05:51:50,091:INFO:_master_model_container: 14
2024-01-03 05:51:50,091:INFO:_display_container: 2
2024-01-03 05:51:50,092:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:51:50,092:INFO:compare_models() successfully completed......................................
2024-01-03 05:52:27,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:52:27,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:52:27,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:52:27,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-03 05:52:29,613:INFO:PyCaret ClassificationExperiment
2024-01-03 05:52:29,613:INFO:Logging name: clf-default-name
2024-01-03 05:52:29,613:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-03 05:52:29,613:INFO:version 3.1.0
2024-01-03 05:52:29,613:INFO:Initializing setup()
2024-01-03 05:52:29,613:INFO:self.USI: 4c0a
2024-01-03 05:52:29,613:INFO:self._variable_keys: {'data', 'n_jobs_param', 'X', 'USI', 'exp_name_log', 'pipeline', 'y_train', 'target_param', 'fold_groups_param', 'is_multiclass', 'X_test', 'log_plots_param', 'fix_imbalance', '_ml_usecase', 'html_param', 'gpu_param', 'X_train', 'y_test', '_available_plots', 'y', 'memory', 'fold_shuffle_param', 'gpu_n_jobs_param', 'fold_generator', 'logging_param', 'exp_id', 'idx', 'seed'}
2024-01-03 05:52:29,613:INFO:Checking environment
2024-01-03 05:52:29,613:INFO:python_version: 3.10.9
2024-01-03 05:52:29,613:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-03 05:52:29,613:INFO:machine: AMD64
2024-01-03 05:52:29,613:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-03 05:52:29,614:INFO:Memory: svmem(total=16954372096, available=5588189184, percent=67.0, used=11366182912, free=5588189184)
2024-01-03 05:52:29,614:INFO:Physical Core: 8
2024-01-03 05:52:29,614:INFO:Logical Core: 16
2024-01-03 05:52:29,614:INFO:Checking libraries
2024-01-03 05:52:29,614:INFO:System:
2024-01-03 05:52:29,614:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-03 05:52:29,614:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-03 05:52:29,614:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-03 05:52:29,614:INFO:PyCaret required dependencies:
2024-01-03 05:52:30,176:INFO:                 pip: 22.3.1
2024-01-03 05:52:30,176:INFO:          setuptools: 65.6.3
2024-01-03 05:52:30,176:INFO:             pycaret: 3.1.0
2024-01-03 05:52:30,176:INFO:             IPython: 8.10.0
2024-01-03 05:52:30,176:INFO:          ipywidgets: 7.6.5
2024-01-03 05:52:30,176:INFO:                tqdm: 4.64.1
2024-01-03 05:52:30,176:INFO:               numpy: 1.23.5
2024-01-03 05:52:30,176:INFO:              pandas: 1.5.3
2024-01-03 05:52:30,176:INFO:              jinja2: 3.1.2
2024-01-03 05:52:30,176:INFO:               scipy: 1.10.1
2024-01-03 05:52:30,176:INFO:              joblib: 1.3.2
2024-01-03 05:52:30,176:INFO:             sklearn: 1.2.1
2024-01-03 05:52:30,176:INFO:                pyod: 1.1.0
2024-01-03 05:52:30,176:INFO:            imblearn: 0.10.1
2024-01-03 05:52:30,177:INFO:   category_encoders: 2.6.2
2024-01-03 05:52:30,177:INFO:            lightgbm: 4.1.0
2024-01-03 05:52:30,177:INFO:               numba: 0.56.4
2024-01-03 05:52:30,177:INFO:            requests: 2.28.1
2024-01-03 05:52:30,177:INFO:          matplotlib: 3.7.0
2024-01-03 05:52:30,177:INFO:          scikitplot: 0.3.7
2024-01-03 05:52:30,177:INFO:         yellowbrick: 1.5
2024-01-03 05:52:30,177:INFO:              plotly: 5.9.0
2024-01-03 05:52:30,177:INFO:    plotly-resampler: Not installed
2024-01-03 05:52:30,177:INFO:             kaleido: 0.2.1
2024-01-03 05:52:30,177:INFO:           schemdraw: 0.15
2024-01-03 05:52:30,177:INFO:         statsmodels: 0.13.5
2024-01-03 05:52:30,177:INFO:              sktime: 0.21.1
2024-01-03 05:52:30,177:INFO:               tbats: 1.1.3
2024-01-03 05:52:30,177:INFO:            pmdarima: 2.0.3
2024-01-03 05:52:30,177:INFO:              psutil: 5.9.0
2024-01-03 05:52:30,177:INFO:          markupsafe: 2.1.1
2024-01-03 05:52:30,177:INFO:             pickle5: Not installed
2024-01-03 05:52:30,177:INFO:         cloudpickle: 2.0.0
2024-01-03 05:52:30,177:INFO:         deprecation: 2.1.0
2024-01-03 05:52:30,177:INFO:              xxhash: 3.4.1
2024-01-03 05:52:30,177:INFO:           wurlitzer: Not installed
2024-01-03 05:52:30,177:INFO:PyCaret optional dependencies:
2024-01-03 05:52:30,192:INFO:                shap: Not installed
2024-01-03 05:52:30,192:INFO:           interpret: Not installed
2024-01-03 05:52:30,192:INFO:                umap: Not installed
2024-01-03 05:52:30,193:INFO:     ydata_profiling: 4.6.0
2024-01-03 05:52:30,193:INFO:  explainerdashboard: Not installed
2024-01-03 05:52:30,193:INFO:             autoviz: Not installed
2024-01-03 05:52:30,193:INFO:           fairlearn: Not installed
2024-01-03 05:52:30,193:INFO:          deepchecks: Not installed
2024-01-03 05:52:30,193:INFO:             xgboost: Not installed
2024-01-03 05:52:30,193:INFO:            catboost: Not installed
2024-01-03 05:52:30,193:INFO:              kmodes: Not installed
2024-01-03 05:52:30,193:INFO:             mlxtend: Not installed
2024-01-03 05:52:30,193:INFO:       statsforecast: Not installed
2024-01-03 05:52:30,193:INFO:        tune_sklearn: Not installed
2024-01-03 05:52:30,193:INFO:                 ray: Not installed
2024-01-03 05:52:30,193:INFO:            hyperopt: Not installed
2024-01-03 05:52:30,193:INFO:              optuna: Not installed
2024-01-03 05:52:30,193:INFO:               skopt: Not installed
2024-01-03 05:52:30,193:INFO:              mlflow: Not installed
2024-01-03 05:52:30,193:INFO:              gradio: Not installed
2024-01-03 05:52:30,193:INFO:             fastapi: Not installed
2024-01-03 05:52:30,193:INFO:             uvicorn: Not installed
2024-01-03 05:52:30,193:INFO:              m2cgen: Not installed
2024-01-03 05:52:30,193:INFO:           evidently: Not installed
2024-01-03 05:52:30,193:INFO:               fugue: Not installed
2024-01-03 05:52:30,193:INFO:           streamlit: Not installed
2024-01-03 05:52:30,193:INFO:             prophet: Not installed
2024-01-03 05:52:30,194:INFO:None
2024-01-03 05:52:30,194:INFO:Set up data.
2024-01-03 05:52:30,244:INFO:Set up folding strategy.
2024-01-03 05:52:30,244:INFO:Set up train/test split.
2024-01-03 05:52:30,274:INFO:Set up index.
2024-01-03 05:52:30,275:INFO:Assigning column types.
2024-01-03 05:52:30,298:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-03 05:52:30,338:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:52:30,340:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:52:30,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,407:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-03 05:52:30,408:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:52:30,432:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,432:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-03 05:52:30,473:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:52:30,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-03 05:52:30,568:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,568:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,568:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-03 05:52:30,636:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,636:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,701:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:30,703:INFO:Preparing preprocessing pipeline...
2024-01-03 05:52:30,707:INFO:Set up simple imputation.
2024-01-03 05:52:30,711:INFO:Set up column name cleaning.
2024-01-03 05:52:30,824:INFO:Finished creating preprocessing pipeline.
2024-01-03 05:52:30,830:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-03 05:52:30,830:INFO:Creating final display dataframe.
2024-01-03 05:52:31,140:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              4c0a
2024-01-03 05:52:31,212:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:31,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:31,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:31,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-03 05:52:31,279:INFO:setup() successfully completed in 1.67s...............
2024-01-03 05:52:31,307:INFO:Initializing compare_models()
2024-01-03 05:52:31,307:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-03 05:52:31,307:INFO:Checking exceptions
2024-01-03 05:52:31,341:INFO:Preparing display monitor
2024-01-03 05:52:31,373:INFO:Initializing Logistic Regression
2024-01-03 05:52:31,374:INFO:Total runtime is 0.0 minutes
2024-01-03 05:52:31,377:INFO:SubProcess create_model() called ==================================
2024-01-03 05:52:31,377:INFO:Initializing create_model()
2024-01-03 05:52:31,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:52:31,377:INFO:Checking exceptions
2024-01-03 05:52:31,377:INFO:Importing libraries
2024-01-03 05:52:31,378:INFO:Copying training dataset
2024-01-03 05:52:31,416:INFO:Defining folds
2024-01-03 05:52:31,417:INFO:Declaring metric variables
2024-01-03 05:52:31,420:INFO:Importing untrained model
2024-01-03 05:52:31,424:INFO:Logistic Regression Imported successfully
2024-01-03 05:52:31,431:INFO:Starting cross validation
2024-01-03 05:52:31,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:39,110:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,153:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,226:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,302:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,313:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,527:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,575:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,667:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,721:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:53:39,874:INFO:Calculating mean and std
2024-01-03 05:53:39,879:INFO:Creating metrics dataframe
2024-01-03 05:53:39,893:INFO:Uploading results into container
2024-01-03 05:53:39,896:INFO:Uploading model into container now
2024-01-03 05:53:39,898:INFO:_master_model_container: 1
2024-01-03 05:53:39,898:INFO:_display_container: 2
2024-01-03 05:53:39,902:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 05:53:39,903:INFO:create_model() successfully completed......................................
2024-01-03 05:53:39,981:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:39,981:INFO:Creating metrics dataframe
2024-01-03 05:53:39,990:INFO:Initializing K Neighbors Classifier
2024-01-03 05:53:39,990:INFO:Total runtime is 1.1436078151067097 minutes
2024-01-03 05:53:39,992:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:39,993:INFO:Initializing create_model()
2024-01-03 05:53:39,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:39,993:INFO:Checking exceptions
2024-01-03 05:53:39,993:INFO:Importing libraries
2024-01-03 05:53:39,993:INFO:Copying training dataset
2024-01-03 05:53:40,023:INFO:Defining folds
2024-01-03 05:53:40,024:INFO:Declaring metric variables
2024-01-03 05:53:40,027:INFO:Importing untrained model
2024-01-03 05:53:40,030:INFO:K Neighbors Classifier Imported successfully
2024-01-03 05:53:40,036:INFO:Starting cross validation
2024-01-03 05:53:40,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:46,863:INFO:Calculating mean and std
2024-01-03 05:53:46,867:INFO:Creating metrics dataframe
2024-01-03 05:53:46,877:INFO:Uploading results into container
2024-01-03 05:53:46,878:INFO:Uploading model into container now
2024-01-03 05:53:46,879:INFO:_master_model_container: 2
2024-01-03 05:53:46,879:INFO:_display_container: 2
2024-01-03 05:53:46,879:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 05:53:46,879:INFO:create_model() successfully completed......................................
2024-01-03 05:53:46,955:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:46,956:INFO:Creating metrics dataframe
2024-01-03 05:53:46,965:INFO:Initializing Naive Bayes
2024-01-03 05:53:46,965:INFO:Total runtime is 1.25986377398173 minutes
2024-01-03 05:53:46,969:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:46,969:INFO:Initializing create_model()
2024-01-03 05:53:46,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:46,969:INFO:Checking exceptions
2024-01-03 05:53:46,969:INFO:Importing libraries
2024-01-03 05:53:46,969:INFO:Copying training dataset
2024-01-03 05:53:47,002:INFO:Defining folds
2024-01-03 05:53:47,002:INFO:Declaring metric variables
2024-01-03 05:53:47,006:INFO:Importing untrained model
2024-01-03 05:53:47,009:INFO:Naive Bayes Imported successfully
2024-01-03 05:53:47,015:INFO:Starting cross validation
2024-01-03 05:53:47,016:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:48,103:INFO:Calculating mean and std
2024-01-03 05:53:48,107:INFO:Creating metrics dataframe
2024-01-03 05:53:48,118:INFO:Uploading results into container
2024-01-03 05:53:48,120:INFO:Uploading model into container now
2024-01-03 05:53:48,121:INFO:_master_model_container: 3
2024-01-03 05:53:48,122:INFO:_display_container: 2
2024-01-03 05:53:48,122:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 05:53:48,123:INFO:create_model() successfully completed......................................
2024-01-03 05:53:48,198:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:48,198:INFO:Creating metrics dataframe
2024-01-03 05:53:48,207:INFO:Initializing Decision Tree Classifier
2024-01-03 05:53:48,207:INFO:Total runtime is 1.28055678208669 minutes
2024-01-03 05:53:48,210:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:48,211:INFO:Initializing create_model()
2024-01-03 05:53:48,211:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:48,211:INFO:Checking exceptions
2024-01-03 05:53:48,211:INFO:Importing libraries
2024-01-03 05:53:48,211:INFO:Copying training dataset
2024-01-03 05:53:48,241:INFO:Defining folds
2024-01-03 05:53:48,241:INFO:Declaring metric variables
2024-01-03 05:53:48,245:INFO:Importing untrained model
2024-01-03 05:53:48,249:INFO:Decision Tree Classifier Imported successfully
2024-01-03 05:53:48,256:INFO:Starting cross validation
2024-01-03 05:53:48,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:49,548:INFO:Calculating mean and std
2024-01-03 05:53:49,552:INFO:Creating metrics dataframe
2024-01-03 05:53:49,565:INFO:Uploading results into container
2024-01-03 05:53:49,568:INFO:Uploading model into container now
2024-01-03 05:53:49,570:INFO:_master_model_container: 4
2024-01-03 05:53:49,571:INFO:_display_container: 2
2024-01-03 05:53:49,572:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-03 05:53:49,573:INFO:create_model() successfully completed......................................
2024-01-03 05:53:49,648:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:49,648:INFO:Creating metrics dataframe
2024-01-03 05:53:49,657:INFO:Initializing SVM - Linear Kernel
2024-01-03 05:53:49,657:INFO:Total runtime is 1.3047317902247109 minutes
2024-01-03 05:53:49,660:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:49,660:INFO:Initializing create_model()
2024-01-03 05:53:49,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:49,660:INFO:Checking exceptions
2024-01-03 05:53:49,661:INFO:Importing libraries
2024-01-03 05:53:49,661:INFO:Copying training dataset
2024-01-03 05:53:49,691:INFO:Defining folds
2024-01-03 05:53:49,692:INFO:Declaring metric variables
2024-01-03 05:53:49,695:INFO:Importing untrained model
2024-01-03 05:53:49,699:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 05:53:49,706:INFO:Starting cross validation
2024-01-03 05:53:49,707:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:50,701:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:50,915:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:50,956:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:50,984:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:50,994:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:51,012:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:51,052:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:51,063:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:51,129:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:53:51,255:INFO:Calculating mean and std
2024-01-03 05:53:51,257:INFO:Creating metrics dataframe
2024-01-03 05:53:51,264:INFO:Uploading results into container
2024-01-03 05:53:51,265:INFO:Uploading model into container now
2024-01-03 05:53:51,265:INFO:_master_model_container: 5
2024-01-03 05:53:51,265:INFO:_display_container: 2
2024-01-03 05:53:51,266:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 05:53:51,266:INFO:create_model() successfully completed......................................
2024-01-03 05:53:51,336:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:51,336:INFO:Creating metrics dataframe
2024-01-03 05:53:51,346:INFO:Initializing Ridge Classifier
2024-01-03 05:53:51,346:INFO:Total runtime is 1.3328843037287392 minutes
2024-01-03 05:53:51,350:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:51,350:INFO:Initializing create_model()
2024-01-03 05:53:51,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:51,350:INFO:Checking exceptions
2024-01-03 05:53:51,350:INFO:Importing libraries
2024-01-03 05:53:51,350:INFO:Copying training dataset
2024-01-03 05:53:51,383:INFO:Defining folds
2024-01-03 05:53:51,383:INFO:Declaring metric variables
2024-01-03 05:53:51,386:INFO:Importing untrained model
2024-01-03 05:53:51,390:INFO:Ridge Classifier Imported successfully
2024-01-03 05:53:51,397:INFO:Starting cross validation
2024-01-03 05:53:51,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:52,203:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,212:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,214:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,244:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,262:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,265:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,272:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,280:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,281:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,294:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:53:52,420:INFO:Calculating mean and std
2024-01-03 05:53:52,421:INFO:Creating metrics dataframe
2024-01-03 05:53:52,424:INFO:Uploading results into container
2024-01-03 05:53:52,425:INFO:Uploading model into container now
2024-01-03 05:53:52,425:INFO:_master_model_container: 6
2024-01-03 05:53:52,425:INFO:_display_container: 2
2024-01-03 05:53:52,426:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-03 05:53:52,426:INFO:create_model() successfully completed......................................
2024-01-03 05:53:52,498:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:52,498:INFO:Creating metrics dataframe
2024-01-03 05:53:52,508:INFO:Initializing Random Forest Classifier
2024-01-03 05:53:52,508:INFO:Total runtime is 1.3522484819094338 minutes
2024-01-03 05:53:52,511:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:52,512:INFO:Initializing create_model()
2024-01-03 05:53:52,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:52,512:INFO:Checking exceptions
2024-01-03 05:53:52,512:INFO:Importing libraries
2024-01-03 05:53:52,512:INFO:Copying training dataset
2024-01-03 05:53:52,543:INFO:Defining folds
2024-01-03 05:53:52,543:INFO:Declaring metric variables
2024-01-03 05:53:52,547:INFO:Importing untrained model
2024-01-03 05:53:52,551:INFO:Random Forest Classifier Imported successfully
2024-01-03 05:53:52,557:INFO:Starting cross validation
2024-01-03 05:53:52,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:53:59,242:INFO:Calculating mean and std
2024-01-03 05:53:59,243:INFO:Creating metrics dataframe
2024-01-03 05:53:59,248:INFO:Uploading results into container
2024-01-03 05:53:59,249:INFO:Uploading model into container now
2024-01-03 05:53:59,249:INFO:_master_model_container: 7
2024-01-03 05:53:59,250:INFO:_display_container: 2
2024-01-03 05:53:59,250:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-03 05:53:59,250:INFO:create_model() successfully completed......................................
2024-01-03 05:53:59,339:INFO:SubProcess create_model() end ==================================
2024-01-03 05:53:59,340:INFO:Creating metrics dataframe
2024-01-03 05:53:59,351:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 05:53:59,351:INFO:Total runtime is 1.4662977695465087 minutes
2024-01-03 05:53:59,354:INFO:SubProcess create_model() called ==================================
2024-01-03 05:53:59,354:INFO:Initializing create_model()
2024-01-03 05:53:59,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:53:59,354:INFO:Checking exceptions
2024-01-03 05:53:59,355:INFO:Importing libraries
2024-01-03 05:53:59,355:INFO:Copying training dataset
2024-01-03 05:53:59,387:INFO:Defining folds
2024-01-03 05:53:59,387:INFO:Declaring metric variables
2024-01-03 05:53:59,390:INFO:Importing untrained model
2024-01-03 05:53:59,394:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 05:53:59,400:INFO:Starting cross validation
2024-01-03 05:53:59,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:00,729:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,764:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,784:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,787:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,807:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,808:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,837:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,876:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,918:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:00,929:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:54:01,308:INFO:Calculating mean and std
2024-01-03 05:54:01,311:INFO:Creating metrics dataframe
2024-01-03 05:54:01,324:INFO:Uploading results into container
2024-01-03 05:54:01,326:INFO:Uploading model into container now
2024-01-03 05:54:01,327:INFO:_master_model_container: 8
2024-01-03 05:54:01,327:INFO:_display_container: 2
2024-01-03 05:54:01,327:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 05:54:01,327:INFO:create_model() successfully completed......................................
2024-01-03 05:54:01,402:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:01,402:INFO:Creating metrics dataframe
2024-01-03 05:54:01,412:INFO:Initializing Ada Boost Classifier
2024-01-03 05:54:01,412:INFO:Total runtime is 1.500649603207906 minutes
2024-01-03 05:54:01,415:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:01,415:INFO:Initializing create_model()
2024-01-03 05:54:01,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:01,415:INFO:Checking exceptions
2024-01-03 05:54:01,415:INFO:Importing libraries
2024-01-03 05:54:01,416:INFO:Copying training dataset
2024-01-03 05:54:01,446:INFO:Defining folds
2024-01-03 05:54:01,446:INFO:Declaring metric variables
2024-01-03 05:54:01,449:INFO:Importing untrained model
2024-01-03 05:54:01,453:INFO:Ada Boost Classifier Imported successfully
2024-01-03 05:54:01,459:INFO:Starting cross validation
2024-01-03 05:54:01,460:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:06,966:INFO:Calculating mean and std
2024-01-03 05:54:06,970:INFO:Creating metrics dataframe
2024-01-03 05:54:06,982:INFO:Uploading results into container
2024-01-03 05:54:06,984:INFO:Uploading model into container now
2024-01-03 05:54:06,985:INFO:_master_model_container: 9
2024-01-03 05:54:06,985:INFO:_display_container: 2
2024-01-03 05:54:06,986:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-03 05:54:06,986:INFO:create_model() successfully completed......................................
2024-01-03 05:54:07,061:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:07,062:INFO:Creating metrics dataframe
2024-01-03 05:54:07,073:INFO:Initializing Gradient Boosting Classifier
2024-01-03 05:54:07,073:INFO:Total runtime is 1.5950038949648537 minutes
2024-01-03 05:54:07,077:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:07,077:INFO:Initializing create_model()
2024-01-03 05:54:07,077:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:07,077:INFO:Checking exceptions
2024-01-03 05:54:07,077:INFO:Importing libraries
2024-01-03 05:54:07,077:INFO:Copying training dataset
2024-01-03 05:54:07,109:INFO:Defining folds
2024-01-03 05:54:07,109:INFO:Declaring metric variables
2024-01-03 05:54:07,113:INFO:Importing untrained model
2024-01-03 05:54:07,116:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 05:54:07,123:INFO:Starting cross validation
2024-01-03 05:54:07,124:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:13,516:INFO:Calculating mean and std
2024-01-03 05:54:13,520:INFO:Creating metrics dataframe
2024-01-03 05:54:13,530:INFO:Uploading results into container
2024-01-03 05:54:13,531:INFO:Uploading model into container now
2024-01-03 05:54:13,532:INFO:_master_model_container: 10
2024-01-03 05:54:13,532:INFO:_display_container: 2
2024-01-03 05:54:13,533:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 05:54:13,533:INFO:create_model() successfully completed......................................
2024-01-03 05:54:13,608:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:13,608:INFO:Creating metrics dataframe
2024-01-03 05:54:13,619:INFO:Initializing Linear Discriminant Analysis
2024-01-03 05:54:13,619:INFO:Total runtime is 1.7040973504384356 minutes
2024-01-03 05:54:13,623:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:13,623:INFO:Initializing create_model()
2024-01-03 05:54:13,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:13,623:INFO:Checking exceptions
2024-01-03 05:54:13,623:INFO:Importing libraries
2024-01-03 05:54:13,623:INFO:Copying training dataset
2024-01-03 05:54:13,656:INFO:Defining folds
2024-01-03 05:54:13,656:INFO:Declaring metric variables
2024-01-03 05:54:13,660:INFO:Importing untrained model
2024-01-03 05:54:13,664:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 05:54:13,671:INFO:Starting cross validation
2024-01-03 05:54:13,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:17,748:INFO:Calculating mean and std
2024-01-03 05:54:17,750:INFO:Creating metrics dataframe
2024-01-03 05:54:17,753:INFO:Uploading results into container
2024-01-03 05:54:17,754:INFO:Uploading model into container now
2024-01-03 05:54:17,754:INFO:_master_model_container: 11
2024-01-03 05:54:17,754:INFO:_display_container: 2
2024-01-03 05:54:17,755:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 05:54:17,755:INFO:create_model() successfully completed......................................
2024-01-03 05:54:17,853:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:17,853:INFO:Creating metrics dataframe
2024-01-03 05:54:17,867:INFO:Initializing Extra Trees Classifier
2024-01-03 05:54:17,867:INFO:Total runtime is 1.774891352653503 minutes
2024-01-03 05:54:17,870:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:17,870:INFO:Initializing create_model()
2024-01-03 05:54:17,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:17,871:INFO:Checking exceptions
2024-01-03 05:54:17,871:INFO:Importing libraries
2024-01-03 05:54:17,871:INFO:Copying training dataset
2024-01-03 05:54:17,906:INFO:Defining folds
2024-01-03 05:54:17,906:INFO:Declaring metric variables
2024-01-03 05:54:17,912:INFO:Importing untrained model
2024-01-03 05:54:17,916:INFO:Extra Trees Classifier Imported successfully
2024-01-03 05:54:17,924:INFO:Starting cross validation
2024-01-03 05:54:17,926:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:26,663:INFO:Calculating mean and std
2024-01-03 05:54:26,666:INFO:Creating metrics dataframe
2024-01-03 05:54:26,677:INFO:Uploading results into container
2024-01-03 05:54:26,679:INFO:Uploading model into container now
2024-01-03 05:54:26,681:INFO:_master_model_container: 12
2024-01-03 05:54:26,681:INFO:_display_container: 2
2024-01-03 05:54:26,683:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-03 05:54:26,683:INFO:create_model() successfully completed......................................
2024-01-03 05:54:26,758:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:26,758:INFO:Creating metrics dataframe
2024-01-03 05:54:26,770:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 05:54:26,771:INFO:Total runtime is 1.9232837955156958 minutes
2024-01-03 05:54:26,774:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:26,774:INFO:Initializing create_model()
2024-01-03 05:54:26,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:26,774:INFO:Checking exceptions
2024-01-03 05:54:26,774:INFO:Importing libraries
2024-01-03 05:54:26,774:INFO:Copying training dataset
2024-01-03 05:54:26,807:INFO:Defining folds
2024-01-03 05:54:26,807:INFO:Declaring metric variables
2024-01-03 05:54:26,811:INFO:Importing untrained model
2024-01-03 05:54:26,815:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:54:26,822:INFO:Starting cross validation
2024-01-03 05:54:26,823:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:28,991:INFO:Calculating mean and std
2024-01-03 05:54:28,994:INFO:Creating metrics dataframe
2024-01-03 05:54:29,006:INFO:Uploading results into container
2024-01-03 05:54:29,008:INFO:Uploading model into container now
2024-01-03 05:54:29,009:INFO:_master_model_container: 13
2024-01-03 05:54:29,010:INFO:_display_container: 2
2024-01-03 05:54:29,011:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:54:29,011:INFO:create_model() successfully completed......................................
2024-01-03 05:54:29,086:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:29,086:INFO:Creating metrics dataframe
2024-01-03 05:54:29,097:INFO:Initializing Dummy Classifier
2024-01-03 05:54:29,097:INFO:Total runtime is 1.9620566566785174 minutes
2024-01-03 05:54:29,101:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:29,101:INFO:Initializing create_model()
2024-01-03 05:54:29,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F495C98280>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:29,101:INFO:Checking exceptions
2024-01-03 05:54:29,101:INFO:Importing libraries
2024-01-03 05:54:29,102:INFO:Copying training dataset
2024-01-03 05:54:29,132:INFO:Defining folds
2024-01-03 05:54:29,132:INFO:Declaring metric variables
2024-01-03 05:54:29,136:INFO:Importing untrained model
2024-01-03 05:54:29,139:INFO:Dummy Classifier Imported successfully
2024-01-03 05:54:29,146:INFO:Starting cross validation
2024-01-03 05:54:29,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:54:29,714:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,716:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,721:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,735:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,742:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,761:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,764:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,769:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,773:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,775:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:54:29,899:INFO:Calculating mean and std
2024-01-03 05:54:29,904:INFO:Creating metrics dataframe
2024-01-03 05:54:29,915:INFO:Uploading results into container
2024-01-03 05:54:29,917:INFO:Uploading model into container now
2024-01-03 05:54:29,918:INFO:_master_model_container: 14
2024-01-03 05:54:29,919:INFO:_display_container: 2
2024-01-03 05:54:29,919:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-03 05:54:29,919:INFO:create_model() successfully completed......................................
2024-01-03 05:54:30,024:INFO:SubProcess create_model() end ==================================
2024-01-03 05:54:30,024:INFO:Creating metrics dataframe
2024-01-03 05:54:30,046:INFO:Initializing create_model()
2024-01-03 05:54:30,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:30,046:INFO:Checking exceptions
2024-01-03 05:54:30,048:INFO:Importing libraries
2024-01-03 05:54:30,048:INFO:Copying training dataset
2024-01-03 05:54:30,079:INFO:Defining folds
2024-01-03 05:54:30,079:INFO:Declaring metric variables
2024-01-03 05:54:30,079:INFO:Importing untrained model
2024-01-03 05:54:30,079:INFO:Declaring custom model
2024-01-03 05:54:30,080:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:54:30,081:INFO:Cross validation set to False
2024-01-03 05:54:30,081:INFO:Fitting Model
2024-01-03 05:54:30,198:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:54:30,199:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:54:30,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001380 seconds.
2024-01-03 05:54:30,202:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:54:30,202:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:54:30,202:INFO:[LightGBM] [Info] Total Bins 444
2024-01-03 05:54:30,203:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:54:30,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:54:30,203:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:54:30,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:54:30,320:INFO:create_model() successfully completed......................................
2024-01-03 05:54:30,451:INFO:_master_model_container: 14
2024-01-03 05:54:30,451:INFO:_display_container: 2
2024-01-03 05:54:30,451:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:54:30,452:INFO:compare_models() successfully completed......................................
2024-01-03 05:54:55,079:INFO:Initializing compare_models()
2024-01-03 05:54:55,079:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-03 05:54:55,079:INFO:Checking exceptions
2024-01-03 05:54:55,092:INFO:Preparing display monitor
2024-01-03 05:54:55,122:INFO:Initializing Logistic Regression
2024-01-03 05:54:55,123:INFO:Total runtime is 1.6681353251139323e-05 minutes
2024-01-03 05:54:55,126:INFO:SubProcess create_model() called ==================================
2024-01-03 05:54:55,127:INFO:Initializing create_model()
2024-01-03 05:54:55,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:54:55,128:INFO:Checking exceptions
2024-01-03 05:54:55,128:INFO:Importing libraries
2024-01-03 05:54:55,128:INFO:Copying training dataset
2024-01-03 05:54:55,165:INFO:Defining folds
2024-01-03 05:54:55,165:INFO:Declaring metric variables
2024-01-03 05:54:55,169:INFO:Importing untrained model
2024-01-03 05:54:55,172:INFO:Logistic Regression Imported successfully
2024-01-03 05:54:55,178:INFO:Starting cross validation
2024-01-03 05:54:55,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:22,650:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:22,682:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:22,830:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:22,862:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:22,929:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:22,982:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:23,031:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:23,055:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:23,069:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-03 05:55:23,216:INFO:Calculating mean and std
2024-01-03 05:55:23,219:INFO:Creating metrics dataframe
2024-01-03 05:55:23,227:INFO:Uploading results into container
2024-01-03 05:55:23,228:INFO:Uploading model into container now
2024-01-03 05:55:23,229:INFO:_master_model_container: 15
2024-01-03 05:55:23,229:INFO:_display_container: 3
2024-01-03 05:55:23,230:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-03 05:55:23,230:INFO:create_model() successfully completed......................................
2024-01-03 05:55:23,305:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:23,305:INFO:Creating metrics dataframe
2024-01-03 05:55:23,313:INFO:Initializing K Neighbors Classifier
2024-01-03 05:55:23,313:INFO:Total runtime is 0.46984561681747433 minutes
2024-01-03 05:55:23,316:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:23,317:INFO:Initializing create_model()
2024-01-03 05:55:23,317:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:23,317:INFO:Checking exceptions
2024-01-03 05:55:23,317:INFO:Importing libraries
2024-01-03 05:55:23,317:INFO:Copying training dataset
2024-01-03 05:55:23,349:INFO:Defining folds
2024-01-03 05:55:23,350:INFO:Declaring metric variables
2024-01-03 05:55:23,354:INFO:Importing untrained model
2024-01-03 05:55:23,357:INFO:K Neighbors Classifier Imported successfully
2024-01-03 05:55:23,365:INFO:Starting cross validation
2024-01-03 05:55:23,367:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:27,004:INFO:Calculating mean and std
2024-01-03 05:55:27,008:INFO:Creating metrics dataframe
2024-01-03 05:55:27,021:INFO:Uploading results into container
2024-01-03 05:55:27,023:INFO:Uploading model into container now
2024-01-03 05:55:27,025:INFO:_master_model_container: 16
2024-01-03 05:55:27,026:INFO:_display_container: 3
2024-01-03 05:55:27,028:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-03 05:55:27,028:INFO:create_model() successfully completed......................................
2024-01-03 05:55:27,100:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:27,101:INFO:Creating metrics dataframe
2024-01-03 05:55:27,109:INFO:Initializing Naive Bayes
2024-01-03 05:55:27,109:INFO:Total runtime is 0.533116590976715 minutes
2024-01-03 05:55:27,112:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:27,112:INFO:Initializing create_model()
2024-01-03 05:55:27,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:27,112:INFO:Checking exceptions
2024-01-03 05:55:27,112:INFO:Importing libraries
2024-01-03 05:55:27,113:INFO:Copying training dataset
2024-01-03 05:55:27,145:INFO:Defining folds
2024-01-03 05:55:27,145:INFO:Declaring metric variables
2024-01-03 05:55:27,150:INFO:Importing untrained model
2024-01-03 05:55:27,154:INFO:Naive Bayes Imported successfully
2024-01-03 05:55:27,160:INFO:Starting cross validation
2024-01-03 05:55:27,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:28,246:INFO:Calculating mean and std
2024-01-03 05:55:28,250:INFO:Creating metrics dataframe
2024-01-03 05:55:28,263:INFO:Uploading results into container
2024-01-03 05:55:28,266:INFO:Uploading model into container now
2024-01-03 05:55:28,267:INFO:_master_model_container: 17
2024-01-03 05:55:28,267:INFO:_display_container: 3
2024-01-03 05:55:28,268:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-03 05:55:28,268:INFO:create_model() successfully completed......................................
2024-01-03 05:55:28,371:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:28,371:INFO:Creating metrics dataframe
2024-01-03 05:55:28,381:INFO:Initializing Decision Tree Classifier
2024-01-03 05:55:28,381:INFO:Total runtime is 0.55432497660319 minutes
2024-01-03 05:55:28,384:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:28,385:INFO:Initializing create_model()
2024-01-03 05:55:28,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:28,385:INFO:Checking exceptions
2024-01-03 05:55:28,385:INFO:Importing libraries
2024-01-03 05:55:28,385:INFO:Copying training dataset
2024-01-03 05:55:28,418:INFO:Defining folds
2024-01-03 05:55:28,419:INFO:Declaring metric variables
2024-01-03 05:55:28,424:INFO:Importing untrained model
2024-01-03 05:55:28,427:INFO:Decision Tree Classifier Imported successfully
2024-01-03 05:55:28,434:INFO:Starting cross validation
2024-01-03 05:55:28,436:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:29,721:INFO:Calculating mean and std
2024-01-03 05:55:29,725:INFO:Creating metrics dataframe
2024-01-03 05:55:29,737:INFO:Uploading results into container
2024-01-03 05:55:29,739:INFO:Uploading model into container now
2024-01-03 05:55:29,740:INFO:_master_model_container: 18
2024-01-03 05:55:29,741:INFO:_display_container: 3
2024-01-03 05:55:29,742:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-03 05:55:29,742:INFO:create_model() successfully completed......................................
2024-01-03 05:55:29,832:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:29,832:INFO:Creating metrics dataframe
2024-01-03 05:55:29,841:INFO:Initializing SVM - Linear Kernel
2024-01-03 05:55:29,842:INFO:Total runtime is 0.5786601225535074 minutes
2024-01-03 05:55:29,845:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:29,845:INFO:Initializing create_model()
2024-01-03 05:55:29,845:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:29,846:INFO:Checking exceptions
2024-01-03 05:55:29,846:INFO:Importing libraries
2024-01-03 05:55:29,846:INFO:Copying training dataset
2024-01-03 05:55:29,878:INFO:Defining folds
2024-01-03 05:55:29,878:INFO:Declaring metric variables
2024-01-03 05:55:29,883:INFO:Importing untrained model
2024-01-03 05:55:29,887:INFO:SVM - Linear Kernel Imported successfully
2024-01-03 05:55:29,893:INFO:Starting cross validation
2024-01-03 05:55:29,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:30,893:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,066:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,129:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,134:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,176:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,185:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,192:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,213:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,216:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,281:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-03 05:55:31,408:INFO:Calculating mean and std
2024-01-03 05:55:31,412:INFO:Creating metrics dataframe
2024-01-03 05:55:31,418:INFO:Uploading results into container
2024-01-03 05:55:31,419:INFO:Uploading model into container now
2024-01-03 05:55:31,419:INFO:_master_model_container: 19
2024-01-03 05:55:31,419:INFO:_display_container: 3
2024-01-03 05:55:31,420:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-03 05:55:31,420:INFO:create_model() successfully completed......................................
2024-01-03 05:55:31,494:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:31,494:INFO:Creating metrics dataframe
2024-01-03 05:55:31,503:INFO:Initializing Ridge Classifier
2024-01-03 05:55:31,503:INFO:Total runtime is 0.606342848141988 minutes
2024-01-03 05:55:31,506:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:31,506:INFO:Initializing create_model()
2024-01-03 05:55:31,506:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:31,506:INFO:Checking exceptions
2024-01-03 05:55:31,506:INFO:Importing libraries
2024-01-03 05:55:31,506:INFO:Copying training dataset
2024-01-03 05:55:31,540:INFO:Defining folds
2024-01-03 05:55:31,540:INFO:Declaring metric variables
2024-01-03 05:55:31,544:INFO:Importing untrained model
2024-01-03 05:55:31,549:INFO:Ridge Classifier Imported successfully
2024-01-03 05:55:31,555:INFO:Starting cross validation
2024-01-03 05:55:31,557:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:32,395:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,396:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,417:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,418:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,419:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,439:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,439:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,440:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,443:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,450:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-03 05:55:32,585:INFO:Calculating mean and std
2024-01-03 05:55:32,589:INFO:Creating metrics dataframe
2024-01-03 05:55:32,599:INFO:Uploading results into container
2024-01-03 05:55:32,600:INFO:Uploading model into container now
2024-01-03 05:55:32,601:INFO:_master_model_container: 20
2024-01-03 05:55:32,602:INFO:_display_container: 3
2024-01-03 05:55:32,602:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-03 05:55:32,602:INFO:create_model() successfully completed......................................
2024-01-03 05:55:32,676:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:32,676:INFO:Creating metrics dataframe
2024-01-03 05:55:32,685:INFO:Initializing Random Forest Classifier
2024-01-03 05:55:32,685:INFO:Total runtime is 0.6260499000549316 minutes
2024-01-03 05:55:32,688:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:32,689:INFO:Initializing create_model()
2024-01-03 05:55:32,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:32,689:INFO:Checking exceptions
2024-01-03 05:55:32,689:INFO:Importing libraries
2024-01-03 05:55:32,689:INFO:Copying training dataset
2024-01-03 05:55:32,722:INFO:Defining folds
2024-01-03 05:55:32,722:INFO:Declaring metric variables
2024-01-03 05:55:32,726:INFO:Importing untrained model
2024-01-03 05:55:32,732:INFO:Random Forest Classifier Imported successfully
2024-01-03 05:55:32,739:INFO:Starting cross validation
2024-01-03 05:55:32,741:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:39,665:INFO:Calculating mean and std
2024-01-03 05:55:39,667:INFO:Creating metrics dataframe
2024-01-03 05:55:39,671:INFO:Uploading results into container
2024-01-03 05:55:39,671:INFO:Uploading model into container now
2024-01-03 05:55:39,672:INFO:_master_model_container: 21
2024-01-03 05:55:39,672:INFO:_display_container: 3
2024-01-03 05:55:39,673:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-03 05:55:39,673:INFO:create_model() successfully completed......................................
2024-01-03 05:55:39,747:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:39,747:INFO:Creating metrics dataframe
2024-01-03 05:55:39,758:INFO:Initializing Quadratic Discriminant Analysis
2024-01-03 05:55:39,758:INFO:Total runtime is 0.743927792708079 minutes
2024-01-03 05:55:39,762:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:39,762:INFO:Initializing create_model()
2024-01-03 05:55:39,762:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:39,762:INFO:Checking exceptions
2024-01-03 05:55:39,763:INFO:Importing libraries
2024-01-03 05:55:39,763:INFO:Copying training dataset
2024-01-03 05:55:39,795:INFO:Defining folds
2024-01-03 05:55:39,795:INFO:Declaring metric variables
2024-01-03 05:55:39,799:INFO:Importing untrained model
2024-01-03 05:55:39,803:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-03 05:55:39,810:INFO:Starting cross validation
2024-01-03 05:55:39,811:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:41,033:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,036:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,061:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,088:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,102:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,105:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,113:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,142:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,145:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,153:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-03 05:55:41,599:INFO:Calculating mean and std
2024-01-03 05:55:41,603:INFO:Creating metrics dataframe
2024-01-03 05:55:41,614:INFO:Uploading results into container
2024-01-03 05:55:41,617:INFO:Uploading model into container now
2024-01-03 05:55:41,619:INFO:_master_model_container: 22
2024-01-03 05:55:41,619:INFO:_display_container: 3
2024-01-03 05:55:41,620:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-03 05:55:41,621:INFO:create_model() successfully completed......................................
2024-01-03 05:55:41,722:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:41,722:INFO:Creating metrics dataframe
2024-01-03 05:55:41,734:INFO:Initializing Ada Boost Classifier
2024-01-03 05:55:41,734:INFO:Total runtime is 0.7768747687339782 minutes
2024-01-03 05:55:41,738:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:41,738:INFO:Initializing create_model()
2024-01-03 05:55:41,738:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:41,738:INFO:Checking exceptions
2024-01-03 05:55:41,738:INFO:Importing libraries
2024-01-03 05:55:41,739:INFO:Copying training dataset
2024-01-03 05:55:41,772:INFO:Defining folds
2024-01-03 05:55:41,772:INFO:Declaring metric variables
2024-01-03 05:55:41,777:INFO:Importing untrained model
2024-01-03 05:55:41,782:INFO:Ada Boost Classifier Imported successfully
2024-01-03 05:55:41,791:INFO:Starting cross validation
2024-01-03 05:55:41,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:47,369:INFO:Calculating mean and std
2024-01-03 05:55:47,373:INFO:Creating metrics dataframe
2024-01-03 05:55:47,385:INFO:Uploading results into container
2024-01-03 05:55:47,387:INFO:Uploading model into container now
2024-01-03 05:55:47,388:INFO:_master_model_container: 23
2024-01-03 05:55:47,388:INFO:_display_container: 3
2024-01-03 05:55:47,389:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-03 05:55:47,389:INFO:create_model() successfully completed......................................
2024-01-03 05:55:47,490:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:47,490:INFO:Creating metrics dataframe
2024-01-03 05:55:47,504:INFO:Initializing Gradient Boosting Classifier
2024-01-03 05:55:47,505:INFO:Total runtime is 0.8730387687683104 minutes
2024-01-03 05:55:47,508:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:47,508:INFO:Initializing create_model()
2024-01-03 05:55:47,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:47,508:INFO:Checking exceptions
2024-01-03 05:55:47,508:INFO:Importing libraries
2024-01-03 05:55:47,508:INFO:Copying training dataset
2024-01-03 05:55:47,541:INFO:Defining folds
2024-01-03 05:55:47,541:INFO:Declaring metric variables
2024-01-03 05:55:47,544:INFO:Importing untrained model
2024-01-03 05:55:47,549:INFO:Gradient Boosting Classifier Imported successfully
2024-01-03 05:55:47,556:INFO:Starting cross validation
2024-01-03 05:55:47,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:54,005:INFO:Calculating mean and std
2024-01-03 05:55:54,009:INFO:Creating metrics dataframe
2024-01-03 05:55:54,018:INFO:Uploading results into container
2024-01-03 05:55:54,020:INFO:Uploading model into container now
2024-01-03 05:55:54,020:INFO:_master_model_container: 24
2024-01-03 05:55:54,020:INFO:_display_container: 3
2024-01-03 05:55:54,021:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-03 05:55:54,021:INFO:create_model() successfully completed......................................
2024-01-03 05:55:54,097:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:54,097:INFO:Creating metrics dataframe
2024-01-03 05:55:54,109:INFO:Initializing Linear Discriminant Analysis
2024-01-03 05:55:54,109:INFO:Total runtime is 0.9831185499827066 minutes
2024-01-03 05:55:54,113:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:54,113:INFO:Initializing create_model()
2024-01-03 05:55:54,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:54,114:INFO:Checking exceptions
2024-01-03 05:55:54,114:INFO:Importing libraries
2024-01-03 05:55:54,114:INFO:Copying training dataset
2024-01-03 05:55:54,148:INFO:Defining folds
2024-01-03 05:55:54,148:INFO:Declaring metric variables
2024-01-03 05:55:54,153:INFO:Importing untrained model
2024-01-03 05:55:54,158:INFO:Linear Discriminant Analysis Imported successfully
2024-01-03 05:55:54,167:INFO:Starting cross validation
2024-01-03 05:55:54,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:55:58,108:INFO:Calculating mean and std
2024-01-03 05:55:58,111:INFO:Creating metrics dataframe
2024-01-03 05:55:58,126:INFO:Uploading results into container
2024-01-03 05:55:58,127:INFO:Uploading model into container now
2024-01-03 05:55:58,127:INFO:_master_model_container: 25
2024-01-03 05:55:58,127:INFO:_display_container: 3
2024-01-03 05:55:58,127:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-03 05:55:58,127:INFO:create_model() successfully completed......................................
2024-01-03 05:55:58,201:INFO:SubProcess create_model() end ==================================
2024-01-03 05:55:58,201:INFO:Creating metrics dataframe
2024-01-03 05:55:58,213:INFO:Initializing Extra Trees Classifier
2024-01-03 05:55:58,213:INFO:Total runtime is 1.0515192071596782 minutes
2024-01-03 05:55:58,216:INFO:SubProcess create_model() called ==================================
2024-01-03 05:55:58,217:INFO:Initializing create_model()
2024-01-03 05:55:58,217:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:55:58,217:INFO:Checking exceptions
2024-01-03 05:55:58,217:INFO:Importing libraries
2024-01-03 05:55:58,217:INFO:Copying training dataset
2024-01-03 05:55:58,251:INFO:Defining folds
2024-01-03 05:55:58,251:INFO:Declaring metric variables
2024-01-03 05:55:58,255:INFO:Importing untrained model
2024-01-03 05:55:58,258:INFO:Extra Trees Classifier Imported successfully
2024-01-03 05:55:58,266:INFO:Starting cross validation
2024-01-03 05:55:58,267:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:56:08,361:INFO:Calculating mean and std
2024-01-03 05:56:08,362:INFO:Creating metrics dataframe
2024-01-03 05:56:08,367:INFO:Uploading results into container
2024-01-03 05:56:08,368:INFO:Uploading model into container now
2024-01-03 05:56:08,369:INFO:_master_model_container: 26
2024-01-03 05:56:08,369:INFO:_display_container: 3
2024-01-03 05:56:08,369:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-03 05:56:08,369:INFO:create_model() successfully completed......................................
2024-01-03 05:56:08,511:INFO:SubProcess create_model() end ==================================
2024-01-03 05:56:08,512:INFO:Creating metrics dataframe
2024-01-03 05:56:08,524:INFO:Initializing Light Gradient Boosting Machine
2024-01-03 05:56:08,525:INFO:Total runtime is 1.2233829776446026 minutes
2024-01-03 05:56:08,528:INFO:SubProcess create_model() called ==================================
2024-01-03 05:56:08,528:INFO:Initializing create_model()
2024-01-03 05:56:08,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:56:08,529:INFO:Checking exceptions
2024-01-03 05:56:08,529:INFO:Importing libraries
2024-01-03 05:56:08,529:INFO:Copying training dataset
2024-01-03 05:56:08,562:INFO:Defining folds
2024-01-03 05:56:08,563:INFO:Declaring metric variables
2024-01-03 05:56:08,567:INFO:Importing untrained model
2024-01-03 05:56:08,571:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:56:08,578:INFO:Starting cross validation
2024-01-03 05:56:08,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:56:10,910:INFO:Calculating mean and std
2024-01-03 05:56:10,911:INFO:Creating metrics dataframe
2024-01-03 05:56:10,915:INFO:Uploading results into container
2024-01-03 05:56:10,916:INFO:Uploading model into container now
2024-01-03 05:56:10,916:INFO:_master_model_container: 27
2024-01-03 05:56:10,916:INFO:_display_container: 3
2024-01-03 05:56:10,917:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:56:10,917:INFO:create_model() successfully completed......................................
2024-01-03 05:56:11,030:INFO:SubProcess create_model() end ==================================
2024-01-03 05:56:11,030:INFO:Creating metrics dataframe
2024-01-03 05:56:11,042:INFO:Initializing Dummy Classifier
2024-01-03 05:56:11,042:INFO:Total runtime is 1.2653265357017518 minutes
2024-01-03 05:56:11,045:INFO:SubProcess create_model() called ==================================
2024-01-03 05:56:11,045:INFO:Initializing create_model()
2024-01-03 05:56:11,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F4EC3CEF20>, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:56:11,045:INFO:Checking exceptions
2024-01-03 05:56:11,045:INFO:Importing libraries
2024-01-03 05:56:11,046:INFO:Copying training dataset
2024-01-03 05:56:11,078:INFO:Defining folds
2024-01-03 05:56:11,078:INFO:Declaring metric variables
2024-01-03 05:56:11,081:INFO:Importing untrained model
2024-01-03 05:56:11,085:INFO:Dummy Classifier Imported successfully
2024-01-03 05:56:11,094:INFO:Starting cross validation
2024-01-03 05:56:11,095:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-03 05:56:11,672:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,683:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,697:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,703:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,713:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,715:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,716:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,717:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,719:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,727:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-03 05:56:11,855:INFO:Calculating mean and std
2024-01-03 05:56:11,859:INFO:Creating metrics dataframe
2024-01-03 05:56:11,867:INFO:Uploading results into container
2024-01-03 05:56:11,868:INFO:Uploading model into container now
2024-01-03 05:56:11,868:INFO:_master_model_container: 28
2024-01-03 05:56:11,869:INFO:_display_container: 3
2024-01-03 05:56:11,869:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-03 05:56:11,869:INFO:create_model() successfully completed......................................
2024-01-03 05:56:11,945:INFO:SubProcess create_model() end ==================================
2024-01-03 05:56:11,945:INFO:Creating metrics dataframe
2024-01-03 05:56:11,966:INFO:Initializing create_model()
2024-01-03 05:56:11,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F492792050>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-03 05:56:11,967:INFO:Checking exceptions
2024-01-03 05:56:11,968:INFO:Importing libraries
2024-01-03 05:56:11,969:INFO:Copying training dataset
2024-01-03 05:56:12,000:INFO:Defining folds
2024-01-03 05:56:12,000:INFO:Declaring metric variables
2024-01-03 05:56:12,000:INFO:Importing untrained model
2024-01-03 05:56:12,000:INFO:Declaring custom model
2024-01-03 05:56:12,001:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-03 05:56:12,002:INFO:Cross validation set to False
2024-01-03 05:56:12,002:INFO:Fitting Model
2024-01-03 05:56:12,153:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-03 05:56:12,153:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-03 05:56:12,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001123 seconds.
2024-01-03 05:56:12,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-03 05:56:12,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-03 05:56:12,157:INFO:[LightGBM] [Info] Total Bins 444
2024-01-03 05:56:12,157:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-03 05:56:12,158:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-03 05:56:12,158:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-03 05:56:12,271:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:56:12,271:INFO:create_model() successfully completed......................................
2024-01-03 05:56:12,409:INFO:_master_model_container: 28
2024-01-03 05:56:12,409:INFO:_display_container: 3
2024-01-03 05:56:12,410:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-03 05:56:12,410:INFO:compare_models() successfully completed......................................
2024-01-04 14:02:06,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:02:06,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:02:06,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:02:06,147:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:02:08,232:INFO:PyCaret ClassificationExperiment
2024-01-04 14:02:08,232:INFO:Logging name: clf-default-name
2024-01-04 14:02:08,232:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-04 14:02:08,232:INFO:version 3.1.0
2024-01-04 14:02:08,232:INFO:Initializing setup()
2024-01-04 14:02:08,232:INFO:self.USI: 5ebf
2024-01-04 14:02:08,233:INFO:self._variable_keys: {'_ml_usecase', 'fold_shuffle_param', 'X', 'exp_name_log', 'y_train', 'fold_groups_param', 'exp_id', 'fold_generator', 'data', 'gpu_n_jobs_param', 'is_multiclass', 'X_test', 'y', 'html_param', 'logging_param', 'memory', 'pipeline', 'target_param', 'USI', 'X_train', 'n_jobs_param', 'fix_imbalance', 'y_test', 'seed', 'log_plots_param', 'idx', '_available_plots', 'gpu_param'}
2024-01-04 14:02:08,233:INFO:Checking environment
2024-01-04 14:02:08,233:INFO:python_version: 3.10.9
2024-01-04 14:02:08,233:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-04 14:02:08,233:INFO:machine: AMD64
2024-01-04 14:02:08,233:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-04 14:02:08,233:INFO:Memory: svmem(total=16954372096, available=6033788928, percent=64.4, used=10920583168, free=6033788928)
2024-01-04 14:02:08,233:INFO:Physical Core: 8
2024-01-04 14:02:08,233:INFO:Logical Core: 16
2024-01-04 14:02:08,233:INFO:Checking libraries
2024-01-04 14:02:08,233:INFO:System:
2024-01-04 14:02:08,233:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-04 14:02:08,233:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-04 14:02:08,233:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-04 14:02:08,233:INFO:PyCaret required dependencies:
2024-01-04 14:02:08,951:INFO:                 pip: 22.3.1
2024-01-04 14:02:09,021:INFO:          setuptools: 65.6.3
2024-01-04 14:02:09,021:INFO:             pycaret: 3.1.0
2024-01-04 14:02:09,022:INFO:             IPython: 8.10.0
2024-01-04 14:02:09,022:INFO:          ipywidgets: 7.6.5
2024-01-04 14:02:09,022:INFO:                tqdm: 4.64.1
2024-01-04 14:02:09,022:INFO:               numpy: 1.23.5
2024-01-04 14:02:09,022:INFO:              pandas: 1.5.3
2024-01-04 14:02:09,022:INFO:              jinja2: 3.1.2
2024-01-04 14:02:09,022:INFO:               scipy: 1.10.1
2024-01-04 14:02:09,022:INFO:              joblib: 1.3.2
2024-01-04 14:02:09,022:INFO:             sklearn: 1.2.1
2024-01-04 14:02:09,022:INFO:                pyod: 1.1.0
2024-01-04 14:02:09,022:INFO:            imblearn: 0.10.1
2024-01-04 14:02:09,022:INFO:   category_encoders: 2.6.2
2024-01-04 14:02:09,022:INFO:            lightgbm: 4.1.0
2024-01-04 14:02:09,022:INFO:               numba: 0.56.4
2024-01-04 14:02:09,022:INFO:            requests: 2.28.1
2024-01-04 14:02:09,022:INFO:          matplotlib: 3.7.0
2024-01-04 14:02:09,023:INFO:          scikitplot: 0.3.7
2024-01-04 14:02:09,023:INFO:         yellowbrick: 1.5
2024-01-04 14:02:09,023:INFO:              plotly: 5.9.0
2024-01-04 14:02:09,023:INFO:    plotly-resampler: Not installed
2024-01-04 14:02:09,023:INFO:             kaleido: 0.2.1
2024-01-04 14:02:09,023:INFO:           schemdraw: 0.15
2024-01-04 14:02:09,023:INFO:         statsmodels: 0.13.5
2024-01-04 14:02:09,023:INFO:              sktime: 0.21.1
2024-01-04 14:02:09,023:INFO:               tbats: 1.1.3
2024-01-04 14:02:09,023:INFO:            pmdarima: 2.0.3
2024-01-04 14:02:09,023:INFO:              psutil: 5.9.0
2024-01-04 14:02:09,023:INFO:          markupsafe: 2.1.1
2024-01-04 14:02:09,023:INFO:             pickle5: Not installed
2024-01-04 14:02:09,023:INFO:         cloudpickle: 2.0.0
2024-01-04 14:02:09,024:INFO:         deprecation: 2.1.0
2024-01-04 14:02:09,024:INFO:              xxhash: 3.4.1
2024-01-04 14:02:09,024:INFO:           wurlitzer: Not installed
2024-01-04 14:02:09,024:INFO:PyCaret optional dependencies:
2024-01-04 14:02:09,037:INFO:                shap: Not installed
2024-01-04 14:02:09,038:INFO:           interpret: Not installed
2024-01-04 14:02:09,038:INFO:                umap: Not installed
2024-01-04 14:02:09,038:INFO:     ydata_profiling: 4.6.0
2024-01-04 14:02:09,038:INFO:  explainerdashboard: Not installed
2024-01-04 14:02:09,038:INFO:             autoviz: Not installed
2024-01-04 14:02:09,038:INFO:           fairlearn: Not installed
2024-01-04 14:02:09,038:INFO:          deepchecks: Not installed
2024-01-04 14:02:09,038:INFO:             xgboost: Not installed
2024-01-04 14:02:09,038:INFO:            catboost: Not installed
2024-01-04 14:02:09,038:INFO:              kmodes: Not installed
2024-01-04 14:02:09,038:INFO:             mlxtend: Not installed
2024-01-04 14:02:09,038:INFO:       statsforecast: Not installed
2024-01-04 14:02:09,038:INFO:        tune_sklearn: Not installed
2024-01-04 14:02:09,038:INFO:                 ray: Not installed
2024-01-04 14:02:09,038:INFO:            hyperopt: Not installed
2024-01-04 14:02:09,038:INFO:              optuna: Not installed
2024-01-04 14:02:09,038:INFO:               skopt: Not installed
2024-01-04 14:02:09,038:INFO:              mlflow: Not installed
2024-01-04 14:02:09,038:INFO:              gradio: Not installed
2024-01-04 14:02:09,038:INFO:             fastapi: Not installed
2024-01-04 14:02:09,038:INFO:             uvicorn: Not installed
2024-01-04 14:02:09,038:INFO:              m2cgen: Not installed
2024-01-04 14:02:09,038:INFO:           evidently: Not installed
2024-01-04 14:02:09,038:INFO:               fugue: Not installed
2024-01-04 14:02:09,038:INFO:           streamlit: Not installed
2024-01-04 14:02:09,039:INFO:             prophet: Not installed
2024-01-04 14:02:09,039:INFO:None
2024-01-04 14:02:09,039:INFO:Set up data.
2024-01-04 14:02:09,090:INFO:Set up folding strategy.
2024-01-04 14:02:09,090:INFO:Set up train/test split.
2024-01-04 14:02:09,122:INFO:Set up index.
2024-01-04 14:02:09,125:INFO:Assigning column types.
2024-01-04 14:02:09,147:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-04 14:02:09,184:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-04 14:02:09,620:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:02:09,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,698:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-04 14:02:09,699:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:02:09,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,722:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-04 14:02:09,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:02:09,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,782:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:02:09,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,841:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-04 14:02:09,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:09,962:INFO:Preparing preprocessing pipeline...
2024-01-04 14:02:09,976:INFO:Set up simple imputation.
2024-01-04 14:02:09,979:INFO:Set up column name cleaning.
2024-01-04 14:02:10,088:INFO:Finished creating preprocessing pipeline.
2024-01-04 14:02:10,094:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-04 14:02:10,095:INFO:Creating final display dataframe.
2024-01-04 14:02:10,393:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              5ebf
2024-01-04 14:02:10,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:10,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:10,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:10,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:02:10,523:INFO:setup() successfully completed in 2.31s...............
2024-01-04 14:02:10,531:INFO:Initializing compare_models()
2024-01-04 14:02:10,531:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-04 14:02:10,531:INFO:Checking exceptions
2024-01-04 14:02:10,552:INFO:Preparing display monitor
2024-01-04 14:02:10,576:INFO:Initializing Logistic Regression
2024-01-04 14:02:10,577:INFO:Total runtime is 1.6721089680989585e-05 minutes
2024-01-04 14:02:10,581:INFO:SubProcess create_model() called ==================================
2024-01-04 14:02:10,581:INFO:Initializing create_model()
2024-01-04 14:02:10,581:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:02:10,581:INFO:Checking exceptions
2024-01-04 14:02:10,582:INFO:Importing libraries
2024-01-04 14:02:10,582:INFO:Copying training dataset
2024-01-04 14:02:10,612:INFO:Defining folds
2024-01-04 14:02:10,612:INFO:Declaring metric variables
2024-01-04 14:02:10,615:INFO:Importing untrained model
2024-01-04 14:02:10,617:INFO:Logistic Regression Imported successfully
2024-01-04 14:02:10,624:INFO:Starting cross validation
2024-01-04 14:02:10,625:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:02:45,867:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:45,897:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,015:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,116:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,126:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,134:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,189:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,233:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,385:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:02:46,524:INFO:Calculating mean and std
2024-01-04 14:02:46,526:INFO:Creating metrics dataframe
2024-01-04 14:02:46,540:INFO:Uploading results into container
2024-01-04 14:02:46,541:INFO:Uploading model into container now
2024-01-04 14:02:46,542:INFO:_master_model_container: 1
2024-01-04 14:02:46,542:INFO:_display_container: 2
2024-01-04 14:02:46,542:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-04 14:02:46,542:INFO:create_model() successfully completed......................................
2024-01-04 14:02:46,610:INFO:SubProcess create_model() end ==================================
2024-01-04 14:02:46,611:INFO:Creating metrics dataframe
2024-01-04 14:02:46,626:INFO:Initializing K Neighbors Classifier
2024-01-04 14:02:46,626:INFO:Total runtime is 0.6008244355519613 minutes
2024-01-04 14:02:46,629:INFO:SubProcess create_model() called ==================================
2024-01-04 14:02:46,629:INFO:Initializing create_model()
2024-01-04 14:02:46,630:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:02:46,630:INFO:Checking exceptions
2024-01-04 14:02:46,630:INFO:Importing libraries
2024-01-04 14:02:46,630:INFO:Copying training dataset
2024-01-04 14:02:46,655:INFO:Defining folds
2024-01-04 14:02:46,656:INFO:Declaring metric variables
2024-01-04 14:02:46,658:INFO:Importing untrained model
2024-01-04 14:02:46,660:INFO:K Neighbors Classifier Imported successfully
2024-01-04 14:02:46,666:INFO:Starting cross validation
2024-01-04 14:02:46,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:02:53,377:INFO:Calculating mean and std
2024-01-04 14:02:53,380:INFO:Creating metrics dataframe
2024-01-04 14:02:53,389:INFO:Uploading results into container
2024-01-04 14:02:53,390:INFO:Uploading model into container now
2024-01-04 14:02:53,391:INFO:_master_model_container: 2
2024-01-04 14:02:53,391:INFO:_display_container: 2
2024-01-04 14:02:53,392:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-04 14:02:53,393:INFO:create_model() successfully completed......................................
2024-01-04 14:02:53,472:INFO:SubProcess create_model() end ==================================
2024-01-04 14:02:53,472:INFO:Creating metrics dataframe
2024-01-04 14:02:53,481:INFO:Initializing Naive Bayes
2024-01-04 14:02:53,481:INFO:Total runtime is 0.7150844097137452 minutes
2024-01-04 14:02:53,484:INFO:SubProcess create_model() called ==================================
2024-01-04 14:02:53,484:INFO:Initializing create_model()
2024-01-04 14:02:53,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:02:53,484:INFO:Checking exceptions
2024-01-04 14:02:53,484:INFO:Importing libraries
2024-01-04 14:02:53,484:INFO:Copying training dataset
2024-01-04 14:02:53,514:INFO:Defining folds
2024-01-04 14:02:53,514:INFO:Declaring metric variables
2024-01-04 14:02:53,518:INFO:Importing untrained model
2024-01-04 14:02:53,521:INFO:Naive Bayes Imported successfully
2024-01-04 14:02:53,527:INFO:Starting cross validation
2024-01-04 14:02:53,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:02:54,681:INFO:Calculating mean and std
2024-01-04 14:02:54,683:INFO:Creating metrics dataframe
2024-01-04 14:02:54,687:INFO:Uploading results into container
2024-01-04 14:02:54,688:INFO:Uploading model into container now
2024-01-04 14:02:54,689:INFO:_master_model_container: 3
2024-01-04 14:02:54,689:INFO:_display_container: 2
2024-01-04 14:02:54,689:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-04 14:02:54,690:INFO:create_model() successfully completed......................................
2024-01-04 14:02:54,795:INFO:SubProcess create_model() end ==================================
2024-01-04 14:02:54,795:INFO:Creating metrics dataframe
2024-01-04 14:02:54,806:INFO:Initializing Decision Tree Classifier
2024-01-04 14:02:54,806:INFO:Total runtime is 0.7371703982353212 minutes
2024-01-04 14:02:54,810:INFO:SubProcess create_model() called ==================================
2024-01-04 14:02:54,810:INFO:Initializing create_model()
2024-01-04 14:02:54,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:02:54,811:INFO:Checking exceptions
2024-01-04 14:02:54,811:INFO:Importing libraries
2024-01-04 14:02:54,811:INFO:Copying training dataset
2024-01-04 14:02:54,843:INFO:Defining folds
2024-01-04 14:02:54,843:INFO:Declaring metric variables
2024-01-04 14:02:54,847:INFO:Importing untrained model
2024-01-04 14:02:54,852:INFO:Decision Tree Classifier Imported successfully
2024-01-04 14:02:54,862:INFO:Starting cross validation
2024-01-04 14:02:54,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:02:56,458:INFO:Calculating mean and std
2024-01-04 14:02:56,460:INFO:Creating metrics dataframe
2024-01-04 14:02:56,464:INFO:Uploading results into container
2024-01-04 14:02:56,464:INFO:Uploading model into container now
2024-01-04 14:02:56,465:INFO:_master_model_container: 4
2024-01-04 14:02:56,465:INFO:_display_container: 2
2024-01-04 14:02:56,466:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-04 14:02:56,466:INFO:create_model() successfully completed......................................
2024-01-04 14:02:56,554:INFO:SubProcess create_model() end ==================================
2024-01-04 14:02:56,555:INFO:Creating metrics dataframe
2024-01-04 14:02:56,565:INFO:Initializing SVM - Linear Kernel
2024-01-04 14:02:56,565:INFO:Total runtime is 0.7664833943049114 minutes
2024-01-04 14:02:56,569:INFO:SubProcess create_model() called ==================================
2024-01-04 14:02:56,569:INFO:Initializing create_model()
2024-01-04 14:02:56,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:02:56,569:INFO:Checking exceptions
2024-01-04 14:02:56,570:INFO:Importing libraries
2024-01-04 14:02:56,570:INFO:Copying training dataset
2024-01-04 14:02:56,601:INFO:Defining folds
2024-01-04 14:02:56,601:INFO:Declaring metric variables
2024-01-04 14:02:56,605:INFO:Importing untrained model
2024-01-04 14:02:56,608:INFO:SVM - Linear Kernel Imported successfully
2024-01-04 14:02:56,615:INFO:Starting cross validation
2024-01-04 14:02:56,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:02:58,123:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,412:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,453:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,461:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,571:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,587:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,605:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,693:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,695:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,808:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:02:58,940:INFO:Calculating mean and std
2024-01-04 14:02:58,942:INFO:Creating metrics dataframe
2024-01-04 14:02:58,946:INFO:Uploading results into container
2024-01-04 14:02:58,947:INFO:Uploading model into container now
2024-01-04 14:02:58,948:INFO:_master_model_container: 5
2024-01-04 14:02:58,948:INFO:_display_container: 2
2024-01-04 14:02:58,948:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-04 14:02:58,948:INFO:create_model() successfully completed......................................
2024-01-04 14:02:59,080:INFO:SubProcess create_model() end ==================================
2024-01-04 14:02:59,081:INFO:Creating metrics dataframe
2024-01-04 14:02:59,096:INFO:Initializing Ridge Classifier
2024-01-04 14:02:59,097:INFO:Total runtime is 0.8086712916692099 minutes
2024-01-04 14:02:59,103:INFO:SubProcess create_model() called ==================================
2024-01-04 14:02:59,104:INFO:Initializing create_model()
2024-01-04 14:02:59,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:02:59,104:INFO:Checking exceptions
2024-01-04 14:02:59,105:INFO:Importing libraries
2024-01-04 14:02:59,105:INFO:Copying training dataset
2024-01-04 14:02:59,161:INFO:Defining folds
2024-01-04 14:02:59,161:INFO:Declaring metric variables
2024-01-04 14:02:59,165:INFO:Importing untrained model
2024-01-04 14:02:59,170:INFO:Ridge Classifier Imported successfully
2024-01-04 14:02:59,178:INFO:Starting cross validation
2024-01-04 14:02:59,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:00,076:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,084:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,086:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,092:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,095:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,096:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,101:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,110:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,112:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,115:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:03:00,242:INFO:Calculating mean and std
2024-01-04 14:03:00,245:INFO:Creating metrics dataframe
2024-01-04 14:03:00,251:INFO:Uploading results into container
2024-01-04 14:03:00,252:INFO:Uploading model into container now
2024-01-04 14:03:00,253:INFO:_master_model_container: 6
2024-01-04 14:03:00,253:INFO:_display_container: 2
2024-01-04 14:03:00,254:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-04 14:03:00,254:INFO:create_model() successfully completed......................................
2024-01-04 14:03:00,375:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:00,375:INFO:Creating metrics dataframe
2024-01-04 14:03:00,388:INFO:Initializing Random Forest Classifier
2024-01-04 14:03:00,389:INFO:Total runtime is 0.8302086710929872 minutes
2024-01-04 14:03:00,392:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:00,392:INFO:Initializing create_model()
2024-01-04 14:03:00,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:00,393:INFO:Checking exceptions
2024-01-04 14:03:00,393:INFO:Importing libraries
2024-01-04 14:03:00,393:INFO:Copying training dataset
2024-01-04 14:03:00,424:INFO:Defining folds
2024-01-04 14:03:00,425:INFO:Declaring metric variables
2024-01-04 14:03:00,429:INFO:Importing untrained model
2024-01-04 14:03:00,432:INFO:Random Forest Classifier Imported successfully
2024-01-04 14:03:00,439:INFO:Starting cross validation
2024-01-04 14:03:00,440:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:07,555:INFO:Calculating mean and std
2024-01-04 14:03:07,558:INFO:Creating metrics dataframe
2024-01-04 14:03:07,569:INFO:Uploading results into container
2024-01-04 14:03:07,571:INFO:Uploading model into container now
2024-01-04 14:03:07,573:INFO:_master_model_container: 7
2024-01-04 14:03:07,573:INFO:_display_container: 2
2024-01-04 14:03:07,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-04 14:03:07,574:INFO:create_model() successfully completed......................................
2024-01-04 14:03:07,655:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:07,656:INFO:Creating metrics dataframe
2024-01-04 14:03:07,666:INFO:Initializing Quadratic Discriminant Analysis
2024-01-04 14:03:07,667:INFO:Total runtime is 0.9515065153439841 minutes
2024-01-04 14:03:07,670:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:07,670:INFO:Initializing create_model()
2024-01-04 14:03:07,671:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:07,671:INFO:Checking exceptions
2024-01-04 14:03:07,671:INFO:Importing libraries
2024-01-04 14:03:07,671:INFO:Copying training dataset
2024-01-04 14:03:07,704:INFO:Defining folds
2024-01-04 14:03:07,704:INFO:Declaring metric variables
2024-01-04 14:03:07,707:INFO:Importing untrained model
2024-01-04 14:03:07,712:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-04 14:03:07,719:INFO:Starting cross validation
2024-01-04 14:03:07,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:09,109:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,130:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,152:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,156:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,161:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,161:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,200:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,212:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,231:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:03:09,648:INFO:Calculating mean and std
2024-01-04 14:03:09,650:INFO:Creating metrics dataframe
2024-01-04 14:03:09,654:INFO:Uploading results into container
2024-01-04 14:03:09,655:INFO:Uploading model into container now
2024-01-04 14:03:09,655:INFO:_master_model_container: 8
2024-01-04 14:03:09,655:INFO:_display_container: 2
2024-01-04 14:03:09,656:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-04 14:03:09,656:INFO:create_model() successfully completed......................................
2024-01-04 14:03:09,767:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:09,767:INFO:Creating metrics dataframe
2024-01-04 14:03:09,780:INFO:Initializing Ada Boost Classifier
2024-01-04 14:03:09,780:INFO:Total runtime is 0.9867305835088096 minutes
2024-01-04 14:03:09,784:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:09,784:INFO:Initializing create_model()
2024-01-04 14:03:09,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:09,784:INFO:Checking exceptions
2024-01-04 14:03:09,784:INFO:Importing libraries
2024-01-04 14:03:09,785:INFO:Copying training dataset
2024-01-04 14:03:09,818:INFO:Defining folds
2024-01-04 14:03:09,818:INFO:Declaring metric variables
2024-01-04 14:03:09,822:INFO:Importing untrained model
2024-01-04 14:03:09,826:INFO:Ada Boost Classifier Imported successfully
2024-01-04 14:03:09,834:INFO:Starting cross validation
2024-01-04 14:03:09,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:16,034:INFO:Calculating mean and std
2024-01-04 14:03:16,036:INFO:Creating metrics dataframe
2024-01-04 14:03:16,039:INFO:Uploading results into container
2024-01-04 14:03:16,040:INFO:Uploading model into container now
2024-01-04 14:03:16,040:INFO:_master_model_container: 9
2024-01-04 14:03:16,040:INFO:_display_container: 2
2024-01-04 14:03:16,041:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-04 14:03:16,041:INFO:create_model() successfully completed......................................
2024-01-04 14:03:16,117:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:16,117:INFO:Creating metrics dataframe
2024-01-04 14:03:16,129:INFO:Initializing Gradient Boosting Classifier
2024-01-04 14:03:16,130:INFO:Total runtime is 1.0925624926884971 minutes
2024-01-04 14:03:16,133:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:16,134:INFO:Initializing create_model()
2024-01-04 14:03:16,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:16,134:INFO:Checking exceptions
2024-01-04 14:03:16,134:INFO:Importing libraries
2024-01-04 14:03:16,134:INFO:Copying training dataset
2024-01-04 14:03:16,165:INFO:Defining folds
2024-01-04 14:03:16,165:INFO:Declaring metric variables
2024-01-04 14:03:16,168:INFO:Importing untrained model
2024-01-04 14:03:16,172:INFO:Gradient Boosting Classifier Imported successfully
2024-01-04 14:03:16,178:INFO:Starting cross validation
2024-01-04 14:03:16,179:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:22,773:INFO:Calculating mean and std
2024-01-04 14:03:22,774:INFO:Creating metrics dataframe
2024-01-04 14:03:22,777:INFO:Uploading results into container
2024-01-04 14:03:22,778:INFO:Uploading model into container now
2024-01-04 14:03:22,778:INFO:_master_model_container: 10
2024-01-04 14:03:22,779:INFO:_display_container: 2
2024-01-04 14:03:22,779:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-04 14:03:22,779:INFO:create_model() successfully completed......................................
2024-01-04 14:03:22,850:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:22,850:INFO:Creating metrics dataframe
2024-01-04 14:03:22,860:INFO:Initializing Linear Discriminant Analysis
2024-01-04 14:03:22,860:INFO:Total runtime is 1.2047266205151879 minutes
2024-01-04 14:03:22,863:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:22,863:INFO:Initializing create_model()
2024-01-04 14:03:22,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:22,864:INFO:Checking exceptions
2024-01-04 14:03:22,864:INFO:Importing libraries
2024-01-04 14:03:22,864:INFO:Copying training dataset
2024-01-04 14:03:22,890:INFO:Defining folds
2024-01-04 14:03:22,890:INFO:Declaring metric variables
2024-01-04 14:03:22,893:INFO:Importing untrained model
2024-01-04 14:03:22,896:INFO:Linear Discriminant Analysis Imported successfully
2024-01-04 14:03:22,901:INFO:Starting cross validation
2024-01-04 14:03:22,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:26,561:INFO:Calculating mean and std
2024-01-04 14:03:26,563:INFO:Creating metrics dataframe
2024-01-04 14:03:26,566:INFO:Uploading results into container
2024-01-04 14:03:26,566:INFO:Uploading model into container now
2024-01-04 14:03:26,567:INFO:_master_model_container: 11
2024-01-04 14:03:26,567:INFO:_display_container: 2
2024-01-04 14:03:26,567:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-04 14:03:26,567:INFO:create_model() successfully completed......................................
2024-01-04 14:03:26,638:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:26,722:INFO:Creating metrics dataframe
2024-01-04 14:03:26,733:INFO:Initializing Extra Trees Classifier
2024-01-04 14:03:26,733:INFO:Total runtime is 1.269284808635712 minutes
2024-01-04 14:03:26,736:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:26,736:INFO:Initializing create_model()
2024-01-04 14:03:26,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:26,736:INFO:Checking exceptions
2024-01-04 14:03:26,736:INFO:Importing libraries
2024-01-04 14:03:26,736:INFO:Copying training dataset
2024-01-04 14:03:26,762:INFO:Defining folds
2024-01-04 14:03:26,762:INFO:Declaring metric variables
2024-01-04 14:03:26,766:INFO:Importing untrained model
2024-01-04 14:03:26,769:INFO:Extra Trees Classifier Imported successfully
2024-01-04 14:03:26,775:INFO:Starting cross validation
2024-01-04 14:03:26,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:35,802:INFO:Calculating mean and std
2024-01-04 14:03:35,803:INFO:Creating metrics dataframe
2024-01-04 14:03:35,806:INFO:Uploading results into container
2024-01-04 14:03:35,807:INFO:Uploading model into container now
2024-01-04 14:03:35,807:INFO:_master_model_container: 12
2024-01-04 14:03:35,807:INFO:_display_container: 2
2024-01-04 14:03:35,808:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-04 14:03:35,808:INFO:create_model() successfully completed......................................
2024-01-04 14:03:35,885:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:35,885:INFO:Creating metrics dataframe
2024-01-04 14:03:35,917:INFO:Initializing Light Gradient Boosting Machine
2024-01-04 14:03:35,917:INFO:Total runtime is 1.4223507841428125 minutes
2024-01-04 14:03:35,920:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:35,920:INFO:Initializing create_model()
2024-01-04 14:03:35,920:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:35,920:INFO:Checking exceptions
2024-01-04 14:03:35,920:INFO:Importing libraries
2024-01-04 14:03:35,920:INFO:Copying training dataset
2024-01-04 14:03:35,949:INFO:Defining folds
2024-01-04 14:03:35,950:INFO:Declaring metric variables
2024-01-04 14:03:35,953:INFO:Importing untrained model
2024-01-04 14:03:35,957:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:03:35,962:INFO:Starting cross validation
2024-01-04 14:03:35,964:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:38,314:INFO:Calculating mean and std
2024-01-04 14:03:38,315:INFO:Creating metrics dataframe
2024-01-04 14:03:38,319:INFO:Uploading results into container
2024-01-04 14:03:38,320:INFO:Uploading model into container now
2024-01-04 14:03:38,320:INFO:_master_model_container: 13
2024-01-04 14:03:38,320:INFO:_display_container: 2
2024-01-04 14:03:38,321:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:03:38,321:INFO:create_model() successfully completed......................................
2024-01-04 14:03:38,398:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:38,400:INFO:Creating metrics dataframe
2024-01-04 14:03:38,431:INFO:Initializing Dummy Classifier
2024-01-04 14:03:38,432:INFO:Total runtime is 1.4642518679300949 minutes
2024-01-04 14:03:38,434:INFO:SubProcess create_model() called ==================================
2024-01-04 14:03:38,435:INFO:Initializing create_model()
2024-01-04 14:03:38,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001B0A62610C0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:38,435:INFO:Checking exceptions
2024-01-04 14:03:38,435:INFO:Importing libraries
2024-01-04 14:03:38,435:INFO:Copying training dataset
2024-01-04 14:03:38,462:INFO:Defining folds
2024-01-04 14:03:38,462:INFO:Declaring metric variables
2024-01-04 14:03:38,465:INFO:Importing untrained model
2024-01-04 14:03:38,468:INFO:Dummy Classifier Imported successfully
2024-01-04 14:03:38,474:INFO:Starting cross validation
2024-01-04 14:03:38,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:03:38,978:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:38,982:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:38,995:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:38,996:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,004:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,007:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,012:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,019:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,036:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,053:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:03:39,170:INFO:Calculating mean and std
2024-01-04 14:03:39,173:INFO:Creating metrics dataframe
2024-01-04 14:03:39,185:INFO:Uploading results into container
2024-01-04 14:03:39,187:INFO:Uploading model into container now
2024-01-04 14:03:39,188:INFO:_master_model_container: 14
2024-01-04 14:03:39,188:INFO:_display_container: 2
2024-01-04 14:03:39,188:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-04 14:03:39,189:INFO:create_model() successfully completed......................................
2024-01-04 14:03:39,263:INFO:SubProcess create_model() end ==================================
2024-01-04 14:03:39,263:INFO:Creating metrics dataframe
2024-01-04 14:03:39,282:INFO:Initializing create_model()
2024-01-04 14:03:39,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001B0CC6567A0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:03:39,283:INFO:Checking exceptions
2024-01-04 14:03:39,284:INFO:Importing libraries
2024-01-04 14:03:39,284:INFO:Copying training dataset
2024-01-04 14:03:39,311:INFO:Defining folds
2024-01-04 14:03:39,311:INFO:Declaring metric variables
2024-01-04 14:03:39,311:INFO:Importing untrained model
2024-01-04 14:03:39,311:INFO:Declaring custom model
2024-01-04 14:03:39,312:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:03:39,313:INFO:Cross validation set to False
2024-01-04 14:03:39,313:INFO:Fitting Model
2024-01-04 14:03:39,423:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:03:39,423:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:03:39,426:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001482 seconds.
2024-01-04 14:03:39,426:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:03:39,426:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:03:39,426:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 14:03:39,427:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-04 14:03:39,427:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:03:39,428:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:03:39,525:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:03:39,526:INFO:create_model() successfully completed......................................
2024-01-04 14:03:39,646:INFO:_master_model_container: 14
2024-01-04 14:03:39,646:INFO:_display_container: 2
2024-01-04 14:03:39,647:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:03:39,647:INFO:compare_models() successfully completed......................................
2024-01-04 14:39:23,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:39:23,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:39:23,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:39:23,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:39:23,274:INFO:PyCaret ClassificationExperiment
2024-01-04 14:39:23,274:INFO:Logging name: clf-default-name
2024-01-04 14:39:23,274:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-04 14:39:23,274:INFO:version 3.1.0
2024-01-04 14:39:23,274:INFO:Initializing setup()
2024-01-04 14:39:23,274:INFO:self.USI: 8b8e
2024-01-04 14:39:23,274:INFO:self._variable_keys: {'_ml_usecase', 'X_train', 'memory', 'data', 'y', 'gpu_param', 'X_test', 'is_multiclass', 'fold_groups_param', 'log_plots_param', '_available_plots', 'y_train', 'X', 'fix_imbalance', 'html_param', 'seed', 'logging_param', 'n_jobs_param', 'pipeline', 'target_param', 'exp_name_log', 'idx', 'y_test', 'fold_generator', 'gpu_n_jobs_param', 'USI', 'exp_id', 'fold_shuffle_param'}
2024-01-04 14:39:23,274:INFO:Checking environment
2024-01-04 14:39:23,274:INFO:python_version: 3.10.9
2024-01-04 14:39:23,274:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-04 14:39:23,274:INFO:machine: AMD64
2024-01-04 14:39:23,274:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-04 14:39:23,275:INFO:Memory: svmem(total=16954372096, available=6334730240, percent=62.6, used=10619641856, free=6334730240)
2024-01-04 14:39:23,275:INFO:Physical Core: 8
2024-01-04 14:39:23,275:INFO:Logical Core: 16
2024-01-04 14:39:23,275:INFO:Checking libraries
2024-01-04 14:39:23,275:INFO:System:
2024-01-04 14:39:23,275:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-04 14:39:23,275:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-04 14:39:23,275:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-04 14:39:23,275:INFO:PyCaret required dependencies:
2024-01-04 14:39:23,825:INFO:                 pip: 22.3.1
2024-01-04 14:39:23,825:INFO:          setuptools: 65.6.3
2024-01-04 14:39:23,825:INFO:             pycaret: 3.1.0
2024-01-04 14:39:23,825:INFO:             IPython: 8.10.0
2024-01-04 14:39:23,825:INFO:          ipywidgets: 7.6.5
2024-01-04 14:39:23,825:INFO:                tqdm: 4.64.1
2024-01-04 14:39:23,826:INFO:               numpy: 1.23.5
2024-01-04 14:39:23,826:INFO:              pandas: 1.5.3
2024-01-04 14:39:23,826:INFO:              jinja2: 3.1.2
2024-01-04 14:39:23,826:INFO:               scipy: 1.10.1
2024-01-04 14:39:23,826:INFO:              joblib: 1.3.2
2024-01-04 14:39:23,826:INFO:             sklearn: 1.2.1
2024-01-04 14:39:23,826:INFO:                pyod: 1.1.0
2024-01-04 14:39:23,826:INFO:            imblearn: 0.10.1
2024-01-04 14:39:23,826:INFO:   category_encoders: 2.6.2
2024-01-04 14:39:23,826:INFO:            lightgbm: 4.1.0
2024-01-04 14:39:23,826:INFO:               numba: 0.56.4
2024-01-04 14:39:23,826:INFO:            requests: 2.28.1
2024-01-04 14:39:23,826:INFO:          matplotlib: 3.7.0
2024-01-04 14:39:23,826:INFO:          scikitplot: 0.3.7
2024-01-04 14:39:23,826:INFO:         yellowbrick: 1.5
2024-01-04 14:39:23,826:INFO:              plotly: 5.9.0
2024-01-04 14:39:23,826:INFO:    plotly-resampler: Not installed
2024-01-04 14:39:23,826:INFO:             kaleido: 0.2.1
2024-01-04 14:39:23,826:INFO:           schemdraw: 0.15
2024-01-04 14:39:23,826:INFO:         statsmodels: 0.13.5
2024-01-04 14:39:23,826:INFO:              sktime: 0.21.1
2024-01-04 14:39:23,826:INFO:               tbats: 1.1.3
2024-01-04 14:39:23,826:INFO:            pmdarima: 2.0.3
2024-01-04 14:39:23,826:INFO:              psutil: 5.9.0
2024-01-04 14:39:23,826:INFO:          markupsafe: 2.1.1
2024-01-04 14:39:23,826:INFO:             pickle5: Not installed
2024-01-04 14:39:23,827:INFO:         cloudpickle: 2.0.0
2024-01-04 14:39:23,827:INFO:         deprecation: 2.1.0
2024-01-04 14:39:23,827:INFO:              xxhash: 3.4.1
2024-01-04 14:39:23,827:INFO:           wurlitzer: Not installed
2024-01-04 14:39:23,827:INFO:PyCaret optional dependencies:
2024-01-04 14:39:23,840:INFO:                shap: Not installed
2024-01-04 14:39:23,840:INFO:           interpret: Not installed
2024-01-04 14:39:23,840:INFO:                umap: Not installed
2024-01-04 14:39:23,840:INFO:     ydata_profiling: 4.6.0
2024-01-04 14:39:23,840:INFO:  explainerdashboard: Not installed
2024-01-04 14:39:23,840:INFO:             autoviz: Not installed
2024-01-04 14:39:23,841:INFO:           fairlearn: Not installed
2024-01-04 14:39:23,841:INFO:          deepchecks: Not installed
2024-01-04 14:39:23,841:INFO:             xgboost: Not installed
2024-01-04 14:39:23,841:INFO:            catboost: Not installed
2024-01-04 14:39:23,841:INFO:              kmodes: Not installed
2024-01-04 14:39:23,841:INFO:             mlxtend: Not installed
2024-01-04 14:39:23,841:INFO:       statsforecast: Not installed
2024-01-04 14:39:23,841:INFO:        tune_sklearn: Not installed
2024-01-04 14:39:23,841:INFO:                 ray: Not installed
2024-01-04 14:39:23,841:INFO:            hyperopt: Not installed
2024-01-04 14:39:23,841:INFO:              optuna: Not installed
2024-01-04 14:39:23,841:INFO:               skopt: Not installed
2024-01-04 14:39:23,841:INFO:              mlflow: Not installed
2024-01-04 14:39:23,841:INFO:              gradio: Not installed
2024-01-04 14:39:23,841:INFO:             fastapi: Not installed
2024-01-04 14:39:23,841:INFO:             uvicorn: Not installed
2024-01-04 14:39:23,841:INFO:              m2cgen: Not installed
2024-01-04 14:39:23,841:INFO:           evidently: Not installed
2024-01-04 14:39:23,841:INFO:               fugue: Not installed
2024-01-04 14:39:23,841:INFO:           streamlit: Not installed
2024-01-04 14:39:23,841:INFO:             prophet: Not installed
2024-01-04 14:39:23,841:INFO:None
2024-01-04 14:39:23,841:INFO:Set up data.
2024-01-04 14:39:23,884:INFO:Set up folding strategy.
2024-01-04 14:39:23,885:INFO:Set up train/test split.
2024-01-04 14:39:23,899:INFO:Set up index.
2024-01-04 14:39:23,900:INFO:Assigning column types.
2024-01-04 14:39:23,903:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-04 14:39:23,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-04 14:39:23,943:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:39:23,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:23,971:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,008:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-04 14:39:24,009:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:39:24,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,033:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-04 14:39:24,070:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:39:24,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,133:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:39:24,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,157:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-04 14:39:24,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,278:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:24,279:INFO:Preparing preprocessing pipeline...
2024-01-04 14:39:24,280:INFO:Set up simple imputation.
2024-01-04 14:39:24,285:INFO:Set up encoding of ordinal features.
2024-01-04 14:39:24,287:INFO:Set up encoding of categorical features.
2024-01-04 14:39:24,288:INFO:Set up column name cleaning.
2024-01-04 14:39:24,653:INFO:Finished creating preprocessing pipeline.
2024-01-04 14:39:24,672:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',...
                 TransformerWrapper(exclude=None, include=['country'],
                                    transformer=TargetEncoder(cols=['country'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-04 14:39:24,672:INFO:Creating final display dataframe.
2024-01-04 14:39:25,187:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 12)
4        Transformed data shape       (32561, 42)
5   Transformed train set shape       (26048, 42)
6    Transformed test set shape        (6513, 42)
7              Ordinal features                 1
8              Numeric features                 5
9          Categorical features                 6
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              8b8e
2024-01-04 14:39:25,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:25,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:25,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:25,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:39:25,319:INFO:setup() successfully completed in 2.05s...............
2024-01-04 14:39:37,145:INFO:Initializing compare_models()
2024-01-04 14:39:37,145:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-04 14:39:37,145:INFO:Checking exceptions
2024-01-04 14:39:37,151:INFO:Preparing display monitor
2024-01-04 14:39:37,179:INFO:Initializing Logistic Regression
2024-01-04 14:39:37,179:INFO:Total runtime is 0.0 minutes
2024-01-04 14:39:37,182:INFO:SubProcess create_model() called ==================================
2024-01-04 14:39:37,182:INFO:Initializing create_model()
2024-01-04 14:39:37,183:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:39:37,183:INFO:Checking exceptions
2024-01-04 14:39:37,183:INFO:Importing libraries
2024-01-04 14:39:37,183:INFO:Copying training dataset
2024-01-04 14:39:37,192:INFO:Defining folds
2024-01-04 14:39:37,193:INFO:Declaring metric variables
2024-01-04 14:39:37,196:INFO:Importing untrained model
2024-01-04 14:39:37,200:INFO:Logistic Regression Imported successfully
2024-01-04 14:39:37,209:INFO:Starting cross validation
2024-01-04 14:39:37,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:03,554:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:03,581:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:03,791:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:03,947:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:03,968:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:04,096:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:04,101:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:04,152:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:04,204:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:40:04,307:INFO:Calculating mean and std
2024-01-04 14:40:04,309:INFO:Creating metrics dataframe
2024-01-04 14:40:04,317:INFO:Uploading results into container
2024-01-04 14:40:04,318:INFO:Uploading model into container now
2024-01-04 14:40:04,650:INFO:_master_model_container: 1
2024-01-04 14:40:04,650:INFO:_display_container: 2
2024-01-04 14:40:04,650:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-04 14:40:04,650:INFO:create_model() successfully completed......................................
2024-01-04 14:40:04,848:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:04,848:INFO:Creating metrics dataframe
2024-01-04 14:40:04,856:INFO:Initializing K Neighbors Classifier
2024-01-04 14:40:04,856:INFO:Total runtime is 0.46128188371658324 minutes
2024-01-04 14:40:04,859:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:04,860:INFO:Initializing create_model()
2024-01-04 14:40:04,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:04,860:INFO:Checking exceptions
2024-01-04 14:40:04,860:INFO:Importing libraries
2024-01-04 14:40:04,860:INFO:Copying training dataset
2024-01-04 14:40:04,871:INFO:Defining folds
2024-01-04 14:40:04,871:INFO:Declaring metric variables
2024-01-04 14:40:04,875:INFO:Importing untrained model
2024-01-04 14:40:04,879:INFO:K Neighbors Classifier Imported successfully
2024-01-04 14:40:04,888:INFO:Starting cross validation
2024-01-04 14:40:04,891:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:12,352:INFO:Calculating mean and std
2024-01-04 14:40:12,354:INFO:Creating metrics dataframe
2024-01-04 14:40:12,359:INFO:Uploading results into container
2024-01-04 14:40:12,359:INFO:Uploading model into container now
2024-01-04 14:40:12,360:INFO:_master_model_container: 2
2024-01-04 14:40:12,360:INFO:_display_container: 2
2024-01-04 14:40:12,360:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-04 14:40:12,360:INFO:create_model() successfully completed......................................
2024-01-04 14:40:12,537:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:12,538:INFO:Creating metrics dataframe
2024-01-04 14:40:12,547:INFO:Initializing Naive Bayes
2024-01-04 14:40:12,547:INFO:Total runtime is 0.5894636193911235 minutes
2024-01-04 14:40:12,550:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:12,550:INFO:Initializing create_model()
2024-01-04 14:40:12,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:12,550:INFO:Checking exceptions
2024-01-04 14:40:12,550:INFO:Importing libraries
2024-01-04 14:40:12,550:INFO:Copying training dataset
2024-01-04 14:40:12,558:INFO:Defining folds
2024-01-04 14:40:12,558:INFO:Declaring metric variables
2024-01-04 14:40:12,562:INFO:Importing untrained model
2024-01-04 14:40:12,565:INFO:Naive Bayes Imported successfully
2024-01-04 14:40:12,571:INFO:Starting cross validation
2024-01-04 14:40:12,573:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:14,080:INFO:Calculating mean and std
2024-01-04 14:40:14,083:INFO:Creating metrics dataframe
2024-01-04 14:40:14,088:INFO:Uploading results into container
2024-01-04 14:40:14,089:INFO:Uploading model into container now
2024-01-04 14:40:14,089:INFO:_master_model_container: 3
2024-01-04 14:40:14,090:INFO:_display_container: 2
2024-01-04 14:40:14,090:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-04 14:40:14,090:INFO:create_model() successfully completed......................................
2024-01-04 14:40:14,310:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:14,310:INFO:Creating metrics dataframe
2024-01-04 14:40:14,320:INFO:Initializing Decision Tree Classifier
2024-01-04 14:40:14,320:INFO:Total runtime is 0.6190172115961711 minutes
2024-01-04 14:40:14,323:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:14,324:INFO:Initializing create_model()
2024-01-04 14:40:14,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:14,324:INFO:Checking exceptions
2024-01-04 14:40:14,324:INFO:Importing libraries
2024-01-04 14:40:14,324:INFO:Copying training dataset
2024-01-04 14:40:14,334:INFO:Defining folds
2024-01-04 14:40:14,334:INFO:Declaring metric variables
2024-01-04 14:40:14,338:INFO:Importing untrained model
2024-01-04 14:40:14,343:INFO:Decision Tree Classifier Imported successfully
2024-01-04 14:40:14,351:INFO:Starting cross validation
2024-01-04 14:40:14,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:16,265:INFO:Calculating mean and std
2024-01-04 14:40:16,266:INFO:Creating metrics dataframe
2024-01-04 14:40:16,270:INFO:Uploading results into container
2024-01-04 14:40:16,271:INFO:Uploading model into container now
2024-01-04 14:40:16,271:INFO:_master_model_container: 4
2024-01-04 14:40:16,272:INFO:_display_container: 2
2024-01-04 14:40:16,272:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-04 14:40:16,272:INFO:create_model() successfully completed......................................
2024-01-04 14:40:16,454:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:16,454:INFO:Creating metrics dataframe
2024-01-04 14:40:16,463:INFO:Initializing SVM - Linear Kernel
2024-01-04 14:40:16,463:INFO:Total runtime is 0.6547394474347432 minutes
2024-01-04 14:40:16,466:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:16,467:INFO:Initializing create_model()
2024-01-04 14:40:16,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:16,467:INFO:Checking exceptions
2024-01-04 14:40:16,467:INFO:Importing libraries
2024-01-04 14:40:16,467:INFO:Copying training dataset
2024-01-04 14:40:16,475:INFO:Defining folds
2024-01-04 14:40:16,475:INFO:Declaring metric variables
2024-01-04 14:40:16,479:INFO:Importing untrained model
2024-01-04 14:40:16,483:INFO:SVM - Linear Kernel Imported successfully
2024-01-04 14:40:16,490:INFO:Starting cross validation
2024-01-04 14:40:16,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:18,482:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,491:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,540:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,544:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,570:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,575:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,576:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,590:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,598:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,665:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:40:18,686:INFO:Calculating mean and std
2024-01-04 14:40:18,688:INFO:Creating metrics dataframe
2024-01-04 14:40:18,691:INFO:Uploading results into container
2024-01-04 14:40:18,692:INFO:Uploading model into container now
2024-01-04 14:40:18,693:INFO:_master_model_container: 5
2024-01-04 14:40:18,693:INFO:_display_container: 2
2024-01-04 14:40:18,694:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-04 14:40:18,694:INFO:create_model() successfully completed......................................
2024-01-04 14:40:18,855:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:18,855:INFO:Creating metrics dataframe
2024-01-04 14:40:18,865:INFO:Initializing Ridge Classifier
2024-01-04 14:40:18,865:INFO:Total runtime is 0.6947689135869344 minutes
2024-01-04 14:40:18,868:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:18,868:INFO:Initializing create_model()
2024-01-04 14:40:18,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:18,868:INFO:Checking exceptions
2024-01-04 14:40:18,869:INFO:Importing libraries
2024-01-04 14:40:18,869:INFO:Copying training dataset
2024-01-04 14:40:18,877:INFO:Defining folds
2024-01-04 14:40:18,877:INFO:Declaring metric variables
2024-01-04 14:40:18,881:INFO:Importing untrained model
2024-01-04 14:40:18,885:INFO:Ridge Classifier Imported successfully
2024-01-04 14:40:18,892:INFO:Starting cross validation
2024-01-04 14:40:18,895:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:20,374:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,429:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,432:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,435:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,446:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,468:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,469:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,470:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,476:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,483:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:40:20,523:INFO:Calculating mean and std
2024-01-04 14:40:20,524:INFO:Creating metrics dataframe
2024-01-04 14:40:20,528:INFO:Uploading results into container
2024-01-04 14:40:20,529:INFO:Uploading model into container now
2024-01-04 14:40:20,529:INFO:_master_model_container: 6
2024-01-04 14:40:20,529:INFO:_display_container: 2
2024-01-04 14:40:20,530:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-04 14:40:20,530:INFO:create_model() successfully completed......................................
2024-01-04 14:40:20,719:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:20,719:INFO:Creating metrics dataframe
2024-01-04 14:40:20,730:INFO:Initializing Random Forest Classifier
2024-01-04 14:40:20,730:INFO:Total runtime is 0.7258607943852742 minutes
2024-01-04 14:40:20,733:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:20,733:INFO:Initializing create_model()
2024-01-04 14:40:20,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:20,734:INFO:Checking exceptions
2024-01-04 14:40:20,734:INFO:Importing libraries
2024-01-04 14:40:20,734:INFO:Copying training dataset
2024-01-04 14:40:20,743:INFO:Defining folds
2024-01-04 14:40:20,744:INFO:Declaring metric variables
2024-01-04 14:40:20,747:INFO:Importing untrained model
2024-01-04 14:40:20,751:INFO:Random Forest Classifier Imported successfully
2024-01-04 14:40:20,761:INFO:Starting cross validation
2024-01-04 14:40:20,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:26,308:INFO:Calculating mean and std
2024-01-04 14:40:26,309:INFO:Creating metrics dataframe
2024-01-04 14:40:26,314:INFO:Uploading results into container
2024-01-04 14:40:26,314:INFO:Uploading model into container now
2024-01-04 14:40:26,315:INFO:_master_model_container: 7
2024-01-04 14:40:26,315:INFO:_display_container: 2
2024-01-04 14:40:26,315:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-04 14:40:26,316:INFO:create_model() successfully completed......................................
2024-01-04 14:40:26,540:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:26,541:INFO:Creating metrics dataframe
2024-01-04 14:40:26,552:INFO:Initializing Quadratic Discriminant Analysis
2024-01-04 14:40:26,552:INFO:Total runtime is 0.8228846112887064 minutes
2024-01-04 14:40:26,560:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:26,561:INFO:Initializing create_model()
2024-01-04 14:40:26,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:26,561:INFO:Checking exceptions
2024-01-04 14:40:26,561:INFO:Importing libraries
2024-01-04 14:40:26,561:INFO:Copying training dataset
2024-01-04 14:40:26,581:INFO:Defining folds
2024-01-04 14:40:26,581:INFO:Declaring metric variables
2024-01-04 14:40:26,587:INFO:Importing untrained model
2024-01-04 14:40:26,592:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-04 14:40:26,601:INFO:Starting cross validation
2024-01-04 14:40:26,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:28,008:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,014:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,110:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,126:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,201:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,201:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,213:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,242:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,242:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,253:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:40:28,495:INFO:Calculating mean and std
2024-01-04 14:40:28,497:INFO:Creating metrics dataframe
2024-01-04 14:40:28,504:INFO:Uploading results into container
2024-01-04 14:40:28,505:INFO:Uploading model into container now
2024-01-04 14:40:28,506:INFO:_master_model_container: 8
2024-01-04 14:40:28,506:INFO:_display_container: 2
2024-01-04 14:40:28,507:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-04 14:40:28,507:INFO:create_model() successfully completed......................................
2024-01-04 14:40:28,825:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:28,825:INFO:Creating metrics dataframe
2024-01-04 14:40:28,838:INFO:Initializing Ada Boost Classifier
2024-01-04 14:40:28,838:INFO:Total runtime is 0.8609946290651956 minutes
2024-01-04 14:40:28,843:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:28,843:INFO:Initializing create_model()
2024-01-04 14:40:28,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:28,843:INFO:Checking exceptions
2024-01-04 14:40:28,843:INFO:Importing libraries
2024-01-04 14:40:28,843:INFO:Copying training dataset
2024-01-04 14:40:28,857:INFO:Defining folds
2024-01-04 14:40:28,858:INFO:Declaring metric variables
2024-01-04 14:40:28,863:INFO:Importing untrained model
2024-01-04 14:40:28,868:INFO:Ada Boost Classifier Imported successfully
2024-01-04 14:40:28,877:INFO:Starting cross validation
2024-01-04 14:40:28,880:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:33,956:INFO:Calculating mean and std
2024-01-04 14:40:33,958:INFO:Creating metrics dataframe
2024-01-04 14:40:33,962:INFO:Uploading results into container
2024-01-04 14:40:33,962:INFO:Uploading model into container now
2024-01-04 14:40:33,963:INFO:_master_model_container: 9
2024-01-04 14:40:33,963:INFO:_display_container: 2
2024-01-04 14:40:33,964:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-04 14:40:33,964:INFO:create_model() successfully completed......................................
2024-01-04 14:40:34,234:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:34,234:INFO:Creating metrics dataframe
2024-01-04 14:40:34,247:INFO:Initializing Gradient Boosting Classifier
2024-01-04 14:40:34,247:INFO:Total runtime is 0.9511425654093424 minutes
2024-01-04 14:40:34,253:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:34,253:INFO:Initializing create_model()
2024-01-04 14:40:34,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:34,254:INFO:Checking exceptions
2024-01-04 14:40:34,254:INFO:Importing libraries
2024-01-04 14:40:34,254:INFO:Copying training dataset
2024-01-04 14:40:34,265:INFO:Defining folds
2024-01-04 14:40:34,266:INFO:Declaring metric variables
2024-01-04 14:40:34,270:INFO:Importing untrained model
2024-01-04 14:40:34,274:INFO:Gradient Boosting Classifier Imported successfully
2024-01-04 14:40:34,282:INFO:Starting cross validation
2024-01-04 14:40:34,284:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:40,232:INFO:Calculating mean and std
2024-01-04 14:40:40,233:INFO:Creating metrics dataframe
2024-01-04 14:40:40,237:INFO:Uploading results into container
2024-01-04 14:40:40,237:INFO:Uploading model into container now
2024-01-04 14:40:40,238:INFO:_master_model_container: 10
2024-01-04 14:40:40,238:INFO:_display_container: 2
2024-01-04 14:40:40,238:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-04 14:40:40,239:INFO:create_model() successfully completed......................................
2024-01-04 14:40:40,432:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:40,432:INFO:Creating metrics dataframe
2024-01-04 14:40:40,443:INFO:Initializing Linear Discriminant Analysis
2024-01-04 14:40:40,444:INFO:Total runtime is 1.0544234752655028 minutes
2024-01-04 14:40:40,447:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:40,447:INFO:Initializing create_model()
2024-01-04 14:40:40,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:40,447:INFO:Checking exceptions
2024-01-04 14:40:40,447:INFO:Importing libraries
2024-01-04 14:40:40,447:INFO:Copying training dataset
2024-01-04 14:40:40,459:INFO:Defining folds
2024-01-04 14:40:40,459:INFO:Declaring metric variables
2024-01-04 14:40:40,463:INFO:Importing untrained model
2024-01-04 14:40:40,467:INFO:Linear Discriminant Analysis Imported successfully
2024-01-04 14:40:40,475:INFO:Starting cross validation
2024-01-04 14:40:40,477:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:43,108:INFO:Calculating mean and std
2024-01-04 14:40:43,109:INFO:Creating metrics dataframe
2024-01-04 14:40:43,113:INFO:Uploading results into container
2024-01-04 14:40:43,114:INFO:Uploading model into container now
2024-01-04 14:40:43,114:INFO:_master_model_container: 11
2024-01-04 14:40:43,114:INFO:_display_container: 2
2024-01-04 14:40:43,114:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-04 14:40:43,115:INFO:create_model() successfully completed......................................
2024-01-04 14:40:43,299:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:43,299:INFO:Creating metrics dataframe
2024-01-04 14:40:43,310:INFO:Initializing Extra Trees Classifier
2024-01-04 14:40:43,310:INFO:Total runtime is 1.1021795868873596 minutes
2024-01-04 14:40:43,314:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:43,314:INFO:Initializing create_model()
2024-01-04 14:40:43,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:43,314:INFO:Checking exceptions
2024-01-04 14:40:43,315:INFO:Importing libraries
2024-01-04 14:40:43,315:INFO:Copying training dataset
2024-01-04 14:40:43,324:INFO:Defining folds
2024-01-04 14:40:43,324:INFO:Declaring metric variables
2024-01-04 14:40:43,329:INFO:Importing untrained model
2024-01-04 14:40:43,333:INFO:Extra Trees Classifier Imported successfully
2024-01-04 14:40:43,341:INFO:Starting cross validation
2024-01-04 14:40:43,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:49,662:INFO:Calculating mean and std
2024-01-04 14:40:49,664:INFO:Creating metrics dataframe
2024-01-04 14:40:49,669:INFO:Uploading results into container
2024-01-04 14:40:49,670:INFO:Uploading model into container now
2024-01-04 14:40:49,670:INFO:_master_model_container: 12
2024-01-04 14:40:49,671:INFO:_display_container: 2
2024-01-04 14:40:49,671:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-04 14:40:49,671:INFO:create_model() successfully completed......................................
2024-01-04 14:40:50,030:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:50,030:INFO:Creating metrics dataframe
2024-01-04 14:40:50,043:INFO:Initializing Light Gradient Boosting Machine
2024-01-04 14:40:50,043:INFO:Total runtime is 1.214404853185018 minutes
2024-01-04 14:40:50,057:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:50,059:INFO:Initializing create_model()
2024-01-04 14:40:50,059:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:50,059:INFO:Checking exceptions
2024-01-04 14:40:50,060:INFO:Importing libraries
2024-01-04 14:40:50,060:INFO:Copying training dataset
2024-01-04 14:40:50,074:INFO:Defining folds
2024-01-04 14:40:50,075:INFO:Declaring metric variables
2024-01-04 14:40:50,080:INFO:Importing untrained model
2024-01-04 14:40:50,085:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:40:50,093:INFO:Starting cross validation
2024-01-04 14:40:50,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:53,662:INFO:Calculating mean and std
2024-01-04 14:40:53,664:INFO:Creating metrics dataframe
2024-01-04 14:40:53,671:INFO:Uploading results into container
2024-01-04 14:40:53,672:INFO:Uploading model into container now
2024-01-04 14:40:53,673:INFO:_master_model_container: 13
2024-01-04 14:40:53,673:INFO:_display_container: 2
2024-01-04 14:40:53,674:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:40:53,674:INFO:create_model() successfully completed......................................
2024-01-04 14:40:54,052:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:54,053:INFO:Creating metrics dataframe
2024-01-04 14:40:54,073:INFO:Initializing Dummy Classifier
2024-01-04 14:40:54,074:INFO:Total runtime is 1.28158145348231 minutes
2024-01-04 14:40:54,079:INFO:SubProcess create_model() called ==================================
2024-01-04 14:40:54,079:INFO:Initializing create_model()
2024-01-04 14:40:54,079:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6F4C12470>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:54,080:INFO:Checking exceptions
2024-01-04 14:40:54,080:INFO:Importing libraries
2024-01-04 14:40:54,080:INFO:Copying training dataset
2024-01-04 14:40:54,094:INFO:Defining folds
2024-01-04 14:40:54,095:INFO:Declaring metric variables
2024-01-04 14:40:54,098:INFO:Importing untrained model
2024-01-04 14:40:54,102:INFO:Dummy Classifier Imported successfully
2024-01-04 14:40:54,109:INFO:Starting cross validation
2024-01-04 14:40:54,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:40:55,664:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,664:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,686:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,691:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,703:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,726:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,728:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,733:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,735:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,745:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:40:55,770:INFO:Calculating mean and std
2024-01-04 14:40:55,772:INFO:Creating metrics dataframe
2024-01-04 14:40:55,777:INFO:Uploading results into container
2024-01-04 14:40:55,778:INFO:Uploading model into container now
2024-01-04 14:40:55,779:INFO:_master_model_container: 14
2024-01-04 14:40:55,779:INFO:_display_container: 2
2024-01-04 14:40:55,779:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-04 14:40:55,779:INFO:create_model() successfully completed......................................
2024-01-04 14:40:56,241:INFO:SubProcess create_model() end ==================================
2024-01-04 14:40:56,242:INFO:Creating metrics dataframe
2024-01-04 14:40:56,271:INFO:Initializing create_model()
2024-01-04 14:40:56,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:40:56,272:INFO:Checking exceptions
2024-01-04 14:40:56,275:INFO:Importing libraries
2024-01-04 14:40:56,275:INFO:Copying training dataset
2024-01-04 14:40:56,284:INFO:Defining folds
2024-01-04 14:40:56,285:INFO:Declaring metric variables
2024-01-04 14:40:56,285:INFO:Importing untrained model
2024-01-04 14:40:56,285:INFO:Declaring custom model
2024-01-04 14:40:56,286:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:40:56,287:INFO:Cross validation set to False
2024-01-04 14:40:56,287:INFO:Fitting Model
2024-01-04 14:40:56,664:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:40:56,665:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:40:56,667:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000908 seconds.
2024-01-04 14:40:56,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:40:56,668:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:40:56,668:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 14:40:56,668:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 37
2024-01-04 14:40:56,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:40:56,669:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:40:56,804:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:40:56,805:INFO:create_model() successfully completed......................................
2024-01-04 14:40:57,050:INFO:_master_model_container: 14
2024-01-04 14:40:57,050:INFO:_display_container: 2
2024-01-04 14:40:57,050:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:40:57,050:INFO:compare_models() successfully completed......................................
2024-01-04 14:40:57,508:INFO:Initializing plot_model()
2024-01-04 14:40:57,508:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, system=True)
2024-01-04 14:40:57,509:INFO:Checking exceptions
2024-01-04 14:40:57,520:INFO:Preloading libraries
2024-01-04 14:40:57,534:INFO:Copying training dataset
2024-01-04 14:40:57,534:INFO:Plot type: auc
2024-01-04 14:40:57,879:INFO:Fitting Model
2024-01-04 14:40:57,880:INFO:Scoring test/hold-out set
2024-01-04 14:40:58,198:INFO:Visual Rendered Successfully
2024-01-04 14:40:58,394:INFO:plot_model() successfully completed......................................
2024-01-04 14:40:58,447:INFO:Initializing plot_model()
2024-01-04 14:40:58,447:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, system=True)
2024-01-04 14:40:58,447:INFO:Checking exceptions
2024-01-04 14:40:58,452:INFO:Preloading libraries
2024-01-04 14:40:58,457:INFO:Copying training dataset
2024-01-04 14:40:58,457:INFO:Plot type: confusion_matrix
2024-01-04 14:40:58,619:INFO:Fitting Model
2024-01-04 14:40:58,620:INFO:Scoring test/hold-out set
2024-01-04 14:40:58,807:INFO:Visual Rendered Successfully
2024-01-04 14:40:59,005:INFO:plot_model() successfully completed......................................
2024-01-04 14:40:59,064:INFO:Initializing plot_model()
2024-01-04 14:40:59,064:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, system=True)
2024-01-04 14:40:59,064:INFO:Checking exceptions
2024-01-04 14:40:59,069:INFO:Preloading libraries
2024-01-04 14:40:59,075:INFO:Copying training dataset
2024-01-04 14:40:59,075:INFO:Plot type: class_report
2024-01-04 14:40:59,231:INFO:Fitting Model
2024-01-04 14:40:59,231:INFO:Scoring test/hold-out set
2024-01-04 14:40:59,549:INFO:Visual Rendered Successfully
2024-01-04 14:40:59,761:INFO:plot_model() successfully completed......................................
2024-01-04 14:40:59,829:INFO:Initializing tune_model()
2024-01-04 14:40:59,829:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>)
2024-01-04 14:40:59,829:INFO:Checking exceptions
2024-01-04 14:40:59,854:INFO:Copying training dataset
2024-01-04 14:40:59,861:INFO:Checking base model
2024-01-04 14:40:59,861:INFO:Base model : Light Gradient Boosting Machine
2024-01-04 14:40:59,864:INFO:Declaring metric variables
2024-01-04 14:40:59,868:INFO:Defining Hyperparameters
2024-01-04 14:41:00,121:INFO:Tuning with n_jobs=-1
2024-01-04 14:41:00,121:INFO:Initializing RandomizedSearchCV
2024-01-04 14:41:49,317:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-04 14:41:49,318:INFO:Hyperparameter search completed
2024-01-04 14:41:49,318:INFO:SubProcess create_model() called ==================================
2024-01-04 14:41:49,320:INFO:Initializing create_model()
2024-01-04 14:41:49,320:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002A6E904FCA0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-04 14:41:49,320:INFO:Checking exceptions
2024-01-04 14:41:49,320:INFO:Importing libraries
2024-01-04 14:41:49,320:INFO:Copying training dataset
2024-01-04 14:41:49,336:INFO:Defining folds
2024-01-04 14:41:49,336:INFO:Declaring metric variables
2024-01-04 14:41:49,342:INFO:Importing untrained model
2024-01-04 14:41:49,342:INFO:Declaring custom model
2024-01-04 14:41:49,348:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:41:49,358:INFO:Starting cross validation
2024-01-04 14:41:49,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:41:53,449:INFO:Calculating mean and std
2024-01-04 14:41:53,451:INFO:Creating metrics dataframe
2024-01-04 14:41:53,460:INFO:Finalizing model
2024-01-04 14:41:53,822:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-04 14:41:53,822:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-04 14:41:53,822:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-04 14:41:53,835:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:41:53,836:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-04 14:41:53,836:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-04 14:41:53,836:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-04 14:41:53,836:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:41:53,839:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.
2024-01-04 14:41:53,839:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:41:53,839:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:41:53,839:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 14:41:53,839:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 37
2024-01-04 14:41:53,840:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:41:53,840:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:41:53,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,865:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,936:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,949:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,976:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:53,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,006:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,030:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,052:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,055:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,056:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,061:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,065:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,066:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,071:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:41:54,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:41:54,102:INFO:Uploading results into container
2024-01-04 14:41:54,104:INFO:Uploading model into container now
2024-01-04 14:41:54,106:INFO:_master_model_container: 15
2024-01-04 14:41:54,106:INFO:_display_container: 3
2024-01-04 14:41:54,107:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:41:54,107:INFO:create_model() successfully completed......................................
2024-01-04 14:41:54,312:INFO:SubProcess create_model() end ==================================
2024-01-04 14:41:54,312:INFO:choose_better activated
2024-01-04 14:41:54,316:INFO:SubProcess create_model() called ==================================
2024-01-04 14:41:54,316:INFO:Initializing create_model()
2024-01-04 14:41:54,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:41:54,316:INFO:Checking exceptions
2024-01-04 14:41:54,318:INFO:Importing libraries
2024-01-04 14:41:54,318:INFO:Copying training dataset
2024-01-04 14:41:54,327:INFO:Defining folds
2024-01-04 14:41:54,327:INFO:Declaring metric variables
2024-01-04 14:41:54,327:INFO:Importing untrained model
2024-01-04 14:41:54,327:INFO:Declaring custom model
2024-01-04 14:41:54,328:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:41:54,328:INFO:Starting cross validation
2024-01-04 14:41:54,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:41:57,281:INFO:Calculating mean and std
2024-01-04 14:41:57,282:INFO:Creating metrics dataframe
2024-01-04 14:41:57,285:INFO:Finalizing model
2024-01-04 14:41:57,666:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:41:57,666:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:41:57,668:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000920 seconds.
2024-01-04 14:41:57,668:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:41:57,669:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:41:57,669:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 14:41:57,669:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 37
2024-01-04 14:41:57,669:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:41:57,669:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:41:57,763:INFO:Uploading results into container
2024-01-04 14:41:57,764:INFO:Uploading model into container now
2024-01-04 14:41:57,764:INFO:_master_model_container: 16
2024-01-04 14:41:57,764:INFO:_display_container: 4
2024-01-04 14:41:57,765:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:41:57,765:INFO:create_model() successfully completed......................................
2024-01-04 14:41:57,946:INFO:SubProcess create_model() end ==================================
2024-01-04 14:41:57,947:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8715
2024-01-04 14:41:57,947:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8692
2024-01-04 14:41:57,948:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-04 14:41:57,948:INFO:choose_better completed
2024-01-04 14:41:57,948:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-04 14:41:57,956:INFO:_master_model_container: 16
2024-01-04 14:41:57,957:INFO:_display_container: 3
2024-01-04 14:41:57,957:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:41:57,957:INFO:tune_model() successfully completed......................................
2024-01-04 14:41:58,424:INFO:Initializing plot_model()
2024-01-04 14:41:58,424:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, system=True)
2024-01-04 14:41:58,424:INFO:Checking exceptions
2024-01-04 14:41:58,430:INFO:Preloading libraries
2024-01-04 14:41:58,435:INFO:Copying training dataset
2024-01-04 14:41:58,436:INFO:Plot type: auc
2024-01-04 14:41:58,591:INFO:Fitting Model
2024-01-04 14:41:58,592:INFO:Scoring test/hold-out set
2024-01-04 14:41:58,903:INFO:Visual Rendered Successfully
2024-01-04 14:41:59,067:INFO:plot_model() successfully completed......................................
2024-01-04 14:41:59,094:INFO:Initializing plot_model()
2024-01-04 14:41:59,095:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, system=True)
2024-01-04 14:41:59,095:INFO:Checking exceptions
2024-01-04 14:41:59,101:INFO:Preloading libraries
2024-01-04 14:41:59,106:INFO:Copying training dataset
2024-01-04 14:41:59,106:INFO:Plot type: confusion_matrix
2024-01-04 14:41:59,256:INFO:Fitting Model
2024-01-04 14:41:59,256:INFO:Scoring test/hold-out set
2024-01-04 14:41:59,435:INFO:Visual Rendered Successfully
2024-01-04 14:41:59,595:INFO:plot_model() successfully completed......................................
2024-01-04 14:41:59,630:INFO:Initializing plot_model()
2024-01-04 14:41:59,630:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, system=True)
2024-01-04 14:41:59,630:INFO:Checking exceptions
2024-01-04 14:41:59,637:INFO:Preloading libraries
2024-01-04 14:41:59,642:INFO:Copying training dataset
2024-01-04 14:41:59,642:INFO:Plot type: class_report
2024-01-04 14:41:59,798:INFO:Fitting Model
2024-01-04 14:41:59,798:INFO:Scoring test/hold-out set
2024-01-04 14:42:00,108:INFO:Visual Rendered Successfully
2024-01-04 14:42:00,284:INFO:plot_model() successfully completed......................................
2024-01-04 14:42:00,321:INFO:Initializing finalize_model()
2024-01-04 14:42:00,321:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-04 14:42:00,321:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:42:00,326:INFO:Initializing create_model()
2024-01-04 14:42:00,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-04 14:42:00,326:INFO:Checking exceptions
2024-01-04 14:42:00,327:INFO:Importing libraries
2024-01-04 14:42:00,327:INFO:Copying training dataset
2024-01-04 14:42:00,328:INFO:Defining folds
2024-01-04 14:42:00,328:INFO:Declaring metric variables
2024-01-04 14:42:00,328:INFO:Importing untrained model
2024-01-04 14:42:00,328:INFO:Declaring custom model
2024-01-04 14:42:00,328:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:42:00,330:INFO:Cross validation set to False
2024-01-04 14:42:00,330:INFO:Fitting Model
2024-01-04 14:42:00,739:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:42:00,739:INFO:[LightGBM] [Info] Number of positive: 7841, number of negative: 24720
2024-01-04 14:42:00,742:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000856 seconds.
2024-01-04 14:42:00,742:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:42:00,742:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:42:00,742:INFO:[LightGBM] [Info] Total Bins 451
2024-01-04 14:42:00,742:INFO:[LightGBM] [Info] Number of data points in the train set: 32561, number of used features: 38
2024-01-04 14:42:00,743:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240810 -> initscore=-1.148246
2024-01-04 14:42:00,743:INFO:[LightGBM] [Info] Start training from score -1.148246
2024-01-04 14:42:00,883:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_im...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-04 14:42:00,883:INFO:create_model() successfully completed......................................
2024-01-04 14:42:01,070:INFO:_master_model_container: 16
2024-01-04 14:42:01,070:INFO:_display_container: 3
2024-01-04 14:42:01,089:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_im...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-04 14:42:01,089:INFO:finalize_model() successfully completed......................................
2024-01-04 14:43:07,610:INFO:Initializing predict_model()
2024-01-04 14:43:07,610:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_im...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A681945F30>)
2024-01-04 14:43:07,610:INFO:Checking exceptions
2024-01-04 14:43:07,610:INFO:Preloading libraries
2024-01-04 14:43:07,613:INFO:Set up data.
2024-01-04 14:43:07,688:INFO:Set up index.
2024-01-04 14:48:16,997:INFO:Initializing predict_model()
2024-01-04 14:48:16,997:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002A6F4C125F0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_im...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002A680918430>)
2024-01-04 14:48:16,997:INFO:Checking exceptions
2024-01-04 14:48:16,997:INFO:Preloading libraries
2024-01-04 14:48:17,001:INFO:Set up data.
2024-01-04 14:48:17,053:INFO:Set up index.
2024-01-04 14:50:27,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:50:27,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:50:27,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:50:27,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-01-04 14:50:28,347:INFO:PyCaret ClassificationExperiment
2024-01-04 14:50:28,347:INFO:Logging name: clf-default-name
2024-01-04 14:50:28,347:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-01-04 14:50:28,347:INFO:version 3.1.0
2024-01-04 14:50:28,347:INFO:Initializing setup()
2024-01-04 14:50:28,347:INFO:self.USI: 0e3a
2024-01-04 14:50:28,347:INFO:self._variable_keys: {'idx', 'gpu_param', 'fold_groups_param', 'gpu_n_jobs_param', 'y', 'exp_name_log', 'X_train', 'y_test', 'y_train', 'html_param', 'target_param', 'X_test', 'X', 'USI', 'data', 'fold_shuffle_param', '_available_plots', 'logging_param', 'log_plots_param', 'memory', 'n_jobs_param', '_ml_usecase', 'exp_id', 'seed', 'pipeline', 'is_multiclass', 'fix_imbalance', 'fold_generator'}
2024-01-04 14:50:28,347:INFO:Checking environment
2024-01-04 14:50:28,347:INFO:python_version: 3.10.9
2024-01-04 14:50:28,347:INFO:python_build: ('main', 'Mar  1 2023 18:18:15')
2024-01-04 14:50:28,348:INFO:machine: AMD64
2024-01-04 14:50:28,348:INFO:platform: Windows-10-10.0.22631-SP0
2024-01-04 14:50:28,348:INFO:Memory: svmem(total=16954372096, available=6684778496, percent=60.6, used=10269593600, free=6684778496)
2024-01-04 14:50:28,348:INFO:Physical Core: 8
2024-01-04 14:50:28,348:INFO:Logical Core: 16
2024-01-04 14:50:28,348:INFO:Checking libraries
2024-01-04 14:50:28,348:INFO:System:
2024-01-04 14:50:28,348:INFO:    python: 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]
2024-01-04 14:50:28,348:INFO:executable: c:\Users\visha\anaconda3\python.exe
2024-01-04 14:50:28,348:INFO:   machine: Windows-10-10.0.22631-SP0
2024-01-04 14:50:28,348:INFO:PyCaret required dependencies:
2024-01-04 14:50:29,014:INFO:                 pip: 22.3.1
2024-01-04 14:50:29,014:INFO:          setuptools: 65.6.3
2024-01-04 14:50:29,015:INFO:             pycaret: 3.1.0
2024-01-04 14:50:29,015:INFO:             IPython: 8.10.0
2024-01-04 14:50:29,015:INFO:          ipywidgets: 7.6.5
2024-01-04 14:50:29,015:INFO:                tqdm: 4.64.1
2024-01-04 14:50:29,015:INFO:               numpy: 1.23.5
2024-01-04 14:50:29,015:INFO:              pandas: 1.5.3
2024-01-04 14:50:29,015:INFO:              jinja2: 3.1.2
2024-01-04 14:50:29,015:INFO:               scipy: 1.10.1
2024-01-04 14:50:29,015:INFO:              joblib: 1.3.2
2024-01-04 14:50:29,015:INFO:             sklearn: 1.2.1
2024-01-04 14:50:29,015:INFO:                pyod: 1.1.0
2024-01-04 14:50:29,015:INFO:            imblearn: 0.10.1
2024-01-04 14:50:29,015:INFO:   category_encoders: 2.6.2
2024-01-04 14:50:29,015:INFO:            lightgbm: 4.1.0
2024-01-04 14:50:29,016:INFO:               numba: 0.56.4
2024-01-04 14:50:29,016:INFO:            requests: 2.28.1
2024-01-04 14:50:29,016:INFO:          matplotlib: 3.7.0
2024-01-04 14:50:29,016:INFO:          scikitplot: 0.3.7
2024-01-04 14:50:29,016:INFO:         yellowbrick: 1.5
2024-01-04 14:50:29,016:INFO:              plotly: 5.9.0
2024-01-04 14:50:29,016:INFO:    plotly-resampler: Not installed
2024-01-04 14:50:29,016:INFO:             kaleido: 0.2.1
2024-01-04 14:50:29,016:INFO:           schemdraw: 0.15
2024-01-04 14:50:29,016:INFO:         statsmodels: 0.13.5
2024-01-04 14:50:29,016:INFO:              sktime: 0.21.1
2024-01-04 14:50:29,016:INFO:               tbats: 1.1.3
2024-01-04 14:50:29,016:INFO:            pmdarima: 2.0.3
2024-01-04 14:50:29,016:INFO:              psutil: 5.9.0
2024-01-04 14:50:29,016:INFO:          markupsafe: 2.1.1
2024-01-04 14:50:29,016:INFO:             pickle5: Not installed
2024-01-04 14:50:29,016:INFO:         cloudpickle: 2.0.0
2024-01-04 14:50:29,016:INFO:         deprecation: 2.1.0
2024-01-04 14:50:29,016:INFO:              xxhash: 3.4.1
2024-01-04 14:50:29,016:INFO:           wurlitzer: Not installed
2024-01-04 14:50:29,016:INFO:PyCaret optional dependencies:
2024-01-04 14:50:29,032:INFO:                shap: Not installed
2024-01-04 14:50:29,032:INFO:           interpret: Not installed
2024-01-04 14:50:29,032:INFO:                umap: Not installed
2024-01-04 14:50:29,032:INFO:     ydata_profiling: 4.6.0
2024-01-04 14:50:29,032:INFO:  explainerdashboard: Not installed
2024-01-04 14:50:29,032:INFO:             autoviz: Not installed
2024-01-04 14:50:29,032:INFO:           fairlearn: Not installed
2024-01-04 14:50:29,032:INFO:          deepchecks: Not installed
2024-01-04 14:50:29,032:INFO:             xgboost: Not installed
2024-01-04 14:50:29,032:INFO:            catboost: Not installed
2024-01-04 14:50:29,032:INFO:              kmodes: Not installed
2024-01-04 14:50:29,032:INFO:             mlxtend: Not installed
2024-01-04 14:50:29,032:INFO:       statsforecast: Not installed
2024-01-04 14:50:29,032:INFO:        tune_sklearn: Not installed
2024-01-04 14:50:29,032:INFO:                 ray: Not installed
2024-01-04 14:50:29,032:INFO:            hyperopt: Not installed
2024-01-04 14:50:29,032:INFO:              optuna: Not installed
2024-01-04 14:50:29,032:INFO:               skopt: Not installed
2024-01-04 14:50:29,032:INFO:              mlflow: Not installed
2024-01-04 14:50:29,033:INFO:              gradio: Not installed
2024-01-04 14:50:29,033:INFO:             fastapi: Not installed
2024-01-04 14:50:29,033:INFO:             uvicorn: Not installed
2024-01-04 14:50:29,033:INFO:              m2cgen: Not installed
2024-01-04 14:50:29,033:INFO:           evidently: Not installed
2024-01-04 14:50:29,033:INFO:               fugue: Not installed
2024-01-04 14:50:29,033:INFO:           streamlit: Not installed
2024-01-04 14:50:29,033:INFO:             prophet: Not installed
2024-01-04 14:50:29,033:INFO:None
2024-01-04 14:50:29,033:INFO:Set up data.
2024-01-04 14:50:29,067:INFO:Set up folding strategy.
2024-01-04 14:50:29,068:INFO:Set up train/test split.
2024-01-04 14:50:29,100:INFO:Set up index.
2024-01-04 14:50:29,101:INFO:Assigning column types.
2024-01-04 14:50:29,119:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-01-04 14:50:29,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-04 14:50:29,167:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:50:29,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-01-04 14:50:29,247:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:50:29,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,276:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-01-04 14:50:29,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:50:29,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-01-04 14:50:29,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,427:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,427:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-01-04 14:50:29,502:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,502:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:29,580:INFO:Preparing preprocessing pipeline...
2024-01-04 14:50:29,584:INFO:Set up simple imputation.
2024-01-04 14:50:29,587:INFO:Set up column name cleaning.
2024-01-04 14:50:29,720:INFO:Finished creating preprocessing pipeline.
2024-01-04 14:50:29,728:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\visha\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2024-01-04 14:50:29,728:INFO:Creating final display dataframe.
2024-01-04 14:50:30,113:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target        income_num
2                   Target type            Binary
3           Original data shape       (32561, 77)
4        Transformed data shape       (32561, 77)
5   Transformed train set shape       (26048, 77)
6    Transformed test set shape        (6513, 77)
7              Numeric features                76
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              0e3a
2024-01-04 14:50:30,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:30,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:30,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:30,272:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-01-04 14:50:30,272:INFO:setup() successfully completed in 1.93s...............
2024-01-04 14:50:30,310:INFO:Initializing compare_models()
2024-01-04 14:50:30,310:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-04 14:50:30,310:INFO:Checking exceptions
2024-01-04 14:50:30,335:INFO:Preparing display monitor
2024-01-04 14:50:30,368:INFO:Initializing Logistic Regression
2024-01-04 14:50:30,368:INFO:Total runtime is 0.0 minutes
2024-01-04 14:50:30,374:INFO:SubProcess create_model() called ==================================
2024-01-04 14:50:30,375:INFO:Initializing create_model()
2024-01-04 14:50:30,375:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:50:30,375:INFO:Checking exceptions
2024-01-04 14:50:30,375:INFO:Importing libraries
2024-01-04 14:50:30,375:INFO:Copying training dataset
2024-01-04 14:50:30,424:INFO:Defining folds
2024-01-04 14:50:30,424:INFO:Declaring metric variables
2024-01-04 14:50:30,428:INFO:Importing untrained model
2024-01-04 14:50:30,431:INFO:Logistic Regression Imported successfully
2024-01-04 14:50:30,439:INFO:Starting cross validation
2024-01-04 14:50:30,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:05,366:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,427:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,513:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,586:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,626:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,796:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,854:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,891:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:05,926:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:51:06,083:INFO:Calculating mean and std
2024-01-04 14:51:06,085:INFO:Creating metrics dataframe
2024-01-04 14:51:06,089:INFO:Uploading results into container
2024-01-04 14:51:06,091:INFO:Uploading model into container now
2024-01-04 14:51:06,092:INFO:_master_model_container: 1
2024-01-04 14:51:06,092:INFO:_display_container: 2
2024-01-04 14:51:06,093:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-04 14:51:06,093:INFO:create_model() successfully completed......................................
2024-01-04 14:51:06,274:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:06,274:INFO:Creating metrics dataframe
2024-01-04 14:51:06,283:INFO:Initializing K Neighbors Classifier
2024-01-04 14:51:06,283:INFO:Total runtime is 0.598596449693044 minutes
2024-01-04 14:51:06,287:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:06,287:INFO:Initializing create_model()
2024-01-04 14:51:06,287:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:06,287:INFO:Checking exceptions
2024-01-04 14:51:06,287:INFO:Importing libraries
2024-01-04 14:51:06,287:INFO:Copying training dataset
2024-01-04 14:51:06,326:INFO:Defining folds
2024-01-04 14:51:06,326:INFO:Declaring metric variables
2024-01-04 14:51:06,329:INFO:Importing untrained model
2024-01-04 14:51:06,333:INFO:K Neighbors Classifier Imported successfully
2024-01-04 14:51:06,339:INFO:Starting cross validation
2024-01-04 14:51:06,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:13,604:INFO:Calculating mean and std
2024-01-04 14:51:13,605:INFO:Creating metrics dataframe
2024-01-04 14:51:13,608:INFO:Uploading results into container
2024-01-04 14:51:13,610:INFO:Uploading model into container now
2024-01-04 14:51:13,610:INFO:_master_model_container: 2
2024-01-04 14:51:13,610:INFO:_display_container: 2
2024-01-04 14:51:13,610:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-04 14:51:13,610:INFO:create_model() successfully completed......................................
2024-01-04 14:51:13,748:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:13,748:INFO:Creating metrics dataframe
2024-01-04 14:51:13,756:INFO:Initializing Naive Bayes
2024-01-04 14:51:13,756:INFO:Total runtime is 0.7231435696283977 minutes
2024-01-04 14:51:13,759:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:13,759:INFO:Initializing create_model()
2024-01-04 14:51:13,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:13,759:INFO:Checking exceptions
2024-01-04 14:51:13,759:INFO:Importing libraries
2024-01-04 14:51:13,759:INFO:Copying training dataset
2024-01-04 14:51:13,796:INFO:Defining folds
2024-01-04 14:51:13,796:INFO:Declaring metric variables
2024-01-04 14:51:13,800:INFO:Importing untrained model
2024-01-04 14:51:13,803:INFO:Naive Bayes Imported successfully
2024-01-04 14:51:13,809:INFO:Starting cross validation
2024-01-04 14:51:13,810:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:14,976:INFO:Calculating mean and std
2024-01-04 14:51:14,979:INFO:Creating metrics dataframe
2024-01-04 14:51:14,983:INFO:Uploading results into container
2024-01-04 14:51:14,984:INFO:Uploading model into container now
2024-01-04 14:51:14,985:INFO:_master_model_container: 3
2024-01-04 14:51:14,985:INFO:_display_container: 2
2024-01-04 14:51:14,985:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-04 14:51:14,985:INFO:create_model() successfully completed......................................
2024-01-04 14:51:15,129:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:15,129:INFO:Creating metrics dataframe
2024-01-04 14:51:15,139:INFO:Initializing Decision Tree Classifier
2024-01-04 14:51:15,139:INFO:Total runtime is 0.7461870114008586 minutes
2024-01-04 14:51:15,142:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:15,143:INFO:Initializing create_model()
2024-01-04 14:51:15,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:15,143:INFO:Checking exceptions
2024-01-04 14:51:15,143:INFO:Importing libraries
2024-01-04 14:51:15,143:INFO:Copying training dataset
2024-01-04 14:51:15,181:INFO:Defining folds
2024-01-04 14:51:15,181:INFO:Declaring metric variables
2024-01-04 14:51:15,185:INFO:Importing untrained model
2024-01-04 14:51:15,189:INFO:Decision Tree Classifier Imported successfully
2024-01-04 14:51:15,196:INFO:Starting cross validation
2024-01-04 14:51:15,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:16,676:INFO:Calculating mean and std
2024-01-04 14:51:16,677:INFO:Creating metrics dataframe
2024-01-04 14:51:16,681:INFO:Uploading results into container
2024-01-04 14:51:16,682:INFO:Uploading model into container now
2024-01-04 14:51:16,682:INFO:_master_model_container: 4
2024-01-04 14:51:16,682:INFO:_display_container: 2
2024-01-04 14:51:16,683:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-04 14:51:16,683:INFO:create_model() successfully completed......................................
2024-01-04 14:51:16,828:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:16,828:INFO:Creating metrics dataframe
2024-01-04 14:51:16,838:INFO:Initializing SVM - Linear Kernel
2024-01-04 14:51:16,838:INFO:Total runtime is 0.7745061755180359 minutes
2024-01-04 14:51:16,842:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:16,842:INFO:Initializing create_model()
2024-01-04 14:51:16,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:16,842:INFO:Checking exceptions
2024-01-04 14:51:16,843:INFO:Importing libraries
2024-01-04 14:51:16,843:INFO:Copying training dataset
2024-01-04 14:51:16,880:INFO:Defining folds
2024-01-04 14:51:16,880:INFO:Declaring metric variables
2024-01-04 14:51:16,884:INFO:Importing untrained model
2024-01-04 14:51:16,887:INFO:SVM - Linear Kernel Imported successfully
2024-01-04 14:51:16,894:INFO:Starting cross validation
2024-01-04 14:51:16,896:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:17,968:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,198:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,245:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,300:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,316:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,346:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,348:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,385:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,398:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,455:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:51:18,575:INFO:Calculating mean and std
2024-01-04 14:51:18,577:INFO:Creating metrics dataframe
2024-01-04 14:51:18,580:INFO:Uploading results into container
2024-01-04 14:51:18,580:INFO:Uploading model into container now
2024-01-04 14:51:18,581:INFO:_master_model_container: 5
2024-01-04 14:51:18,581:INFO:_display_container: 2
2024-01-04 14:51:18,581:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-04 14:51:18,582:INFO:create_model() successfully completed......................................
2024-01-04 14:51:18,721:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:18,722:INFO:Creating metrics dataframe
2024-01-04 14:51:18,732:INFO:Initializing Ridge Classifier
2024-01-04 14:51:18,732:INFO:Total runtime is 0.8060694813728333 minutes
2024-01-04 14:51:18,735:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:18,736:INFO:Initializing create_model()
2024-01-04 14:51:18,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:18,736:INFO:Checking exceptions
2024-01-04 14:51:18,736:INFO:Importing libraries
2024-01-04 14:51:18,736:INFO:Copying training dataset
2024-01-04 14:51:18,772:INFO:Defining folds
2024-01-04 14:51:18,773:INFO:Declaring metric variables
2024-01-04 14:51:18,776:INFO:Importing untrained model
2024-01-04 14:51:18,779:INFO:Ridge Classifier Imported successfully
2024-01-04 14:51:18,785:INFO:Starting cross validation
2024-01-04 14:51:18,786:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:19,620:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,627:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,641:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,680:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,681:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,684:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,687:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,692:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,696:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:51:19,834:INFO:Calculating mean and std
2024-01-04 14:51:19,835:INFO:Creating metrics dataframe
2024-01-04 14:51:19,839:INFO:Uploading results into container
2024-01-04 14:51:19,840:INFO:Uploading model into container now
2024-01-04 14:51:19,840:INFO:_master_model_container: 6
2024-01-04 14:51:19,840:INFO:_display_container: 2
2024-01-04 14:51:19,841:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-04 14:51:19,841:INFO:create_model() successfully completed......................................
2024-01-04 14:51:20,053:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:20,054:INFO:Creating metrics dataframe
2024-01-04 14:51:20,065:INFO:Initializing Random Forest Classifier
2024-01-04 14:51:20,065:INFO:Total runtime is 0.8282991528511048 minutes
2024-01-04 14:51:20,070:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:20,070:INFO:Initializing create_model()
2024-01-04 14:51:20,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:20,071:INFO:Checking exceptions
2024-01-04 14:51:20,071:INFO:Importing libraries
2024-01-04 14:51:20,071:INFO:Copying training dataset
2024-01-04 14:51:20,117:INFO:Defining folds
2024-01-04 14:51:20,117:INFO:Declaring metric variables
2024-01-04 14:51:20,121:INFO:Importing untrained model
2024-01-04 14:51:20,125:INFO:Random Forest Classifier Imported successfully
2024-01-04 14:51:20,132:INFO:Starting cross validation
2024-01-04 14:51:20,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:27,889:INFO:Calculating mean and std
2024-01-04 14:51:27,890:INFO:Creating metrics dataframe
2024-01-04 14:51:27,894:INFO:Uploading results into container
2024-01-04 14:51:27,895:INFO:Uploading model into container now
2024-01-04 14:51:27,898:INFO:_master_model_container: 7
2024-01-04 14:51:27,899:INFO:_display_container: 2
2024-01-04 14:51:27,903:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-04 14:51:27,904:INFO:create_model() successfully completed......................................
2024-01-04 14:51:28,071:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:28,071:INFO:Creating metrics dataframe
2024-01-04 14:51:28,081:INFO:Initializing Quadratic Discriminant Analysis
2024-01-04 14:51:28,081:INFO:Total runtime is 0.9618869026501974 minutes
2024-01-04 14:51:28,084:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:28,084:INFO:Initializing create_model()
2024-01-04 14:51:28,084:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:28,084:INFO:Checking exceptions
2024-01-04 14:51:28,084:INFO:Importing libraries
2024-01-04 14:51:28,084:INFO:Copying training dataset
2024-01-04 14:51:28,121:INFO:Defining folds
2024-01-04 14:51:28,122:INFO:Declaring metric variables
2024-01-04 14:51:28,125:INFO:Importing untrained model
2024-01-04 14:51:28,129:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-04 14:51:28,136:INFO:Starting cross validation
2024-01-04 14:51:28,137:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:29,411:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,517:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,559:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,565:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,591:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,622:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,664:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,667:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:29,690:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:51:30,073:INFO:Calculating mean and std
2024-01-04 14:51:30,074:INFO:Creating metrics dataframe
2024-01-04 14:51:30,077:INFO:Uploading results into container
2024-01-04 14:51:30,078:INFO:Uploading model into container now
2024-01-04 14:51:30,078:INFO:_master_model_container: 8
2024-01-04 14:51:30,079:INFO:_display_container: 2
2024-01-04 14:51:30,079:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-04 14:51:30,079:INFO:create_model() successfully completed......................................
2024-01-04 14:51:30,223:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:30,223:INFO:Creating metrics dataframe
2024-01-04 14:51:30,233:INFO:Initializing Ada Boost Classifier
2024-01-04 14:51:30,233:INFO:Total runtime is 0.9977652033170065 minutes
2024-01-04 14:51:30,237:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:30,237:INFO:Initializing create_model()
2024-01-04 14:51:30,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:30,237:INFO:Checking exceptions
2024-01-04 14:51:30,237:INFO:Importing libraries
2024-01-04 14:51:30,237:INFO:Copying training dataset
2024-01-04 14:51:30,279:INFO:Defining folds
2024-01-04 14:51:30,280:INFO:Declaring metric variables
2024-01-04 14:51:30,283:INFO:Importing untrained model
2024-01-04 14:51:30,287:INFO:Ada Boost Classifier Imported successfully
2024-01-04 14:51:30,297:INFO:Starting cross validation
2024-01-04 14:51:30,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:36,188:INFO:Calculating mean and std
2024-01-04 14:51:36,190:INFO:Creating metrics dataframe
2024-01-04 14:51:36,192:INFO:Uploading results into container
2024-01-04 14:51:36,193:INFO:Uploading model into container now
2024-01-04 14:51:36,193:INFO:_master_model_container: 9
2024-01-04 14:51:36,193:INFO:_display_container: 2
2024-01-04 14:51:36,194:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-04 14:51:36,194:INFO:create_model() successfully completed......................................
2024-01-04 14:51:36,322:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:36,323:INFO:Creating metrics dataframe
2024-01-04 14:51:36,334:INFO:Initializing Gradient Boosting Classifier
2024-01-04 14:51:36,334:INFO:Total runtime is 1.0994415680567424 minutes
2024-01-04 14:51:36,337:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:36,337:INFO:Initializing create_model()
2024-01-04 14:51:36,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:36,337:INFO:Checking exceptions
2024-01-04 14:51:36,337:INFO:Importing libraries
2024-01-04 14:51:36,337:INFO:Copying training dataset
2024-01-04 14:51:36,374:INFO:Defining folds
2024-01-04 14:51:36,374:INFO:Declaring metric variables
2024-01-04 14:51:36,377:INFO:Importing untrained model
2024-01-04 14:51:36,381:INFO:Gradient Boosting Classifier Imported successfully
2024-01-04 14:51:36,386:INFO:Starting cross validation
2024-01-04 14:51:36,389:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:42,890:INFO:Calculating mean and std
2024-01-04 14:51:42,891:INFO:Creating metrics dataframe
2024-01-04 14:51:42,894:INFO:Uploading results into container
2024-01-04 14:51:42,895:INFO:Uploading model into container now
2024-01-04 14:51:42,895:INFO:_master_model_container: 10
2024-01-04 14:51:42,895:INFO:_display_container: 2
2024-01-04 14:51:42,896:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-04 14:51:42,896:INFO:create_model() successfully completed......................................
2024-01-04 14:51:43,019:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:43,019:INFO:Creating metrics dataframe
2024-01-04 14:51:43,029:INFO:Initializing Linear Discriminant Analysis
2024-01-04 14:51:43,029:INFO:Total runtime is 1.211026692390442 minutes
2024-01-04 14:51:43,033:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:43,033:INFO:Initializing create_model()
2024-01-04 14:51:43,033:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:43,033:INFO:Checking exceptions
2024-01-04 14:51:43,033:INFO:Importing libraries
2024-01-04 14:51:43,033:INFO:Copying training dataset
2024-01-04 14:51:43,069:INFO:Defining folds
2024-01-04 14:51:43,070:INFO:Declaring metric variables
2024-01-04 14:51:43,073:INFO:Importing untrained model
2024-01-04 14:51:43,076:INFO:Linear Discriminant Analysis Imported successfully
2024-01-04 14:51:43,083:INFO:Starting cross validation
2024-01-04 14:51:43,084:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:47,127:INFO:Calculating mean and std
2024-01-04 14:51:47,131:INFO:Creating metrics dataframe
2024-01-04 14:51:47,146:INFO:Uploading results into container
2024-01-04 14:51:47,150:INFO:Uploading model into container now
2024-01-04 14:51:47,151:INFO:_master_model_container: 11
2024-01-04 14:51:47,151:INFO:_display_container: 2
2024-01-04 14:51:47,152:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-04 14:51:47,153:INFO:create_model() successfully completed......................................
2024-01-04 14:51:47,301:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:47,301:INFO:Creating metrics dataframe
2024-01-04 14:51:47,312:INFO:Initializing Extra Trees Classifier
2024-01-04 14:51:47,313:INFO:Total runtime is 1.282416645685832 minutes
2024-01-04 14:51:47,316:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:47,316:INFO:Initializing create_model()
2024-01-04 14:51:47,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:47,316:INFO:Checking exceptions
2024-01-04 14:51:47,316:INFO:Importing libraries
2024-01-04 14:51:47,316:INFO:Copying training dataset
2024-01-04 14:51:47,355:INFO:Defining folds
2024-01-04 14:51:47,355:INFO:Declaring metric variables
2024-01-04 14:51:47,358:INFO:Importing untrained model
2024-01-04 14:51:47,362:INFO:Extra Trees Classifier Imported successfully
2024-01-04 14:51:47,368:INFO:Starting cross validation
2024-01-04 14:51:47,369:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:56,760:INFO:Calculating mean and std
2024-01-04 14:51:56,761:INFO:Creating metrics dataframe
2024-01-04 14:51:56,765:INFO:Uploading results into container
2024-01-04 14:51:56,766:INFO:Uploading model into container now
2024-01-04 14:51:56,767:INFO:_master_model_container: 12
2024-01-04 14:51:56,767:INFO:_display_container: 2
2024-01-04 14:51:56,768:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-04 14:51:56,768:INFO:create_model() successfully completed......................................
2024-01-04 14:51:56,957:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:56,958:INFO:Creating metrics dataframe
2024-01-04 14:51:56,969:INFO:Initializing Light Gradient Boosting Machine
2024-01-04 14:51:56,969:INFO:Total runtime is 1.443358866373698 minutes
2024-01-04 14:51:56,972:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:56,972:INFO:Initializing create_model()
2024-01-04 14:51:56,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:56,973:INFO:Checking exceptions
2024-01-04 14:51:56,973:INFO:Importing libraries
2024-01-04 14:51:56,973:INFO:Copying training dataset
2024-01-04 14:51:57,011:INFO:Defining folds
2024-01-04 14:51:57,011:INFO:Declaring metric variables
2024-01-04 14:51:57,016:INFO:Importing untrained model
2024-01-04 14:51:57,020:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:51:57,027:INFO:Starting cross validation
2024-01-04 14:51:57,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:51:59,307:INFO:Calculating mean and std
2024-01-04 14:51:59,309:INFO:Creating metrics dataframe
2024-01-04 14:51:59,312:INFO:Uploading results into container
2024-01-04 14:51:59,313:INFO:Uploading model into container now
2024-01-04 14:51:59,313:INFO:_master_model_container: 13
2024-01-04 14:51:59,313:INFO:_display_container: 2
2024-01-04 14:51:59,314:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:51:59,314:INFO:create_model() successfully completed......................................
2024-01-04 14:51:59,450:INFO:SubProcess create_model() end ==================================
2024-01-04 14:51:59,450:INFO:Creating metrics dataframe
2024-01-04 14:51:59,461:INFO:Initializing Dummy Classifier
2024-01-04 14:51:59,461:INFO:Total runtime is 1.4848904609680178 minutes
2024-01-04 14:51:59,464:INFO:SubProcess create_model() called ==================================
2024-01-04 14:51:59,464:INFO:Initializing create_model()
2024-01-04 14:51:59,464:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D100857040>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:51:59,464:INFO:Checking exceptions
2024-01-04 14:51:59,465:INFO:Importing libraries
2024-01-04 14:51:59,465:INFO:Copying training dataset
2024-01-04 14:51:59,502:INFO:Defining folds
2024-01-04 14:51:59,502:INFO:Declaring metric variables
2024-01-04 14:51:59,505:INFO:Importing untrained model
2024-01-04 14:51:59,508:INFO:Dummy Classifier Imported successfully
2024-01-04 14:51:59,515:INFO:Starting cross validation
2024-01-04 14:51:59,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:52:00,073:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,093:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,117:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,128:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,136:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,136:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,140:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,144:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,159:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:52:00,385:INFO:Calculating mean and std
2024-01-04 14:52:00,386:INFO:Creating metrics dataframe
2024-01-04 14:52:00,390:INFO:Uploading results into container
2024-01-04 14:52:00,391:INFO:Uploading model into container now
2024-01-04 14:52:00,391:INFO:_master_model_container: 14
2024-01-04 14:52:00,391:INFO:_display_container: 2
2024-01-04 14:52:00,391:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-04 14:52:00,391:INFO:create_model() successfully completed......................................
2024-01-04 14:52:00,517:INFO:SubProcess create_model() end ==================================
2024-01-04 14:52:00,517:INFO:Creating metrics dataframe
2024-01-04 14:52:00,537:INFO:Initializing create_model()
2024-01-04 14:52:00,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:52:00,537:INFO:Checking exceptions
2024-01-04 14:52:00,539:INFO:Importing libraries
2024-01-04 14:52:00,539:INFO:Copying training dataset
2024-01-04 14:52:00,580:INFO:Defining folds
2024-01-04 14:52:00,580:INFO:Declaring metric variables
2024-01-04 14:52:00,580:INFO:Importing untrained model
2024-01-04 14:52:00,581:INFO:Declaring custom model
2024-01-04 14:52:00,582:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:52:00,583:INFO:Cross validation set to False
2024-01-04 14:52:00,583:INFO:Fitting Model
2024-01-04 14:52:00,754:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:52:00,754:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:52:00,757:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000954 seconds.
2024-01-04 14:52:00,757:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:52:00,757:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:52:00,757:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 14:52:00,758:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-04 14:52:00,758:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:52:00,758:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:52:00,871:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:52:00,871:INFO:create_model() successfully completed......................................
2024-01-04 14:52:01,057:INFO:_master_model_container: 14
2024-01-04 14:52:01,057:INFO:_display_container: 2
2024-01-04 14:52:01,058:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:52:01,058:INFO:compare_models() successfully completed......................................
2024-01-04 14:52:01,371:INFO:Initializing plot_model()
2024-01-04 14:52:01,371:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 14:52:01,372:INFO:Checking exceptions
2024-01-04 14:52:01,391:INFO:Preloading libraries
2024-01-04 14:52:01,396:INFO:Copying training dataset
2024-01-04 14:52:01,396:INFO:Plot type: auc
2024-01-04 14:52:01,727:INFO:Fitting Model
2024-01-04 14:52:01,728:INFO:Scoring test/hold-out set
2024-01-04 14:52:02,041:INFO:Visual Rendered Successfully
2024-01-04 14:52:02,181:INFO:plot_model() successfully completed......................................
2024-01-04 14:52:02,229:INFO:Initializing plot_model()
2024-01-04 14:52:02,229:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 14:52:02,230:INFO:Checking exceptions
2024-01-04 14:52:02,247:INFO:Preloading libraries
2024-01-04 14:52:02,252:INFO:Copying training dataset
2024-01-04 14:52:02,252:INFO:Plot type: confusion_matrix
2024-01-04 14:52:02,603:INFO:Fitting Model
2024-01-04 14:52:02,604:INFO:Scoring test/hold-out set
2024-01-04 14:52:02,800:INFO:Visual Rendered Successfully
2024-01-04 14:52:02,933:INFO:plot_model() successfully completed......................................
2024-01-04 14:52:02,966:INFO:Initializing plot_model()
2024-01-04 14:52:02,966:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 14:52:02,967:INFO:Checking exceptions
2024-01-04 14:52:02,982:INFO:Preloading libraries
2024-01-04 14:52:02,987:INFO:Copying training dataset
2024-01-04 14:52:02,987:INFO:Plot type: class_report
2024-01-04 14:52:03,349:INFO:Fitting Model
2024-01-04 14:52:03,349:INFO:Scoring test/hold-out set
2024-01-04 14:52:03,651:INFO:Visual Rendered Successfully
2024-01-04 14:52:03,782:INFO:plot_model() successfully completed......................................
2024-01-04 14:52:03,823:INFO:Initializing tune_model()
2024-01-04 14:52:03,823:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 14:52:03,824:INFO:Checking exceptions
2024-01-04 14:52:03,862:INFO:Copying training dataset
2024-01-04 14:52:03,896:INFO:Checking base model
2024-01-04 14:52:03,896:INFO:Base model : Light Gradient Boosting Machine
2024-01-04 14:52:03,903:INFO:Declaring metric variables
2024-01-04 14:52:03,908:INFO:Defining Hyperparameters
2024-01-04 14:52:04,084:INFO:Tuning with n_jobs=-1
2024-01-04 14:52:04,084:INFO:Initializing RandomizedSearchCV
2024-01-04 14:52:34,180:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-04 14:52:34,183:INFO:Hyperparameter search completed
2024-01-04 14:52:34,184:INFO:SubProcess create_model() called ==================================
2024-01-04 14:52:34,185:INFO:Initializing create_model()
2024-01-04 14:52:34,185:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-04 14:52:34,185:INFO:Checking exceptions
2024-01-04 14:52:34,185:INFO:Importing libraries
2024-01-04 14:52:34,187:INFO:Copying training dataset
2024-01-04 14:52:34,250:INFO:Defining folds
2024-01-04 14:52:34,250:INFO:Declaring metric variables
2024-01-04 14:52:34,254:INFO:Importing untrained model
2024-01-04 14:52:34,254:INFO:Declaring custom model
2024-01-04 14:52:34,258:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:52:34,268:INFO:Starting cross validation
2024-01-04 14:52:34,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:52:37,615:INFO:Calculating mean and std
2024-01-04 14:52:37,617:INFO:Creating metrics dataframe
2024-01-04 14:52:37,623:INFO:Finalizing model
2024-01-04 14:52:37,781:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-04 14:52:37,781:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-04 14:52:37,781:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-04 14:52:37,800:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:52:37,800:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-04 14:52:37,800:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-04 14:52:37,801:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-04 14:52:37,801:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:52:37,804:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.
2024-01-04 14:52:37,804:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:52:37,804:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:52:37,804:INFO:[LightGBM] [Info] Total Bins 428
2024-01-04 14:52:37,804:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 53
2024-01-04 14:52:37,805:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:52:37,805:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:52:37,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,811:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,817:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,822:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,850:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,913:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,915:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,931:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,934:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,939:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,947:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,951:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:37,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,961:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,962:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,963:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,964:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,965:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:37,965:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,966:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,967:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,968:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,969:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,970:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,971:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,972:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,973:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,974:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,975:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,977:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,978:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,979:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,980:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:37,980:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,981:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,991:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,997:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:37,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:37,999:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,014:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,022:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,027:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,028:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,029:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,044:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,045:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,045:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:52:38,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,050:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:52:38,084:INFO:Uploading results into container
2024-01-04 14:52:38,086:INFO:Uploading model into container now
2024-01-04 14:52:38,086:INFO:_master_model_container: 15
2024-01-04 14:52:38,086:INFO:_display_container: 3
2024-01-04 14:52:38,087:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:52:38,088:INFO:create_model() successfully completed......................................
2024-01-04 14:52:38,262:INFO:SubProcess create_model() end ==================================
2024-01-04 14:52:38,262:INFO:choose_better activated
2024-01-04 14:52:38,266:INFO:SubProcess create_model() called ==================================
2024-01-04 14:52:38,267:INFO:Initializing create_model()
2024-01-04 14:52:38,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:52:38,267:INFO:Checking exceptions
2024-01-04 14:52:38,269:INFO:Importing libraries
2024-01-04 14:52:38,270:INFO:Copying training dataset
2024-01-04 14:52:38,312:INFO:Defining folds
2024-01-04 14:52:38,313:INFO:Declaring metric variables
2024-01-04 14:52:38,313:INFO:Importing untrained model
2024-01-04 14:52:38,313:INFO:Declaring custom model
2024-01-04 14:52:38,314:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:52:38,314:INFO:Starting cross validation
2024-01-04 14:52:38,315:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:52:40,536:INFO:Calculating mean and std
2024-01-04 14:52:40,538:INFO:Creating metrics dataframe
2024-01-04 14:52:40,543:INFO:Finalizing model
2024-01-04 14:52:40,678:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:52:40,678:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:52:40,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001735 seconds.
2024-01-04 14:52:40,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:52:40,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:52:40,683:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 14:52:40,683:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-04 14:52:40,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:52:40,684:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:52:40,799:INFO:Uploading results into container
2024-01-04 14:52:40,800:INFO:Uploading model into container now
2024-01-04 14:52:40,800:INFO:_master_model_container: 16
2024-01-04 14:52:40,800:INFO:_display_container: 4
2024-01-04 14:52:40,801:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:52:40,801:INFO:create_model() successfully completed......................................
2024-01-04 14:52:40,963:INFO:SubProcess create_model() end ==================================
2024-01-04 14:52:40,963:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8707
2024-01-04 14:52:40,963:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8695
2024-01-04 14:52:40,964:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-04 14:52:40,964:INFO:choose_better completed
2024-01-04 14:52:40,964:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-04 14:52:40,974:INFO:_master_model_container: 16
2024-01-04 14:52:40,974:INFO:_display_container: 3
2024-01-04 14:52:40,974:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:52:40,976:INFO:tune_model() successfully completed......................................
2024-01-04 14:52:41,454:INFO:Initializing plot_model()
2024-01-04 14:52:41,454:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 14:52:41,454:INFO:Checking exceptions
2024-01-04 14:52:41,474:INFO:Preloading libraries
2024-01-04 14:52:41,479:INFO:Copying training dataset
2024-01-04 14:52:41,480:INFO:Plot type: auc
2024-01-04 14:52:41,843:INFO:Fitting Model
2024-01-04 14:52:41,844:INFO:Scoring test/hold-out set
2024-01-04 14:52:42,183:INFO:Visual Rendered Successfully
2024-01-04 14:52:42,323:INFO:plot_model() successfully completed......................................
2024-01-04 14:52:42,361:INFO:Initializing plot_model()
2024-01-04 14:52:42,362:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 14:52:42,362:INFO:Checking exceptions
2024-01-04 14:52:42,382:INFO:Preloading libraries
2024-01-04 14:52:42,387:INFO:Copying training dataset
2024-01-04 14:52:42,387:INFO:Plot type: confusion_matrix
2024-01-04 14:52:42,744:INFO:Fitting Model
2024-01-04 14:52:42,744:INFO:Scoring test/hold-out set
2024-01-04 14:52:42,943:INFO:Visual Rendered Successfully
2024-01-04 14:52:43,084:INFO:plot_model() successfully completed......................................
2024-01-04 14:52:43,127:INFO:Initializing plot_model()
2024-01-04 14:52:43,127:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 14:52:43,127:INFO:Checking exceptions
2024-01-04 14:52:43,143:INFO:Preloading libraries
2024-01-04 14:52:43,149:INFO:Copying training dataset
2024-01-04 14:52:43,149:INFO:Plot type: class_report
2024-01-04 14:52:43,502:INFO:Fitting Model
2024-01-04 14:52:43,503:INFO:Scoring test/hold-out set
2024-01-04 14:52:43,809:INFO:Visual Rendered Successfully
2024-01-04 14:52:43,944:INFO:plot_model() successfully completed......................................
2024-01-04 14:52:43,974:INFO:Initializing finalize_model()
2024-01-04 14:52:43,974:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-04 14:52:43,975:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:52:43,996:INFO:Initializing create_model()
2024-01-04 14:52:43,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-04 14:52:43,996:INFO:Checking exceptions
2024-01-04 14:52:44,000:INFO:Importing libraries
2024-01-04 14:52:44,000:INFO:Copying training dataset
2024-01-04 14:52:44,002:INFO:Defining folds
2024-01-04 14:52:44,002:INFO:Declaring metric variables
2024-01-04 14:52:44,002:INFO:Importing untrained model
2024-01-04 14:52:44,002:INFO:Declaring custom model
2024-01-04 14:52:44,003:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:52:44,004:INFO:Cross validation set to False
2024-01-04 14:52:44,004:INFO:Fitting Model
2024-01-04 14:52:44,171:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:52:44,761:INFO:[LightGBM] [Info] Number of positive: 7841, number of negative: 24720
2024-01-04 14:52:44,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002079 seconds.
2024-01-04 14:52:44,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:52:44,766:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:52:44,766:INFO:[LightGBM] [Info] Total Bins 464
2024-01-04 14:52:44,766:INFO:[LightGBM] [Info] Number of data points in the train set: 32561, number of used features: 64
2024-01-04 14:52:44,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240810 -> initscore=-1.148246
2024-01-04 14:52:44,766:INFO:[LightGBM] [Info] Start training from score -1.148246
2024-01-04 14:52:44,883:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-04 14:52:44,883:INFO:create_model() successfully completed......................................
2024-01-04 14:52:45,080:INFO:_master_model_container: 16
2024-01-04 14:52:45,081:INFO:_display_container: 3
2024-01-04 14:52:45,090:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-04 14:52:45,090:INFO:finalize_model() successfully completed......................................
2024-01-04 14:52:45,338:INFO:Initializing predict_model()
2024-01-04 14:52:45,339:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D10BD16EF0>)
2024-01-04 14:52:45,339:INFO:Checking exceptions
2024-01-04 14:52:45,339:INFO:Preloading libraries
2024-01-04 14:52:45,341:INFO:Set up data.
2024-01-04 14:52:45,378:INFO:Set up index.
2024-01-04 14:54:35,887:INFO:Initializing compare_models()
2024-01-04 14:54:35,887:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-01-04 14:54:35,887:INFO:Checking exceptions
2024-01-04 14:54:35,901:INFO:Preparing display monitor
2024-01-04 14:54:35,930:INFO:Initializing Logistic Regression
2024-01-04 14:54:35,930:INFO:Total runtime is 0.0 minutes
2024-01-04 14:54:35,933:INFO:SubProcess create_model() called ==================================
2024-01-04 14:54:35,934:INFO:Initializing create_model()
2024-01-04 14:54:35,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:54:35,934:INFO:Checking exceptions
2024-01-04 14:54:35,934:INFO:Importing libraries
2024-01-04 14:54:35,934:INFO:Copying training dataset
2024-01-04 14:54:35,976:INFO:Defining folds
2024-01-04 14:54:35,976:INFO:Declaring metric variables
2024-01-04 14:54:35,981:INFO:Importing untrained model
2024-01-04 14:54:35,986:INFO:Logistic Regression Imported successfully
2024-01-04 14:54:35,993:INFO:Starting cross validation
2024-01-04 14:54:35,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:05,974:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,043:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,080:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,179:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,211:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,237:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,289:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,295:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,342:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 14:55:06,485:INFO:Calculating mean and std
2024-01-04 14:55:06,488:INFO:Creating metrics dataframe
2024-01-04 14:55:06,499:INFO:Uploading results into container
2024-01-04 14:55:06,500:INFO:Uploading model into container now
2024-01-04 14:55:06,501:INFO:_master_model_container: 17
2024-01-04 14:55:06,501:INFO:_display_container: 5
2024-01-04 14:55:06,502:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-04 14:55:06,502:INFO:create_model() successfully completed......................................
2024-01-04 14:55:06,667:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:06,667:INFO:Creating metrics dataframe
2024-01-04 14:55:06,674:INFO:Initializing K Neighbors Classifier
2024-01-04 14:55:06,674:INFO:Total runtime is 0.5124045332272847 minutes
2024-01-04 14:55:06,678:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:06,678:INFO:Initializing create_model()
2024-01-04 14:55:06,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:06,678:INFO:Checking exceptions
2024-01-04 14:55:06,678:INFO:Importing libraries
2024-01-04 14:55:06,678:INFO:Copying training dataset
2024-01-04 14:55:06,714:INFO:Defining folds
2024-01-04 14:55:06,714:INFO:Declaring metric variables
2024-01-04 14:55:06,718:INFO:Importing untrained model
2024-01-04 14:55:06,721:INFO:K Neighbors Classifier Imported successfully
2024-01-04 14:55:06,727:INFO:Starting cross validation
2024-01-04 14:55:06,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:09,805:INFO:Calculating mean and std
2024-01-04 14:55:09,806:INFO:Creating metrics dataframe
2024-01-04 14:55:09,810:INFO:Uploading results into container
2024-01-04 14:55:09,811:INFO:Uploading model into container now
2024-01-04 14:55:09,811:INFO:_master_model_container: 18
2024-01-04 14:55:09,811:INFO:_display_container: 5
2024-01-04 14:55:09,812:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-01-04 14:55:09,812:INFO:create_model() successfully completed......................................
2024-01-04 14:55:09,999:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:10,000:INFO:Creating metrics dataframe
2024-01-04 14:55:10,025:INFO:Initializing Naive Bayes
2024-01-04 14:55:10,025:INFO:Total runtime is 0.5682435830434164 minutes
2024-01-04 14:55:10,028:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:10,028:INFO:Initializing create_model()
2024-01-04 14:55:10,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:10,028:INFO:Checking exceptions
2024-01-04 14:55:10,028:INFO:Importing libraries
2024-01-04 14:55:10,029:INFO:Copying training dataset
2024-01-04 14:55:10,068:INFO:Defining folds
2024-01-04 14:55:10,068:INFO:Declaring metric variables
2024-01-04 14:55:10,071:INFO:Importing untrained model
2024-01-04 14:55:10,075:INFO:Naive Bayes Imported successfully
2024-01-04 14:55:10,081:INFO:Starting cross validation
2024-01-04 14:55:10,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:11,218:INFO:Calculating mean and std
2024-01-04 14:55:11,219:INFO:Creating metrics dataframe
2024-01-04 14:55:11,223:INFO:Uploading results into container
2024-01-04 14:55:11,224:INFO:Uploading model into container now
2024-01-04 14:55:11,225:INFO:_master_model_container: 19
2024-01-04 14:55:11,225:INFO:_display_container: 5
2024-01-04 14:55:11,225:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-01-04 14:55:11,225:INFO:create_model() successfully completed......................................
2024-01-04 14:55:11,389:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:11,389:INFO:Creating metrics dataframe
2024-01-04 14:55:11,398:INFO:Initializing Decision Tree Classifier
2024-01-04 14:55:11,398:INFO:Total runtime is 0.5911257942517599 minutes
2024-01-04 14:55:11,401:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:11,402:INFO:Initializing create_model()
2024-01-04 14:55:11,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:11,402:INFO:Checking exceptions
2024-01-04 14:55:11,402:INFO:Importing libraries
2024-01-04 14:55:11,402:INFO:Copying training dataset
2024-01-04 14:55:11,441:INFO:Defining folds
2024-01-04 14:55:11,441:INFO:Declaring metric variables
2024-01-04 14:55:11,445:INFO:Importing untrained model
2024-01-04 14:55:11,448:INFO:Decision Tree Classifier Imported successfully
2024-01-04 14:55:11,455:INFO:Starting cross validation
2024-01-04 14:55:11,456:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:12,759:INFO:Calculating mean and std
2024-01-04 14:55:12,762:INFO:Creating metrics dataframe
2024-01-04 14:55:12,776:INFO:Uploading results into container
2024-01-04 14:55:12,777:INFO:Uploading model into container now
2024-01-04 14:55:12,778:INFO:_master_model_container: 20
2024-01-04 14:55:12,779:INFO:_display_container: 5
2024-01-04 14:55:12,780:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2024-01-04 14:55:12,780:INFO:create_model() successfully completed......................................
2024-01-04 14:55:12,944:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:12,944:INFO:Creating metrics dataframe
2024-01-04 14:55:12,953:INFO:Initializing SVM - Linear Kernel
2024-01-04 14:55:12,953:INFO:Total runtime is 0.6170425812403362 minutes
2024-01-04 14:55:12,956:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:12,956:INFO:Initializing create_model()
2024-01-04 14:55:12,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:12,956:INFO:Checking exceptions
2024-01-04 14:55:12,956:INFO:Importing libraries
2024-01-04 14:55:12,956:INFO:Copying training dataset
2024-01-04 14:55:12,992:INFO:Defining folds
2024-01-04 14:55:12,993:INFO:Declaring metric variables
2024-01-04 14:55:12,996:INFO:Importing untrained model
2024-01-04 14:55:13,000:INFO:SVM - Linear Kernel Imported successfully
2024-01-04 14:55:13,009:INFO:Starting cross validation
2024-01-04 14:55:13,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:14,077:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,316:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,381:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,382:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,408:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,433:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,565:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,514:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1236, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-01-04 14:55:14,706:INFO:Calculating mean and std
2024-01-04 14:55:14,707:INFO:Creating metrics dataframe
2024-01-04 14:55:14,710:INFO:Uploading results into container
2024-01-04 14:55:14,711:INFO:Uploading model into container now
2024-01-04 14:55:14,711:INFO:_master_model_container: 21
2024-01-04 14:55:14,711:INFO:_display_container: 5
2024-01-04 14:55:14,712:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-01-04 14:55:14,712:INFO:create_model() successfully completed......................................
2024-01-04 14:55:14,879:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:14,879:INFO:Creating metrics dataframe
2024-01-04 14:55:14,889:INFO:Initializing Ridge Classifier
2024-01-04 14:55:14,889:INFO:Total runtime is 0.6493204832077027 minutes
2024-01-04 14:55:14,892:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:14,892:INFO:Initializing create_model()
2024-01-04 14:55:14,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:14,892:INFO:Checking exceptions
2024-01-04 14:55:14,892:INFO:Importing libraries
2024-01-04 14:55:14,892:INFO:Copying training dataset
2024-01-04 14:55:14,933:INFO:Defining folds
2024-01-04 14:55:14,933:INFO:Declaring metric variables
2024-01-04 14:55:14,936:INFO:Importing untrained model
2024-01-04 14:55:14,940:INFO:Ridge Classifier Imported successfully
2024-01-04 14:55:14,946:INFO:Starting cross validation
2024-01-04 14:55:14,948:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:15,818:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,836:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,836:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,852:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,863:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,863:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,878:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,881:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,884:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:15,885:WARNING:c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\visha\anaconda3\lib\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-01-04 14:55:16,014:INFO:Calculating mean and std
2024-01-04 14:55:16,018:INFO:Creating metrics dataframe
2024-01-04 14:55:16,024:INFO:Uploading results into container
2024-01-04 14:55:16,024:INFO:Uploading model into container now
2024-01-04 14:55:16,025:INFO:_master_model_container: 22
2024-01-04 14:55:16,025:INFO:_display_container: 5
2024-01-04 14:55:16,025:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2024-01-04 14:55:16,025:INFO:create_model() successfully completed......................................
2024-01-04 14:55:16,245:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:16,246:INFO:Creating metrics dataframe
2024-01-04 14:55:16,255:INFO:Initializing Random Forest Classifier
2024-01-04 14:55:16,255:INFO:Total runtime is 0.672088114420573 minutes
2024-01-04 14:55:16,259:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:16,259:INFO:Initializing create_model()
2024-01-04 14:55:16,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:16,259:INFO:Checking exceptions
2024-01-04 14:55:16,259:INFO:Importing libraries
2024-01-04 14:55:16,259:INFO:Copying training dataset
2024-01-04 14:55:16,308:INFO:Defining folds
2024-01-04 14:55:16,308:INFO:Declaring metric variables
2024-01-04 14:55:16,311:INFO:Importing untrained model
2024-01-04 14:55:16,315:INFO:Random Forest Classifier Imported successfully
2024-01-04 14:55:16,322:INFO:Starting cross validation
2024-01-04 14:55:16,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:23,130:INFO:Calculating mean and std
2024-01-04 14:55:23,133:INFO:Creating metrics dataframe
2024-01-04 14:55:23,141:INFO:Uploading results into container
2024-01-04 14:55:23,144:INFO:Uploading model into container now
2024-01-04 14:55:23,146:INFO:_master_model_container: 23
2024-01-04 14:55:23,146:INFO:_display_container: 5
2024-01-04 14:55:23,148:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2024-01-04 14:55:23,148:INFO:create_model() successfully completed......................................
2024-01-04 14:55:23,330:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:23,330:INFO:Creating metrics dataframe
2024-01-04 14:55:23,341:INFO:Initializing Quadratic Discriminant Analysis
2024-01-04 14:55:23,341:INFO:Total runtime is 0.7901846607526144 minutes
2024-01-04 14:55:23,344:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:23,344:INFO:Initializing create_model()
2024-01-04 14:55:23,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:23,345:INFO:Checking exceptions
2024-01-04 14:55:23,345:INFO:Importing libraries
2024-01-04 14:55:23,345:INFO:Copying training dataset
2024-01-04 14:55:23,382:INFO:Defining folds
2024-01-04 14:55:23,383:INFO:Declaring metric variables
2024-01-04 14:55:23,387:INFO:Importing untrained model
2024-01-04 14:55:23,391:INFO:Quadratic Discriminant Analysis Imported successfully
2024-01-04 14:55:23,398:INFO:Starting cross validation
2024-01-04 14:55:23,399:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:24,729:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,765:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,814:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,857:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,883:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,902:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,906:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,927:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,949:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:24,955:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-01-04 14:55:25,353:INFO:Calculating mean and std
2024-01-04 14:55:25,355:INFO:Creating metrics dataframe
2024-01-04 14:55:25,358:INFO:Uploading results into container
2024-01-04 14:55:25,359:INFO:Uploading model into container now
2024-01-04 14:55:25,359:INFO:_master_model_container: 24
2024-01-04 14:55:25,360:INFO:_display_container: 5
2024-01-04 14:55:25,360:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-01-04 14:55:25,360:INFO:create_model() successfully completed......................................
2024-01-04 14:55:25,559:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:25,559:INFO:Creating metrics dataframe
2024-01-04 14:55:25,570:INFO:Initializing Ada Boost Classifier
2024-01-04 14:55:25,570:INFO:Total runtime is 0.8273303469022115 minutes
2024-01-04 14:55:25,574:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:25,574:INFO:Initializing create_model()
2024-01-04 14:55:25,574:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:25,574:INFO:Checking exceptions
2024-01-04 14:55:25,574:INFO:Importing libraries
2024-01-04 14:55:25,574:INFO:Copying training dataset
2024-01-04 14:55:25,622:INFO:Defining folds
2024-01-04 14:55:25,622:INFO:Declaring metric variables
2024-01-04 14:55:25,626:INFO:Importing untrained model
2024-01-04 14:55:25,630:INFO:Ada Boost Classifier Imported successfully
2024-01-04 14:55:25,638:INFO:Starting cross validation
2024-01-04 14:55:25,640:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:31,420:INFO:Calculating mean and std
2024-01-04 14:55:31,424:INFO:Creating metrics dataframe
2024-01-04 14:55:31,434:INFO:Uploading results into container
2024-01-04 14:55:31,434:INFO:Uploading model into container now
2024-01-04 14:55:31,435:INFO:_master_model_container: 25
2024-01-04 14:55:31,435:INFO:_display_container: 5
2024-01-04 14:55:31,435:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2024-01-04 14:55:31,435:INFO:create_model() successfully completed......................................
2024-01-04 14:55:31,608:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:31,608:INFO:Creating metrics dataframe
2024-01-04 14:55:31,619:INFO:Initializing Gradient Boosting Classifier
2024-01-04 14:55:31,619:INFO:Total runtime is 0.9281408429145813 minutes
2024-01-04 14:55:31,623:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:31,623:INFO:Initializing create_model()
2024-01-04 14:55:31,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:31,623:INFO:Checking exceptions
2024-01-04 14:55:31,624:INFO:Importing libraries
2024-01-04 14:55:31,624:INFO:Copying training dataset
2024-01-04 14:55:31,677:INFO:Defining folds
2024-01-04 14:55:31,677:INFO:Declaring metric variables
2024-01-04 14:55:31,680:INFO:Importing untrained model
2024-01-04 14:55:31,684:INFO:Gradient Boosting Classifier Imported successfully
2024-01-04 14:55:31,692:INFO:Starting cross validation
2024-01-04 14:55:31,693:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:38,172:INFO:Calculating mean and std
2024-01-04 14:55:38,174:INFO:Creating metrics dataframe
2024-01-04 14:55:38,177:INFO:Uploading results into container
2024-01-04 14:55:38,178:INFO:Uploading model into container now
2024-01-04 14:55:38,178:INFO:_master_model_container: 26
2024-01-04 14:55:38,178:INFO:_display_container: 5
2024-01-04 14:55:38,179:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-01-04 14:55:38,179:INFO:create_model() successfully completed......................................
2024-01-04 14:55:38,343:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:38,343:INFO:Creating metrics dataframe
2024-01-04 14:55:38,353:INFO:Initializing Linear Discriminant Analysis
2024-01-04 14:55:38,353:INFO:Total runtime is 1.040376647313436 minutes
2024-01-04 14:55:38,357:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:38,357:INFO:Initializing create_model()
2024-01-04 14:55:38,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:38,357:INFO:Checking exceptions
2024-01-04 14:55:38,357:INFO:Importing libraries
2024-01-04 14:55:38,357:INFO:Copying training dataset
2024-01-04 14:55:38,399:INFO:Defining folds
2024-01-04 14:55:38,399:INFO:Declaring metric variables
2024-01-04 14:55:38,404:INFO:Importing untrained model
2024-01-04 14:55:38,408:INFO:Linear Discriminant Analysis Imported successfully
2024-01-04 14:55:38,416:INFO:Starting cross validation
2024-01-04 14:55:38,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:42,493:INFO:Calculating mean and std
2024-01-04 14:55:42,494:INFO:Creating metrics dataframe
2024-01-04 14:55:42,498:INFO:Uploading results into container
2024-01-04 14:55:42,499:INFO:Uploading model into container now
2024-01-04 14:55:42,500:INFO:_master_model_container: 27
2024-01-04 14:55:42,500:INFO:_display_container: 5
2024-01-04 14:55:42,500:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-01-04 14:55:42,500:INFO:create_model() successfully completed......................................
2024-01-04 14:55:42,672:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:42,672:INFO:Creating metrics dataframe
2024-01-04 14:55:42,683:INFO:Initializing Extra Trees Classifier
2024-01-04 14:55:42,683:INFO:Total runtime is 1.11254643201828 minutes
2024-01-04 14:55:42,686:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:42,686:INFO:Initializing create_model()
2024-01-04 14:55:42,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:42,686:INFO:Checking exceptions
2024-01-04 14:55:42,687:INFO:Importing libraries
2024-01-04 14:55:42,687:INFO:Copying training dataset
2024-01-04 14:55:42,723:INFO:Defining folds
2024-01-04 14:55:42,723:INFO:Declaring metric variables
2024-01-04 14:55:42,727:INFO:Importing untrained model
2024-01-04 14:55:42,731:INFO:Extra Trees Classifier Imported successfully
2024-01-04 14:55:42,738:INFO:Starting cross validation
2024-01-04 14:55:42,739:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:52,037:INFO:Calculating mean and std
2024-01-04 14:55:52,040:INFO:Creating metrics dataframe
2024-01-04 14:55:52,043:INFO:Uploading results into container
2024-01-04 14:55:52,044:INFO:Uploading model into container now
2024-01-04 14:55:52,044:INFO:_master_model_container: 28
2024-01-04 14:55:52,044:INFO:_display_container: 5
2024-01-04 14:55:52,045:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2024-01-04 14:55:52,045:INFO:create_model() successfully completed......................................
2024-01-04 14:55:52,274:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:52,274:INFO:Creating metrics dataframe
2024-01-04 14:55:52,286:INFO:Initializing Light Gradient Boosting Machine
2024-01-04 14:55:52,286:INFO:Total runtime is 1.272598946094513 minutes
2024-01-04 14:55:52,290:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:52,290:INFO:Initializing create_model()
2024-01-04 14:55:52,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:52,290:INFO:Checking exceptions
2024-01-04 14:55:52,290:INFO:Importing libraries
2024-01-04 14:55:52,290:INFO:Copying training dataset
2024-01-04 14:55:52,330:INFO:Defining folds
2024-01-04 14:55:52,330:INFO:Declaring metric variables
2024-01-04 14:55:52,334:INFO:Importing untrained model
2024-01-04 14:55:52,338:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:55:52,344:INFO:Starting cross validation
2024-01-04 14:55:52,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:54,583:INFO:Calculating mean and std
2024-01-04 14:55:54,585:INFO:Creating metrics dataframe
2024-01-04 14:55:54,589:INFO:Uploading results into container
2024-01-04 14:55:54,589:INFO:Uploading model into container now
2024-01-04 14:55:54,590:INFO:_master_model_container: 29
2024-01-04 14:55:54,590:INFO:_display_container: 5
2024-01-04 14:55:54,591:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:55:54,591:INFO:create_model() successfully completed......................................
2024-01-04 14:55:54,774:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:54,774:INFO:Creating metrics dataframe
2024-01-04 14:55:54,786:INFO:Initializing Dummy Classifier
2024-01-04 14:55:54,786:INFO:Total runtime is 1.3142652551333112 minutes
2024-01-04 14:55:54,789:INFO:SubProcess create_model() called ==================================
2024-01-04 14:55:54,789:INFO:Initializing create_model()
2024-01-04 14:55:54,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D10242FEB0>, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:54,789:INFO:Checking exceptions
2024-01-04 14:55:54,789:INFO:Importing libraries
2024-01-04 14:55:54,789:INFO:Copying training dataset
2024-01-04 14:55:54,829:INFO:Defining folds
2024-01-04 14:55:54,829:INFO:Declaring metric variables
2024-01-04 14:55:54,833:INFO:Importing untrained model
2024-01-04 14:55:54,837:INFO:Dummy Classifier Imported successfully
2024-01-04 14:55:54,844:INFO:Starting cross validation
2024-01-04 14:55:54,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:55:55,386:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,396:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,411:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,422:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,426:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,457:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,477:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,481:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,487:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,496:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-01-04 14:55:55,618:INFO:Calculating mean and std
2024-01-04 14:55:55,622:INFO:Creating metrics dataframe
2024-01-04 14:55:55,634:INFO:Uploading results into container
2024-01-04 14:55:55,635:INFO:Uploading model into container now
2024-01-04 14:55:55,636:INFO:_master_model_container: 30
2024-01-04 14:55:55,636:INFO:_display_container: 5
2024-01-04 14:55:55,636:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2024-01-04 14:55:55,637:INFO:create_model() successfully completed......................................
2024-01-04 14:55:55,799:INFO:SubProcess create_model() end ==================================
2024-01-04 14:55:55,799:INFO:Creating metrics dataframe
2024-01-04 14:55:55,819:INFO:Initializing create_model()
2024-01-04 14:55:55,819:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:55:55,820:INFO:Checking exceptions
2024-01-04 14:55:55,821:INFO:Importing libraries
2024-01-04 14:55:55,821:INFO:Copying training dataset
2024-01-04 14:55:55,859:INFO:Defining folds
2024-01-04 14:55:55,860:INFO:Declaring metric variables
2024-01-04 14:55:55,860:INFO:Importing untrained model
2024-01-04 14:55:55,860:INFO:Declaring custom model
2024-01-04 14:55:55,861:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:55:55,862:INFO:Cross validation set to False
2024-01-04 14:55:55,862:INFO:Fitting Model
2024-01-04 14:55:55,966:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:55:55,967:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:55:55,969:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000959 seconds.
2024-01-04 14:55:55,969:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:55:55,969:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:55:55,969:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 14:55:55,970:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-04 14:55:55,970:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:55:55,970:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:55:56,075:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:55:56,075:INFO:create_model() successfully completed......................................
2024-01-04 14:55:56,291:INFO:_master_model_container: 30
2024-01-04 14:55:56,292:INFO:_display_container: 5
2024-01-04 14:55:56,292:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:55:56,292:INFO:compare_models() successfully completed......................................
2024-01-04 14:55:56,471:INFO:Initializing tune_model()
2024-01-04 14:55:56,471:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 14:55:56,472:INFO:Checking exceptions
2024-01-04 14:55:56,508:INFO:Copying training dataset
2024-01-04 14:55:56,536:INFO:Checking base model
2024-01-04 14:55:56,536:INFO:Base model : Light Gradient Boosting Machine
2024-01-04 14:55:56,540:INFO:Declaring metric variables
2024-01-04 14:55:56,544:INFO:Defining Hyperparameters
2024-01-04 14:55:56,796:INFO:Tuning with n_jobs=-1
2024-01-04 14:55:56,796:INFO:Initializing RandomizedSearchCV
2024-01-04 14:56:26,990:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-01-04 14:56:26,994:INFO:Hyperparameter search completed
2024-01-04 14:56:26,996:INFO:SubProcess create_model() called ==================================
2024-01-04 14:56:26,998:INFO:Initializing create_model()
2024-01-04 14:56:26,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D1024FADA0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-01-04 14:56:26,998:INFO:Checking exceptions
2024-01-04 14:56:26,999:INFO:Importing libraries
2024-01-04 14:56:26,999:INFO:Copying training dataset
2024-01-04 14:56:27,046:INFO:Defining folds
2024-01-04 14:56:27,046:INFO:Declaring metric variables
2024-01-04 14:56:27,050:INFO:Importing untrained model
2024-01-04 14:56:27,050:INFO:Declaring custom model
2024-01-04 14:56:27,054:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:56:27,060:INFO:Starting cross validation
2024-01-04 14:56:27,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:56:30,347:INFO:Calculating mean and std
2024-01-04 14:56:30,348:INFO:Creating metrics dataframe
2024-01-04 14:56:30,354:INFO:Finalizing model
2024-01-04 14:56:30,485:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-04 14:56:30,485:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-04 14:56:30,485:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-04 14:56:30,509:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:56:30,510:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-01-04 14:56:30,510:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-01-04 14:56:30,510:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-01-04 14:56:30,510:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:56:30,515:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001555 seconds.
2024-01-04 14:56:30,515:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:56:30,515:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:56:30,515:INFO:[LightGBM] [Info] Total Bins 428
2024-01-04 14:56:30,515:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 53
2024-01-04 14:56:30,516:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:56:30,516:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:56:30,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,554:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,565:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,568:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,571:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,573:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,576:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,584:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,673:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,674:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,676:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,678:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,679:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,681:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,682:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,683:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,684:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,687:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,688:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,690:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,691:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,693:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,694:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,695:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,696:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,697:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,698:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,699:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,701:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,703:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,704:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,705:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,706:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,708:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,710:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,716:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,721:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,731:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,733:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,741:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,754:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,756:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,771:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,777:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,785:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,786:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,787:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,788:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,789:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,790:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,791:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,792:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,793:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,794:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,796:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,797:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,798:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,799:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,800:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,801:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,802:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,803:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,806:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,807:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,808:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,809:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,810:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,810:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,812:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,813:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,814:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,814:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,815:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,815:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,816:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,816:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,818:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,819:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,820:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,821:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,832:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,833:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,835:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,836:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-01-04 14:56:30,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,843:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-01-04 14:56:30,871:INFO:Uploading results into container
2024-01-04 14:56:30,873:INFO:Uploading model into container now
2024-01-04 14:56:30,874:INFO:_master_model_container: 31
2024-01-04 14:56:30,875:INFO:_display_container: 6
2024-01-04 14:56:30,875:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:56:30,876:INFO:create_model() successfully completed......................................
2024-01-04 14:56:31,084:INFO:SubProcess create_model() end ==================================
2024-01-04 14:56:31,084:INFO:choose_better activated
2024-01-04 14:56:31,086:INFO:SubProcess create_model() called ==================================
2024-01-04 14:56:31,087:INFO:Initializing create_model()
2024-01-04 14:56:31,087:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 14:56:31,087:INFO:Checking exceptions
2024-01-04 14:56:31,088:INFO:Importing libraries
2024-01-04 14:56:31,089:INFO:Copying training dataset
2024-01-04 14:56:31,126:INFO:Defining folds
2024-01-04 14:56:31,126:INFO:Declaring metric variables
2024-01-04 14:56:31,126:INFO:Importing untrained model
2024-01-04 14:56:31,127:INFO:Declaring custom model
2024-01-04 14:56:31,127:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 14:56:31,127:INFO:Starting cross validation
2024-01-04 14:56:31,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 14:56:33,487:INFO:Calculating mean and std
2024-01-04 14:56:33,488:INFO:Creating metrics dataframe
2024-01-04 14:56:33,490:INFO:Finalizing model
2024-01-04 14:56:33,670:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 14:56:33,670:INFO:[LightGBM] [Info] Number of positive: 6273, number of negative: 19775
2024-01-04 14:56:33,674:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001565 seconds.
2024-01-04 14:56:33,675:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 14:56:33,675:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 14:56:33,675:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 14:56:33,675:INFO:[LightGBM] [Info] Number of data points in the train set: 26048, number of used features: 61
2024-01-04 14:56:33,675:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240825 -> initscore=-1.148164
2024-01-04 14:56:33,675:INFO:[LightGBM] [Info] Start training from score -1.148164
2024-01-04 14:56:33,791:INFO:Uploading results into container
2024-01-04 14:56:33,792:INFO:Uploading model into container now
2024-01-04 14:56:33,792:INFO:_master_model_container: 32
2024-01-04 14:56:33,792:INFO:_display_container: 7
2024-01-04 14:56:33,793:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:56:33,793:INFO:create_model() successfully completed......................................
2024-01-04 14:56:33,988:INFO:SubProcess create_model() end ==================================
2024-01-04 14:56:33,988:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8707
2024-01-04 14:56:33,989:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=41, min_child_weight=0.001, min_split_gain=0.9,
               n_estimators=260, n_jobs=-1, num_leaves=70, objective=None,
               random_state=123, reg_alpha=2, reg_lambda=3, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.8695
2024-01-04 14:56:33,989:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2024-01-04 14:56:33,989:INFO:choose_better completed
2024-01-04 14:56:33,989:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-01-04 14:56:33,999:INFO:_master_model_container: 32
2024-01-04 14:56:33,999:INFO:_display_container: 6
2024-01-04 14:56:34,000:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 14:56:34,000:INFO:tune_model() successfully completed......................................
2024-01-04 14:57:12,708:INFO:Initializing tune_model()
2024-01-04 14:57:12,708:INFO:tune_model(estimator=lr, fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 14:57:12,708:INFO:Checking exceptions
2024-01-04 15:01:18,008:INFO:Initializing tune_model()
2024-01-04 15:01:18,008:INFO:tune_model(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, positive=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 15:01:18,008:INFO:Checking exceptions
2024-01-04 15:01:18,039:INFO:Copying training dataset
2024-01-04 15:01:18,072:INFO:Checking base model
2024-01-04 15:03:21,682:INFO:Initializing tune_model()
2024-01-04 15:03:21,682:INFO:tune_model(estimator=LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, positive=False), fold=None, round=4, n_iter=10, custom_grid={'fit_intercept': [True, False], 'normalize': [True, False]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 15:03:21,682:INFO:Checking exceptions
2024-01-04 15:03:21,716:INFO:Copying training dataset
2024-01-04 15:03:21,746:INFO:Checking base model
2024-01-04 15:03:21,746:INFO:A custom model has been passed
2024-01-04 15:03:21,747:INFO:Base model : LinearRegression
2024-01-04 15:03:21,752:INFO:Declaring metric variables
2024-01-04 15:03:21,756:INFO:Defining Hyperparameters
2024-01-04 15:03:22,059:INFO:custom_grid: {'actual_estimator__fit_intercept': [True, False], 'actual_estimator__normalize': [True, False]}
2024-01-04 15:03:22,060:INFO:Tuning with n_jobs=-1
2024-01-04 15:03:22,060:INFO:Initializing RandomizedSearchCV
2024-01-04 15:04:29,728:INFO:Initializing tune_model()
2024-01-04 15:04:29,728:INFO:tune_model(estimator=lr, fold=None, round=4, n_iter=10, custom_grid={'fit_intercept': [True, False], 'normalize': [True, False]}, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 15:04:29,729:INFO:Checking exceptions
2024-01-04 15:05:13,318:INFO:Initializing create_model()
2024-01-04 15:05:13,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=lr, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-01-04 15:05:13,318:INFO:Checking exceptions
2024-01-04 15:05:13,341:INFO:Importing libraries
2024-01-04 15:05:13,342:INFO:Copying training dataset
2024-01-04 15:05:13,407:INFO:Defining folds
2024-01-04 15:05:13,408:INFO:Declaring metric variables
2024-01-04 15:05:13,416:INFO:Importing untrained model
2024-01-04 15:05:13,424:INFO:Logistic Regression Imported successfully
2024-01-04 15:05:13,441:INFO:Starting cross validation
2024-01-04 15:05:13,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-01-04 15:05:52,580:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:52,704:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:52,790:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:52,806:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:53,064:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:53,150:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:53,150:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:53,206:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:53,220:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:05:53,388:INFO:Calculating mean and std
2024-01-04 15:05:53,390:INFO:Creating metrics dataframe
2024-01-04 15:05:53,398:INFO:Finalizing model
2024-01-04 15:05:57,472:INFO:Uploading results into container
2024-01-04 15:05:57,473:INFO:Uploading model into container now
2024-01-04 15:05:57,487:INFO:_master_model_container: 33
2024-01-04 15:05:57,488:INFO:_display_container: 7
2024-01-04 15:05:57,489:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-01-04 15:05:57,489:INFO:create_model() successfully completed......................................
2024-01-04 15:05:57,774:INFO:Initializing tune_model()
2024-01-04 15:05:57,774:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>)
2024-01-04 15:05:57,775:INFO:Checking exceptions
2024-01-04 15:05:57,819:INFO:Copying training dataset
2024-01-04 15:05:57,871:INFO:Checking base model
2024-01-04 15:05:57,871:INFO:Base model : Logistic Regression
2024-01-04 15:05:57,878:INFO:Declaring metric variables
2024-01-04 15:05:57,884:INFO:Defining Hyperparameters
2024-01-04 15:05:58,183:INFO:Tuning with n_jobs=-1
2024-01-04 15:05:58,183:INFO:Initializing RandomizedSearchCV
2024-01-04 15:06:34,656:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:35,189:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:35,232:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:35,341:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:35,591:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:36,407:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:37,370:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:40,001:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:06:42,110:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:00,478:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:00,572:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:06,058:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:07,393:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:08,029:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:14,606:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:15,723:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:20,454:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:22,023:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:23,005:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:23,405:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:24,278:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:25,197:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:27,360:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:27,871:WARNING:c:\Users\visha\anaconda3\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-01-04 15:07:45,612:INFO:Initializing evaluate_model()
2024-01-04 15:07:45,612:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-04 15:07:45,661:INFO:Initializing plot_model()
2024-01-04 15:07:45,661:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:07:45,661:INFO:Checking exceptions
2024-01-04 15:07:45,681:INFO:Preloading libraries
2024-01-04 15:07:45,690:INFO:Copying training dataset
2024-01-04 15:07:45,690:INFO:Plot type: pipeline
2024-01-04 15:07:46,077:INFO:Visual Rendered Successfully
2024-01-04 15:07:46,426:INFO:plot_model() successfully completed......................................
2024-01-04 15:07:49,636:INFO:Initializing plot_model()
2024-01-04 15:07:49,637:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:07:49,637:INFO:Checking exceptions
2024-01-04 15:07:49,655:INFO:Preloading libraries
2024-01-04 15:07:49,661:INFO:Copying training dataset
2024-01-04 15:07:49,661:INFO:Plot type: threshold
2024-01-04 15:07:49,998:INFO:Fitting Model
2024-01-04 15:07:50,038:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:50,039:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:07:50,042:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001378 seconds.
2024-01-04 15:07:50,042:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:50,042:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:50,043:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:07:50,043:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:50,043:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:07:50,043:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:07:50,279:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:50,280:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:07:50,284:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001492 seconds.
2024-01-04 15:07:50,284:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:50,284:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:50,284:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:07:50,284:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:50,285:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:07:50,285:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:07:50,526:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:50,526:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:07:50,530:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.
2024-01-04 15:07:50,530:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:50,530:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:50,530:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:07:50,530:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:50,531:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:07:50,531:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:07:50,777:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:50,778:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:07:50,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.
2024-01-04 15:07:50,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:50,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:50,782:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:07:50,782:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:50,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:07:50,783:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:07:51,036:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:51,037:INFO:[LightGBM] [Info] Number of positive: 5684, number of negative: 17759
2024-01-04 15:07:51,041:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.
2024-01-04 15:07:51,041:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:51,041:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:51,041:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:51,041:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:51,042:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242460 -> initscore=-1.139237
2024-01-04 15:07:51,042:INFO:[LightGBM] [Info] Start training from score -1.139237
2024-01-04 15:07:51,294:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:51,295:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:07:51,298:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001407 seconds.
2024-01-04 15:07:51,298:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:51,298:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:51,299:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:07:51,299:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:51,299:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:07:51,299:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:07:51,556:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:52,149:INFO:[LightGBM] [Info] Number of positive: 5653, number of negative: 17790
2024-01-04 15:07:52,152:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001246 seconds.
2024-01-04 15:07:52,152:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:52,152:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:52,152:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:07:52,152:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:52,153:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241138 -> initscore=-1.146450
2024-01-04 15:07:52,153:INFO:[LightGBM] [Info] Start training from score -1.146450
2024-01-04 15:07:52,432:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:52,432:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:07:52,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.
2024-01-04 15:07:52,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:52,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:52,437:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:07:52,437:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:52,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:07:52,437:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:07:52,697:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:52,698:INFO:[LightGBM] [Info] Number of positive: 5595, number of negative: 17848
2024-01-04 15:07:52,702:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.
2024-01-04 15:07:52,702:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:52,702:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:52,702:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:52,702:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:52,702:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238664 -> initscore=-1.160018
2024-01-04 15:07:52,703:INFO:[LightGBM] [Info] Start training from score -1.160018
2024-01-04 15:07:52,957:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:52,957:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:07:52,961:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002010 seconds.
2024-01-04 15:07:52,961:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:52,961:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:52,962:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:52,962:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:52,962:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:07:52,962:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:07:53,228:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:53,229:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:07:53,232:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001550 seconds.
2024-01-04 15:07:53,232:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:53,232:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:53,233:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:07:53,233:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:53,234:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:07:53,234:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:07:53,490:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:53,491:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:07:53,494:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001405 seconds.
2024-01-04 15:07:53,494:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:53,494:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:53,494:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:07:53,495:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:53,495:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:07:53,495:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:07:53,761:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:53,762:INFO:[LightGBM] [Info] Number of positive: 5627, number of negative: 17816
2024-01-04 15:07:53,765:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001578 seconds.
2024-01-04 15:07:53,765:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:53,765:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:53,766:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:07:53,766:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:53,766:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240029 -> initscore=-1.152520
2024-01-04 15:07:53,766:INFO:[LightGBM] [Info] Start training from score -1.152520
2024-01-04 15:07:54,027:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:54,028:INFO:[LightGBM] [Info] Number of positive: 5631, number of negative: 17812
2024-01-04 15:07:54,032:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001586 seconds.
2024-01-04 15:07:54,032:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:54,032:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:54,032:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:07:54,032:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:54,033:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240200 -> initscore=-1.151585
2024-01-04 15:07:54,033:INFO:[LightGBM] [Info] Start training from score -1.151585
2024-01-04 15:07:54,301:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:54,301:INFO:[LightGBM] [Info] Number of positive: 5668, number of negative: 17775
2024-01-04 15:07:54,305:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001569 seconds.
2024-01-04 15:07:54,305:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:54,305:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:54,305:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:07:54,305:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:54,306:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241778 -> initscore=-1.142957
2024-01-04 15:07:54,306:INFO:[LightGBM] [Info] Start training from score -1.142957
2024-01-04 15:07:54,564:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:54,565:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:07:54,568:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001503 seconds.
2024-01-04 15:07:54,568:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:54,568:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:54,569:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:07:54,569:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:54,569:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:07:54,569:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:07:54,822:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:54,824:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:07:54,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001681 seconds.
2024-01-04 15:07:54,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:54,828:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:54,828:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:54,828:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:54,829:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:07:54,829:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:07:55,091:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:55,091:INFO:[LightGBM] [Info] Number of positive: 5662, number of negative: 17781
2024-01-04 15:07:55,095:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001515 seconds.
2024-01-04 15:07:55,095:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:55,095:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:55,095:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:07:55,095:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:55,096:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241522 -> initscore=-1.144353
2024-01-04 15:07:55,096:INFO:[LightGBM] [Info] Start training from score -1.144353
2024-01-04 15:07:55,362:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:55,364:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:07:55,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003139 seconds.
2024-01-04 15:07:55,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:55,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:55,370:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:55,371:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:55,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:07:55,371:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:07:55,659:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:55,660:INFO:[LightGBM] [Info] Number of positive: 5634, number of negative: 17809
2024-01-04 15:07:55,664:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001662 seconds.
2024-01-04 15:07:55,664:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:55,664:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:55,664:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:55,664:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:55,665:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240328 -> initscore=-1.150884
2024-01-04 15:07:55,665:INFO:[LightGBM] [Info] Start training from score -1.150884
2024-01-04 15:07:55,935:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:55,936:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:07:55,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001828 seconds.
2024-01-04 15:07:55,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:55,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:55,941:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:55,941:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:55,942:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:07:55,942:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:07:56,207:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:56,207:INFO:[LightGBM] [Info] Number of positive: 5613, number of negative: 17830
2024-01-04 15:07:56,211:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.
2024-01-04 15:07:56,211:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:56,211:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:56,211:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:07:56,211:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:56,212:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239432 -> initscore=-1.155797
2024-01-04 15:07:56,212:INFO:[LightGBM] [Info] Start training from score -1.155797
2024-01-04 15:07:56,468:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:56,468:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:07:56,472:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001605 seconds.
2024-01-04 15:07:56,472:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:56,472:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:56,472:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:07:56,473:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:56,473:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:07:56,473:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:07:56,720:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:56,721:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:07:56,724:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001576 seconds.
2024-01-04 15:07:56,725:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:56,725:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:56,725:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:07:56,725:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:56,725:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:07:56,726:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:07:56,990:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:56,991:INFO:[LightGBM] [Info] Number of positive: 5644, number of negative: 17799
2024-01-04 15:07:56,995:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001675 seconds.
2024-01-04 15:07:56,995:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:56,995:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:56,995:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:07:56,995:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:56,996:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240754 -> initscore=-1.148549
2024-01-04 15:07:56,996:INFO:[LightGBM] [Info] Start training from score -1.148549
2024-01-04 15:07:57,273:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:57,274:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:07:57,277:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001710 seconds.
2024-01-04 15:07:57,278:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:57,278:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:57,278:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:57,278:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:57,279:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:07:57,279:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:07:57,545:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:57,545:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:07:57,549:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.
2024-01-04 15:07:57,549:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:57,549:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:57,549:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:07:57,549:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:57,550:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:07:57,550:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:07:57,822:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:57,823:INFO:[LightGBM] [Info] Number of positive: 5660, number of negative: 17783
2024-01-04 15:07:57,827:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001890 seconds.
2024-01-04 15:07:57,827:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:57,827:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:57,827:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:07:57,828:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:57,828:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241437 -> initscore=-1.144819
2024-01-04 15:07:57,828:INFO:[LightGBM] [Info] Start training from score -1.144819
2024-01-04 15:07:58,114:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:58,115:INFO:[LightGBM] [Info] Number of positive: 5641, number of negative: 17802
2024-01-04 15:07:58,118:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001920 seconds.
2024-01-04 15:07:58,119:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:58,119:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:58,119:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:07:58,119:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:58,119:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240626 -> initscore=-1.149249
2024-01-04 15:07:58,120:INFO:[LightGBM] [Info] Start training from score -1.149249
2024-01-04 15:07:58,435:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:58,436:INFO:[LightGBM] [Info] Number of positive: 5654, number of negative: 17789
2024-01-04 15:07:58,441:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002245 seconds.
2024-01-04 15:07:58,441:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:58,441:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:58,442:INFO:[LightGBM] [Info] Total Bins 432
2024-01-04 15:07:58,442:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:58,443:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241181 -> initscore=-1.146217
2024-01-04 15:07:58,443:INFO:[LightGBM] [Info] Start training from score -1.146217
2024-01-04 15:07:58,728:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:58,728:INFO:[LightGBM] [Info] Number of positive: 5670, number of negative: 17773
2024-01-04 15:07:58,733:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002089 seconds.
2024-01-04 15:07:58,733:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:58,733:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:58,733:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:07:58,733:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:58,734:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241863 -> initscore=-1.142491
2024-01-04 15:07:58,734:INFO:[LightGBM] [Info] Start training from score -1.142491
2024-01-04 15:07:59,070:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:59,071:INFO:[LightGBM] [Info] Number of positive: 5609, number of negative: 17834
2024-01-04 15:07:59,076:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002028 seconds.
2024-01-04 15:07:59,076:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:59,076:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:59,077:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:07:59,077:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:07:59,077:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239261 -> initscore=-1.156734
2024-01-04 15:07:59,077:INFO:[LightGBM] [Info] Start training from score -1.156734
2024-01-04 15:07:59,344:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:59,344:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:07:59,348:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001547 seconds.
2024-01-04 15:07:59,348:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:59,348:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:59,348:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:07:59,349:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:59,349:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:07:59,349:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:07:59,632:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:59,633:INFO:[LightGBM] [Info] Number of positive: 5687, number of negative: 17756
2024-01-04 15:07:59,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001429 seconds.
2024-01-04 15:07:59,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:59,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:59,637:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:07:59,637:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:59,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242588 -> initscore=-1.138541
2024-01-04 15:07:59,637:INFO:[LightGBM] [Info] Start training from score -1.138541
2024-01-04 15:07:59,902:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:07:59,903:INFO:[LightGBM] [Info] Number of positive: 5651, number of negative: 17792
2024-01-04 15:07:59,907:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.
2024-01-04 15:07:59,908:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:07:59,908:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:07:59,908:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:07:59,908:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:07:59,909:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241053 -> initscore=-1.146916
2024-01-04 15:07:59,909:INFO:[LightGBM] [Info] Start training from score -1.146916
2024-01-04 15:08:00,169:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:00,169:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:00,173:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001628 seconds.
2024-01-04 15:08:00,173:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:00,173:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:00,173:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:00,173:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:00,174:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:00,174:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:00,438:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:00,439:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:00,442:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.
2024-01-04 15:08:00,442:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:00,442:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:00,443:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:00,443:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:00,444:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:00,444:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:00,754:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:00,755:INFO:[LightGBM] [Info] Number of positive: 5628, number of negative: 17815
2024-01-04 15:08:00,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002943 seconds.
2024-01-04 15:08:00,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:00,761:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:00,762:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:00,762:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:00,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240072 -> initscore=-1.152287
2024-01-04 15:08:00,763:INFO:[LightGBM] [Info] Start training from score -1.152287
2024-01-04 15:08:01,104:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:01,105:INFO:[LightGBM] [Info] Number of positive: 5678, number of negative: 17765
2024-01-04 15:08:01,109:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001646 seconds.
2024-01-04 15:08:01,109:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:01,109:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:01,109:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:01,110:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:01,110:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242204 -> initscore=-1.140631
2024-01-04 15:08:01,110:INFO:[LightGBM] [Info] Start training from score -1.140631
2024-01-04 15:08:01,409:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:01,409:INFO:[LightGBM] [Info] Number of positive: 5646, number of negative: 17797
2024-01-04 15:08:01,413:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001820 seconds.
2024-01-04 15:08:01,414:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:01,414:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:01,414:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:01,414:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:01,415:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240839 -> initscore=-1.148083
2024-01-04 15:08:01,415:INFO:[LightGBM] [Info] Start training from score -1.148083
2024-01-04 15:08:01,729:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:01,729:INFO:[LightGBM] [Info] Number of positive: 5657, number of negative: 17786
2024-01-04 15:08:01,736:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001898 seconds.
2024-01-04 15:08:01,736:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:01,736:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:01,737:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:08:01,737:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:01,738:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241309 -> initscore=-1.145518
2024-01-04 15:08:01,738:INFO:[LightGBM] [Info] Start training from score -1.145518
2024-01-04 15:08:01,992:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:01,993:INFO:[LightGBM] [Info] Number of positive: 5640, number of negative: 17803
2024-01-04 15:08:01,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001575 seconds.
2024-01-04 15:08:01,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:01,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:01,997:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 15:08:01,997:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:01,998:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240584 -> initscore=-1.149483
2024-01-04 15:08:01,998:INFO:[LightGBM] [Info] Start training from score -1.149483
2024-01-04 15:08:02,262:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:02,262:INFO:[LightGBM] [Info] Number of positive: 5611, number of negative: 17832
2024-01-04 15:08:02,265:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001332 seconds.
2024-01-04 15:08:02,265:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:02,265:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:02,266:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:02,266:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:02,266:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239347 -> initscore=-1.156266
2024-01-04 15:08:02,266:INFO:[LightGBM] [Info] Start training from score -1.156266
2024-01-04 15:08:02,523:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:02,524:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:02,527:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001537 seconds.
2024-01-04 15:08:02,528:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:02,528:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:02,528:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:02,528:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:02,528:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:02,529:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:02,781:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:02,782:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:08:02,786:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001955 seconds.
2024-01-04 15:08:02,786:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:02,786:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:02,786:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:02,786:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:02,787:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:08:02,787:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:08:03,043:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:03,044:INFO:[LightGBM] [Info] Number of positive: 5638, number of negative: 17805
2024-01-04 15:08:03,047:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001510 seconds.
2024-01-04 15:08:03,047:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:03,047:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:03,047:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:03,048:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:03,048:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240498 -> initscore=-1.149950
2024-01-04 15:08:03,048:INFO:[LightGBM] [Info] Start training from score -1.149950
2024-01-04 15:08:03,306:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:03,307:INFO:[LightGBM] [Info] Number of positive: 5645, number of negative: 17798
2024-01-04 15:08:03,310:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001505 seconds.
2024-01-04 15:08:03,310:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:03,310:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:03,311:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:03,311:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:03,311:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240797 -> initscore=-1.148316
2024-01-04 15:08:03,311:INFO:[LightGBM] [Info] Start training from score -1.148316
2024-01-04 15:08:03,572:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:03,573:INFO:[LightGBM] [Info] Number of positive: 5648, number of negative: 17795
2024-01-04 15:08:03,577:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001762 seconds.
2024-01-04 15:08:03,577:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:03,577:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:03,577:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:03,578:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:03,578:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240925 -> initscore=-1.147616
2024-01-04 15:08:03,578:INFO:[LightGBM] [Info] Start training from score -1.147616
2024-01-04 15:08:03,839:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:03,840:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:08:03,842:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001522 seconds.
2024-01-04 15:08:03,843:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:03,843:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:03,843:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:03,843:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:03,843:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:08:03,844:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:08:04,104:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:04,105:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:04,108:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.
2024-01-04 15:08:04,108:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:04,108:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:04,109:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:08:04,109:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:04,109:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:04,109:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:05,342:INFO:Scoring test/hold-out set
2024-01-04 15:08:05,769:INFO:Visual Rendered Successfully
2024-01-04 15:08:05,977:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:06,004:INFO:Initializing evaluate_model()
2024-01-04 15:08:06,005:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-04 15:08:06,044:INFO:Initializing plot_model()
2024-01-04 15:08:06,044:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:06,044:INFO:Checking exceptions
2024-01-04 15:08:06,060:INFO:Preloading libraries
2024-01-04 15:08:06,066:INFO:Copying training dataset
2024-01-04 15:08:06,066:INFO:Plot type: pipeline
2024-01-04 15:08:06,350:INFO:Visual Rendered Successfully
2024-01-04 15:08:06,576:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:06,604:INFO:Initializing plot_model()
2024-01-04 15:08:06,604:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:06,605:INFO:Checking exceptions
2024-01-04 15:08:06,622:INFO:Preloading libraries
2024-01-04 15:08:06,627:INFO:Copying training dataset
2024-01-04 15:08:06,627:INFO:Plot type: pipeline
2024-01-04 15:08:06,876:INFO:Visual Rendered Successfully
2024-01-04 15:08:07,083:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:08,247:INFO:Initializing plot_model()
2024-01-04 15:08:08,248:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:08,248:INFO:Checking exceptions
2024-01-04 15:08:08,265:INFO:Preloading libraries
2024-01-04 15:08:08,271:INFO:Copying training dataset
2024-01-04 15:08:08,271:INFO:Plot type: threshold
2024-01-04 15:08:08,610:INFO:Fitting Model
2024-01-04 15:08:08,656:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:08,656:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:08:08,660:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001850 seconds.
2024-01-04 15:08:08,660:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:08,661:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:08,661:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:08,661:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:08,661:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:08:08,661:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:08:08,909:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:08,910:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:08:08,913:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.
2024-01-04 15:08:08,914:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:08,914:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:08,914:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:08,914:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:08,915:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:08:08,915:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:08:09,171:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:09,172:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:09,175:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001729 seconds.
2024-01-04 15:08:09,176:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:09,176:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:09,176:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:08:09,176:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:09,176:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:09,177:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:09,430:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:09,431:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:08:09,434:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001418 seconds.
2024-01-04 15:08:09,435:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:09,435:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:09,435:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:09,435:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:09,435:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:08:09,436:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:08:09,687:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:09,687:INFO:[LightGBM] [Info] Number of positive: 5684, number of negative: 17759
2024-01-04 15:08:09,690:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.
2024-01-04 15:08:09,690:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:09,691:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:09,691:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:09,691:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:09,691:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242460 -> initscore=-1.139237
2024-01-04 15:08:09,692:INFO:[LightGBM] [Info] Start training from score -1.139237
2024-01-04 15:08:09,942:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:09,944:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:08:09,947:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001634 seconds.
2024-01-04 15:08:09,948:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:09,948:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:09,948:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:09,948:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:09,949:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:08:09,949:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:08:10,200:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:10,200:INFO:[LightGBM] [Info] Number of positive: 5653, number of negative: 17790
2024-01-04 15:08:10,204:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001558 seconds.
2024-01-04 15:08:10,204:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:10,204:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:10,204:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:08:10,205:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:10,205:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241138 -> initscore=-1.146450
2024-01-04 15:08:10,205:INFO:[LightGBM] [Info] Start training from score -1.146450
2024-01-04 15:08:10,467:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:10,467:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:08:10,471:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001436 seconds.
2024-01-04 15:08:10,471:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:10,471:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:10,471:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:10,471:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:10,472:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:08:10,472:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:08:10,733:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:10,734:INFO:[LightGBM] [Info] Number of positive: 5595, number of negative: 17848
2024-01-04 15:08:10,739:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.
2024-01-04 15:08:10,739:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:10,739:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:10,739:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:10,739:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:10,740:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238664 -> initscore=-1.160018
2024-01-04 15:08:10,740:INFO:[LightGBM] [Info] Start training from score -1.160018
2024-01-04 15:08:11,024:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:11,025:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:08:11,028:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001496 seconds.
2024-01-04 15:08:11,028:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:11,028:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:11,029:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:11,029:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:11,029:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:08:11,029:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:08:11,278:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:11,279:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:11,282:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001548 seconds.
2024-01-04 15:08:11,282:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:11,283:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:11,283:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:11,283:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:11,284:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:11,284:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:11,536:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:11,536:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:08:11,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.
2024-01-04 15:08:11,540:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:11,540:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:11,540:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:11,540:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:11,541:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:08:11,541:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:08:11,792:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:11,793:INFO:[LightGBM] [Info] Number of positive: 5627, number of negative: 17816
2024-01-04 15:08:11,797:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001613 seconds.
2024-01-04 15:08:11,797:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:11,797:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:11,797:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:11,797:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:11,798:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240029 -> initscore=-1.152520
2024-01-04 15:08:11,798:INFO:[LightGBM] [Info] Start training from score -1.152520
2024-01-04 15:08:12,059:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:12,059:INFO:[LightGBM] [Info] Number of positive: 5631, number of negative: 17812
2024-01-04 15:08:12,063:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.
2024-01-04 15:08:12,063:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:12,063:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:12,063:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:12,064:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:12,064:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240200 -> initscore=-1.151585
2024-01-04 15:08:12,064:INFO:[LightGBM] [Info] Start training from score -1.151585
2024-01-04 15:08:12,328:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:12,328:INFO:[LightGBM] [Info] Number of positive: 5668, number of negative: 17775
2024-01-04 15:08:12,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001506 seconds.
2024-01-04 15:08:12,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:12,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:12,332:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:12,332:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:12,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241778 -> initscore=-1.142957
2024-01-04 15:08:12,333:INFO:[LightGBM] [Info] Start training from score -1.142957
2024-01-04 15:08:12,587:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:12,588:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:08:12,592:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.
2024-01-04 15:08:12,592:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:12,592:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:12,592:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:12,593:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:12,593:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:08:12,593:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:08:12,843:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:12,844:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:12,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001596 seconds.
2024-01-04 15:08:12,848:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:12,848:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:12,848:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:12,848:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:12,848:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:12,849:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:13,106:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:13,107:INFO:[LightGBM] [Info] Number of positive: 5662, number of negative: 17781
2024-01-04 15:08:13,110:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001452 seconds.
2024-01-04 15:08:13,110:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:13,110:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:13,111:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:13,111:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:13,111:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241522 -> initscore=-1.144353
2024-01-04 15:08:13,111:INFO:[LightGBM] [Info] Start training from score -1.144353
2024-01-04 15:08:13,366:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:13,366:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:08:13,370:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001477 seconds.
2024-01-04 15:08:13,370:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:13,370:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:13,370:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:13,370:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:13,371:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:08:13,371:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:08:13,623:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:13,624:INFO:[LightGBM] [Info] Number of positive: 5634, number of negative: 17809
2024-01-04 15:08:13,628:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001524 seconds.
2024-01-04 15:08:13,628:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:13,628:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:13,628:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:13,628:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:13,629:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240328 -> initscore=-1.150884
2024-01-04 15:08:13,629:INFO:[LightGBM] [Info] Start training from score -1.150884
2024-01-04 15:08:13,886:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:13,887:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:08:13,890:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001432 seconds.
2024-01-04 15:08:13,891:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:13,891:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:13,891:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:13,891:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:13,892:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:08:13,892:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:08:14,152:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:14,152:INFO:[LightGBM] [Info] Number of positive: 5613, number of negative: 17830
2024-01-04 15:08:14,156:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001542 seconds.
2024-01-04 15:08:14,156:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:14,156:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:14,157:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:08:14,157:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:14,157:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239432 -> initscore=-1.155797
2024-01-04 15:08:14,157:INFO:[LightGBM] [Info] Start training from score -1.155797
2024-01-04 15:08:14,419:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:14,421:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:08:14,424:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001504 seconds.
2024-01-04 15:08:14,424:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:14,424:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:14,425:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:08:14,425:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:14,425:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:08:14,425:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:08:14,678:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:14,679:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:08:14,683:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001592 seconds.
2024-01-04 15:08:14,683:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:14,683:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:14,683:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:14,683:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:14,684:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:08:14,684:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:08:14,949:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:14,950:INFO:[LightGBM] [Info] Number of positive: 5644, number of negative: 17799
2024-01-04 15:08:14,954:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001584 seconds.
2024-01-04 15:08:14,954:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:14,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:14,954:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:14,954:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:14,955:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240754 -> initscore=-1.148549
2024-01-04 15:08:14,955:INFO:[LightGBM] [Info] Start training from score -1.148549
2024-01-04 15:08:15,215:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:15,215:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:08:15,219:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.
2024-01-04 15:08:15,219:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:15,219:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:15,219:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:15,220:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:15,220:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:08:15,220:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:08:15,494:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:15,496:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:15,499:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001688 seconds.
2024-01-04 15:08:15,499:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:15,499:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:15,499:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:15,500:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:15,500:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:15,500:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:15,776:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:15,776:INFO:[LightGBM] [Info] Number of positive: 5660, number of negative: 17783
2024-01-04 15:08:15,780:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001639 seconds.
2024-01-04 15:08:15,780:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:15,780:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:15,780:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:15,781:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:15,781:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241437 -> initscore=-1.144819
2024-01-04 15:08:15,781:INFO:[LightGBM] [Info] Start training from score -1.144819
2024-01-04 15:08:16,057:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:16,057:INFO:[LightGBM] [Info] Number of positive: 5641, number of negative: 17802
2024-01-04 15:08:16,060:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001237 seconds.
2024-01-04 15:08:16,060:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:16,061:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:16,061:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:16,061:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:16,061:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240626 -> initscore=-1.149249
2024-01-04 15:08:16,061:INFO:[LightGBM] [Info] Start training from score -1.149249
2024-01-04 15:08:16,334:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:16,334:INFO:[LightGBM] [Info] Number of positive: 5654, number of negative: 17789
2024-01-04 15:08:16,340:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002381 seconds.
2024-01-04 15:08:16,340:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:16,340:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:16,340:INFO:[LightGBM] [Info] Total Bins 432
2024-01-04 15:08:16,341:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:16,341:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241181 -> initscore=-1.146217
2024-01-04 15:08:16,341:INFO:[LightGBM] [Info] Start training from score -1.146217
2024-01-04 15:08:16,609:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:16,610:INFO:[LightGBM] [Info] Number of positive: 5670, number of negative: 17773
2024-01-04 15:08:16,613:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001462 seconds.
2024-01-04 15:08:16,614:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:16,614:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:16,614:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:16,614:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:16,614:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241863 -> initscore=-1.142491
2024-01-04 15:08:16,615:INFO:[LightGBM] [Info] Start training from score -1.142491
2024-01-04 15:08:16,875:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:16,876:INFO:[LightGBM] [Info] Number of positive: 5609, number of negative: 17834
2024-01-04 15:08:16,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001638 seconds.
2024-01-04 15:08:16,879:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:16,879:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:16,880:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:16,880:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:16,880:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239261 -> initscore=-1.156734
2024-01-04 15:08:16,880:INFO:[LightGBM] [Info] Start training from score -1.156734
2024-01-04 15:08:17,149:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:17,149:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:08:17,153:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001685 seconds.
2024-01-04 15:08:17,153:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:17,153:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:17,154:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:17,154:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:17,154:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:08:17,154:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:08:17,426:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:17,427:INFO:[LightGBM] [Info] Number of positive: 5687, number of negative: 17756
2024-01-04 15:08:17,430:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001509 seconds.
2024-01-04 15:08:17,430:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:17,430:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:17,431:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:17,431:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:17,431:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242588 -> initscore=-1.138541
2024-01-04 15:08:17,431:INFO:[LightGBM] [Info] Start training from score -1.138541
2024-01-04 15:08:17,688:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:17,689:INFO:[LightGBM] [Info] Number of positive: 5651, number of negative: 17792
2024-01-04 15:08:17,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001532 seconds.
2024-01-04 15:08:17,693:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:17,693:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:17,693:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:17,693:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:17,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241053 -> initscore=-1.146916
2024-01-04 15:08:17,694:INFO:[LightGBM] [Info] Start training from score -1.146916
2024-01-04 15:08:17,953:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:17,954:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:17,957:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001506 seconds.
2024-01-04 15:08:17,957:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:17,957:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:17,958:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:17,958:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:17,958:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:17,959:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:18,225:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:18,226:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:18,230:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001644 seconds.
2024-01-04 15:08:18,230:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:18,230:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:18,230:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:18,230:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:18,231:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:18,231:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:18,483:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:18,484:INFO:[LightGBM] [Info] Number of positive: 5628, number of negative: 17815
2024-01-04 15:08:18,488:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001667 seconds.
2024-01-04 15:08:18,488:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:18,488:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:18,488:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:18,489:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:18,489:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240072 -> initscore=-1.152287
2024-01-04 15:08:18,489:INFO:[LightGBM] [Info] Start training from score -1.152287
2024-01-04 15:08:18,744:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:18,745:INFO:[LightGBM] [Info] Number of positive: 5678, number of negative: 17765
2024-01-04 15:08:18,748:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001473 seconds.
2024-01-04 15:08:18,748:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:18,748:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:18,748:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:18,749:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:18,749:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242204 -> initscore=-1.140631
2024-01-04 15:08:18,749:INFO:[LightGBM] [Info] Start training from score -1.140631
2024-01-04 15:08:19,007:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:19,008:INFO:[LightGBM] [Info] Number of positive: 5646, number of negative: 17797
2024-01-04 15:08:19,012:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001891 seconds.
2024-01-04 15:08:19,012:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:19,012:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:19,012:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:19,012:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:19,013:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240839 -> initscore=-1.148083
2024-01-04 15:08:19,013:INFO:[LightGBM] [Info] Start training from score -1.148083
2024-01-04 15:08:19,263:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:19,264:INFO:[LightGBM] [Info] Number of positive: 5657, number of negative: 17786
2024-01-04 15:08:19,269:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001456 seconds.
2024-01-04 15:08:19,269:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:19,269:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:19,269:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:08:19,269:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:19,270:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241309 -> initscore=-1.145518
2024-01-04 15:08:19,270:INFO:[LightGBM] [Info] Start training from score -1.145518
2024-01-04 15:08:19,520:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:19,521:INFO:[LightGBM] [Info] Number of positive: 5640, number of negative: 17803
2024-01-04 15:08:19,525:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001594 seconds.
2024-01-04 15:08:19,525:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:19,526:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:19,526:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 15:08:19,526:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:19,526:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240584 -> initscore=-1.149483
2024-01-04 15:08:19,526:INFO:[LightGBM] [Info] Start training from score -1.149483
2024-01-04 15:08:19,778:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:19,779:INFO:[LightGBM] [Info] Number of positive: 5611, number of negative: 17832
2024-01-04 15:08:19,782:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001460 seconds.
2024-01-04 15:08:19,782:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:19,782:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:19,782:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:19,782:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:19,783:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239347 -> initscore=-1.156266
2024-01-04 15:08:19,783:INFO:[LightGBM] [Info] Start training from score -1.156266
2024-01-04 15:08:20,036:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:20,037:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:20,040:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001603 seconds.
2024-01-04 15:08:20,040:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:20,040:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:20,041:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:20,041:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:20,041:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:20,041:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:20,290:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:20,291:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:08:20,294:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001526 seconds.
2024-01-04 15:08:20,294:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:20,295:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:20,295:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:20,295:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:20,296:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:08:20,296:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:08:20,547:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:20,548:INFO:[LightGBM] [Info] Number of positive: 5638, number of negative: 17805
2024-01-04 15:08:20,550:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001063 seconds.
2024-01-04 15:08:20,550:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:20,550:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:20,551:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:20,551:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:20,551:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240498 -> initscore=-1.149950
2024-01-04 15:08:20,551:INFO:[LightGBM] [Info] Start training from score -1.149950
2024-01-04 15:08:20,805:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:20,806:INFO:[LightGBM] [Info] Number of positive: 5645, number of negative: 17798
2024-01-04 15:08:20,810:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001670 seconds.
2024-01-04 15:08:20,810:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:20,810:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:20,810:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:20,810:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:20,811:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240797 -> initscore=-1.148316
2024-01-04 15:08:20,811:INFO:[LightGBM] [Info] Start training from score -1.148316
2024-01-04 15:08:21,070:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:21,070:INFO:[LightGBM] [Info] Number of positive: 5648, number of negative: 17795
2024-01-04 15:08:21,074:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001266 seconds.
2024-01-04 15:08:21,074:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:21,074:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:21,074:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:21,074:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:21,075:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240925 -> initscore=-1.147616
2024-01-04 15:08:21,075:INFO:[LightGBM] [Info] Start training from score -1.147616
2024-01-04 15:08:21,328:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:21,329:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:08:21,332:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.
2024-01-04 15:08:21,332:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:21,332:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:21,332:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:21,332:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:21,333:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:08:21,333:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:08:21,601:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:21,601:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:21,605:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001619 seconds.
2024-01-04 15:08:21,605:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:21,605:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:21,606:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:08:21,606:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:21,606:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:21,606:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:22,842:INFO:Scoring test/hold-out set
2024-01-04 15:08:23,188:INFO:Visual Rendered Successfully
2024-01-04 15:08:23,421:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:23,442:INFO:Initializing evaluate_model()
2024-01-04 15:08:23,442:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-04 15:08:23,477:INFO:Initializing plot_model()
2024-01-04 15:08:23,477:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:23,477:INFO:Checking exceptions
2024-01-04 15:08:23,494:INFO:Preloading libraries
2024-01-04 15:08:23,501:INFO:Copying training dataset
2024-01-04 15:08:23,501:INFO:Plot type: pipeline
2024-01-04 15:08:23,805:INFO:Visual Rendered Successfully
2024-01-04 15:08:24,037:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:24,056:INFO:Initializing plot_model()
2024-01-04 15:08:24,057:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:24,057:INFO:Checking exceptions
2024-01-04 15:08:24,077:INFO:Preloading libraries
2024-01-04 15:08:24,082:INFO:Copying training dataset
2024-01-04 15:08:24,082:INFO:Plot type: parameter
2024-01-04 15:08:24,088:INFO:Visual Rendered Successfully
2024-01-04 15:08:24,337:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:24,801:INFO:Initializing plot_model()
2024-01-04 15:08:24,801:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:24,801:INFO:Checking exceptions
2024-01-04 15:08:24,820:INFO:Preloading libraries
2024-01-04 15:08:24,826:INFO:Copying training dataset
2024-01-04 15:08:24,827:INFO:Plot type: parameter
2024-01-04 15:08:24,833:INFO:Visual Rendered Successfully
2024-01-04 15:08:25,073:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:27,055:INFO:Initializing plot_model()
2024-01-04 15:08:27,055:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:27,055:INFO:Checking exceptions
2024-01-04 15:08:27,070:INFO:Preloading libraries
2024-01-04 15:08:27,076:INFO:Copying training dataset
2024-01-04 15:08:27,077:INFO:Plot type: threshold
2024-01-04 15:08:27,415:INFO:Fitting Model
2024-01-04 15:08:27,455:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:27,456:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:08:27,459:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.
2024-01-04 15:08:27,459:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:27,459:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:27,460:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:27,460:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:27,460:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:08:27,460:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:08:27,728:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:27,729:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:08:27,732:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001156 seconds.
2024-01-04 15:08:27,732:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:27,732:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:27,732:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:27,732:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:27,733:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:08:27,733:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:08:27,992:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:27,993:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:27,997:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001658 seconds.
2024-01-04 15:08:27,997:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:27,997:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:27,998:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:08:27,998:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:27,998:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:27,999:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:28,267:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:28,267:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:08:28,270:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001025 seconds.
2024-01-04 15:08:28,270:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:28,270:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:28,270:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:28,271:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:28,271:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:08:28,271:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:08:28,537:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:28,537:INFO:[LightGBM] [Info] Number of positive: 5684, number of negative: 17759
2024-01-04 15:08:28,540:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001588 seconds.
2024-01-04 15:08:28,541:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:28,541:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:28,541:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:28,541:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:28,542:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242460 -> initscore=-1.139237
2024-01-04 15:08:28,542:INFO:[LightGBM] [Info] Start training from score -1.139237
2024-01-04 15:08:28,797:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:28,798:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:08:28,801:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001373 seconds.
2024-01-04 15:08:28,801:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:28,801:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:28,802:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:28,802:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:28,802:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:08:28,802:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:08:29,071:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:29,072:INFO:[LightGBM] [Info] Number of positive: 5653, number of negative: 17790
2024-01-04 15:08:29,075:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.
2024-01-04 15:08:29,075:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:29,075:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:29,076:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:08:29,076:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:29,076:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241138 -> initscore=-1.146450
2024-01-04 15:08:29,076:INFO:[LightGBM] [Info] Start training from score -1.146450
2024-01-04 15:08:29,338:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:29,339:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:08:29,342:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001227 seconds.
2024-01-04 15:08:29,342:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:29,342:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:29,342:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:29,342:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:29,343:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:08:29,343:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:08:29,603:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:29,604:INFO:[LightGBM] [Info] Number of positive: 5595, number of negative: 17848
2024-01-04 15:08:29,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001799 seconds.
2024-01-04 15:08:29,608:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:29,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:29,608:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:29,608:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:29,609:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238664 -> initscore=-1.160018
2024-01-04 15:08:29,609:INFO:[LightGBM] [Info] Start training from score -1.160018
2024-01-04 15:08:29,867:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:29,868:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:08:29,871:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001127 seconds.
2024-01-04 15:08:29,871:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:29,871:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:29,871:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:29,871:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:29,872:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:08:29,872:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:08:30,134:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:30,135:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:30,139:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001420 seconds.
2024-01-04 15:08:30,139:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:30,139:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:30,139:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:30,139:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:30,140:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:30,140:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:30,377:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:30,378:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:08:30,381:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001630 seconds.
2024-01-04 15:08:30,381:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:30,381:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:30,382:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:30,382:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:30,382:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:08:30,382:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:08:30,648:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:30,649:INFO:[LightGBM] [Info] Number of positive: 5627, number of negative: 17816
2024-01-04 15:08:30,651:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001185 seconds.
2024-01-04 15:08:30,652:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:30,652:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:30,652:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:30,652:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:30,652:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240029 -> initscore=-1.152520
2024-01-04 15:08:30,652:INFO:[LightGBM] [Info] Start training from score -1.152520
2024-01-04 15:08:30,919:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:30,920:INFO:[LightGBM] [Info] Number of positive: 5631, number of negative: 17812
2024-01-04 15:08:30,923:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001406 seconds.
2024-01-04 15:08:30,924:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:30,924:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:30,924:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:30,924:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:30,924:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240200 -> initscore=-1.151585
2024-01-04 15:08:30,924:INFO:[LightGBM] [Info] Start training from score -1.151585
2024-01-04 15:08:31,182:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:31,183:INFO:[LightGBM] [Info] Number of positive: 5668, number of negative: 17775
2024-01-04 15:08:31,187:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001851 seconds.
2024-01-04 15:08:31,187:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:31,188:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:31,188:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:31,188:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:31,188:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241778 -> initscore=-1.142957
2024-01-04 15:08:31,188:INFO:[LightGBM] [Info] Start training from score -1.142957
2024-01-04 15:08:31,444:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:31,444:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:08:31,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001583 seconds.
2024-01-04 15:08:31,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:31,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:31,448:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:31,448:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:31,449:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:08:31,449:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:08:31,714:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:31,715:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:31,718:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001144 seconds.
2024-01-04 15:08:31,718:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:31,718:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:31,719:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:31,719:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:31,719:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:31,719:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:31,969:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:31,969:INFO:[LightGBM] [Info] Number of positive: 5662, number of negative: 17781
2024-01-04 15:08:31,973:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001508 seconds.
2024-01-04 15:08:31,973:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:31,973:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:31,973:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:31,973:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:31,974:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241522 -> initscore=-1.144353
2024-01-04 15:08:31,974:INFO:[LightGBM] [Info] Start training from score -1.144353
2024-01-04 15:08:32,231:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:32,232:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:08:32,285:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001714 seconds.
2024-01-04 15:08:32,285:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:32,285:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:32,285:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:32,285:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:32,286:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:08:32,286:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:08:32,530:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:32,531:INFO:[LightGBM] [Info] Number of positive: 5634, number of negative: 17809
2024-01-04 15:08:32,534:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001508 seconds.
2024-01-04 15:08:32,534:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:32,534:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:32,535:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:32,535:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:32,535:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240328 -> initscore=-1.150884
2024-01-04 15:08:32,535:INFO:[LightGBM] [Info] Start training from score -1.150884
2024-01-04 15:08:32,790:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:32,791:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:08:32,795:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.
2024-01-04 15:08:32,795:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:32,795:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:32,795:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:32,795:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:32,796:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:08:32,796:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:08:33,073:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:33,074:INFO:[LightGBM] [Info] Number of positive: 5613, number of negative: 17830
2024-01-04 15:08:33,077:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001228 seconds.
2024-01-04 15:08:33,077:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:33,077:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:33,077:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:08:33,078:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:33,078:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239432 -> initscore=-1.155797
2024-01-04 15:08:33,078:INFO:[LightGBM] [Info] Start training from score -1.155797
2024-01-04 15:08:33,335:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:33,336:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:08:33,339:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001384 seconds.
2024-01-04 15:08:33,339:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:33,339:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:33,339:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:08:33,339:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:33,340:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:08:33,340:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:08:33,603:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:33,604:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:08:33,607:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001559 seconds.
2024-01-04 15:08:33,607:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:33,608:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:33,608:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:33,608:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:33,608:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:08:33,608:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:08:33,863:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:33,864:INFO:[LightGBM] [Info] Number of positive: 5644, number of negative: 17799
2024-01-04 15:08:33,868:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001645 seconds.
2024-01-04 15:08:33,868:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:33,868:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:33,868:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:33,868:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:33,869:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240754 -> initscore=-1.148549
2024-01-04 15:08:33,869:INFO:[LightGBM] [Info] Start training from score -1.148549
2024-01-04 15:08:34,124:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:34,126:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:08:34,129:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001553 seconds.
2024-01-04 15:08:34,129:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:34,129:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:34,129:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:34,129:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:34,130:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:08:34,130:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:08:34,384:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:34,385:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:34,388:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001589 seconds.
2024-01-04 15:08:34,388:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:34,388:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:34,389:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:34,389:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:34,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:34,389:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:34,639:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:34,640:INFO:[LightGBM] [Info] Number of positive: 5660, number of negative: 17783
2024-01-04 15:08:34,644:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001481 seconds.
2024-01-04 15:08:34,644:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:34,644:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:34,644:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:34,645:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:34,645:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241437 -> initscore=-1.144819
2024-01-04 15:08:34,645:INFO:[LightGBM] [Info] Start training from score -1.144819
2024-01-04 15:08:34,912:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:34,912:INFO:[LightGBM] [Info] Number of positive: 5641, number of negative: 17802
2024-01-04 15:08:34,915:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001523 seconds.
2024-01-04 15:08:34,915:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:34,915:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:34,916:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:34,916:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:34,916:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240626 -> initscore=-1.149249
2024-01-04 15:08:34,916:INFO:[LightGBM] [Info] Start training from score -1.149249
2024-01-04 15:08:35,173:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:35,174:INFO:[LightGBM] [Info] Number of positive: 5654, number of negative: 17789
2024-01-04 15:08:35,177:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001302 seconds.
2024-01-04 15:08:35,177:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:35,177:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:35,178:INFO:[LightGBM] [Info] Total Bins 432
2024-01-04 15:08:35,178:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:35,178:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241181 -> initscore=-1.146217
2024-01-04 15:08:35,178:INFO:[LightGBM] [Info] Start training from score -1.146217
2024-01-04 15:08:35,433:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:35,434:INFO:[LightGBM] [Info] Number of positive: 5670, number of negative: 17773
2024-01-04 15:08:35,437:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001533 seconds.
2024-01-04 15:08:35,437:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:35,437:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:35,438:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:35,438:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:35,438:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241863 -> initscore=-1.142491
2024-01-04 15:08:35,438:INFO:[LightGBM] [Info] Start training from score -1.142491
2024-01-04 15:08:35,690:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:35,690:INFO:[LightGBM] [Info] Number of positive: 5609, number of negative: 17834
2024-01-04 15:08:35,693:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001361 seconds.
2024-01-04 15:08:35,694:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:35,694:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:35,694:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:35,694:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:35,694:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239261 -> initscore=-1.156734
2024-01-04 15:08:35,695:INFO:[LightGBM] [Info] Start training from score -1.156734
2024-01-04 15:08:35,948:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:35,949:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:08:35,952:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001643 seconds.
2024-01-04 15:08:35,952:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:35,954:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:35,954:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:35,954:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:35,954:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:08:35,954:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:08:36,218:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:36,218:INFO:[LightGBM] [Info] Number of positive: 5687, number of negative: 17756
2024-01-04 15:08:36,222:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001490 seconds.
2024-01-04 15:08:36,222:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:36,222:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:36,222:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:36,222:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:36,223:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242588 -> initscore=-1.138541
2024-01-04 15:08:36,223:INFO:[LightGBM] [Info] Start training from score -1.138541
2024-01-04 15:08:36,482:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:36,482:INFO:[LightGBM] [Info] Number of positive: 5651, number of negative: 17792
2024-01-04 15:08:36,485:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001242 seconds.
2024-01-04 15:08:36,485:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:36,486:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:36,486:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:36,486:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:36,486:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241053 -> initscore=-1.146916
2024-01-04 15:08:36,486:INFO:[LightGBM] [Info] Start training from score -1.146916
2024-01-04 15:08:36,758:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:36,758:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:36,761:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001287 seconds.
2024-01-04 15:08:36,761:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:36,762:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:36,762:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:36,762:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:36,762:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:36,762:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:37,019:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:37,019:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:37,023:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.
2024-01-04 15:08:37,023:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:37,023:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:37,023:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:37,023:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:37,024:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:37,024:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:37,292:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:37,293:INFO:[LightGBM] [Info] Number of positive: 5628, number of negative: 17815
2024-01-04 15:08:37,296:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001466 seconds.
2024-01-04 15:08:37,296:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:37,296:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:37,297:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:37,297:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:37,297:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240072 -> initscore=-1.152287
2024-01-04 15:08:37,297:INFO:[LightGBM] [Info] Start training from score -1.152287
2024-01-04 15:08:37,561:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:37,562:INFO:[LightGBM] [Info] Number of positive: 5678, number of negative: 17765
2024-01-04 15:08:37,565:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001211 seconds.
2024-01-04 15:08:37,565:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:37,565:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:37,565:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:37,565:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:37,566:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242204 -> initscore=-1.140631
2024-01-04 15:08:37,566:INFO:[LightGBM] [Info] Start training from score -1.140631
2024-01-04 15:08:37,830:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:37,830:INFO:[LightGBM] [Info] Number of positive: 5646, number of negative: 17797
2024-01-04 15:08:37,833:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001457 seconds.
2024-01-04 15:08:37,834:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:37,834:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:37,834:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:37,834:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:37,835:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240839 -> initscore=-1.148083
2024-01-04 15:08:37,835:INFO:[LightGBM] [Info] Start training from score -1.148083
2024-01-04 15:08:38,102:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:38,103:INFO:[LightGBM] [Info] Number of positive: 5657, number of negative: 17786
2024-01-04 15:08:38,107:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001543 seconds.
2024-01-04 15:08:38,107:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:38,107:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:38,107:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:08:38,107:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:38,108:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241309 -> initscore=-1.145518
2024-01-04 15:08:38,108:INFO:[LightGBM] [Info] Start training from score -1.145518
2024-01-04 15:08:38,363:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:38,364:INFO:[LightGBM] [Info] Number of positive: 5640, number of negative: 17803
2024-01-04 15:08:38,367:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001136 seconds.
2024-01-04 15:08:38,367:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:38,367:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:38,367:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 15:08:38,367:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:38,368:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240584 -> initscore=-1.149483
2024-01-04 15:08:38,368:INFO:[LightGBM] [Info] Start training from score -1.149483
2024-01-04 15:08:38,626:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:38,627:INFO:[LightGBM] [Info] Number of positive: 5611, number of negative: 17832
2024-01-04 15:08:38,631:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001467 seconds.
2024-01-04 15:08:38,631:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:38,631:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:38,631:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:38,631:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:38,632:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239347 -> initscore=-1.156266
2024-01-04 15:08:38,632:INFO:[LightGBM] [Info] Start training from score -1.156266
2024-01-04 15:08:38,905:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:38,905:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:38,909:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001485 seconds.
2024-01-04 15:08:38,909:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:38,909:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:38,909:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:38,910:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:38,910:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:38,910:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:39,160:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:39,161:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:08:39,164:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001495 seconds.
2024-01-04 15:08:39,164:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:39,164:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:39,165:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:39,165:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:39,165:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:08:39,165:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:08:39,418:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:39,419:INFO:[LightGBM] [Info] Number of positive: 5638, number of negative: 17805
2024-01-04 15:08:39,422:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001200 seconds.
2024-01-04 15:08:39,422:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:39,422:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:39,422:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:39,422:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:39,423:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240498 -> initscore=-1.149950
2024-01-04 15:08:39,423:INFO:[LightGBM] [Info] Start training from score -1.149950
2024-01-04 15:08:39,684:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:39,685:INFO:[LightGBM] [Info] Number of positive: 5645, number of negative: 17798
2024-01-04 15:08:39,688:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001620 seconds.
2024-01-04 15:08:39,688:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:39,688:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:39,689:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:39,689:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:39,689:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240797 -> initscore=-1.148316
2024-01-04 15:08:39,689:INFO:[LightGBM] [Info] Start training from score -1.148316
2024-01-04 15:08:39,937:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:39,938:INFO:[LightGBM] [Info] Number of positive: 5648, number of negative: 17795
2024-01-04 15:08:39,941:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001512 seconds.
2024-01-04 15:08:39,941:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:39,941:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:39,942:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:39,942:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:39,942:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240925 -> initscore=-1.147616
2024-01-04 15:08:39,942:INFO:[LightGBM] [Info] Start training from score -1.147616
2024-01-04 15:08:40,186:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:40,187:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:08:40,190:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001447 seconds.
2024-01-04 15:08:40,190:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:40,190:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:40,191:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:40,191:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:40,191:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:08:40,191:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:08:40,432:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:40,433:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:40,436:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001600 seconds.
2024-01-04 15:08:40,436:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:40,436:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:40,436:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:08:40,437:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:40,437:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:40,437:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:41,670:INFO:Scoring test/hold-out set
2024-01-04 15:08:42,025:INFO:Visual Rendered Successfully
2024-01-04 15:08:42,238:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:42,357:INFO:Initializing plot_model()
2024-01-04 15:08:42,357:INFO:plot_model(plot=lift, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:42,358:INFO:Checking exceptions
2024-01-04 15:08:42,377:INFO:Preloading libraries
2024-01-04 15:08:42,384:INFO:Copying training dataset
2024-01-04 15:08:42,384:INFO:Plot type: lift
2024-01-04 15:08:42,384:INFO:Generating predictions / predict_proba on X_test
2024-01-04 15:08:42,881:INFO:Visual Rendered Successfully
2024-01-04 15:08:43,083:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:45,304:INFO:Initializing plot_model()
2024-01-04 15:08:45,304:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:45,304:INFO:Checking exceptions
2024-01-04 15:08:45,319:INFO:Preloading libraries
2024-01-04 15:08:45,325:INFO:Copying training dataset
2024-01-04 15:08:45,326:INFO:Plot type: auc
2024-01-04 15:08:45,826:INFO:Fitting Model
2024-01-04 15:08:45,827:INFO:Scoring test/hold-out set
2024-01-04 15:08:46,142:INFO:Visual Rendered Successfully
2024-01-04 15:08:46,394:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:49,319:INFO:Initializing plot_model()
2024-01-04 15:08:49,319:INFO:plot_model(plot=confusion_matrix, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:49,319:INFO:Checking exceptions
2024-01-04 15:08:49,332:INFO:Preloading libraries
2024-01-04 15:08:49,338:INFO:Copying training dataset
2024-01-04 15:08:49,338:INFO:Plot type: confusion_matrix
2024-01-04 15:08:49,639:INFO:Fitting Model
2024-01-04 15:08:49,639:INFO:Scoring test/hold-out set
2024-01-04 15:08:49,819:INFO:Visual Rendered Successfully
2024-01-04 15:08:50,003:INFO:plot_model() successfully completed......................................
2024-01-04 15:08:51,287:INFO:Initializing plot_model()
2024-01-04 15:08:51,287:INFO:plot_model(plot=threshold, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:08:51,287:INFO:Checking exceptions
2024-01-04 15:08:51,301:INFO:Preloading libraries
2024-01-04 15:08:51,306:INFO:Copying training dataset
2024-01-04 15:08:51,306:INFO:Plot type: threshold
2024-01-04 15:08:51,616:INFO:Fitting Model
2024-01-04 15:08:51,653:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:51,653:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:08:51,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.
2024-01-04 15:08:51,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:51,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:51,656:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:51,656:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:51,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:08:51,657:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:08:51,844:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:51,845:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:08:51,847:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.
2024-01-04 15:08:51,847:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:51,847:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:51,848:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:51,848:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:51,848:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:08:51,848:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:08:52,052:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:52,052:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:52,055:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000934 seconds.
2024-01-04 15:08:52,055:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:52,055:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:52,055:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:08:52,055:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:52,056:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:52,056:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:52,251:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:52,251:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:08:52,254:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001040 seconds.
2024-01-04 15:08:52,254:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:52,254:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:52,254:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:52,255:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:52,255:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:08:52,255:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:08:52,450:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:52,451:INFO:[LightGBM] [Info] Number of positive: 5684, number of negative: 17759
2024-01-04 15:08:52,453:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000912 seconds.
2024-01-04 15:08:52,453:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:52,453:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:52,453:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:52,453:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:52,453:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242460 -> initscore=-1.139237
2024-01-04 15:08:52,454:INFO:[LightGBM] [Info] Start training from score -1.139237
2024-01-04 15:08:52,652:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:52,652:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:08:52,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000990 seconds.
2024-01-04 15:08:52,655:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:52,655:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:52,655:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:52,656:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:52,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:08:52,656:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:08:52,854:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:52,854:INFO:[LightGBM] [Info] Number of positive: 5653, number of negative: 17790
2024-01-04 15:08:52,857:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000960 seconds.
2024-01-04 15:08:52,857:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:52,857:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:52,857:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:08:52,857:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:52,858:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241138 -> initscore=-1.146450
2024-01-04 15:08:52,858:INFO:[LightGBM] [Info] Start training from score -1.146450
2024-01-04 15:08:53,056:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:53,056:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:08:53,059:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001367 seconds.
2024-01-04 15:08:53,059:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:53,060:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:53,060:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:53,060:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:53,060:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:08:53,061:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:08:53,255:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:53,255:INFO:[LightGBM] [Info] Number of positive: 5595, number of negative: 17848
2024-01-04 15:08:53,257:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000972 seconds.
2024-01-04 15:08:53,258:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:53,258:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:53,258:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:53,258:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:53,258:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.238664 -> initscore=-1.160018
2024-01-04 15:08:53,258:INFO:[LightGBM] [Info] Start training from score -1.160018
2024-01-04 15:08:53,462:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:53,463:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:08:53,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001682 seconds.
2024-01-04 15:08:53,467:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:53,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:53,467:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:53,468:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:53,468:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:08:53,468:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:08:53,692:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:53,693:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:53,695:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000913 seconds.
2024-01-04 15:08:53,695:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:53,695:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:53,696:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:53,696:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:53,696:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:53,696:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:53,972:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:53,973:INFO:[LightGBM] [Info] Number of positive: 5629, number of negative: 17814
2024-01-04 15:08:53,975:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001088 seconds.
2024-01-04 15:08:53,975:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:53,975:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:53,976:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:53,976:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:53,976:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240114 -> initscore=-1.152053
2024-01-04 15:08:53,976:INFO:[LightGBM] [Info] Start training from score -1.152053
2024-01-04 15:08:54,181:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:54,182:INFO:[LightGBM] [Info] Number of positive: 5627, number of negative: 17816
2024-01-04 15:08:54,184:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000993 seconds.
2024-01-04 15:08:54,184:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:54,184:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:54,184:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:54,184:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:54,185:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240029 -> initscore=-1.152520
2024-01-04 15:08:54,185:INFO:[LightGBM] [Info] Start training from score -1.152520
2024-01-04 15:08:54,462:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:54,463:INFO:[LightGBM] [Info] Number of positive: 5631, number of negative: 17812
2024-01-04 15:08:54,466:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001479 seconds.
2024-01-04 15:08:54,466:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:54,467:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:54,467:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:54,467:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:54,467:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240200 -> initscore=-1.151585
2024-01-04 15:08:54,467:INFO:[LightGBM] [Info] Start training from score -1.151585
2024-01-04 15:08:54,676:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:54,676:INFO:[LightGBM] [Info] Number of positive: 5668, number of negative: 17775
2024-01-04 15:08:54,679:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000983 seconds.
2024-01-04 15:08:54,679:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:54,679:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:54,679:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:54,679:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:54,679:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241778 -> initscore=-1.142957
2024-01-04 15:08:54,680:INFO:[LightGBM] [Info] Start training from score -1.142957
2024-01-04 15:08:54,880:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:54,880:INFO:[LightGBM] [Info] Number of positive: 5663, number of negative: 17780
2024-01-04 15:08:54,883:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001422 seconds.
2024-01-04 15:08:54,883:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:54,884:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:54,884:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:54,884:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:54,884:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241565 -> initscore=-1.144120
2024-01-04 15:08:54,884:INFO:[LightGBM] [Info] Start training from score -1.144120
2024-01-04 15:08:55,117:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:55,118:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:08:55,121:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000975 seconds.
2024-01-04 15:08:55,121:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:55,121:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:55,121:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:55,121:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:55,122:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:08:55,122:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:08:55,322:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:55,323:INFO:[LightGBM] [Info] Number of positive: 5662, number of negative: 17781
2024-01-04 15:08:55,326:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001738 seconds.
2024-01-04 15:08:55,326:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:55,326:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:55,327:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:55,327:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:55,327:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241522 -> initscore=-1.144353
2024-01-04 15:08:55,327:INFO:[LightGBM] [Info] Start training from score -1.144353
2024-01-04 15:08:55,540:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:55,541:INFO:[LightGBM] [Info] Number of positive: 5669, number of negative: 17774
2024-01-04 15:08:55,543:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000942 seconds.
2024-01-04 15:08:55,543:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:55,543:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:55,543:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:55,543:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:55,544:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241821 -> initscore=-1.142724
2024-01-04 15:08:55,544:INFO:[LightGBM] [Info] Start training from score -1.142724
2024-01-04 15:08:55,771:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:55,772:INFO:[LightGBM] [Info] Number of positive: 5634, number of negative: 17809
2024-01-04 15:08:55,775:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001494 seconds.
2024-01-04 15:08:55,775:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:55,775:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:55,775:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:55,775:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:55,775:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240328 -> initscore=-1.150884
2024-01-04 15:08:55,776:INFO:[LightGBM] [Info] Start training from score -1.150884
2024-01-04 15:08:56,012:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:56,013:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:08:56,017:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001579 seconds.
2024-01-04 15:08:56,017:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:56,017:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:56,017:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:56,017:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:56,018:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:08:56,018:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:08:56,243:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:56,243:INFO:[LightGBM] [Info] Number of positive: 5613, number of negative: 17830
2024-01-04 15:08:56,246:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001028 seconds.
2024-01-04 15:08:56,246:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:56,246:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:56,246:INFO:[LightGBM] [Info] Total Bins 442
2024-01-04 15:08:56,246:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:56,247:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239432 -> initscore=-1.155797
2024-01-04 15:08:56,247:INFO:[LightGBM] [Info] Start training from score -1.155797
2024-01-04 15:08:56,461:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:56,463:INFO:[LightGBM] [Info] Number of positive: 5636, number of negative: 17807
2024-01-04 15:08:56,465:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001035 seconds.
2024-01-04 15:08:56,465:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:56,465:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:56,466:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:08:56,466:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:56,466:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240413 -> initscore=-1.150417
2024-01-04 15:08:56,466:INFO:[LightGBM] [Info] Start training from score -1.150417
2024-01-04 15:08:56,671:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:56,672:INFO:[LightGBM] [Info] Number of positive: 5619, number of negative: 17824
2024-01-04 15:08:56,676:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001817 seconds.
2024-01-04 15:08:56,676:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:56,676:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:56,677:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:56,677:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:56,677:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239688 -> initscore=-1.154392
2024-01-04 15:08:56,677:INFO:[LightGBM] [Info] Start training from score -1.154392
2024-01-04 15:08:56,915:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:56,916:INFO:[LightGBM] [Info] Number of positive: 5644, number of negative: 17799
2024-01-04 15:08:56,920:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001695 seconds.
2024-01-04 15:08:56,920:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:56,920:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:56,920:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:56,920:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:56,922:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240754 -> initscore=-1.148549
2024-01-04 15:08:56,922:INFO:[LightGBM] [Info] Start training from score -1.148549
2024-01-04 15:08:57,193:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:57,194:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:08:57,196:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001014 seconds.
2024-01-04 15:08:57,197:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:57,197:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:57,197:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:57,197:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:57,197:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:08:57,198:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:08:57,447:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:57,448:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:57,451:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001353 seconds.
2024-01-04 15:08:57,451:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:57,451:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:57,451:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:57,452:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:57,452:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:57,452:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:57,653:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:57,653:INFO:[LightGBM] [Info] Number of positive: 5660, number of negative: 17783
2024-01-04 15:08:57,656:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000972 seconds.
2024-01-04 15:08:57,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:57,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:57,656:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:57,656:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:57,657:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241437 -> initscore=-1.144819
2024-01-04 15:08:57,657:INFO:[LightGBM] [Info] Start training from score -1.144819
2024-01-04 15:08:57,890:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:57,890:INFO:[LightGBM] [Info] Number of positive: 5641, number of negative: 17802
2024-01-04 15:08:57,895:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001950 seconds.
2024-01-04 15:08:57,895:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:57,895:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:57,895:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:08:57,896:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:57,896:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240626 -> initscore=-1.149249
2024-01-04 15:08:57,896:INFO:[LightGBM] [Info] Start training from score -1.149249
2024-01-04 15:08:58,130:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:58,130:INFO:[LightGBM] [Info] Number of positive: 5654, number of negative: 17789
2024-01-04 15:08:58,135:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001725 seconds.
2024-01-04 15:08:58,135:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:58,135:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:58,135:INFO:[LightGBM] [Info] Total Bins 432
2024-01-04 15:08:58,135:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:58,136:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241181 -> initscore=-1.146217
2024-01-04 15:08:58,136:INFO:[LightGBM] [Info] Start training from score -1.146217
2024-01-04 15:08:58,383:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:58,384:INFO:[LightGBM] [Info] Number of positive: 5670, number of negative: 17773
2024-01-04 15:08:58,388:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001893 seconds.
2024-01-04 15:08:58,388:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:58,388:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:58,388:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:58,389:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:58,389:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241863 -> initscore=-1.142491
2024-01-04 15:08:58,389:INFO:[LightGBM] [Info] Start training from score -1.142491
2024-01-04 15:08:58,632:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:58,633:INFO:[LightGBM] [Info] Number of positive: 5609, number of negative: 17834
2024-01-04 15:08:58,636:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001530 seconds.
2024-01-04 15:08:58,636:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:58,636:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:58,636:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:58,636:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:58,637:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239261 -> initscore=-1.156734
2024-01-04 15:08:58,637:INFO:[LightGBM] [Info] Start training from score -1.156734
2024-01-04 15:08:58,849:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:58,850:INFO:[LightGBM] [Info] Number of positive: 5649, number of negative: 17794
2024-01-04 15:08:58,854:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001202 seconds.
2024-01-04 15:08:58,854:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:58,854:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:58,854:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:58,854:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:58,854:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240967 -> initscore=-1.147383
2024-01-04 15:08:58,854:INFO:[LightGBM] [Info] Start training from score -1.147383
2024-01-04 15:08:59,069:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:59,069:INFO:[LightGBM] [Info] Number of positive: 5687, number of negative: 17756
2024-01-04 15:08:59,072:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001129 seconds.
2024-01-04 15:08:59,072:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:59,072:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:59,072:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:08:59,072:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:59,072:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242588 -> initscore=-1.138541
2024-01-04 15:08:59,073:INFO:[LightGBM] [Info] Start training from score -1.138541
2024-01-04 15:08:59,283:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:59,283:INFO:[LightGBM] [Info] Number of positive: 5651, number of negative: 17792
2024-01-04 15:08:59,286:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001076 seconds.
2024-01-04 15:08:59,286:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:59,286:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:59,286:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:08:59,286:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:59,287:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241053 -> initscore=-1.146916
2024-01-04 15:08:59,287:INFO:[LightGBM] [Info] Start training from score -1.146916
2024-01-04 15:08:59,493:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:59,493:INFO:[LightGBM] [Info] Number of positive: 5650, number of negative: 17793
2024-01-04 15:08:59,496:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001197 seconds.
2024-01-04 15:08:59,496:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:59,496:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:59,497:INFO:[LightGBM] [Info] Total Bins 436
2024-01-04 15:08:59,497:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:08:59,497:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241010 -> initscore=-1.147150
2024-01-04 15:08:59,497:INFO:[LightGBM] [Info] Start training from score -1.147150
2024-01-04 15:08:59,705:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:59,706:INFO:[LightGBM] [Info] Number of positive: 5630, number of negative: 17813
2024-01-04 15:08:59,709:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001003 seconds.
2024-01-04 15:08:59,709:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:59,709:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:59,709:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:08:59,709:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:59,709:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240157 -> initscore=-1.151819
2024-01-04 15:08:59,710:INFO:[LightGBM] [Info] Start training from score -1.151819
2024-01-04 15:08:59,926:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:08:59,926:INFO:[LightGBM] [Info] Number of positive: 5628, number of negative: 17815
2024-01-04 15:08:59,931:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001894 seconds.
2024-01-04 15:08:59,931:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:08:59,931:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:08:59,931:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:08:59,931:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:08:59,932:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240072 -> initscore=-1.152287
2024-01-04 15:08:59,932:INFO:[LightGBM] [Info] Start training from score -1.152287
2024-01-04 15:09:00,196:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:00,197:INFO:[LightGBM] [Info] Number of positive: 5678, number of negative: 17765
2024-01-04 15:09:00,202:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002873 seconds.
2024-01-04 15:09:00,203:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:00,203:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:00,203:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:09:00,203:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:09:00,203:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.242204 -> initscore=-1.140631
2024-01-04 15:09:00,204:INFO:[LightGBM] [Info] Start training from score -1.140631
2024-01-04 15:09:00,457:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:00,458:INFO:[LightGBM] [Info] Number of positive: 5646, number of negative: 17797
2024-01-04 15:09:00,460:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001238 seconds.
2024-01-04 15:09:00,460:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:00,460:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:00,461:INFO:[LightGBM] [Info] Total Bins 441
2024-01-04 15:09:00,461:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:09:00,461:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240839 -> initscore=-1.148083
2024-01-04 15:09:00,461:INFO:[LightGBM] [Info] Start training from score -1.148083
2024-01-04 15:09:00,695:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:00,696:INFO:[LightGBM] [Info] Number of positive: 5657, number of negative: 17786
2024-01-04 15:09:00,699:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001307 seconds.
2024-01-04 15:09:00,699:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:00,699:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:00,700:INFO:[LightGBM] [Info] Total Bins 434
2024-01-04 15:09:00,700:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:00,700:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241309 -> initscore=-1.145518
2024-01-04 15:09:00,700:INFO:[LightGBM] [Info] Start training from score -1.145518
2024-01-04 15:09:00,961:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:00,962:INFO:[LightGBM] [Info] Number of positive: 5640, number of negative: 17803
2024-01-04 15:09:00,965:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001601 seconds.
2024-01-04 15:09:00,965:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:00,965:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:00,965:INFO:[LightGBM] [Info] Total Bins 444
2024-01-04 15:09:00,965:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:09:00,966:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240584 -> initscore=-1.149483
2024-01-04 15:09:00,966:INFO:[LightGBM] [Info] Start training from score -1.149483
2024-01-04 15:09:01,220:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:01,220:INFO:[LightGBM] [Info] Number of positive: 5611, number of negative: 17832
2024-01-04 15:09:01,223:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001039 seconds.
2024-01-04 15:09:01,223:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:01,223:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:01,223:INFO:[LightGBM] [Info] Total Bins 440
2024-01-04 15:09:01,223:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:09:01,224:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239347 -> initscore=-1.156266
2024-01-04 15:09:01,224:INFO:[LightGBM] [Info] Start training from score -1.156266
2024-01-04 15:09:01,435:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:01,436:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:09:01,439:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001059 seconds.
2024-01-04 15:09:01,439:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:01,439:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:01,439:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:09:01,439:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:01,440:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:09:01,440:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:09:01,651:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:01,651:INFO:[LightGBM] [Info] Number of positive: 5652, number of negative: 17791
2024-01-04 15:09:01,655:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001708 seconds.
2024-01-04 15:09:01,656:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:01,656:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:01,656:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:09:01,656:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:01,656:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.241095 -> initscore=-1.146683
2024-01-04 15:09:01,657:INFO:[LightGBM] [Info] Start training from score -1.146683
2024-01-04 15:09:01,914:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:01,915:INFO:[LightGBM] [Info] Number of positive: 5638, number of negative: 17805
2024-01-04 15:09:01,918:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001574 seconds.
2024-01-04 15:09:01,918:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:01,918:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:01,918:INFO:[LightGBM] [Info] Total Bins 439
2024-01-04 15:09:01,919:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:01,919:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240498 -> initscore=-1.149950
2024-01-04 15:09:01,919:INFO:[LightGBM] [Info] Start training from score -1.149950
2024-01-04 15:09:02,226:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:02,227:INFO:[LightGBM] [Info] Number of positive: 5645, number of negative: 17798
2024-01-04 15:09:02,231:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001963 seconds.
2024-01-04 15:09:02,231:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:02,231:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:02,232:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:09:02,232:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:02,232:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240797 -> initscore=-1.148316
2024-01-04 15:09:02,233:INFO:[LightGBM] [Info] Start training from score -1.148316
2024-01-04 15:09:02,576:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:02,576:INFO:[LightGBM] [Info] Number of positive: 5648, number of negative: 17795
2024-01-04 15:09:02,580:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001655 seconds.
2024-01-04 15:09:02,580:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:02,580:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:02,581:INFO:[LightGBM] [Info] Total Bins 437
2024-01-04 15:09:02,581:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:02,581:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240925 -> initscore=-1.147616
2024-01-04 15:09:02,581:INFO:[LightGBM] [Info] Start training from score -1.147616
2024-01-04 15:09:02,875:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:02,875:INFO:[LightGBM] [Info] Number of positive: 5615, number of negative: 17828
2024-01-04 15:09:02,879:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001804 seconds.
2024-01-04 15:09:02,879:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:02,880:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:02,880:INFO:[LightGBM] [Info] Total Bins 438
2024-01-04 15:09:02,880:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 60
2024-01-04 15:09:02,880:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.239517 -> initscore=-1.155329
2024-01-04 15:09:02,881:INFO:[LightGBM] [Info] Start training from score -1.155329
2024-01-04 15:09:03,275:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:09:03,276:INFO:[LightGBM] [Info] Number of positive: 5637, number of negative: 17806
2024-01-04 15:09:03,279:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001568 seconds.
2024-01-04 15:09:03,279:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:09:03,279:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:09:03,280:INFO:[LightGBM] [Info] Total Bins 435
2024-01-04 15:09:03,280:INFO:[LightGBM] [Info] Number of data points in the train set: 23443, number of used features: 61
2024-01-04 15:09:03,280:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240456 -> initscore=-1.150183
2024-01-04 15:09:03,280:INFO:[LightGBM] [Info] Start training from score -1.150183
2024-01-04 15:09:04,498:INFO:Scoring test/hold-out set
2024-01-04 15:09:04,825:INFO:Visual Rendered Successfully
2024-01-04 15:09:05,017:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:05,033:INFO:Initializing evaluate_model()
2024-01-04 15:09:05,033:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-01-04 15:09:05,069:INFO:Initializing plot_model()
2024-01-04 15:09:05,069:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:05,069:INFO:Checking exceptions
2024-01-04 15:09:05,084:INFO:Preloading libraries
2024-01-04 15:09:05,090:INFO:Copying training dataset
2024-01-04 15:09:05,090:INFO:Plot type: pipeline
2024-01-04 15:09:05,358:INFO:Visual Rendered Successfully
2024-01-04 15:09:05,549:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:05,563:INFO:Initializing plot_model()
2024-01-04 15:09:05,563:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:05,563:INFO:Checking exceptions
2024-01-04 15:09:05,579:INFO:Preloading libraries
2024-01-04 15:09:05,585:INFO:Copying training dataset
2024-01-04 15:09:05,585:INFO:Plot type: pr
2024-01-04 15:09:05,946:INFO:Fitting Model
2024-01-04 15:09:05,947:INFO:Scoring test/hold-out set
2024-01-04 15:09:06,275:INFO:Visual Rendered Successfully
2024-01-04 15:09:06,463:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:08,127:INFO:Initializing plot_model()
2024-01-04 15:09:08,128:INFO:plot_model(plot=parameter, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:08,128:INFO:Checking exceptions
2024-01-04 15:09:08,141:INFO:Preloading libraries
2024-01-04 15:09:08,146:INFO:Copying training dataset
2024-01-04 15:09:08,146:INFO:Plot type: parameter
2024-01-04 15:09:08,151:INFO:Visual Rendered Successfully
2024-01-04 15:09:08,357:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:12,549:INFO:Initializing plot_model()
2024-01-04 15:09:12,549:INFO:plot_model(plot=tree, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:12,549:INFO:Checking exceptions
2024-01-04 15:09:17,964:INFO:Initializing plot_model()
2024-01-04 15:09:17,965:INFO:plot_model(plot=feature_all, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:17,965:INFO:Checking exceptions
2024-01-04 15:09:17,980:INFO:Preloading libraries
2024-01-04 15:09:17,985:INFO:Copying training dataset
2024-01-04 15:09:17,985:INFO:Plot type: feature_all
2024-01-04 15:09:18,114:WARNING:No coef_ found. Trying feature_importances_
2024-01-04 15:09:18,882:INFO:Visual Rendered Successfully
2024-01-04 15:09:19,072:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:44,039:INFO:Initializing plot_model()
2024-01-04 15:09:44,040:INFO:plot_model(plot=calibration, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:44,040:INFO:Checking exceptions
2024-01-04 15:09:44,054:INFO:Preloading libraries
2024-01-04 15:09:44,059:INFO:Copying training dataset
2024-01-04 15:09:44,059:INFO:Plot type: calibration
2024-01-04 15:09:44,078:INFO:Scoring test/hold-out set
2024-01-04 15:09:44,438:INFO:Visual Rendered Successfully
2024-01-04 15:09:44,623:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:55,461:INFO:Initializing plot_model()
2024-01-04 15:09:55,461:INFO:plot_model(plot=dimension, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:55,461:INFO:Checking exceptions
2024-01-04 15:09:55,473:INFO:Preloading libraries
2024-01-04 15:09:55,479:INFO:Copying training dataset
2024-01-04 15:09:55,479:INFO:Plot type: dimension
2024-01-04 15:09:55,645:INFO:Fitting StandardScaler()
2024-01-04 15:09:55,768:INFO:Fitting PCA()
2024-01-04 15:09:56,138:INFO:Fitting & Transforming Model
2024-01-04 15:09:56,915:INFO:Visual Rendered Successfully
2024-01-04 15:09:57,147:INFO:plot_model() successfully completed......................................
2024-01-04 15:09:59,197:INFO:Initializing plot_model()
2024-01-04 15:09:59,197:INFO:plot_model(plot=pr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:09:59,197:INFO:Checking exceptions
2024-01-04 15:09:59,209:INFO:Preloading libraries
2024-01-04 15:09:59,214:INFO:Copying training dataset
2024-01-04 15:09:59,214:INFO:Plot type: pr
2024-01-04 15:09:59,526:INFO:Fitting Model
2024-01-04 15:09:59,527:INFO:Scoring test/hold-out set
2024-01-04 15:09:59,803:INFO:Visual Rendered Successfully
2024-01-04 15:09:59,992:INFO:plot_model() successfully completed......................................
2024-01-04 15:10:05,901:INFO:Initializing plot_model()
2024-01-04 15:10:05,901:INFO:plot_model(plot=auc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:10:05,901:INFO:Checking exceptions
2024-01-04 15:10:05,913:INFO:Preloading libraries
2024-01-04 15:10:05,920:INFO:Copying training dataset
2024-01-04 15:10:05,920:INFO:Plot type: auc
2024-01-04 15:10:06,232:INFO:Fitting Model
2024-01-04 15:10:06,232:INFO:Scoring test/hold-out set
2024-01-04 15:10:06,520:INFO:Visual Rendered Successfully
2024-01-04 15:10:06,713:INFO:plot_model() successfully completed......................................
2024-01-04 15:10:21,856:INFO:Initializing plot_model()
2024-01-04 15:10:21,856:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:10:21,857:INFO:Checking exceptions
2024-01-04 15:10:21,873:INFO:Preloading libraries
2024-01-04 15:10:21,879:INFO:Copying training dataset
2024-01-04 15:10:21,879:INFO:Plot type: auc
2024-01-04 15:10:22,208:INFO:Fitting Model
2024-01-04 15:10:22,209:INFO:Scoring test/hold-out set
2024-01-04 15:10:22,492:INFO:Visual Rendered Successfully
2024-01-04 15:10:22,723:INFO:plot_model() successfully completed......................................
2024-01-04 15:10:33,292:INFO:Initializing finalize_model()
2024-01-04 15:10:33,292:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-01-04 15:10:33,293:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-01-04 15:10:33,307:INFO:Initializing create_model()
2024-01-04 15:10:33,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2024-01-04 15:10:33,307:INFO:Checking exceptions
2024-01-04 15:10:33,309:INFO:Importing libraries
2024-01-04 15:10:33,309:INFO:Copying training dataset
2024-01-04 15:10:33,310:INFO:Defining folds
2024-01-04 15:10:33,310:INFO:Declaring metric variables
2024-01-04 15:10:33,310:INFO:Importing untrained model
2024-01-04 15:10:33,310:INFO:Declaring custom model
2024-01-04 15:10:33,310:INFO:Light Gradient Boosting Machine Imported successfully
2024-01-04 15:10:33,311:INFO:Cross validation set to False
2024-01-04 15:10:33,311:INFO:Fitting Model
2024-01-04 15:10:33,444:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-01-04 15:10:33,445:INFO:[LightGBM] [Info] Number of positive: 7841, number of negative: 24720
2024-01-04 15:10:33,448:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001122 seconds.
2024-01-04 15:10:33,448:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-01-04 15:10:33,448:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-01-04 15:10:33,448:INFO:[LightGBM] [Info] Total Bins 464
2024-01-04 15:10:33,448:INFO:[LightGBM] [Info] Number of data points in the train set: 32561, number of used features: 64
2024-01-04 15:10:33,449:INFO:[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.240810 -> initscore=-1.148246
2024-01-04 15:10:33,449:INFO:[LightGBM] [Info] Start training from score -1.148246
2024-01-04 15:10:33,566:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-04 15:10:33,567:INFO:create_model() successfully completed......................................
2024-01-04 15:10:33,780:INFO:_master_model_container: 33
2024-01-04 15:10:33,780:INFO:_display_container: 7
2024-01-04 15:10:33,786:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2024-01-04 15:10:33,786:INFO:finalize_model() successfully completed......................................
2024-01-04 15:10:37,131:INFO:Initializing plot_model()
2024-01-04 15:10:37,131:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:10:37,132:INFO:Checking exceptions
2024-01-04 15:10:37,147:INFO:Preloading libraries
2024-01-04 15:10:37,153:INFO:Copying training dataset
2024-01-04 15:10:37,153:INFO:Plot type: auc
2024-01-04 15:10:37,521:INFO:Fitting Model
2024-01-04 15:10:37,521:INFO:Scoring test/hold-out set
2024-01-04 15:10:37,812:INFO:Visual Rendered Successfully
2024-01-04 15:10:38,040:INFO:plot_model() successfully completed......................................
2024-01-04 15:10:44,736:INFO:Initializing plot_model()
2024-01-04 15:10:44,737:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 15:10:44,737:INFO:Checking exceptions
2024-01-04 15:10:44,756:INFO:Preloading libraries
2024-01-04 15:10:44,762:INFO:Copying training dataset
2024-01-04 15:10:44,762:INFO:Plot type: auc
2024-01-04 15:10:45,083:INFO:Fitting Model
2024-01-04 15:10:45,083:INFO:Scoring test/hold-out set
2024-01-04 15:10:45,369:INFO:Visual Rendered Successfully
2024-01-04 15:10:45,586:INFO:plot_model() successfully completed......................................
2024-01-04 15:11:17,268:INFO:Initializing predict_model()
2024-01-04 15:11:17,269:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D11428E3B0>)
2024-01-04 15:11:17,269:INFO:Checking exceptions
2024-01-04 15:11:17,269:INFO:Preloading libraries
2024-01-04 15:11:17,271:INFO:Set up data.
2024-01-04 15:11:17,311:INFO:Set up index.
2024-01-04 18:40:55,755:INFO:Initializing plot_model()
2024-01-04 18:40:55,756:INFO:plot_model(plot=auc, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 18:40:55,757:INFO:Checking exceptions
2024-01-04 18:40:55,847:INFO:Preloading libraries
2024-01-04 18:40:55,855:INFO:Copying training dataset
2024-01-04 18:40:55,856:INFO:Plot type: auc
2024-01-04 18:40:56,240:INFO:Fitting Model
2024-01-04 18:40:56,241:INFO:Scoring test/hold-out set
2024-01-04 18:40:56,560:INFO:Visual Rendered Successfully
2024-01-04 18:40:57,260:INFO:plot_model() successfully completed......................................
2024-01-04 18:41:06,243:INFO:Initializing plot_model()
2024-01-04 18:41:06,244:INFO:plot_model(plot=confusion_matrix, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 18:41:06,244:INFO:Checking exceptions
2024-01-04 18:41:06,260:INFO:Preloading libraries
2024-01-04 18:41:06,266:INFO:Copying training dataset
2024-01-04 18:41:06,266:INFO:Plot type: confusion_matrix
2024-01-04 18:41:06,508:INFO:Fitting Model
2024-01-04 18:41:06,509:INFO:Scoring test/hold-out set
2024-01-04 18:41:06,729:INFO:Visual Rendered Successfully
2024-01-04 18:41:06,962:INFO:plot_model() successfully completed......................................
2024-01-04 18:41:23,345:INFO:Initializing plot_model()
2024-01-04 18:41:23,345:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=None, feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 18:41:23,346:INFO:Checking exceptions
2024-01-04 18:41:37,870:INFO:Initializing plot_model()
2024-01-04 18:41:37,871:INFO:plot_model(plot=class_report, fold=None, verbose=True, display=None, display_format=None, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, system=True)
2024-01-04 18:41:37,871:INFO:Checking exceptions
2024-01-04 18:41:37,900:INFO:Preloading libraries
2024-01-04 18:41:37,919:INFO:Copying training dataset
2024-01-04 18:41:37,919:INFO:Plot type: class_report
2024-01-04 18:41:38,133:INFO:Fitting Model
2024-01-04 18:41:38,133:INFO:Scoring test/hold-out set
2024-01-04 18:41:38,420:INFO:Visual Rendered Successfully
2024-01-04 18:41:38,627:INFO:plot_model() successfully completed......................................
2024-01-04 18:46:36,545:INFO:Initializing predict_model()
2024-01-04 18:46:36,545:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D10092BB50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'Education-num',
                                             'capital-gain', 'capital-loss',
                                             'hours-per-week',
                                             'Profession Class_Local-gov',
                                             'Profession Class_Never-worked',
                                             'Profession Class_Private',
                                             'Profession Class_Self-emp-inc',
                                             'Profession '
                                             'Class_Self-emp-not-inc',
                                             'Profession Class_Stat...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D115F50820>)
2024-01-04 18:46:36,545:INFO:Checking exceptions
2024-01-04 18:46:36,546:INFO:Preloading libraries
2024-01-04 18:46:36,548:INFO:Set up data.
2024-01-04 18:46:36,584:INFO:Set up index.
